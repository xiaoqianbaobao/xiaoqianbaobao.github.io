[{"content":"这篇文章主要记录我搭建hugo博客的过程，包括搭建过程中遇到的问题及解决方法\n1、新建github仓库 新建respository, Respository的名称为 \u0026ldquo;你的github名称.github.io\u0026rdquo;.\n2、下载并安装对应版本的hugo 下载链接: 点击选择hugo版本下载\n3、创建hugo网站 进入想要存放网站的文件夹，输入以下命令:\n1 hugo new site demo-blog 4、选择主题 输入命令下载主题:\n1 git clone https://github.com/adityatelange/hugo-PaperMod.git 使用该主题的方法就是在站点文件夹下的配置文件里输入主题的名字:\n然后把主题文件夹里面的一些静态文件和配置文件复制到站点目录下，目的是为了可以自定义博客的样式，而不会改动主题文件夹里的样式，这样主题要更新的时候，直接在主题目录下git pull就可以，站点目录的修改会优先覆盖主题里的配置，所以可以实现平滑更新\n","permalink":"https://csqread.top/posts/blog/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"这篇文章主要记录我搭建hugo博客的过程，包括搭建过程中遇到的问题及解决方法 1、新建github仓库 新建respository, Respos","title":"Hugo博客搭建"},{"content":"有效数据生成以及插入数据库方案 先产生insert数据并存到备份文件中 因为有效数据生成的数量不大， 按照压测那边给我的需求大概每个交易4千笔数据左右，需要并发量比较高的交易也不过4万笔数据，涉及到转账的交易数据量比较高一点。并且需要做一个备份为了以后压测可以备用，因此我选择先生成到不同的表对应的表名文件中，然后再写一个批量执行SQL的程序执行这些文件中的insert语句\n下面的代码做了脱敏处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.FileReader; import java.io.FileWriter; import java.io.IOException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.TimeUnit; import java.util.regex.Matcher; import java.util.regex.Pattern; public class MultiThreadScript { private static final int THREAD_POOL_SIZE = 4; // 线程池大小 private static final String INPUT_FILE_PATH = \u0026#34;input.sql\u0026#34;; // 输入文件路径 private static final String OUTPUT_FILE_PATH = \u0026#34;output.sql\u0026#34;; // 输出文件路径 private static final String INSERT_REGEX = \u0026#34;(?i)^insert into .* values\\\\s*\\\\((.*)\\\\);?$\u0026#34;; // insert语句的正则表达式 private static final String PK_REGEX = \u0026#34;\u0026#39;[0-9A-Za-z]+\u0026#39;\u0026#34;; // 主键的正则表达式 private static final int PK_INDEX = 0; // 主键在值列表中的索引 public static void main(String[] args) throws Exception { // 创建线程池 ExecutorService executor = Executors.newFixedThreadPool(THREAD_POOL_SIZE); try (BufferedReader reader = new BufferedReader(new FileReader(INPUT_FILE_PATH))) { String line; while ((line = reader.readLine()) != null) { if (isInsertStatement(line)) { executor.execute(new InsertTask(line)); } } } // 关闭线程池并等待所有任务完成 executor.shutdown(); executor.awaitTermination(1, TimeUnit.HOURS); } // 判断一行文本是否为insert语句 private static boolean isInsertStatement(String line) { return line.matches(INSERT_REGEX); } // 插入任务 private static class InsertTask implements Runnable { private final String originalSql; public InsertTask(String originalSql) { this.originalSql = originalSql; } @Override public void run() { try { // 提取主键 Pattern pkPattern = Pattern.compile(PK_REGEX); Matcher pkMatcher = pkPattern.matcher(originalSql); pkMatcher.find(); String originalPk = pkMatcher.group(); // 提取值列表 String valueList = originalSql.replaceAll(INSERT_REGEX, \u0026#34;$1\u0026#34;); String[] values = valueList.split(\u0026#34;,\u0026#34;); // 递增主键并生成新的SQL语句 StringBuilder newSqlBuilder = new StringBuilder(); for (int i = 0; i \u0026lt; 40000; i++) { String newPk = getNextPk(originalPk); String newValueList = valueList.replace(originalPk, newPk); String newSql = originalSql.replaceAll(valueList, newValueList); newSqlBuilder.append(newSql).append(\u0026#34;\\n\u0026#34;); } // 写入输出文件 synchronized (MultiThreadScript.class) { try (BufferedWriter writer = new BufferedWriter(new FileWriter(OUTPUT_FILE_PATH, true))) { writer.write(newSqlBuilder.toString()); } } } catch (IOException e) { e.printStackTrace(); } } // 获取下一个主键 private String getNextPk (String originalPk) { String prefix = originalPk.substring(0, originalPk.length() - 1); String suffix = originalPk.substring(originalPk.length() - 1); String newSuffix = getNextSuffix(suffix); return prefix + newSuffix; } // 获取下一个主键后缀 private String getNextSuffix(String suffix) { StringBuilder sb = new StringBuilder(); for (int i = 0; i \u0026lt; suffix.length(); i++) { char c = suffix.charAt(i); if (Character.isDigit(c)) { int digit = Character.getNumericValue(c); if (digit == 9) { sb.append(\u0026#39;A\u0026#39;); } else if (digit == 35) { sb.append(\u0026#39;a\u0026#39;); } else { sb.append(Character.forDigit(digit + 1, 36)); } } else if (Character.isLetter(c)) { if (c == \u0026#39;Z\u0026#39;) { sb.append(\u0026#39;0\u0026#39;); } else if (c == \u0026#39;z\u0026#39;) { sb.append(\u0026#39;0\u0026#39;); } else { sb.append((char) (c + 1)); } } else { sb.append(c); } } return sb.toString(); } } 上面的代码中，MultiThreadScript类是脚本的主类，它负责读取输入文件并创建线程池来处理每条insert语句。InsertTask类是插入任务类，它实现了Runnable接口，用于递增主键并生成新的SQL语句。为了避免多个线程同时写入输出文件，InsertTask类中使用了synchronized关键字来进行同步。\n在getNextPk()方法中，我使用了类似于Excel中列名的递增方式来递增主键。首先，将原始主键分为前缀和后缀两部分，其中前缀是主键的前面部分，后缀是主键的最后一位字符。然后，对后缀进行递增，并根据递增后的后缀重新生成新的主键。\n最后，需要注意的是，由于主键可能包含字母和数字，因此使用36进制来对主键进行递增。例如，对于主键值为\u0026quot;001\u0026quot;，它的下一个值为\u0026quot;002\u0026quot;；对于主键值为\u0026quot;AZ9\u0026quot;，它的下一个值为\u0026quot;BA0\u0026quot;。\n进行插入操作（脱敏处理后的代码）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import java.io.BufferedReader; import java.io.FileReader; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.SQLException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class InsertExecutor { private static final String URL = \u0026#34;jdbc:mysql://localhost:3306/mydatabase\u0026#34;; private static final String USER = \u0026#34;myuser\u0026#34;; private static final String PASSWORD = \u0026#34;mypassword\u0026#34;; private static final int THREAD_POOL_SIZE = 10; public static void main(String[] args) { try { // 读取insert语句文件 BufferedReader reader = new BufferedReader(new FileReader(\u0026#34;inserts.sql\u0026#34;)); String line; Queue\u0026lt;String\u0026gt; inserts = new LinkedList\u0026lt;\u0026gt;(); while ((line = reader.readLine()) != null) { inserts.add(line); } reader.close(); // 创建线程池 ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE); // 执行insert语句 while (!inserts.isEmpty()) { String insert = inserts.poll(); executorService.execute(new InsertWorker(insert)); } // 关闭线程池 executorService.shutdown(); } catch (IOException e) { e.printStackTrace(); } } static class InsertWorker implements Runnable { private String insert; public InsertWorker(String insert) { this.insert = insert; } @Override public void run() { try (Connection conn = DriverManager.getConnection(URL, USER, PASSWORD); PreparedStatement statement = conn.prepareStatement(insert)) { // 执行insert语句 statement.executeUpdate(); } catch (SQLException e) { // 主键冲突，跳过该语句 if (e.getErrorCode() == 1062) { System.out.println(\u0026#34;Skip duplicate insert: \u0026#34; + insert); } else { e.printStackTrace(); } } } } } 上面代码中我们把insert.sql取代为我们想要进行批量insert的sql文件即可，线程数量可根据CPU的情况来看，在不进行其他工作任务的情况下，可尽量压榨CPU的使用率以达到最高的效率。\n亿级别的无效数据生成并插入数据库方案 这里因为涉及到的数据量特别大， 一般是模拟生产环境，因此一张表可能有千万级别以及亿级别的数据量，因此我选择一边生成一边做insert操作。也就是一个生产者一个消费者，当然，这里都是多线程来操作的。一开始我是每次达到20个事务一次提交的，后来换了OceanBase后，只能一次提交一个事务了，效率也变满了一点点. 对于多线程插入数据库，将生成的SQL语句分配给多个线程，每个线程使用单独的数据库连接插入数据库，可以使用线程池来管理多个线程\n下面是脱敏后的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 import java.io.BufferedReader; import java.io.FileReader; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.SQLException; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; public class MultiThreadedSqlInsert { // 数据库连接信息 private static final String DB_URL = \u0026#34;jdbc:mysql://localhost:3306/mydb\u0026#34;; private static final String DB_USER = \u0026#34;root\u0026#34;; private static final String DB_PASSWORD = \u0026#34;mypassword\u0026#34;; // 主键列名和初始值 private static final String PK_COLUMN_NAME = \u0026#34;id\u0026#34;; private static final String PK_INITIAL_VALUE = \u0026#34;1000\u0026#34;; // 线程数和每个线程处理的主键值个数 private static final int THREAD_COUNT = 10; private static final int KEYS_PER_THREAD = 10000000; // 文件名和队列大小 private static final String FILE_NAME = \u0026#34;data.sql\u0026#34;; private static final int QUEUE_SIZE = 10000; public static void main(String[] args) throws Exception { // 读取文件中的 SQL 语句 String sql = readSqlFromFile(FILE_NAME); // 创建线程池和队列 ExecutorService executor = Executors.newFixedThreadPool(THREAD_COUNT); BlockingQueue\u0026lt;String\u0026gt; queue = new LinkedBlockingQueue\u0026lt;\u0026gt;(QUEUE_SIZE); // 创建多个线程，为每个线程分配一段主键值的区间 for (int i = 0; i \u0026lt; THREAD_COUNT; i++) { int start = i * KEYS_PER_THREAD; int end = (i + 1) * KEYS_PER_THREAD - 1; executor.submit(new SqlGenerator(sql, start, end, queue)); } // 创建多个数据库连接，为每个连接分配一个线程 for (int i = 0; i \u0026lt; THREAD_COUNT; i++) { Connection conn = DriverManager.getConnection(DB_URL, DB_USER, DB_PASSWORD); executor.submit(new SqlExecutor(conn, queue)); } // 等待所有线程执行完毕 executor.shutdown(); executor.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS); } // 从文件中读取 SQL 语句 private static String readSqlFromFile(String fileName) throws Exception { try (BufferedReader reader = new BufferedReader(new FileReader(fileName))) { StringBuilder sb = new StringBuilder(); String line; while ((line = reader.readLine()) != null) { sb.append(line).append(\u0026#34;\\n\u0026#34;); } return sb.toString(); } } // 生成新的 SQL 语句 private static String generateSql(String sql, int key) { String pkValue = PK_INITIAL_VALUE + key; return sql.replaceFirst(PK_COLUMN_NAME, pkValue); } // 生成新的 SQL 语句的线程 private static class SqlGenerator implements Runnable { private final String sql; private final int start; private final int end; private final BlockingQueue\u0026lt;String\u0026gt; queue; public SqlGenerator(String sql, int start, int end, BlockingQueue\u0026lt;String\u0026gt; queue) { this.sql = sql; this.start = start; this.end = end; this.queue = queue; } @Override public void run() { for (int i = start; i \u0026lt;= end; i++) { String newSql = generateSql(sql, i); try { queue.put(newSql); } catch (InterruptedException e) { Thread.currentThread().interrupt(); return; } } } } // 执行 SQL 语句的线程 private static class SqlExecutor implements Runnable { private final Connection conn; private final BlockingQueue\u0026lt;String\u0026gt; queue; public SqlExecutor(Connection conn, BlockingQueue\u0026lt;String\u0026gt; queue) { this.conn = conn; this.queue = queue; } @Override public void run() { try (PreparedStatement stmt = conn.prepareStatement(\u0026#34;\u0026#34;)) { while (true) { String sql = queue.take(); if (sql == null) { break; } stmt.addBatch(sql); if (stmt.getBatchSize() \u0026gt;= 1000) { stmt.executeBatch(); } } stmt.executeBatch(); } catch (SQLException | InterruptedException e) { e.printStackTrace(); } } } 这里使用了两个线程池，一个用于生成新的 SQL 语句，一个用于执行 SQL 语句。生成 SQL 语句的线程将生成的 SQL 语句存储到一个线程安全的队列中，执行 SQL 语句的线程从队列中取出 SQL 语句并执行插入操作。程序使用了 JDBC 连接 MySQL 数据库，并使用了 PreparedStatement 批量执行 SQL 语句，以提高插入效率。\n需要注意的是，为了避免多个线程同时操作数据库导致数据不一致的问题，每个线程使用了自己的数据库连接。此外，程序还使用了线程安全的队列和加锁机制来保证线程安全。\n总结 以上就是我在工作中遇到的问题之一，做一个小结，用到了很多线程和线程池的地方，以及操作数据库相关的知识。\n","permalink":"https://csqread.top/posts/tech/%E5%8E%8B%E6%B5%8B%E6%95%B0%E6%8D%AE%E5%BF%AB%E9%80%9F%E7%94%9F%E6%88%90%E5%B9%B6%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%80%BB%E7%BB%93/","summary":"有效数据生成以及插入数据库方案 先产生insert数据并存到备份文件中 因为有效数据生成的数量不大， 按照压测那边给我的需求大概每个交易4千笔数据","title":"压测数据快速生成并插入数据库总结"},{"content":"JVM 内存结构 Java 虚拟机的内存空间分为 5 个部分：\n程序计数器 Java虚拟机栈 本地方法栈 堆 方法区 JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。\n程序计数器(PC寄存器) 程序计数器的定义 程序计数器是一块较小的内存空间，是当前线程正在执行的那条字节码指令的地址。若当前线程正在执行的是一个本地方法，那么此时程序计数器为Undefined。在Java虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制的指示器，分支，循环，跳转、异常处理、线程恢复等基础功能都需要这个计数器来完成。\n程序计数器的作用 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了 ","permalink":"https://csqread.top/posts/tech/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","summary":"JVM 内存结构 Java 虚拟机的内存空间分为 5 个部分： 程序计数器 Java虚拟机栈 本地方法栈 堆 方法区 JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元","title":"Java虚拟机知识总结"},{"content":"什么是Netty 1、Netty 是一个 基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。 2、它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。 3、支持多种协议 如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。 用官方的总结就是：Netty 成功地找到了一种在不妥协可维护性和性能的情况下实现易于开发，性能，稳定性和灵活性的方法。\n除了上面之外，很多开源项目比如我们常用的 Dubbo、RocketMQ、Elasticsearch、gRPC 等等都用到了 Netty\n相比于直接使用 JDK 自带的 NIO 相关的 API 来说更加易用。 统一的 API，支持多种传输类型，阻塞和非阻塞的。 简单而强大的线程模型。 自带编解码器解决 TCP 粘包/拆包问题。 自带各种协议栈。 真正的无连接数据包套接字支持。 比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。 社区活跃、成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。 应用场景 NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做网络通信 : 作为 RPC 框架的网络通信工具 ：我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。不同服务节点之间的通信是如何做的呢？可以使用 Netty 来做。比如我调用另外一个节点的方法的话，至少是要让对方知道我调用的是哪个类中的哪个方法以及相关参数吧！ 实现一个自己的 HTTP 服务器 ：通过 Netty 我们可以自己实现一个简单的 HTTP 服务器，这个大家应该不陌生。说到 HTTP 服务器的话，作为 Java 后端开发，我们一般使用 Tomcat 比较多。一个最基本的 HTTP 服务器可要以处理常见的 HTTP Method 的请求，比如 POST 请求、GET 请求等等。 实现一个即时通讯系统 ：使用 Netty 我们可以实现一个可以聊天类似微信的即时通讯系统， 实现消息推送系统 ：市面上有很多消息推送系统都是基于 Netty 来做的。 Netty 的高性能表现 心跳，对服务端：会定时清除闲置会话 inactive(netty5)，对客户端:用来检测会话是否断开，是否重来，检测网络延迟，其中 idleStateHandler 类 用来检测会话状态 串行无锁化设计，即消息的处理尽可能在同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。表面上看，串行化设计似乎 CPU 利用率不高，并发程度不够。但是，通过调整 NIO 线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。 可靠性，链路有效性检测：链路空闲检测机制，读/写空闲超时机制；内存保护机制：通过内存池重用 ByteBuf;ByteBuf 的解码保护；优雅停机：不再接收新消息、退出前的预处理操作、资源的释放操作。 Netty 安全性：支持的安全协议：SSL V2 和 V3，TLS，SSL 单向认证、双向认证和第三方 CA认证。 高效并发编程的体现：volatile 的大量、正确使用；CAS 和原子类的广泛使用；线程安全容器的使用；通过读写锁提升并发性能。IO 通信性能三原则：传输（AIO）、协议（Http）、线程（主从多线程） 流量整型的作用（变压器）：防止由于上下游网元性能不均衡导致下游网元被压垮，业务流中断；防止由于通信模块接受消息过快，后端业务线程处理不及时导致撑死问题 Netty核心组件 Bootstrap和ServerBootstrap 当需要连接客户端或者服务器绑定指定端口是需要使用Bootstrap，ServerBootstrap有两种类型，一种是用于客户端的Bootstrap，一种是用于服务端 的ServerBootstrap。不管程序使用哪种协议，无论是创建一个客户端还是服务器都需要使 用“引导”。\nBootstrap 是客户端的启动引导类/辅助类\n1 2 3 4 5 6 7 8 9 10 11 12 13 EventLoopGroup group = new NioEventLoopGroup(); try { //创建客户端启动引导/辅助类： Bootstrap Bootstrap b = new Bootstrap(); //指定线程模型 b.group(group). ...... // 尝试建立连接 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); } finally { // 优雅关闭相关线程组资源 group.shutdownGracefully(); } ServerBootstrap 客户端的启动引导类/辅助类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 1.bossGroup 用于接收连接，workerGroup 用于具体的处理 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //2.创建服务端启动引导/辅助类： ServerBootstrap ServerBootstrap b = new ServerBootstrap(); //3.给引导类配置两大线程组,确定了线程模型 b.group(bossGroup, workerGroup). ...... // 6.绑定端口 ChannelFuture f = b.bind(port).sync(); // 等待连接关闭 f.channel().closeFuture().sync(); } finally { //7.优雅关闭相关线程组资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } Bootstrap 通常使用 connet() 方法连接到远程的主机和端口，作为一个 Netty TCP 协议通信中的客户端。另外，Bootstrap 也可以通过 bind() 方法绑定本地的一个端口，作为 UDP 协议通信中的一端。 ServerBootstrap通常使用 bind() 方法绑定本地的端口上，然后等待客户端的连接。\nBootstrap 只需要配置一个线程组— EventLoopGroup，而 ServerBootstrap需要配置两个线程组— EventLoopGroup ，一个用于接收连接，一个用于具体的处理。\n一个 ServerBootstrap 可以认为有2个 Channel 集合，\n第一个集合包含一个单例 ServerChannel，代表持有一个绑定了本地端口的 socket;\n第二集合包含所有创建的 Channel，处理服务器所接收到的客户端进来的连接。\nEventLoop和EventLoopGroup EventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件。\nEventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。\nChannel 和 EventLoop 直接有啥联系呢？\nChannel 为 Netty 网络操作(读写等操作)抽象类，EventLoop 负责处理注册到其上的Channel 处理 I/O 操作，两者配合参与 I/O 操作。\nEventLoopGroup包含多个EventLoop，每个EventLoop通常内部包含一个线程。EventLoop在处理IO事件时在自己的Thread线程上进行，从而保证线程安全\nNioEventLoopGroup在未指定线程数时，默认时当前cpu线程数*2\nEventLoopGroup 是一组 EventLoop 的抽象，Netty 为了更好的利用多核 CPU 资源，一般会有多个 EventLoop 同时工作，每个 EventLoop 维护着一个 Selector 实例。 EventLoopGroup 提供 next 接口，可以从组里面按照一定规则获取其中一个EventLoop来处理任务。在 Netty 服务器端编程中，我们一般都需要提供两个EventLoopGroup，例如:BossEventLoopGroup 和 WorkerEventLoopGroup。 通常一个服务端口即一个ServerSocketChannel对应一个Selector和一个EventLoop 线程。BossEventLoop 负责接收客户端的连接并将 SocketChannel 交给 WorkerEventLoopGroup 来进行 IO 处理\nBossEventLoopGroup 通常是一个单线程的 EventLoop，EventLoop 维护着一个注册了ServerSocketChannel 的Selector 实例BossEventLoop 不断轮询Selector 将连接事件分离出来 通常是 OP_ACCEPT 事件，然后将接收到的 SocketChannel 交给WorkerEventLoopGroup WorkerEventLoopGroup 会由 next 选择其中一个 EventLoop来将这个SocketChannel 注册到其维护的Selector 并对其后续的 IO 事件进行处理 EventLoop继承图\nChannel通道 Channel 接口是 Netty 对网络操作抽象类，它除了包括基本的 I/O 操作，如 bind()、connect()、read()、write() 等。\n比较常用的Channel接口实现类是NioServerSocketChannel（服务端）和NioSocketChannel（客户端），这两个 Channel 可以和 BIO 编程模型中的ServerSocket以及Socket两个概念对应上。Netty 的 Channel 接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。\n1 2 3 4 5 6 7 Channel channel = ...; // 获取channel的引用 ByteBuf buf = Unpooled.copiedBuffer(\u0026#34;your data\u0026#34;, CharsetUtil.UTF_8); //1 ChannelFuture cf = channel.writeAndFlush(buf); //2 cf.addListener(new ChannelFutureListener() { //3 @Override public void operationComplete(ChannelFuture future) { if (future.isSuccess()) { //4 } }); 创建 ByteBuf 保存写的数据 写数据，并刷新 添加 ChannelFutureListener 即可写操作完成后收到通知 写操作没有错误完成 写操作完成时出现错误 channel声明周期 | 状态 | 描述 | | —- | —- | | ChannelUnregistered | Channel 已经被创建，但还未注册到EventLoop | | ChannelRegistered | Channel 已经被注册到了EventLoop | | ChannelActive | Channel 处于活动状态（已经连接到它的远程节点）。它现在可以接收和发送数据了 | | ChannelInactive | Channel 没有连接到远程节点 |\nselector 作用：\nI/O 的就绪与选择 是 NIO 网络编程的基础 SelectonKey 状态 OP_ACCEPT 操作集位用于插座接受操作。 OP_CONNECT 用于套接字连接操作的操作集位。 OP_READ 读操作的操作位。 OP_WRITE 写操作的操作位。 1 2 3 4 5 Selector selector = new Selector.open() SelectorKey selectorKey = channel.register(selector, SelectionKey.OP_READ); int selectNum = selector.select(); Set\u0026lt;Selection\u0026gt; selectionkeys = selector.selectdkeys(); ","permalink":"https://csqread.top/posts/tech/netty%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","summary":"什么是Netty 1、Netty 是一个 基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。 2、它极大","title":"Netty相关总结"},{"content":"面试题目 记录下社招面试拼多多的总结与心得，以及失败的原因吧。\n1、服务注册是如何发现的，eureka的基本原理， 容器ip是动态的还是静态的\n答：eureka, 基本原理大概说个一些：包括服务注册，服务发现，心跳机制，服务下线， 自我保护机制等等。\n2、转账，支付如何保证数据一致性的， 说一下分布式事务的实现， 消息的生产和消费机制。\n这个基本上说出个一二三来。其实就是分布式事务，保证这个数据的一致性就是要保证事务的原子性。即，事务要么全部成功，要么全部失败。我就提了下XA协议和TCC模式，具体如何实现的我也不太清楚。\n3、mysql 索引优化，子查询优化\n这里基本上都讲出来了。之前做过很多压测，包括让sql走上索引，参数表添加缓存等等。\n4、线上有排查过什么问题.\n5、MQ的实现原理\n5、图算法题\n还有些问题已经忘了。\n总结与回顾 其实关于这次面试，我还是没有做好完全的准备，而且是近三年以来的第一次面试，心里难免还是有点紧张。导致我有些东西知道的知识可能一时半会想不起来。后面把这些问到的知识点再复习一下。基本上只是浅浅的了解了一下，细说一下底层原理我就懵了。大概知道我们有这么个流程，知道哪里出了问题该找谁来看。因为现在吧，大公司基本上就是这么个情况， 包括中间件团队，数据库团队，DTF团队，DCF团队等等。基本上我们只用知道这些东西有，然后找相应团队的负责人帮忙看下问题就能解决。我们都是在脚手架上做着CURD。\n但是还是要把面试问到的东西基本原理做一个小小的总结和记录:\nEureka Eureka是Netflix开源的一款提供服务注册和发现的产品， 开源地址为 Eureka, 注册中心是分布式开发的核心组件之一\n而eureka是spring cloud推荐的注册中心实现, Eureka是一个REST (Representational State Transfer)服务 它主要用于AWS云，用于定位服务，以实现中间层服务器的负载平衡和故障转移，我们称此服务为Eureka服务器\nEureka也有一个基于java的客户端组件，Eureka客户端，这使得与服务的交互更加容易，同时客户端也有一个内置的负载平衡器，它执行基本的循环负载均衡。\n自我保护机制 自我保护机制主要在Eureka Client和Eureka Server之间存在网络分区的情况下发挥保护作用，在服务器端和客户端都有对应实现.\n假设在某种特定的情况下（如网络故障）, Eureka Client和Eureka Server无法进行通信，此时Eureka Client无法向Eureka Server发起注册和续约请求，Eureka Server中就可能因注册表中的服务实例租约出现大量过期而面临被剔除的危险，然而此时的Eureka Client可能是处于健康状态的（可接受服务访问），如果直接将注册表中大量过期的服务实例租约剔除显然是不合理的，自我保护机制提高了eureka的服务可用性。\n当自我保护机制触发时，Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务，仍能查询服务信息并且接受新服务注册请求，也就是其他功能是正常的。\n这里思考下，如果eureka节点A触发自我保护机制过程中，有新服务注册了然后网络回复后，其他peer节点能收到A节点的新服务信息，数据同步到peer过程中是有网络异常重试的，也就是说，是能保证最终一致性的。\n服务发现原理 eureka server可以集群部署，多个节点之间会进行（异步方式）数据同步，保证数据最终一致性，Eureka Server作为一个开箱即用的服务注册中心，提供的功能包括：服务注册、接收服务心跳、服务剔除、服务下线等。\n需要注意的是，Eureka Server同时也是一个Eureka Client，在不禁止Eureka Server的客户端行为时，它会向它配置文件中的其他Eureka Server进行拉取注册表、服务注册和发送心跳等操作。\neureka server端通过appName和instanceInfoId来唯一区分一个服务实例，服务实例信息是保存在哪里呢？其实就是一个Map中：\n1 2 // 第一层的key是appName，第二层的key是instanceInfoIdprivate final ConcurrentHashMap\u0026lt;String, Map\u0026lt;String, Lease\u0026lt;InstanceInfo\u0026gt;\u0026gt;\u0026gt; registry = new ConcurrentHashMap\u0026lt;String, Map\u0026lt;String, Lease\u0026lt;InstanceInfo\u0026gt;\u0026gt;\u0026gt;(); 服务注册 Service Provider启动时会将服务信息（InstanceInfo）发送给eureka server，eureka server接收到之后会写入registry中，服务注册默认过期时间DEFAULT_DURATION_IN_SECS = 90秒。InstanceInfo写入到本地registry之后，然后同步给其他peer节点，对应方法com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl#replicateToPeers。\n写入本地redistry 服务信息（InstanceInfo）保存在Lease中，写入本地registry对应方法com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl#register，Lease统一保存在内存的ConcurrentHashMap中，在服务注册过程中，首先加个读锁，然后从registry中判断该Lease是否已存在，如果已存在则比较lastDirtyTimestamp时间戳，取二者最大的服务信息，避免发生数据覆盖。使用InstanceInfo创建一个新的InstanceInfo：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 if (existingLastDirtyTimestamp \u0026gt; registrationLastDirtyTimestamp) { // 已存在Lease则比较时间戳，取二者最大值 registrant = existingLease.getHolder(); } Lease\u0026lt;InstanceInfo\u0026gt; lease = new Lease\u0026lt;InstanceInfo\u0026gt;(registrant, leaseDuration); if (existingLease != null) { // 已存在Lease则取上次up时间戳 lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); } public Lease(T r, int durationInSecs) { holder = r; registrationTimestamp = System.currentTimeMillis(); // 当前时间 lastUpdateTimestamp = registrationTimestamp; duration = (durationInSecs * 1000); } 同步给其他peer InstanceInfo写入到本地registry之后，然后同步给其他peer节点，对应方法com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl#replicateToPeers。如果当前节点接收到的InstanceInfo本身就是另一个节点同步来的，则不会继续同步给其他节点，避免形成“广播效应”；InstanceInfo同步时会排除当前节点。\nInstanceInfo的状态有依以下几种：Heartbeat, Register, Cancel, StatusUpdate, DeleteStatusOverride，默认情况下同步操作时批量异步执行的，同步请求首先缓存到Map中，key为requestType+appName+id，然后由发送线程将请求发送到peer节点。\nPeer之间的状态是采用异步的方式同步的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的。结合服务发现的场景，实际上也并不需要节点间的状态强一致。在一段时间内（比如30秒），节点A比节点B多一个服务实例或少一个服务实例，在业务上也是完全可以接受的（Service Consumer侧一般也会实现错误重试和负载均衡机制）。所以按照CAP理论，Eureka的选择就是放弃C，选择AP。 如果同步过程中，出现了异常怎么办呢，这时会根据异常信息做对应的处理，如果是读取超时或者网络连接异常，则稍后重试；如果其他异常则打印错误日志不再后续处理。\n服务续约 Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。主要是用来告诉Eureka Server Service Provider还活着，避免服务被剔除掉。renew接口实现方式和register基本一致：首先更新自身状态，再同步到其它Peer，服务续约也就是把过期时间设置为当前时间加上duration的值。\n注意：服务注册如果InstanceInfo不存在则加入，存在则更新；而服务预约只是进行更新，如果InstanceInfo不存在直接返回false。\n服务失效剔除 Eureka Server中有一个EvictionTask，用于检查服务是否失效。Eviction（失效服务剔除）用来定期（默认为每60秒）在Eureka Server检测失效的服务，检测标准就是超过一定时间没有Renew的服务。默认失效时间为90秒，也就是如果有服务超过90秒没有向Eureka Server发起Renew请求的话，就会被当做失效服务剔除掉。失效时间可以通过eureka.instance.leaseExpirationDurationInSeconds进行配置，定期扫描时间可以通过eureka.server.evictionIntervalTimerInMs进行配置。\n服务剔除#evict方法中有很多限制，都是为了保证Eureka Server的可用性：比如自我保护时期不能进行服务剔除操作、过期操作是分批进行、服务剔除是随机逐个剔除，剔除均匀分布在所有应用中，防止在同一时间内同一服务集群中的服务全部过期被剔除，以致大量剔除发生时，在未进行自我保护前促使了程序的崩溃。\n服务信息拉取 Eureka consumer服务信息的拉取分为全量式拉取和增量式拉取，eureka consumer启动时进行全量拉取，运行过程中由定时任务进行增量式拉取，如果网络出现异常，可能导致先拉取的数据被旧数据覆盖（比如上一次拉取线程获取结果较慢，数据已更新情况下使用返回结果再次更新，导致数据版本落后），产生脏数据。对此，eureka通过类型AtomicLong的fetchRegistryGeneration对数据版本进行跟踪，版本不一致则表示此次拉取到的数据已过期。\nfetchRegistryGeneration过程是在拉取数据之前，执行fetchRegistryGeneration.get获取当前版本号，获取到数据之后，通过fetchRegistryGeneration.compareAndSet来判断当前版本号是否已更新。 注意：如果增量式更新出现意外，会再次进行一次全量拉取更新。\nEureka server的伸缩容 Eureka Server是怎么知道有多少Peer的呢？Eureka Server在启动后会调用EurekaClientConfig.getEurekaServerServiceUrls来获取所有的Peer节点，并且会定期更新。定期更新频率可以通过eureka.server.peerEurekaNodesUpdateIntervalMs配置。\n这个方法的默认实现是从配置文件读取，所以如果Eureka Server节点相对固定的话，可以通过在配置文件中配置来实现。如果希望能更灵活的控制Eureka Server节点，比如动态扩容/缩容，那么可以override getEurekaServerServiceUrls方法，提供自己的实现，比如我们的项目中会通过数据库读取Eureka Server列表。\neureka server启动时把自己当做是Service Consumer从其它Peer Eureka获取所有服务的注册信息。然后对每个服务信息，在自己这里执行Register，isReplication=true，从而完成初始化。\nService Provider Service Provider启动时首先时注册到Eureka Service上，这样其他消费者才能进行服务调用，除了在启动时之外，只要实例状态信息有变化，也会注册到Eureka Service。需要注意的是，需要确保配置eureka.client.registerWithEureka=true。register逻辑在方法AbstractJerseyEurekaHttpClient.register中，Service Provider会依次注册到配置的Eureka Server Url上，如果注册出现异常，则会继续注册其他的url。\nRenew操作会在Service Provider端定期发起，用来通知Eureka Server自己还活着。 这里instance.leaseRenewalIntervalInSeconds属性表示Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。这部分逻辑在HeartbeatThread类中。在Service Provider服务shutdown的时候，需要及时通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务，逻辑本身比较简单，通过对方法标记@PreDestroy，从而在服务shutdown的时候会被触发。\nService Consumer Service Consumer这块的实现相对就简单一些，因为它只涉及到从Eureka Server获取服务列表和更新服务列表。Service Consumer在启动时会从Eureka Server获取所有服务列表，并在本地缓存。需要注意的是，需要确保配置eureka.client.shouldFetchRegistry=true。由于在本地有一份Service Registries缓存，所以需要定期更新，定期更新频率可以通过eureka.client.registryFetchIntervalSeconds配置。\n总结 我们为什么要使用Eureka呢，在分布式开发架构中， 任何单点的服务都不能保证不会中断，因此需要服务发现机制，某个节点中断后，服务消费者能及时感知到保证服务高可用。注册中心除了Eureka之外，还有Zookeeper、consul、nacos等解决方案，实现原理不同， 各自适用于不同业务场景。\n数据一致性问题 事务 严格意义上的事务实现应该是具备原子性、一致性、隔离性和持久性，简称ACID。\n原子性(Atomicity) ， 可以理解为一个事务内的所有操作要么都执行，要么都不执行。 一致性(Consistency)， 数据是满足完整性约束的，也就是不会存在中间状态的数据，比如说你账户上有400， 我账户上有100， 你给我打200块，此时你账户上的钱应该是200， 我账户上的钱应该是300， 不会存在我账户上的钱加了，你账户上的钱没扣的中间状态 隔离性(Lsolation) ，指的是多个事务并发执行的时候不会互相干扰，即事务内部的数据对于其他事务来说是隔离的 持久性(Durability), 指的是一个事务完成了之后数据就被永远保存下来，之后的其他操作或故障都不会对事务的结果产生影响 而通俗意义上事务就是为了使得一些更新操作要么都成功，要么都失败。\n分布式事务 分布式事务顾名思义就是要在分布式系统中实现事务，它其实是由多个本地事务组合而成。\n对于分布式事务而言几乎满足不了ACID，其实对于单机事务而言大部分情况下也没有满足ACID，不然怎么会有四种隔离级别呢？所以更不用说分布在不用数据库或者不同应用上的分布式事务了。\n2PC 2PC（Two-phase commit protocol），中文叫二阶段提交。 二阶段提交是一种强一致性设计，2PC 引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备（投票）和提交两个阶段。\n注意这只是协议或者说是理论指导，只阐述了大方向，具体落地还是有会有差异的。\n让我们来看下两个阶段的具体流程。\n准备阶段协调者会给各参与者发送准备命令，你可以把准备命令理解成除了提交事务之外啥事都做完了。\n同步等待所有资源的响应之后就进入第二阶段即提交阶段（注意提交阶段不一定是提交事务，也可能是回滚事务）。\n假如在第一阶段所有参与者都返回准备成功，那么协调者则向所有参与者发送提交事务命令，然后等待所有事务都提交成功之后，返回事务执行成功。\n假如在第一阶段有一个参与者返回失败，那么协调者就会向所有参与者发送回滚事务的请求，即分布式事务执行失败。\n那第二阶段提交失败的话呢？\n这里有两种情况。\n第一种是第二阶段执行的是回滚事务操作，那么答案是不断重试，直到所有参与者都回滚了，不然那些在第一阶段准备成功的参与者会一直阻塞着。\n第二种是第二阶段执行的是提交事务操作，那么答案也是不断重试，因为有可能一些参与者的事务已经提交成功了，这个时候只有一条路，就是头铁往前冲，不断的重试，直到提交成功，到最后真的不行只能人工介入处理。\n大体上二阶段提交的流程就是这样，我们再来看看细节。\n首先 2PC 是一个同步阻塞协议，像第一阶段协调者会等待所有参与者响应才会进行下一步操作，当然第一阶段的协调者有超时机制，假设因为网络原因没有收到某参与者的响应或某参与者挂了，那么超时后就会判断事务失败，向所有参与者发送回滚命令。\n在第二阶段协调者的没法超时，因为按照我们上面分析只能不断重试！\n协调者故障分析 协调者是一个单点，存在单点故障问题\n假设协调者在发送准备命令之前挂了， 还行，等于事务没开始。\n假设协调者在发送准备命令之后挂了，这就不太行了，有些参与者等于都执行了处于事务资源锁定的状态。不仅事务执行不下去，还会因为锁定了一些公共资源而阻塞系统其他操作。\n假设协调者在发送事务回滚命令之前挂了，那么事务也是执行不下去，且在第一阶段那些准备成功参与者都阻塞着。\n假设协调者在发送回滚事务命令之后挂了，这个还行，至少命令发出去了，很大概率都会回滚成功，资源都会释放。但是如果出现网络分区问题，某些参与者将因为收不到命令而阻塞着。\n假设协调者在发送提交事务命令之前挂了，这个不行，这下所有资源都阻塞着。\n假设协调者在发送提交事务命令之后挂了，很大概率都会提交成功，然后释放资源。但是如果出现网络分区问题某些参与者因为收不到命令而阻塞着。\n协调者故障，通过选举得到新的协调者 因为协调者单点问题，因此我们可以通过选举等操作选出一个新协调者来顶替。\n如果处于第一阶段，其实影响不大都回滚好了，在第一阶段事务肯定还没提交。\n如果处于第二阶段，假设参与者都没挂，此时新协调者可以向所有参与者确认它们自身情况来推断下一步的操作。\n假设有个别参与者挂了！这就有点僵硬了，比如协调者发送了回滚命令，此时第一个参与者收到了并执行，然后协调者和第一个参与者都挂了。\n此时其他参与者都没收到请求，然后新协调者来了，它询问其他参与者都说OK，但它不知道挂了的那个参与者到底O不OK，所以它傻了。\n问题其实就出在每个参与者自身的状态只有自己和协调者知道，因此新协调者无法通过在场的参与者的状态推断出挂了的参与者是什么情况。\n虽然协议上没说，不过在实现的时候我们可以灵活的让协调者将自己发过的请求在哪个地方记一下，也就是日志记录，这样新协调者来的时候不就知道此时该不该发了？\n但是就算协调者知道自己该发提交请求，那么在参与者也一起挂了的情况下没用，因为你不知道参与者在挂之前有没有提交事务。\n如果参与者在挂之前事务提交成功，新协调者确定存活着的参与者都没问题，那肯定得向其他参与者发送提交事务命令才能保证数据一致。\n如果参与者在挂之前事务还未提交成功，参与者恢复了之后数据是回滚的，此时协调者必须是向其他参与者发送回滚事务命令才能保持事务的一致。\n所以说极端情况下还是无法避免数据不一致问题。\ntalk is cheap 让我们再来看下代码，可能更加的清晰。以下代码取自 Distributed System: Principles and Paradigms。\n这个代码就是实现了 2PC，但是相比于2PC增加了写日志的动作、参与者之间还会互相通知、参与者也实现了超时。这里要注意，一般所说的2PC，不含上述功能，这都是实现的时候添加的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 协调者: write START_2PC to local log; //开始事务 multicast VOTE_REQUEST to all participants; //广播通知参与者投票 while not all votes have been collected { wait for any incoming vote; if timeout { //协调者超时 write GLOBAL_ABORT to local log; //写日志 multicast GLOBAL_ABORT to all participants; //通知事务中断 exit; } record vote; } //如果所有参与者都ok if all participants sent VOTE_COMMIT and coordinator votes COMMIT { write GLOBAL_COMMIT to local log; multicast GLOBAL_COMMIT to all participants; } else { write GLOBAL_ABORT to local log; multicast GLOBAL_ABORT to all participants; } 参与者: write INIT to local log; //写日志 wait for VOTE_REQUEST from coordinator; if timeout { //等待超时 write VOTE_ABORT to local log; exit; } if participant votes COMMIT { write VOTE_COMMIT to local log; //记录自己的决策 send VOTE_COMMIT to coordinator; wait for DECISION from coordinator; if timeout { multicast DECISION_REQUEST to other participants; //超时通知 wait until DECISION is received; /* remain blocked*/ write DECISION to local log; } if DECISION == GLOBAL_COMMIT write GLOBAL_COMMIT to local log; else if DECISION == GLOBAL_ABORT write GLOBAL_ABORT to local log; } else { write VOTE_ABORT to local log; send VOTE_ABORT to coordinator; } 每个参与者维护一个线程处理其它参与者的DECISION_REQUEST请求： while true { wait until any incoming DECISION_REQUEST is received; read most recently recorded STATE from the local log; if STATE == GLOBAL_COMMIT send GLOBAL_COMMIT to requesting participant; else if STATE == INIT or STATE == GLOBAL_ABORT; send GLOBAL_ABORT to requesting participant; else skip; /* participant remains blocked */ } 至此已经详细分析了2PC的各种细节，总结如下：\n2PC是一种尽量保证强一致性的分布式事务，因此它是同步阻塞的，而同步阻塞就导致长久的资源锁定问题，总体而言效率低，并且存在单点故障问题，在极端条件下存在数据不一致的风险。\n当然具体的实现可以变形，比如Tree 2PC、Dynamic 2PC\n2PC适用于数据库层面的分布式事务场景，而我们业务需求有时候不仅仅关乎数据库，也有可能是上传一张图片或者发送一条短信。\n而且像Java中的JTA, 它是基于XA规范实现的事务接口，这里的XA可以简单理解为基于数据库的XA规范来实现的2PC。\n3PC 3PC的出现是为了解决2PC的一些问题。相比于 2PC 它在参与者中也引入了超时机制，并且新增了一个阶段使得参与者可以利用这一个阶段统一各自的状态。\n","permalink":"https://csqread.top/posts/tech/%E6%8B%BC%E5%A4%9A%E5%A4%9A%E9%9D%A2%E7%BB%8F/","summary":"面试题目 记录下社招面试拼多多的总结与心得，以及失败的原因吧。 1、服务注册是如何发现的，eureka的基本原理， 容器ip是动态的还是静态的 答：","title":"拼多多面经"},{"content":"ArrayList 1. 概览 实现了 RandomAccess 接口，因此支持随机访问。这是理所当然的，因为 ArrayList 是基于数组实现的。\n1 2 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。\n1 private static final int DEFAULT_CAPACITY = 10; 2. 扩容 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1)，也就是旧容量的 1.5 倍。\n扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length \u0026gt; 0) grow(minCapacity); } private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } 3. 删除元素 需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看出 ArrayList 删除元素的代价是非常高的。\n1 2 3 4 5 6 7 8 9 10 public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; } 4. Fail-Fast modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。\n在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i\u0026lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } 5. 序列化 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。\n保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。\n1 transient Object[] elementData; // non-private to simplify nested class access ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size \u0026gt; 0) { // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i\u0026lt;size; i++) { a[i] = s.readObject(); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i\u0026lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } 序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。\n1 2 3 ArrayList list = new ArrayList(); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file)); oos.writeObject(list); ","permalink":"https://csqread.top/posts/tech/java-arraylist%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%8E%E6%80%BB%E7%BB%93/","summary":"ArrayList 1. 概览 实现了 RandomAccess 接口，因此支持随机访问。这是理所当然的，因为 ArrayList 是基于数组实现的。 1 2 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1 private static final int DEFAULT_CAPACITY =","title":"Java ArrayList源码分析与总结"},{"content":"缓存优化 1、对应参数表数据量如果小于10M，数据要同时缓存到Redis和本地，查询遵循的缓存原则为:优先查询本地缓存，本地没有查询Redis缓存，Redis没有再查询数据库.\n2、对参数表的缓存要分类进行配置：黑名单类参数表查询，Redis缓存为空时不再查询数据库：常规类参数表查询，Redis缓存为空的时候需要再查询数据库\n3、如果参数表出现大量RPC。确定SQL都是等值的情况下，一般是缓存索引配置的不合适/\n4、如果出现大量RPC，在SQL非等值情况下，需要通过等值SQL去查询，然后在程序代码中去判断数据是否符合要求。\n5、针对查询比较多并且修改也比较多的数据，可以针对部分不变的数据配置缓存。 （比如针对内部合约相关的数据，需要频繁的调用内部账的科目存储字段，虽然内部户的一整条数据会经常变动，但是内部户的科目存储字段基本上不会改变，就可以把这些不变的数据配置缓存，提升查询效率，并且可以减少RPC的次数）。\n6、根据不同条件调用他组缓存表的接口时，可以现根据他组配置缓存索引条件进行查询，然后在程序中再根据非索引条件过滤查询结果。\n编码优化 1、当某业务构件执行缓慢时，除了要排查是否有非必要RPC时或环境影响因素外，还需要检查构件中是否有重复执行的代码和SQL，第一次执行向后传递可以提升传递效率。\n2、如果通过实现JAR包调用他组接口还RPC了的，首先检查他们是否缓存表以及缓存表索引配置是否正确，如以上没问题，则可能是JAR包中未打入实现类。\n3、因为Java接口中传递对象是通过引用方式传递的，如果接口对传入的对象进行了修改，当执行完接口在接口外部拿到的该对象中的数据是被修改的，此时在接口外部继续获取对象中被修改的原数据时容易得到意想不到的结果。\n4、调用某构件的时候，构件中又要获取一些数据进行RPC，如果调用构件之前已有相关数据，可以调用构件时传递进去，可减少RPC。\n5、根据不同条件多次使用其他组的接口进行查询时，可以提取多个条件的交集，根据交集条件查询所有数据，然后在程序中分别根据非交集的条件进行过滤。\n6、对于多次循环调用他组同一个方法时，每次输入的值不同，可将所有输入值包装成LIST一次性传入，得到一个查询列表集合作为类似本地缓存，然后对这个LSIT集合进行循环整理。\n7、RPC接口要尽量简单，输入输出接口不要继承一些不需要的东西，既能减少网络传输消耗，还能减少序列化和反序列化的时间。\n数据库及SQL优化 1、尽量避免使用SELECT * 来查询所有字段，仅查询必要数据行及字段，既能减少网络传输消耗，还能提高命中覆盖索引的概率。\n2、写SQK的时候永远记得WHERE条件要和主键或者索引匹配。\n3、对于查询量非常大修改比较少的表， 且SELECT的字段正好比索引多一个或者两个字段的时候，可以采取把多余的一个或者两个字段冗余到索引上，这种一空间换取时间的方式虽然一定程度上增加了索引空间的开销，但是对于非常高频的SQL直接命中了覆盖索引，避免了回表查询，有助于提升查询效率。\n4、对于修改量非常大的交易，要及其精简索引，能不要的索引最好不要建，在修改表的时候可以减少索引的维护，有助于提升修改效率。\n以上是工作中的性能优化总结，后续如果有新的总结再来记录\n","permalink":"https://csqread.top/posts/tech/%E5%88%86%E5%B8%83%E5%BC%8F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/","summary":"缓存优化 1、对应参数表数据量如果小于10M，数据要同时缓存到Redis和本地，查询遵循的缓存原则为:优先查询本地缓存，本地没有查询Redis","title":"分布式性能优化总结"},{"content":"字符操作 编码与解码 编码就是把字符转换为字节，而解码是把字节重新组合成字符。\n如果编码和解码过程使用不同的编码方式那么就出现了乱码。\nGBK 编码中，中文字符占 2 个字节，英文字符占 1 个字节； UTF-8 编码中，中文字符占 3 个字节，英文字符占 1 个字节； UTF-16be 编码中，中文字符和英文字符都占 2 个字节。 UTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。\nJava 的内存编码使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码是为了让一个中文或者一个英文都能使用一个 char 来存储。\nString 的编码方式 String 可以看成一个字符序列，可以指定一个编码方式将它编码为字节序列，也可以指定一个编码方式将一个字节序列解码为 String。\n1 2 3 4 String str1 = \u0026#34;中文\u0026#34;; byte[] bytes = str1.getBytes(\u0026#34;UTF-8\u0026#34;); String str2 = new String(bytes, \u0026#34;UTF-8\u0026#34;); System.out.println(str2); 在调用无参数 getBytes() 方法时，默认的编码方式不是 UTF-16be。双字节编码的好处是可以使用一个 char 存储中文和英文，而将 String 转为 bytes[] 字节数组就不再需要这个好处，因此也就不再需要双字节编码。getBytes() 的默认编码方式与平台有关，一般为 UTF-8。\n1 byte[] bytes = str1.getBytes(); Reader 与 Writer 不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符。但是在程序中操作的通常是字符形式的数据，因此需要提供对字符进行操作的方法。\nInputStreamReader 实现从字节流解码成字符流； OutputStreamWriter 实现字符流编码成为字节流。 实现逐行输出文本文件的内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void readFileContent(String filePath) throws IOException { FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) { System.out.println(line); } // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close(); } ","permalink":"https://csqread.top/posts/tech/java%E4%B8%AD%E7%9A%84%E5%AD%97%E7%AC%A6%E6%93%8D%E4%BD%9C/","summary":"字符操作 编码与解码 编码就是把字符转换为字节，而解码是把字节重新组合成字符。 如果编码和解码过程使用不同的编码方式那么就出现了乱码。 GBK 编码中，中","title":"Java中的字符操作"},{"content":"自旋锁 互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n锁消除 锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁：\n1 2 3 public static String concatString(String s1, String s2, String s3) { return s1 + s2 + s3; } String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作：\n1 2 3 4 5 6 7 public static String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString(); } 每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。\n锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。\n轻量级锁 JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。\n下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。\n如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。\n偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n","permalink":"https://csqread.top/posts/tech/java%E9%94%81%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/","summary":"自旋锁 互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求","title":"Java锁优化相关笔记"},{"content":"刚开始我没想到用爬虫，就直接手创了一个字典\u0026hellip; 需要安装模块pyechart and pyechart-china-provinces-pypkg\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 from pyecharts.charts import Map from pyecharts import options as opts #省和直辖市 province_distribution = { \u0026#39;湖北\u0026#39;: 4586, \u0026#39;浙江\u0026#39;: 428, \u0026#39;广东\u0026#39;: 311, \u0026#39;湖南\u0026#39;: 277, \u0026#39;河南\u0026#39;: 278, \u0026#39;安徽\u0026#39;: 200, \u0026#39;重庆\u0026#39;: 165, \u0026#39;山东\u0026#39;: 145, \u0026#39;江西\u0026#39;: 162, \u0026#39;四川\u0026#39;: 142, \u0026#39;江苏\u0026#39;: 129, \u0026#39;北京\u0026#39;: 111, \u0026#39;福建\u0026#39;: 101, \u0026#39;上海\u0026#39;: 101, \u0026#39;广西\u0026#39;: 78, \u0026#39;陕西\u0026#39;: 56, \u0026#39;河北\u0026#39;: 48, \u0026#39;云南\u0026#39;: 44, \u0026#39;海南\u0026#39;: 43, \u0026#39;黑龙江\u0026#39;: 43, \u0026#39;辽宁\u0026#39;: 39, \u0026#39;山西\u0026#39;: 35, \u0026#39;天津\u0026#39;: 28, \u0026#39;甘肃\u0026#39;: 26, \u0026#39;内蒙古\u0026#39;: 16, \u0026#39;新疆\u0026#39;: 14, \u0026#39;宁夏\u0026#39;: 12, \u0026#39;贵州\u0026#39;: 12, \u0026#39;吉林\u0026#39;: 14, \u0026#39;台湾\u0026#39;: 8, \u0026#39;香港\u0026#39;: 10, \u0026#39;澳门\u0026#39;: 7, \u0026#39;青海\u0026#39;: 6, \u0026#39;西藏\u0026#39;: 1 } # maptype = \u0026#39;china\u0026#39; 只显示全国直辖市和省级 map = Map() map.set_global_opts( title_opts=opts.TitleOpts(title=\u0026#34;2020中国疫情地图\u0026#34;), visualmap_opts=opts.VisualMapOpts(max_=3600, is_piecewise=True, pieces=[ {\u0026#34;max\u0026#34;: 5000, \u0026#34;min\u0026#34;: 1001, \u0026#34;label\u0026#34;: \u0026#34;\u0026gt;1000\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#8A0808\u0026#34;}, {\u0026#34;max\u0026#34;: 1000, \u0026#34;min\u0026#34;: 500, \u0026#34;label\u0026#34;: \u0026#34;500-1000\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#B40404\u0026#34;}, {\u0026#34;max\u0026#34;: 499, \u0026#34;min\u0026#34;: 100, \u0026#34;label\u0026#34;: \u0026#34;10-99\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#78181\u0026#34;}, {\u0026#34;max\u0026#34;: 99, \u0026#34;min\u0026#34;: 1, \u0026#34;label\u0026#34;: \u0026#34;1-9\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#F5A9A9\u0026#34;}, {\u0026#34;max\u0026#34;: 0, \u0026#34;min\u0026#34;: 0, \u0026#34;label\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#FFFFFF\u0026#34;}, ] ) ) map.add(\u0026#34;20200130中国疫情地图\u0026#34;, data_pair=province_distribution.items(), maptype=\u0026#34;china\u0026#34;, is_roam=True) map.render(\u0026#39;20200130中国1疫情地图.html\u0026#39;) 然后生成了一张图，看起来还行 但是昨天学习了API调用，以及进行可视化，今天怎么能用这么粗糙的方法来做统计，直接爬下来放到字典里然后用pyechart进行可视化岂不美哉\nmain.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 import matplotlib.pyplot as plt import numpy as np import json import requests from matplotlib.font_manager import FontProperties import re import os from pyecharts.charts import Line, Pie, Map from pyecharts import options as opts import pygal from pygal.style import LightColorizedStyle as LCS, LightenStyle as LS # 获取各省市今日的数据，存入josn文件 def get_province_data(month, day, province_name=None): file = open(\u0026#39;results/%d%d.json\u0026#39; % (month, day), \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) json_array = json.loads(file.read()) file.close() if not province_name: return json_array for json_object in json_array: if json_object[\u0026#39;provinceName\u0026#39;] == province_name: return json_object if json_object[\u0026#39;provinceShortName\u0026#39;] == province_name: return json_object return None def get_province_status(month, day, province_name=None): if province_name: print(province_name) json_object = get_province_data(month, day, province_name) data = [] for city in json_object[\u0026#39;cities\u0026#39;]: data.append((city[\u0026#39;cityName\u0026#39;], city[\u0026#39;confirmedCount\u0026#39;])) data.sort(key=lambda x: -x[1]) title = \u0026#39;%s2020年%d月%d日确诊病例\u0026#39; % (province_name, month, day) else: json_array = get_province_data(month, day, province_name) data = [] for province in json_array: data.append((province[\u0026#39;provinceShortName\u0026#39;], province[\u0026#39;confirmedCount\u0026#39;])) data.sort(key=lambda x: -x[1]) title = \u0026#39;全国2020年%d月%d日确诊病例\u0026#39; % (month, day) labels = [d[0] for d in data] counts = [d[1] for d in data] return labels, counts, title def show_province_status(month, day, province_name=None): labels, counts, title = get_province_status(month, day, province_name) # draw_pie(month, day, labels, counts, title) get_pyecharts_pie(month, day, labels, counts, title) #饼状图 def draw_pie(month, day, labels, counts, title): if len(labels) == 0: return labels = np.array(labels) counts = np.array(counts) title += \u0026#39;-%d例\u0026#39; % sum(counts) fig, ax = plt.subplots(figsize=(6, 3), subplot_kw=dict(aspect=\u0026#34;equal\u0026#34;)) explode = np.zeros(len(labels)) explode[np.argmax(counts)] = 0.1 wedges, texts = ax.pie(counts, wedgeprops=dict(width=0.5), startangle=-40, explode=explode) font = FontProperties(fname=\u0026#39;font/ZiXinFangYunYuanTi-2.ttf\u0026#39;) bbox_props = dict(boxstyle=\u0026#34;square,pad=0.3\u0026#34;, fc=\u0026#34;w\u0026#34;, ec=\u0026#34;k\u0026#34;, lw=0.72) kw = dict(arrowprops=dict(arrowstyle=\u0026#34;-\u0026#34;), bbox=bbox_props, zorder=0, va=\u0026#34;center\u0026#34;, fontproperties=font) for i, p in enumerate(wedges[:6]): ang = (p.theta2 - p.theta1) / 2. + p.theta1 y = np.sin(np.deg2rad(ang)) x = np.cos(np.deg2rad(ang)) horizontalalignment = {-1: \u0026#34;right\u0026#34;, 1: \u0026#34;left\u0026#34;}[int(np.sign(x))] connectionstyle = \u0026#34;angle,angleA=0,angleB={}\u0026#34;.format(ang) kw[\u0026#34;arrowprops\u0026#34;].update({\u0026#34;connectionstyle\u0026#34;: connectionstyle}) ax.annotate(\u0026#39;%s-%d例\u0026#39; % (labels[i], counts[i]), xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y), horizontalalignment=horizontalalignment, **kw) ax.set_title(title, fontproperties=font) root = \u0026#39;charts/%d%d\u0026#39; % (month, day) create_dir(root) plt.savefig(\u0026#39;%s/%s.jpg\u0026#39; % (root, title)) plt.show() def create_dir(root): if not os.path.exists(root): os.makedirs(root) def draw(month, day): provinces = get_province_data(month, day) for p in provinces: show_province_status(month, day, p[\u0026#39;provinceShortName\u0026#39;]) show_province_status(month, day) def get_html(month, day): import requests url = \u0026#39;http://3g.dxy.cn/newh5/view/pneumonia\u0026#39; response = requests.get(url) html = str(response.content, \u0026#39;UTF-8\u0026#39;) html_file = open(\u0026#39;results/%d%d.html\u0026#39; % (month, day), \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) html_file.write(html) html_file.close() json_file = open(\u0026#39;results/%d%d.json\u0026#39; % (month, day), \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) matches = re.findall(\u0026#39;\\[[^\u0026gt;]+\\]\u0026#39;, html) for match in matches: if \u0026#39;provinceName\u0026#39; in json.loads(match)[0]: json_file.write(match) break json_file.close() def compare(m1, d1, m2, d2): ps1 = get_province_data(m1, d1) ps2 = get_province_data(m2, d2) ps_dict1 = {} ps_dict2 = {} for p in ps1: ps_dict1[p[\u0026#39;provinceShortName\u0026#39;]] = p[\u0026#39;confirmedCount\u0026#39;] for p in ps2: ps_dict2[p[\u0026#39;provinceShortName\u0026#39;]] = p[\u0026#39;confirmedCount\u0026#39;] data = [] for key in ps_dict2: increased_count = ps_dict2[key] if key in ps_dict1: increased_count -= ps_dict1[key] data.append((key, increased_count)) data.sort(key=lambda x: -x[1]) labels = [d[0] for d in data] counts = [d[1] for d in data] title = \u0026#39;2020年%d月%d日全国新增确诊病例\u0026#39; % (m2, d2) draw_pie(m2, d2, labels, counts, title) get_pyecharts_pie(m2, d2, labels, counts, title) def get_pyecharts_pie(month, day, labels, counts, title): title += \u0026#39;-%d例\u0026#39; % (sum(counts)) c = ( Pie(init_opts=opts.InitOpts(width=\u0026#39;1200px\u0026#39;, height=\u0026#39;700px\u0026#39;)) .add( \u0026#34;\u0026#34;, [list(z) for z in zip(labels, counts)], radius=[\u0026#34;40%\u0026#34;, \u0026#34;80%\u0026#34;], center=[\u0026#39;50%\u0026#39;, \u0026#39;60%\u0026#39;], ) .set_global_opts( title_opts=opts.TitleOpts(title=title), legend_opts=opts.LegendOpts( orient=\u0026#34;vertical\u0026#34;, pos_top=\u0026#34;15%\u0026#34;, pos_left=\u0026#34;2%\u0026#34; ), ) .set_series_opts(label_opts=opts.LabelOpts(formatter=\u0026#34;{b}: {c}\u0026#34;)) ) root = \u0026#39;html-charts/%d%d\u0026#39; % (month, day) create_dir(root) c.render() c.render(\u0026#39;%s/%s.html\u0026#39; % (root, title)) return c def draw_tendency(month, day): dates = [\u0026#39;1-%d\u0026#39; % i for i in range(16, 30)] v0 = [4, 17, 59, 78, 92, 149, 131, 259, 444, 688, 769, 1771, 1459, 1576 ] v1 = [4, 17, 59, 77, 72, 105, 69, 105, 180, 323, 371, 1291, 840, 1032] c = ( Line() .add_xaxis(dates) .add_yaxis(\u0026#34;全国新增确诊病例\u0026#34;, v0, is_smooth=True, linestyle_opts=opts.LineStyleOpts(width=4, color=\u0026#39;#B44038\u0026#39;), itemstyle_opts=opts.ItemStyleOpts( color=\u0026#39;#B44038\u0026#39;, border_color=\u0026#34;#B44038\u0026#34;, border_width=5 )) .add_yaxis(\u0026#34;湖北新增确诊病例\u0026#34;, v1, is_smooth=True, linestyle_opts=opts.LineStyleOpts(width=2, color=\u0026#39;6FA0A7\u0026#39;), label_opts=opts.LabelOpts(position=\u0026#39;bottom\u0026#39;), itemstyle_opts=opts.ItemStyleOpts( color=\u0026#39;#6FA0A7\u0026#39;, border_color=\u0026#34;#6FA0A7\u0026#34;, border_width=3 )) .set_global_opts(title_opts=opts.TitleOpts(title=\u0026#34;\u0026#34;), yaxis_opts=opts.AxisOpts( type_=\u0026#34;log\u0026#34;, name=\u0026#34;y\u0026#34;, splitline_opts=opts.SplitLineOpts(is_show=True), is_scale=True, axisline_opts=opts.AxisLineOpts(is_show=False) ) ) ) c.render(\u0026#39;results/%d%d-新增病例趋势图.html\u0026#39; % (month, day)) return c def draw_map(month, day): labels, counts, title = get_province_status(month, day, None) c = ( Map() .add(\u0026#34;\u0026#34;, [list(z) for z in zip(labels, counts)], \u0026#34;china\u0026#34;) .set_global_opts( title_opts=opts.TitleOpts(title=\u0026#34;新型肺炎全国确诊病例\u0026#34;), visualmap_opts=opts.VisualMapOpts( pieces=[ {\u0026#39;min\u0026#39;: 1000, \u0026#39;color\u0026#39;: \u0026#39;#450704\u0026#39;}, {\u0026#39;max\u0026#39;: 999, \u0026#39;min\u0026#39;: 100, \u0026#39;color\u0026#39;: \u0026#39;#75140B\u0026#39;}, {\u0026#39;max\u0026#39;: 99, \u0026#39;min\u0026#39;: 10, \u0026#39;color\u0026#39;: \u0026#39;#AD2217\u0026#39;}, {\u0026#39;max\u0026#39;: 9, \u0026#39;min\u0026#39;: 1, \u0026#39;color\u0026#39;: \u0026#39;#DE605B\u0026#39;}, {\u0026#39;max\u0026#39;: 0, \u0026#39;color\u0026#39;: \u0026#39;#FFFEE7\u0026#39;}, ], is_piecewise=True ), ) ) c.render(\u0026#39;results/%d%d-疫情地图.html\u0026#39; % (month, day)) if __name__ == \u0026#39;__main__\u0026#39;: m, d = 1, 30 #get_html(m, d) #draw(m, d) #compare(1, 28, 1, 29) #show_province_status(m, d, \u0026#39;云南\u0026#39;) #show_province_status(m, d, None) draw_tendency(m, d) draw_map(m, d) 函数直接都放一个文件里面了，其实进行重构一下代码会更简洁一些\n","permalink":"https://csqread.top/posts/tech/2020-ncov%E7%88%AC%E8%99%AB%E7%BB%9F%E8%AE%A1/","summary":"刚开始我没想到用爬虫，就直接手创了一个字典\u0026hellip; 需要安装模块pyechart and pyechart-china-provinces-pypkg 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25","title":"2020 NCov爬虫统计"},{"content":"《拍电影时我在想的事》是戛纳电影节金棕榈奖得主是枝裕和历史8年，写下的首部自传性随笔集。是枝裕和在书中回顾三十余年的创作生涯，讲述每一部经典作品背后的传奇故事、缘起和理念，记录各个创作时期对电影的创作和思考，以及对世界和人生的看法。 其中不仅汇集了电影大师的哲思与灵光，更讲述了一位导演脚踏实地，从赊账拍片到斩获世界各大电影节奖项的励志旅程。《拍电影时我在想的事》在日本出版后，连续六次紧急加印，得到《朝日新闻》等各大媒体的高度评价，被盛赞到：哪怕再过100年，这本书也一定是作者的圣经，世界如此精彩，日常就很美丽，生命本身就是奇迹。是枝裕和打动世界的理由，都在这本书里。\n关于是枝裕和，大概是我在两年之前接触到的一位导演，那是因为室友推荐的一部电影《无人知晓》，看完之后感觉特别棒，就继续搜罗这他的电影资源，把他的电影大都看了一遍。其中不仅仅是无人知晓让我印象深刻，《如父如子》，《海街日记》，《比海更深》，《奇迹》都挺好看的。我就不一一剧透了，想看的话资源在页面最下面，是枝裕和蓝光合集。 关于他的这本书，看了之后发现其实是枝裕和开始的时候是拍纪录片起家的。那个时候和侯孝贤和杨德昌是同一个时代的导演。甚至是他俩的后来者。记得书中他说过，侯孝贤导演对他在电影上面也有过帮助呢。在开始的时候，是枝裕和使用分镜完成了他的处女作，幻之光，看了他画的分镜，挺有意思的，发现原来电影就是这样开始先是被简单的画出来的啊\n他的第一部电视纪录片的拍摄过程就他别传奇。采访自杀官员的遗孀，对方在一堆采访者中唯独接受是枝裕和的访问，其实是枝裕和也不知道为什么，事后她才道出原委：“你第一天来这里的时候，拘谨地坐在榻榻米上。当时的你，跟我丈夫和我相亲的样子特别像” 我讲述的电影语言，与以电影为母语的创作者所讲述的不同是带着电视口音的方言，也就是说，在语法上是不规范的。对电视的养育之情，我心怀感激，也坦率地承认自己“电视人”的身份。与此同时，我对目前所处的环境感到了某种责任。\n一些笔记： 关于分镜，他还曾被侯孝贤导演指出过： ‘知道被侯孝贤导演指出来，我才意识到自己“被分镜图绑住了手脚”’。 侯导来到日本参加东京电影节，见面时，他对我说：“技术很厉害，但是在拍摄之前，你早就画好了所有的分镜图吧？” “是的，画了，当时的我特别没有自信”我回答。 “不是应该看了演员的表演之后，才确定摄影机的位置吗？你以前是拍记录片的应该知道啊。”\n他对于虚构作品和纪录片的理解： “我一直认为，虚构作品要令观众‘沉醉’，而纪录片”则要让观众清醒。\n“比起有意义的死，不如去发现有意义却丰富的生”作为想法，这是正确的。但是从拍摄的电影来看，与带着这种意识拍摄面成的《花之舞者》相比，将生的实感通过细节表现出来的下一部电影《步履不停》，更明显地体现了这种价值观。\n电影并非空喊口号的东西，它是为了表达生命真实丰富的感受而1存在的。现在我正义这一点为目标而努力\n“在《无人知晓》中，我不想探讨谁对谁错的问题，也不想追究大人应该如何对待孩子，以及围绕孩子的法律应该如何修改等等。所谓的批判，教训和建议都不是我想讲的。我真正想做的是讲述孩子们的日常生活，以及在一旁观察他们，倾听他们的声音。这样一来，孩子们的话语就不再是独白，而是变成了对话。同样孩子们也通过双眼观察着我们”-（这应该是是枝裕和拍纪录片时养成的习惯）\n“我仍然要坚持这样来拍摄《无人知晓》，并非从单纯的黑与白的对立出发，而是从灰色的视角记录世界。没有纯粹的英雄或坏人只是如实的描述我们生活的这个由相对主义价值观构筑的世界”\n“明显的不同在于，在西方人看来，死亡始于生命的终结，也就是说生与死是两个对立的概念。但是在东方人（特别是日本人）看来，生与死是表里一本的，两者的关系甚至有点亲近。死亡未必始于生命的终结，死常常存在于圣的内部。这个观念一直以来都存在于我的思想中”\n“在欧洲，我反复被问到‘为什么您的作品中经常并不出现的死者，为什么不讲述死亡，而是常常讲述死后的世界’，我一直苦于如何回答，当时却不知不觉地说出了这样的答案：日本到某个时期为止，一直都有‘无颜面对祖先’地观念。日本没有绝对权威的神明，但是在日常生活中存在这一种伦理观：应该活得对得起死去的人。我也怀着这样的伦理观。因此在日本文化中的‘死者’代替了西方文化中的‘神’。死去的人并不是就这样离开了世间，而是从外部批判我们的生活，承担着伦理规范的作用1.也就是说，从故事外部批判我们的是死者，而站在故事内部承担这一角色的是孩子” -原来如父如子也是这样的观念啊\n对于死亡，是枝裕和所认为的与村上春树在《挪威的森林》中所写的几乎一模一样：“生常常存在与死的内部”。他们都认为，日本传统文化中一味看重“有意义的死”并非病态文化，没有实实在在生活过的实感，是无法去探讨死亡的意义的。这点和黑泽明在《梦》中所表现的也一样。死去的桃树化为桃树神，从外部批判着我们的生活。日本是一个泛灵的国家，万物皆有灵气，这一点在《千与千寻》，《幽灵公主》等宫崎骏的动漫中也可得以一窥。在《菊与刀》中更是系统的阐述了这一点。\n“游走在网络上的人为u什么普遍是右翼，或者是国家主义者？思考这个问题，会发现与他人缺乏紧密联系的人容易沉迷于网络世界，‘国家’这种概念轻轻松松就会将他们收编，成为他们内心唯一的价值观。在现代日本，所谓的地区共同体已经趋向崩溃，企业共同体随着终身雇佣制度一起消亡，家庭内的关系也越发越远。因此，如果没有可以代替共同体和家庭的事务、场所和价值观，将会有越来越多的人陷入虚幻的国家主义之中” 这么说来来我们人均陷入了虚幻的国家主义，难道因为天朝是家国情怀？\n一些想法： 看完这本书我知道了《无人知晓》是如何拍出来的，《小偷家族》是在表达什么。是枝裕和的电影观念可以这样表达：比起有意义的死，不如去发现无意义却丰富的生。\n电影并非高喊口号的东西，它就是为了表达生命真实丰富的感受而存在的。 有人问是枝裕和，在《无人知晓》中，作为导演你没有对电影中的人物进行道德上的审判，甚至没有指责抛弃孩子的母亲。是枝裕和是这样回答：\n电影不是用来审判人的，电影导演也不是法官。设计一个坏蛋可能会让故事（世界）更易于理解，但是不这样做，反而能让观众将电影中的问题带入日常生活中去思考。 因为观众是要回归日常生活的，每一个观众都要在电影结束后离开电影院。如果一个观众能够看完电影之后，对生活的看法会有所改变，这或许会成为他们带着批判性的视角观察日常生活的契机。\n是的，我喜欢这样的电影哲学，所谓的批判留给其他人，电影只带给观众真实生活的感受。杨德昌说：电影发明之后，人类的生命，比以前延长了三倍。而在观看好莱坞大片时，我们的生活近乎暂停了两个小时。但在观看这种电影时，我们并没有离开生活。所有的电影观众，无一例外的都要在电影散场之后，必须回到他们的日常生活。是枝裕和就这样影响了我们的生活，像他所说 “如果说我的电影中更有共通的东西，那就是无法取代的珍贵之物不在日常生活之外，而是蕴藏在日常生活的细枝末节里”\n是枝裕和合集： 链接：https://pan.baidu.com/s/1dUz8weNnzyc9s3zpKUCO_Q 提取码：janz\n","permalink":"https://csqread.top/posts/read/%E6%88%91%E5%9C%A8%E6%8B%8D%E7%94%B5%E5%BD%B1%E6%97%B6%E6%83%B3%E7%9A%84%E4%BA%8B-%E6%98%AF%E6%9E%9D%E8%A3%95%E5%92%8C/","summary":"《拍电影时我在想的事》是戛纳电影节金棕榈奖得主是枝裕和历史8年，写下的首部自传性随笔集。是枝裕和在书中回顾三十余年的创作生涯，讲述每一部经典","title":"‘我在拍电影时想的事‘ 是枝裕和"}]