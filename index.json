[{"content":"这篇文章主要记录我搭建hugo博客的过程，包括搭建过程中遇到的问题及解决方法\n1、新建github仓库 新建respository, Respository的名称为 \u0026ldquo;你的github名称.github.io\u0026rdquo;.\n2、下载并安装对应版本的hugo 下载链接: 点击选择hugo版本下载\n3、创建hugo网站 进入想要存放网站的文件夹，输入以下命令:\n1 hugo new site demo-blog 4、选择主题 输入命令下载主题:\n1 git clone https://github.com/adityatelange/hugo-PaperMod.git 使用该主题的方法就是在站点文件夹下的配置文件里输入主题的名字:\n然后把主题文件夹里面的一些静态文件和配置文件复制到站点目录下，目的是为了可以自定义博客的样式，而不会改动主题文件夹里的样式，这样主题要更新的时候，直接在主题目录下git pull就可以，站点目录的修改会优先覆盖主题里的配置，所以可以实现平滑更新\n","permalink":"https://csqread.top/posts/blog/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"这篇文章主要记录我搭建hugo博客的过程，包括搭建过程中遇到的问题及解决方法 1、新建github仓库 新建respository, Respos","title":"Hugo博客搭建"},{"content":"Spring 什么是Spring框架 Spring是一种轻量级框架，旨在提高开发人员的开发效率和系统的可维护性。 我们一般说的Spring框架就是SPring Framework，他是很多模块的集合，使用这些模块可以很方便的协助我们进行开发。这些模块是核心容器、数据访问/集成、web、aop、工具、消息和测试模块。比如Core Container中的Core组件是Spring所有组件的核心，Beans组件和Context组件是实现IOC和DI的基础，AOP组件用来实现面向切面编程。\nSpring官网列出来的Spring的6个特征:\n核心技术：依赖注入，aop，事件，资源，i18n，验证，数据绑定，类型转换，SpEL 测试：模拟对象，TestContext框架，SPringMVC测试，WebTestClient 数据访问:事务，DAO支持，JDBC，ORM，编组XML Web支持:Spring MVC和SPring WebFlux Web框架 集成:远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存 语言：Kotlin，Groovy，动态语言 Spring中的单例bean的线程安全问题了解吗？ 大部分我们并没有在系统中使用多线程，所以很少有人会关注这个问题。单例bean存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。\n有两种常见解决方案： 1、在bean对象中尽量避免定义可变的成员变量。 2、在类中定义一个ThreadLocal成员变量，将需要的可变的成员变量保存在ThreadLocal中。\nSpring中的bean生命周期？ Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类：\nBean自身的方法：这个包括了Bean本身调用的方法和通过配置文件中的init-method和destroy-method指定的方法 Bean级生命周期接口方法：这个包括了BeanNameAware、BeanFactoryAware、ApplicationContext;当然也包括InitializingBean和DiposableBean这些接口的方法 容器级生命周期接口方法：这个包括了InstantiationAwareBeanPostProcessor和BeanPostProcessor这两个接口实现，一般称它们的实现类为“后处理器” 工厂后处理器接口方法：这个包括了AspectJWeavingEnabler,ConfigurationClassPostProcessor,CustomAutowireConfigurer等等非常有用的工厂后处理接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。 如何将Bean从XML配置中解析后放到IoC容器中得？ 初始化的入口 对于xml配置的Spring应用，在main()方法中实例化ClasspathXmlApplication即可创建一个IoC容器。我们可以从这个构造方法开始，探究一下IoC容器的初始化过程。\n1 2 // create and configure beans ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;aspects.xml\u0026#34;, \u0026#34;daos.xml\u0026#34;, \u0026#34;services.xml\u0026#34;); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public ClassPathXmlApplicationContext(String... configLocations) throws BeansException { this(configLocations, true, (ApplicationContext)null); } public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException { // 设置Bean资源加载器 super(parent); // 设置配置路径 this.setConfigLocations(configLocations); // 初始化容器 if (refresh) { this.refresh(); } } 设置资源解析器和环境 调用父类容器AbstractApplicationContext的构造方法(super(parent)方法)为容器设置好Bean资源加载器\n1 2 3 4 5 6 7 public AbstractApplicationContext(@Nullable ApplicationContext parent) { // 默认构造函数初始化容器id, name, 状态 以及 资源解析器 this(); // 将父容器的Environment合并到当前容器 this.setParent(parent); } 通过AbstractApplicationContext默认构造器初始化容器id,name,状态以及资源解析器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public AbstractApplicationContext() { this.logger = LogFactory.getLog(this.getClass()); this.id = ObjectUtils.identityToString(this); this.displayName = ObjectUtils.identityToString(this); this.beanFactoryPostProcessors = new ArrayList(); this.active = new AtomicBoolean(); this.closed = new AtomicBoolean(); this.startupShutdownMonitor = new Object(); this.applicationStartup = ApplicationStartup.DEFAULT; this.applicationListeners = new LinkedHashSet(); this.resourcePatternResolver = this.getResourcePatternResolver(); } // Spring资源加载器 protected ResourcePatternResolver getResourcePatternResolver() { return new PathMatchingResourcePatternResolver(this); } 通过AbstractApplicationContext的setParent(parent)方法将父容器的Enviroment合并到当前容器\n1 2 3 4 5 6 7 8 9 public void setParent(@Nullable ApplicationContext parent) { this.parent = parent; if (parent != null) { Environment parentEnvironment = parent.getEnvironment(); if (parentEnvironment instanceof ConfigurableEnvironment) { this.getEnvironment().merge((ConfigurableEnvironment)parentEnvironment); } } } 设置配置路径 在设置容器的资源加载器之后，接下来FileSystemXmlApplicationContent执行setConfigLocations方法通过调用其父类AbstractRefreshableConfigApplicationContext的方法进行对Bean定义资源文件的定位。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public void setConfigLocations(@Nullable String... locations) { if (locations != null) { Assert.noNullElements(locations, \u0026#34;Config locations must not be null\u0026#34;); this.configLocations = new String[locations.length]; for(int i = 0; i \u0026lt; locations.length; ++i) { // 解析配置路径 this.configLocations[i] = this.resolvePath(locations[i]).trim(); } } else { this.configLocations = null; } } protected String resolvePath(String path) { // 从上一步Environment中解析 return this.getEnvironment().resolveRequiredPlaceholders(path); } 初始化的主体流程 Spring IoC容器对Bean定义资源的加载是从refresh()函数开始的，refresh()是一个模板方法，refresh()方法的作用是：在创建IoC容器前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh()之后使用的是新建立起来的IoC容器。refresh的作用类似于对IoC容器的重启，在新建立好的容器中对容器进行初始化，对Bean定义资源进行载入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @Override public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { StartupStep contextRefresh = this.applicationStartup.start(\u0026#34;spring.context.refresh\u0026#34;); // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try { // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(\u0026#34;spring.context.beans.post-process\u0026#34;); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); } catch (BeansException ex) { if (logger.isWarnEnabled()) { logger.warn(\u0026#34;Exception encountered during context initialization - \u0026#34; + \u0026#34;cancelling refresh attempt: \u0026#34; + ex); } // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset \u0026#39;active\u0026#39; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; } finally { // Reset common introspection caches in Spring\u0026#39;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); contextRefresh.end(); } } } 这里的设计上是一个非常典型的资源类加载处理型的思路\n模板方法设计模式，模板方法中使用典型的钩子方法 将具体的初始化加载方法插入到钩子方法之间 将初始化的阶段封装，用来记录当前初始化到什么阶段；常见的设计是xxxPhase/xxxStage 资源加载初始化有失败等处理，必然是try/catch/finally 初始化BeanFactory之obtainFreshBeanFactory AbstractApplicationContext的obtainFreshBeanFactory()方法调用子类容器的refreshBeanFactory()方法，启动容器载入Bean定义资源文件的过程，代码如下\n1 2 3 4 5 protected ConfigurableListableBeanFactory obtainFreshBeanFactory() { // 这里使用了委派设计模式，父类定义了抽象的refreshBeanFactory()方法，具体实现调用子类容器的refreshBeanFactory()方法 refreshBeanFactory(); return getBeanFactory(); } AbstractApplicationCOntext类中只抽象定义了refreshBeanFactory()方法，容器真正调用的是子类的AbstractRefreshableApplicationContext实现的refreshBeanFactory（）方法留在创建IoC容器之前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IoC容器。方法源码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 protected final void refreshBeanFactory() throws BeansException { // 如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IoC容器 if (hasBeanFactory()) { destroyBeans(); closeBeanFactory(); } try { // 创建DefaultListableBeanFactory，并调用loadBeanDefinitions(beanFactory)装载bean定义 DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); // 对IoC容器进行定制化，如设置启动参数，开启注解的自动装配等 loadBeanDefinitions(beanFactory); // 调用载入Bean定义的方法，主要这里又使用了一个委派模式，在当前类中只定义了抽象的loadBeanDefinitions方法，具体的实现调用子类容器 this.beanFactory = beanFactory; } catch (IOException ex) { throw new ApplicationContextException(\u0026#34;I/O error parsing bean definition source for \u0026#34; + getDisplayName(), ex); } } 初始化BeanFactory之loadBeanDefinitions AbstractRefreshableApplicationContext中只定义了抽象的loadBeanDefinitions方法，容器真正调用的是其子类的AbstractXmlApplicationContext对该方法的实现，AbstractXmlApplicationContext的主要源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException { // 创建XmlBeanDefinitionReader，即创建Bean读取器，并通过回调设置到容器中去，容器使用该读取器读取Bean定义资源 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // 配置上下文的环境，资源加载器、解析器 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 为Bean读取器设置SAX xml解析器 // 允许子类自行初始化（比如校验机制），并提供真正的加载方法 initBeanDefinitionReader(beanDefinitionReader); // 当Bean读取器读取Bean定义的Xml资源文件时，启用Xml的校验机制 loadBeanDefinitions(beanDefinitionReader); } protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException { // 加载XML配置方式里的Bean定义的资源 Resource[] configResources = getConfigResources(); if (configResources != null) { reader.loadBeanDefinitions(configResources); } // 加载构造函数里配置的Bean配置文件，即{\u0026#34;aspects.xml\u0026#34;, \u0026#34;daos.xml\u0026#34;, \u0026#34;services.xml\u0026#34;} String[] configLocations = getConfigLocations(); if (configLocations != null) { reader.loadBeanDefinitions(configLocations); } } Xml Bean读取器(XmBeanDefinitionReader)调用其父类AbstractBeanDefinitionReader的reader.loadBeanDefinitions方法读取bean定义资源\n由于我们使用ClassPathXmlApplicationCOntext作为例子分析，因此getConfigResources的返回值为null，因此程序执行reader,loadBeanDefinitions(configLocations)分支。\nAbstractBeanDefinitionReader读取Bean定义资源 AbstractBeanDifinitionReader的loadBeanDefinitions方法源码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Override public int loadBeanDefinitions(String location) throws BeanDefinitionStoreException { return loadBeanDefinitions(location, null); } public int loadBeanDefinitions(String location, @Nullable Set\u0026lt;Resource\u0026gt; actualResources) throws BeanDefinitionStoreException { ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) { throw new BeanDefinitionStoreException( \u0026#34;Cannot load bean definitions from location [\u0026#34; + location + \u0026#34;]: no ResourceLoader available\u0026#34;); } // 模式匹配类型的解析器，这种方式是加载多个满足匹配条件的资源 if (resourceLoader instanceof ResourcePatternResolver) { try { // 获取到要加载的资源 Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); int count = loadBeanDefinitions(resources); // 委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能 if (actualResources != null) { Collections.addAll(actualResources, resources); } if (logger.isTraceEnabled()) { logger.trace(\u0026#34;Loaded \u0026#34; + count + \u0026#34; bean definitions from location pattern [\u0026#34; + location + \u0026#34;]\u0026#34;); } return count; } catch (IOException ex) { throw new BeanDefinitionStoreException( \u0026#34;Could not resolve bean definition resource pattern [\u0026#34; + location + \u0026#34;]\u0026#34;, ex); } } else { // 只能通过绝对路径URL加载单个资源. Resource resource = resourceLoader.getResource(location); int count = loadBeanDefinitions(resource); if (actualResources != null) { actualResources.add(resource); } if (logger.isTraceEnabled()) { logger.trace(\u0026#34;Loaded \u0026#34; + count + \u0026#34; bean definitions from location [\u0026#34; + location + \u0026#34;]\u0026#34;); } return count; } } 从对AbstractBeanDefinitionReader的loadBeanDefinitions方法源码分析可以看出该方法做了以下两件事:\n1、首先，调用资源加载器的获取资源方法resourceLoader.getResource(location)，获取到要加载的资源。 2、其次，真正执行加载功能的是其子类XmlBeanDefinitionReader的loadBeanDefinitions方法\nXmlBeanDefinitionReader加载Bean定义资源 继续看子类XmlBeanDefinitionReader的loadBeanDefinitions(Resource\u0026hellip;)方法看到代表bean文件的资源定义以后的载入过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 /** * 本质上是加载XML配置的Bean。 * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file */ protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException { try { Document doc = doLoadDocument(inputSource, resource); // 将Bean定义资源转换成Document对象 int count = registerBeanDefinitions(doc, resource); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Loaded \u0026#34; + count + \u0026#34; bean definitions from \u0026#34; + resource); } return count; } catch (BeanDefinitionStoreException ex) { throw ex; } catch (SAXParseException ex) { throw new XmlBeanDefinitionStoreException(resource.getDescription(), \u0026#34;Line \u0026#34; + ex.getLineNumber() + \u0026#34; in XML document from \u0026#34; + resource + \u0026#34; is invalid\u0026#34;, ex); } catch (SAXException ex) { throw new XmlBeanDefinitionStoreException(resource.getDescription(), \u0026#34;XML document from \u0026#34; + resource + \u0026#34; is invalid\u0026#34;, ex); } catch (ParserConfigurationException ex) { throw new BeanDefinitionStoreException(resource.getDescription(), \u0026#34;Parser configuration exception parsing XML from \u0026#34; + resource, ex); } catch (IOException ex) { throw new BeanDefinitionStoreException(resource.getDescription(), \u0026#34;IOException parsing XML document from \u0026#34; + resource, ex); } catch (Throwable ex) { throw new BeanDefinitionStoreException(resource.getDescription(), \u0026#34;Unexpected exception parsing XML document from \u0026#34; + resource, ex); } } // 使用配置的DocumentLoader加载XML定义文件为Document. protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception { return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware()); } 通过源码分析，载入Bean定义资源文件的最后一步是将Bean定义资源转换为Document对象，该过程由documentLoader实现\nDocumentLoader将Bean定义资源转换为Document对象 DocumentLoader将Bean定义资源转换为Document对象的源码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // 使用标准的JAXP将载入的Bean定义资源转换成document对象 @Override public Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception { // 创建文件解析器工厂 DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isTraceEnabled()) { logger.trace(\u0026#34;Using JAXP provider [\u0026#34; + factory.getClass().getName() + \u0026#34;]\u0026#34;); } // 创建文档解析器 DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); return builder.parse(inputSource); // 解析 } protected DocumentBuilderFactory createDocumentBuilderFactory(int validationMode, boolean namespaceAware) throws ParserConfigurationException { DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setNamespaceAware(namespaceAware); // 设置解析XML的校验 if (validationMode != XmlValidationModeDetector.VALIDATION_NONE) { factory.setValidating(true); if (validationMode == XmlValidationModeDetector.VALIDATION_XSD) { // Enforce namespace aware for XSD... factory.setNamespaceAware(true); try { factory.setAttribute(SCHEMA_LANGUAGE_ATTRIBUTE, XSD_SCHEMA_LANGUAGE); } catch (IllegalArgumentException ex) { ParserConfigurationException pcex = new ParserConfigurationException( \u0026#34;Unable to validate using XSD: Your JAXP provider [\u0026#34; + factory + \u0026#34;] does not support XML Schema. Are you running on Java 1.4 with Apache Crimson? \u0026#34; + \u0026#34;Upgrade to Apache Xerces (or Java 1.5) for full XSD support.\u0026#34;); pcex.initCause(ex); throw pcex; } } } return factory; } 该解析过程调用JavaEE标准的JAXP标准进行处理。\n至此Spring IoC容器根据定位的Bean定义资源文件，将其加载读入并转换成为Document对象过程完成。\n接下来我们继续分析Spring IoC容器将载入的Bean定义资源文件转换为Document对象之后，是如何将其解析为Spring IoC管理的Bean对象，并将其注册到容器中的。\nXmlBeanDefinitionReader解析载入的Bean定义资源文件 XmlBeanDefinitionReader类中的doLoadBeanDefinitions方法是从特定的XML文件中实际载入Bean定义资源的方法，该方法在载入Bean定义资源之后将其转换为Document对象，接下来调用registerBeanDefinitions启动Spring IoC容器对Bean定义的解析过程，registerBeanDefinition方法源码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 按照Spring的Bean语义要求将Bean定义资源解析并转换为容器内部数据结构 public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); // 解析过程入口，这里使用了委派模式，具体的解析实现过程有实现类DefaultBeanDefinitionDocumentReader完成 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore; // 返回此次解析了多少个对象 } // 创建BeanDefinitionDocumentReader对象，解析Document对象 protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() { return BeanUtils.instantiateClass(this.documentReaderClass); } /** * Create the {@link XmlReaderContext} to pass over to the document reader. */ public XmlReaderContext createReaderContext(Resource resource) { return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver()); } Bean定义资源的载入解析分为以下两个过程:\n1、首先，通过调用XML解析器将Bean定义资源文件转换得到Document对象，但是这些Document对象并没有按照Spring的Bean规则进行解析。这一部是载入的过程 2、其次，在完成通用的XML解析之后，按照Spring的Bean规则对Document对象进行解析。\n按照Spring的Bean规则对Document对象解析的过程是在接口BeanDifinitionDocumentReader的实现类DefaultBeanDefinitionDocumentReader中实现的。\nDefaultBeanDefinitionDocumentReader对bean定义的Document对象解析 BeanDefinitionDocumentReader接口通过registerBeanDefinitions方法调用其实现类DefaultBeanDefinitionDocumentReader对Document对象进行解析，解析代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Override public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) { this.readerContext = readerContext; doRegisterBeanDefinitions(doc.getDocumentElement()); } // 注册\u0026lt;beans/\u0026gt;配置的Beans @SuppressWarnings(\u0026#34;deprecation\u0026#34;) // for Environment.acceptsProfiles(String...) protected void doRegisterBeanDefinitions(Element root) { // Any nested \u0026lt;beans\u0026gt; elements will cause recursion in this method. In // order to propagate and preserve \u0026lt;beans\u0026gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) { String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) { String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); // We cannot use Profiles.of(...) since profile expressions are not supported // in XML config. See SPR-12458 for details. if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Skipped XML bean definition file due to specified profiles [\u0026#34; + profileSpec + \u0026#34;] not matching: \u0026#34; + getReaderContext().getResource()); } return; } } } preProcessXml(root); parseBeanDefinitions(root, this.delegate); // 从Document的根元素开始进行Bean定义的Document对象 postProcessXml(root); this.delegate = parent; } BeanDefinitionParserDelegate 解析Bean定义资源文件生成BeanDefinition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 /** * Parse the elements at the root level in the document: * \u0026#34;import\u0026#34;, \u0026#34;alias\u0026#34;, \u0026#34;bean\u0026#34;. * @param root the DOM root element of the document */ protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { if (delegate.isDefaultNamespace(root)) { NodeList nl = root.getChildNodes(); for (int i = 0; i \u0026lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) { parseDefaultElement(ele, delegate); } else { delegate.parseCustomElement(ele); } } } } else { delegate.parseCustomElement(root); } } private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) { // 如果元素节点是\u0026lt;Import\u0026gt;导入元素，进行导入解析 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) { importBeanDefinitionResource(ele); } // 如果元素节点是\u0026lt;Alias\u0026gt;别名元素，进行别名解析 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) { processAliasRegistration(ele); } // 如果元素节点\u0026lt;Bean\u0026gt;元素, 按照Spring的Bean规则解析元素 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) { processBeanDefinition(ele, delegate); } // 如果元素节点\u0026lt;Beans\u0026gt;元素，即它是嵌套类型的 else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) { // 递归解析 doRegisterBeanDefinitions(ele); } } 解析Bean生成BeanDefinitionHolder的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * Process the given bean element, parsing the bean definition * and registering it with the registry. */ protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) { BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) { bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try { // 注册最终的装饰实例 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); } catch (BeanDefinitionStoreException ex) { getReaderContext().error(\u0026#34;Failed to register bean definition with name \u0026#39;\u0026#34; + bdHolder.getBeanName() + \u0026#34;\u0026#39;\u0026#34;, ele, ex); } // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); } } 解析过后的BeanDefinition在IoC容器中注册 Document对象的解析后得到封装BeanDefinition的BeanDifinitionHold对象，然后调用BeanDefinitionReaderUtils的registerBeanDefinition方法向IoC容器注册解析的Bean，BeanDefinitionReaderUtils的注册的源码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 通过BeanDefinitionRegistry将BeanDefinitionHolder注册到BeanFactory public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException { // Register bean definition under primary name. String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. String[] aliases = definitionHolder.getAliases(); if (aliases != null) { for (String alias : aliases) { registry.registerAlias(beanName, alias); } } } 当调用BeanDefinitionReaderUtils向IoC容器注册解析的BeanDefinition时，真正完成注册功能的是DefaultListableBeanFactory.\nDefaultListableBeanFactory 向IoC容器注册解析后的BeanDefinition IoC容器本质上就是一个beanDefinitionMap，注册即将BeanDefinition put 到map中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 /** Map of bean definition objects, keyed by bean name. */ private final Map\u0026lt;String, BeanDefinition\u0026gt; beanDefinitionMap = new ConcurrentHashMap\u0026lt;\u0026gt;(256); /** Map from bean name to merged BeanDefinitionHolder. */ private final Map\u0026lt;String, BeanDefinitionHolder\u0026gt; mergedBeanDefinitionHolders = new ConcurrentHashMap\u0026lt;\u0026gt;(256); @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { Assert.hasText(beanName, \u0026#34;Bean name must not be empty\u0026#34;); Assert.notNull(beanDefinition, \u0026#34;BeanDefinition must not be null\u0026#34;); if (beanDefinition instanceof AbstractBeanDefinition) { try { ((AbstractBeanDefinition) beanDefinition).validate(); } catch (BeanDefinitionValidationException ex) { throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \u0026#34;Validation of bean definition failed\u0026#34;, ex); } } BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName); // 如果已经注册 if (existingDefinition != null) { // 检查是否可以覆盖 if (!isAllowBeanDefinitionOverriding()) { throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition); } else if (existingDefinition.getRole() \u0026lt; beanDefinition.getRole()) { // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE if (logger.isInfoEnabled()) { logger.info(\u0026#34;Overriding user-defined bean definition for bean \u0026#39;\u0026#34; + beanName + \u0026#34;\u0026#39; with a framework-generated bean definition: replacing [\u0026#34; + existingDefinition + \u0026#34;] with [\u0026#34; + beanDefinition + \u0026#34;]\u0026#34;); } } else if (!beanDefinition.equals(existingDefinition)) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Overriding bean definition for bean \u0026#39;\u0026#34; + beanName + \u0026#34;\u0026#39; with a different definition: replacing [\u0026#34; + existingDefinition + \u0026#34;] with [\u0026#34; + beanDefinition + \u0026#34;]\u0026#34;); } } else { if (logger.isTraceEnabled()) { logger.trace(\u0026#34;Overriding bean definition for bean \u0026#39;\u0026#34; + beanName + \u0026#34;\u0026#39; with an equivalent definition: replacing [\u0026#34; + existingDefinition + \u0026#34;] with [\u0026#34; + beanDefinition + \u0026#34;]\u0026#34;); } } // 覆盖 this.beanDefinitionMap.put(beanName, beanDefinition); } else { if (hasBeanCreationStarted()) { // Cannot modify startup-time collection elements anymore (for stable iteration) synchronized (this.beanDefinitionMap) { this.beanDefinitionMap.put(beanName, beanDefinition); List\u0026lt;String\u0026gt; updatedDefinitions = new ArrayList\u0026lt;\u0026gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; removeManualSingletonName(beanName); } } else { // Still in startup registration phase this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); removeManualSingletonName(beanName); } //重置所有已经注册过的BeanDefinition的缓存 this.frozenBeanDefinitionNames = null; } if (existingDefinition != null || containsSingleton(beanName)) { resetBeanDefinition(beanName); } else if (isConfigurationFrozen()) { clearByTypeCache(); } } 至此，Bean定义资源文件中配置的Bean被解析过后，已经注册到IoC容器中，被容器管理起来，真正完成了IoC容器初始化所做的全部工作。现在IoC容器中已经建立了整个Bean的配置信息，这些BeanDefinition信息已经可以使用，并且可以被检索，IoC容器的作用就是对这些注册的Bean定义信息进行处理和维护。这些的注册的Bean定义信息是IoC容器控制反转的基础，正是有了这些注册的数据，容器才可以进行依赖注入。\n总结 现在通过上面的代码，总结一下IoC容器初始化的基本步骤：\n初始化的入口在容器实现中的refresh()调用来完成 对bean定义载入IoC容器使用的方法是loadBeanDefinition，其中大致过程如下：\n1、通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给出了ResourceLoader的实现，可以从类路径，文件系统，URL等方式来定义为资源位置。如果是XmlBeanFactory作为IOC容器，那么需要为它指定bean定义的资源，也就是说bean定义文件时通过抽象成Resource来被IOC容器处理的。 2、通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册，往往使用的是XmlBeanDefinitionReader来解析bean的xml定义文件-实际的处理过程是委托给BeanDefinitionParserDelegate来完成的，从而得到bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示-这个名字可以让我们想到loadBeanDefinition,RegisterBeanDefinition这些相关方法-他们都是为处理BeanDefinitin服务的。 3、容器解析得到BeanDefinition以后，需要把它在IOC容器中注册，这由IOC实现BeanDefinitionRegister接口来实现。注册过程就是在IOC容器内部维护一个HashMap来保存得到的BeanDefinition的过程。这个HashMap是IoC容器持有bean信息的场所，以后对bean的操作都是围绕这个HashMap来实现的。\n然后我们就可以通过BeanFactory和ApplicationCOntext来享受到SPring IOC的服务了，在使用IoC容器的时候，我们注意到除了少量粘合代码，绝大多数以正确IoC风格编写的应用程序代码完全不用关心如何到达工厂，因为容器将把这些对象与容器管理的其他对象钩在一起。基本的策略是把工厂放到已知的地方，最好是放在对预期使用的上下文有意义的地方，以及代码将实际需要访问工厂的地方。Spring本身提供了对声明式载入Web应用程序用法的应用程序上下文，并将其存储在ServletContext中的框架实现。 Spring中getBean的主体思路 BeanFactory实现getBean方法在AbstractBeanFactory中，这个方法重载都是调用doGetBean方法进行实现的:\n1 2 3 4 5 6 7 8 9 10 11 12 13 public Object getBean(String name) throws BeansException { return doGetBean(name, null, null, false); } public \u0026lt;T\u0026gt; T getBean(String name, Class\u0026lt;T\u0026gt; requiredType) throws BeansException { return doGetBean(name, requiredType, null, false); } public Object getBean(String name, Object... args) throws BeansException { return doGetBean(name, null, args, false); } public \u0026lt;T\u0026gt; T getBean(String name, @Nullable Class\u0026lt;T\u0026gt; requiredType, @Nullable Object... args) throws BeansException { return doGetBean(name, requiredType, args, false); } 接下来看下doGetBean方法(这个方法很长，我们主要看它的整体思路和设计要点):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 // 参数typeCheckOnly：bean实例是否包含一个类型检查 protected \u0026lt;T\u0026gt; T doGetBean( String name, @Nullable Class\u0026lt;T\u0026gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException { // 解析bean的真正name，如果bean是工厂类，name前缀会加\u0026amp;，需要去掉 String beanName = transformedBeanName(name); Object beanInstance; // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null \u0026amp;\u0026amp; args == null) { // 无参单例从缓存中获取 beanInstance = getObjectForBeanInstance(sharedInstance, name, beanName, null); } else { // 如果bean实例还在创建中，则直接抛出异常 if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } // 如果 bean definition 存在于父的bean工厂中，委派给父Bean工厂获取 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null \u0026amp;\u0026amp; !containsBeanDefinition(beanName)) { // Not found -\u0026gt; check parent. String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); } else if (requiredType != null) { // No args -\u0026gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); } else { return (T) parentBeanFactory.getBean(nameToLookup); } } if (!typeCheckOnly) { // 将当前bean实例放入alreadyCreated集合里，标识这个bean准备创建了 markBeanAsCreated(beanName); } StartupStep beanCreation = this.applicationStartup.start(\u0026#34;spring.beans.instantiate\u0026#34;) .tag(\u0026#34;beanName\u0026#34;, name); try { if (requiredType != null) { beanCreation.tag(\u0026#34;beanType\u0026#34;, requiredType::toString); } RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 确保它的依赖也被初始化了. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { if (isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \u0026#34;Circular depends-on relationship between \u0026#39;\u0026#34; + beanName + \u0026#34;\u0026#39; and \u0026#39;\u0026#34; + dep + \u0026#34;\u0026#39;\u0026#34;); } registerDependentBean(dep, beanName); try { getBean(dep); // 初始化它依赖的Bean } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \u0026#34;\u0026#39;\u0026#34; + beanName + \u0026#34;\u0026#39; depends on missing bean \u0026#39;\u0026#34; + dep + \u0026#34;\u0026#39;\u0026#34;, ex); } } } // 创建Bean实例：单例 if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, () -\u0026gt; { try { // 真正创建bean的方法 return createBean(beanName, mbd, args); } catch (BeansException ex) { // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; } }); beanInstance = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } // 创建Bean实例：原型 else if (mbd.isPrototype()) { // It\u0026#39;s a prototype -\u0026gt; create a new instance. Object prototypeInstance = null; try { beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } beanInstance = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); } // 创建Bean实例：根据bean的scope创建 else { String scopeName = mbd.getScope(); if (!StringUtils.hasLength(scopeName)) { throw new IllegalStateException(\u0026#34;No scope name defined for bean ´\u0026#34; + beanName + \u0026#34;\u0026#39;\u0026#34;); } Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException(\u0026#34;No Scope registered for scope name \u0026#39;\u0026#34; + scopeName + \u0026#34;\u0026#39;\u0026#34;); } try { Object scopedInstance = scope.get(beanName, () -\u0026gt; { beforePrototypeCreation(beanName); try { return createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } }); beanInstance = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new ScopeNotActiveException(beanName, scopeName, ex); } } } catch (BeansException ex) { beanCreation.tag(\u0026#34;exception\u0026#34;, ex.getClass().toString()); beanCreation.tag(\u0026#34;message\u0026#34;, String.valueOf(ex.getMessage())); cleanupAfterBeanCreationFailure(beanName); throw ex; } finally { beanCreation.end(); } } return adaptBeanInstance(name, beanInstance, requiredType); } 上述代码主要看中文注释即可:\n解析bean的真正name，如果bean是工厂类，name前缀会加\u0026，需要去掉 无参单例先从缓存中获取 如果bean实例还在创建中，则直接抛出异常 如果bean definition存在于的bean工厂中，委派给父Bean工厂获取 标记这个beanName的实例正在创建 确保它的依赖也被初始化 真正创建:\n1. 单例时\n2. 原型时\n3. 根据bean的scope创建 重点: SPring如何解决循环依赖问题 首先我们需要声明，Spring只是解决了单例模式下属性依赖的循环问题；Spring为了解决单例的循环依赖问题，使用了三级缓存。\nSpring单例模式下的属性依赖 先来看下这三级缓存\n1 2 3 4 5 6 7 8 /** Cache of singleton objects: bean name --\u0026gt; bean instance */ private final Map\u0026lt;String, Object\u0026gt; singletonObjects = new ConcurrentHashMap\u0026lt;String, Object\u0026gt;(256); /** Cache of early singleton objects: bean name --\u0026gt; bean instance */ private final Map\u0026lt;String, Object\u0026gt; earlySingletonObjects = new HashMap\u0026lt;String, Object\u0026gt;(16); /** Cache of singleton factories: bean name --\u0026gt; ObjectFactory */ private final Map\u0026lt;String, ObjectFactory\u0026lt;?\u0026gt;\u0026gt; singletonFactories = new HashMap\u0026lt;String, ObjectFactory\u0026lt;?\u0026gt;\u0026gt;(16); 第一级缓存(singletonObjects): 单例对象缓存池，已经实例化并且属性赋值，这里的对象是成熟对象 第二层缓存(earlySingletonObjects): 单例对象缓存池，已经实例化但尚未属性赋值，这里的对象是半成品对象 第三层缓存(singletonFactories): 单例工厂的缓存 如下是获取单例中:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 protected Object getSingleton(String beanName, boolean allowEarlyReference) { // Spring首先从singletonObjects（一级缓存）中尝试获取 Object singletonObject = this.singletonObjects.get(beanName); // 若是获取不到而且对象在建立中，则尝试从earlySingletonObjects(二级缓存)中获取 if (singletonObject == null \u0026amp;\u0026amp; isSingletonCurrentlyInCreation(beanName)) { synchronized (this.singletonObjects) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null \u0026amp;\u0026amp; allowEarlyReference) { ObjectFactory\u0026lt;?\u0026gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { //若是仍是获取不到而且容许从singletonFactories经过getObject获取，则经过singletonFactory.getObject()(三级缓存)获取 singletonObject = singletonFactory.getObject(); //若是获取到了则将singletonObject放入到earlySingletonObjects,也就是将三级缓存提高到二级缓存中 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return (singletonObject != NULL_OBJECT ? singletonObject : null); } 补充一些方法和参数\nisSingletonCurrentlyIncreation(): 判断当前单例bean是否正在建立中，也就是没有初始化完成(好比A的构造器依赖了B对象因此得先去建立B对象，或则在A得populateBean过程当中依赖了B对象，得先去建立B对象，这时得A就是处于建立中的状态。) allowEarlyRefrence: 是否容许从singletonFactories中经过getObject拿到对象 分析getSinflwton()整个过程，Spring首先从一级缓存singletonObjects中获取。若是获取不到，而且对象正在建立中，就再从二级缓存earlySingletonObjects中获取。若是仍是获取不到且容许singletonFactories经过getObject()获取，就从三级缓存singlwtonFactory.getObject()(三级缓存)获取，若是获取到了则从三级缓存移动到了二级缓存。\n从上面三级缓存的分析，咱们能够知道，Spring解决循环依赖的诀窍就在于singletonFactories这个三级cache。这个cache的类型是ObjectFactory,定义以下:\n1 2 3 public interface ObjectFactory\u0026lt;T\u0026gt; { T getObject() throws BeansException; } 在bean建立过程当中，有两处比较重要的匿名内部类实现了该接口。一处是Spring利用其建立bean的时候，另外一处就是:\n1 2 3 4 addSingletonFactory(beanName, new ObjectFactory\u0026lt;Object\u0026gt;() { @Override public Object getObject() throws BeansException { return getEarlyBeanReference(beanName, mbd, bean); }}); 此处就是解决循环依赖的关键，这段代码发生在createBeanInstance以后，也就是说单例对象此时已经被建立出来的。这个对象已经被生产出来了，虽然还不完美(尚未进行初始化的第二步和第三步)，可是已经能被人认出来了(根据对象引用能定位到堆中的对象)，因此Spring此时将这个对象提早曝光出来让你们认识，让你们使用。\nSpring为何不能解决非单例属性之外的循环依赖？ Spring为什么不能解决构造器的循环依赖 构造器注入形成的循环依赖: 也就是BeanB需要在beanA的构造函数中完成初始化，beanA也需要2在beanB的构造函数中完成初始化，这种情况的结果就是两个bean都不能完成初始化，循环依赖难以解决。\nSpring解决循环依赖主要是依赖三级缓存，但是得在调用构造方法之前还未将其放入三级缓存之中，因此后续得依赖调用构造方法的时候并不能从三级缓存中获取到依赖的Bean，因此不能解决。\nSpring为什么不能解决prototype作用域循环依赖 这种循环依赖同样无法解决，因为Spring不会缓存prototype作用域的bean，而spring中循环依赖的解决正是通过缓存来实现的。\nSpring为什么不能解决多例的循环依赖？ 多实例Bean是每次调用一次getBean都会执行一次构造方法并且给属性赋值，根本没有三级缓存，因此不能解决循环依赖。\n那么其他循环依赖如何解决？ 在实际开发中，类似的依赖是如何解决？\n生成代理对象产生的循环依赖 这类循环依赖解决方法有很多，主要有：\n1、使用@Lazy注解，延迟加载\n2、使用@DependsOn注解，指定加载先后关系\n3、修改文件名称，改变循环依赖类的加载顺序\n使用@DependsOn产生的循环依赖 这类循环依赖问题要找到@DependsOn注解循环依赖的地方，迫使它不循环依赖就可以解决问题。 多例循环依赖 这类循环依赖问题可以通过把bean改成单例的解决 构造器循环依赖 这类循环依赖问题可以通过使用@Lazy注解解决。 重点: Spring中Bean的生命周期 Spring只帮我们管理单例模式Bean的完整的生命周期，对于prototype的bean，SPring在创建好交给使用者之后则不会再管理后续的生命周期。\nSpring容器可以管理singleton作用域Bean的生命周期，在此作用域下，SPring能够精确地知道该Bean何时被创建，何时初始化完成，以及何时被销毁。\n而对于prototype作用域的Bean,Spring只负责创建，当容器创建了Bean的实例后，Bean的实例就交给客户端代码管理，Spring容器就不再跟踪其生命周期。每次客户端请求prototype作用域的Bean时，SPring容器都会创建一个新的实例，并且不会管那些被配置成prototype作用域的Bean的生命周期。\n了解SPring生命周期的意义就在于，可以利用Bean在其存货期间的指定时刻完成一些相关操作。这种时刻可能有很多，但一般情况下，会在Bean被初始化后和被销毁前执行一些相关操作。\nSpring Bean生命周期流程\n在SPring中，Bean的生命周期是一个很复杂的执行过程，我们可以利用Spring提供的方法定制Bean的创建过程。\n如果BeanFactoryPostProcessor和Bean关联，则调用postProcessBeanFactory方法.(即首先尝试从Bean工厂中获取Bean) 如果InstantiationAwareBeanPostProcessor和Bean关联，则调用postProcessBeforeInstantiation方法 根据配置情况调用Bean构造方法实例化Bean。 利用依赖注入完成Bean中所有属性值的配置注入。 如果InstantiationAwareBeanPostProcessor和Bean关联，则调用postProcessAfterInstantition方法和postProcessProperties 调用xxxAware接口(上图只是给了几个例子)\n1、如果bean实现了BeanNameAware接口，则Spring调用Bean的setBeanName()方法传入当前Bean的id值。\n2、如果Bean实现了BeanClassLoaderAware接口，则Spring调用setBeanClassLoader()方法传入classLoader的引用。\n3、如果Bean实现了BeanFactoryAware接口，则Spring调用setBeanFactory()方法传入当前工厂实例的引用。 第二类Aware接口\n1、如果Bean实现了EnvironmentAware接口，则Spring调用setEnviroment()方法传入当前Enviroment实例的引用。\n2、如果Bean实现了EmbeddedValueResolverAware接口，则Spring调用setEmbeddedValueResolver()方法传入当前StringValueResolver实例的引用。\n3、如果Bean实现了ApplicationContextAware接口，则Spring调用setApplicationContext()方法传入当前ApplicationContext实例的引用。 如果BeanPostProcessor和Bean关联，则SPring将调用该接口的预初始化方法postProcessBeforeInitialzation()对Bean进行加工操作，此处非常重要，SPring的AOP就是利用它实现的 如果Bean实现了InitializingBean接口，则SPring将调用afterPropertiesSet()方法。(或者有执行@PostConstruct注解的方法) 如果在配置文件中通过init-method属性指定了初始化方法，则调用该初始化方法 如果BeanPostProcessor和Bean关联，则Spring将调用该接口的初始化方法postProcesasAfterInitialization()。此时，Bean已经可以被应用系统使用了。 如果在bean中指定了该Bean的作用范围为scope=\"singleton\"，则将该Bean放入Spring IoC的缓存池中，将触发Spring对该Bean的生命周期管理;如果在bean中指定了该Bean的作用范围为scope=\"prototype\"，则将该Bean交给调用者，调用者管理该Bean的生命周期，Spring不再管理该Bean. 如果Bean实现了DisposableBean接口，则Spring会调用destory()方法将SPring中的Bean销毁； 如果在配置文件中通过destory-method属性指定了Bean的销毁方法，则Spring将调用该方法对Bean进行销毁。 Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类:\nBean自身的方法: 这个包括了Bean本身调用的方法和通过配置文件中bean的init-method和destroy-method指定的方法 Bean级生命周期接口方法: 这个包括了BeanNameAware、BeanFactoryAware、ApplicationContextAware；当然也包括InitializingBean和DiposableBean这些接口的方法(可以被@PostConstruct和@PreDestroy注解替代) 容器级生命周期接口方法: 这个包括了AspectJWeavingEnable,ConfigurationClassPostProcessor,CustomAutowireConfigurer等的非常有用的工厂后处理接口的方法，工厂后处理器也是容器级的。在应用上下文装配文件之后立即调用。 ","permalink":"https://csqread.top/posts/tech/%E9%98%85%E8%AF%BBspring%E6%BA%90%E7%A0%81/","summary":"Spring 什么是Spring框架 Spring是一种轻量级框架，旨在提高开发人员的开发效率和系统的可维护性。 我们一般说的Spring框架就是SPrin","title":"阅读Spring源码"},{"content":"这周有点拉跨啊，就搞出来2题。\n记录一下吧:\n每个字符最多出现两次的最长子字符串 给你一个字符串 s ，请找出满足每个字符最多出现两次的最长子字符串，并返回该子字符串的最大长度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution { public int maximumLengthSubstring(String S) { char[] s = S.toCharArray(); int ans = 0; int left = 0; int[] cnt = new int[26]; for (int i = 0; i \u0026lt; s.length; i++) { int b = s[i] - \u0026#39;a\u0026#39;; cnt[b]++; while (cnt[b] \u0026gt; 2) { cnt[s[left++] - \u0026#39;a\u0026#39;]--; } ans = Math.max(ans, i - left + 1); } return ans; } } 最高频率的 ID 你需要在一个集合里动态记录 ID 的出现频率。给你两个长度都为 n 的整数数组 nums 和 freq ，nums 中每一个元素表示一个 ID ，对应的 freq 中的元素表示这个 ID 在集合中此次操作后需要增加或者减少的数目。\n增加 ID 的数目：如果 freq[i] 是正数，那么 freq[i] 个 ID 为 nums[i] 的元素在第 i 步操作后会添加到集合中。 减少 ID 的数目：如果 freq[i] 是负数，那么 -freq[i] 个 ID 为 nums[i] 的元素在第 i 步操作后会从集合中删除。 请你返回一个长度为 n 的数组 ans ，其中 ans[i] 表示第 i 步操作后出现频率最高的 ID 数目 ，如果在某次操作后集合为空，那么 ans[i] 为 0 。\n示例 1：\n输入：nums = [2,3,2,1], freq = [3,2,-3,1]\n输出：[3,3,2,2]\n解释：\n第 0 步操作后，有 3 个 ID 为 2 的元素，所以 ans[0] = 3 。 第 1 步操作后，有 3 个 ID 为 2 的元素和 2 个 ID 为 3 的元素，所以 ans[1] = 3 。 第 2 步操作后，有 2 个 ID 为 3 的元素，所以 ans[2] = 2 。 第 3 步操作后，有 2 个 ID 为 3 的元素和 1 个 ID 为 1 的元素，所以 ans[3] = 2 。\n方法一：哈希表 + 有序集合 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Solution { public long[] mostFrequentIDs(int[] nums, int[] freq) { Map\u0026lt;Integer, Long\u0026gt; cnt = new HashMap\u0026lt;\u0026gt;(); TreeMap\u0026lt;Long, Integer\u0026gt; m = new TreeMap\u0026lt;\u0026gt;(); int n = nums.length; long[] ans = new long[n]; for (int i = 0; i \u0026lt; n; i++) { int x = nums[i]; if (cnt.containsKey(x) \u0026amp;\u0026amp; m.containsKey(cnt.get(x)) \u0026amp;\u0026amp; m.merge(cnt.get(x), -1, Integer::sum) == 0) { // --m[cnt[x]] == 0 m.remove(cnt.get(x)); } long c = cnt.merge(x, (long) freq[i], Long::sum); // cnt[x] += freq[i] m.merge(c, 1, Integer::sum); // ++m[cnt[x]] ans[i] = m.lastKey(); } return ans; } } 方法二：哈希表 + 懒删除堆 也可以不用有序集合，而是用一个最大堆保存数对 (cnt[x],x)(\\textit{cnt}[x], x)(cnt[x],x)。\n在堆中查询 cnt[x]\\textit{cnt}[x]cnt[x] 的最大值时，如果堆顶保存的数据并不是目前实际的 cnt[x]\\textit{cnt}[x]cnt[x]，那么就弹出堆顶。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public long[] mostFrequentIDs(int[] nums, int[] freq) { int n = nums.length; long[] ans = new long[n]; Map\u0026lt;Integer, Long\u0026gt; cnt = new HashMap\u0026lt;\u0026gt;(); PriorityQueue\u0026lt;Pair\u0026lt;Long, Integer\u0026gt;\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;((a, b) -\u0026gt; Long.compare(b.getKey(), a.getKey())); for (int i = 0; i \u0026lt; n; i++) { int x = nums[i]; long c = cnt.merge(x, (long) freq[i], Long::sum); pq.add(new Pair\u0026lt;\u0026gt;(c, x)); while (!pq.peek().getKey().equals(cnt.get(pq.peek().getValue()))) { // 堆顶保存的数据已经发生变化 pq.poll(); // 删除 } ans[i] = pq.peek().getKey(); } return ans; } } 最长公共后缀查询 给你两个字符串数组 wordsContainer 和 wordsQuery 。\n对于每个 wordsQuery[i] ，你需要从 wordsContainer 中找到一个与 wordsQuery[i] 有 最长公共后缀 的字符串。如果 wordsContainer 中有两个或者更多字符串有最长公共后缀，那么答案为长度 最短 的。如果有超过两个字符串有 相同 最短长度，那么答案为它们在 wordsContainer 中出现 更早 的一个。\n请你返回一个整数数组 ans ，其中 ans[i]是 wordsContainer中与 wordsQuery[i] 有 最长公共后缀 字符串的下标。\n示例 1：\n输入：wordsContainer = [\u0026ldquo;abcd\u0026rdquo;,\u0026ldquo;bcd\u0026rdquo;,\u0026ldquo;xbcd\u0026rdquo;], wordsQuery = [\u0026ldquo;cd\u0026rdquo;,\u0026ldquo;bcd\u0026rdquo;,\u0026ldquo;xyz\u0026rdquo;]\n输出：[1,1,1]\n解释：\n我们分别来看每一个 wordsQuery[i] ：\n对于 wordsQuery[0] = \u0026ldquo;cd\u0026rdquo; ，wordsContainer 中有最长公共后缀 \u0026ldquo;cd\u0026rdquo; 的字符串下标分别为 0 ，1 和 2 。这些字符串中，答案是下标为 1 的字符串，因为它的长度为 3 ，是最短的字符串。 对于 wordsQuery[1] = \u0026ldquo;bcd\u0026rdquo; ，wordsContainer 中有最长公共后缀 \u0026ldquo;bcd\u0026rdquo; 的字符串下标分别为 0 ，1 和 2 。这些字符串中，答案是下标为 1 的字符串，因为它的长度为 3 ，是最短的字符串。 对于 wordsQuery[2] = \u0026ldquo;xyz\u0026rdquo; ，wordsContainer 中没有字符串跟它有公共后缀，所以最长公共后缀为 \u0026quot;\u0026quot; ，下标为 0 ，1 和 2 的字符串都得到这一公共后缀。这些字符串中， 答案是下标为 1 的字符串，因为它的长度为 3 ，是最短的字符串。 示例 2：\n输入：wordsContainer = [\u0026ldquo;abcdefgh\u0026rdquo;,\u0026ldquo;poiuygh\u0026rdquo;,\u0026ldquo;ghghgh\u0026rdquo;], wordsQuery = [\u0026ldquo;gh\u0026rdquo;,\u0026ldquo;acbfgh\u0026rdquo;,\u0026ldquo;acbfegh\u0026rdquo;]\n输出：[2,0,2]\n解释：\n我们分别来看每一个 wordsQuery[i] ：\n对于 wordsQuery[0] = \u0026ldquo;gh\u0026rdquo; ，wordsContainer 中有最长公共后缀 \u0026ldquo;gh\u0026rdquo; 的字符串下标分别为 0 ，1 和 2 。这些字符串中，答案是下标为 2 的字符串，因为它的长度为 6 ，是最短的字符串。 对于 wordsQuery[1] = \u0026ldquo;acbfgh\u0026rdquo; ，只有下标为 0 的字符串有最长公共后缀 \u0026ldquo;fgh\u0026rdquo; 。所以尽管下标为 2 的字符串是最短的字符串，但答案是 0 。 对于 wordsQuery[2] = \u0026ldquo;acbfegh\u0026rdquo; ，wordsContainer 中有最长公共后缀 \u0026ldquo;gh\u0026rdquo; 的字符串下标分别为 0 ，1 和 2 。这些字符串中，答案是下标为 2 的字符串，因为它的长度为 6 ，是最短的字符串。\n提示：\n1 \u0026lt;= wordsContainer.length, wordsQuery.length \u0026lt;= 104 1 \u0026lt;= wordsContainer[i].length \u0026lt;= 5 * 103 1 \u0026lt;= wordsQuery[i].length \u0026lt;= 5 * 103 wordsContainer[i] 只包含小写英文字母。 wordsQuery[i] 只包含小写英文字母。 wordsContainer[i].length 的和至多为 5 * 105 。 wordsQuery[i].length 的和至多为 5 * 105 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Node { Node[] son = new Node[26]; int minL = Integer.MAX_VALUE; int i; } class Solution { public int[] stringIndices(String[] wordsContainer, String[] wordsQuery) { Node root = new Node(); for (int idx = 0; idx \u0026lt; wordsContainer.length; ++idx) { char[] s = wordsContainer[idx].toCharArray(); int l = s.length; Node cur = root; if (l \u0026lt; cur.minL) { cur.minL = l; cur.i = idx; } for (int i = s.length - 1; i \u0026gt;= 0; i--) { int b = s[i] - \u0026#39;a\u0026#39;; if (cur.son[b] == null) { cur.son[b] = new Node(); } cur = cur.son[b]; if (l \u0026lt; cur.minL) { cur.minL = l; cur.i = idx; } } } int[] ans = new int[wordsQuery.length]; for (int idx = 0; idx \u0026lt; wordsQuery.length; idx++) { char[] s = wordsQuery[idx].toCharArray(); Node cur = root; for (int i = s.length - 1; i \u0026gt;= 0 \u0026amp;\u0026amp; cur.son[s[i] - \u0026#39;a\u0026#39;] != null; i--) { cur = cur.son[s[i] - \u0026#39;a\u0026#39;]; } ans[idx] = cur.i; } return ans; } } 代码参考自灵茶山艾府\n","permalink":"https://csqread.top/posts/tech/20240304%E5%8A%9B%E6%89%A3%E5%91%A8%E8%B5%9B/","summary":"这周有点拉跨啊，就搞出来2题。 记录一下吧: 每个字符最多出现两次的最长子字符串 给你一个字符串 s ，请找出满足每个字符最多出现两次的最长子字符串，","title":"20240304力扣周赛"},{"content":"历时两个多月，终于把这本书看完了，还是有不少启发的。这本书是如何出名的呢，在2020年疫情开始，武汉封城的时候，一位年轻的小伙子带着口罩在病床上读这本书。\n我在2022年经历了上海封城，不堪回首的一段时间，差点让我饿死在出租屋里面。其实很久之前就想开始读福山的这一系列书，终于在2024年排上了档期。所以这本书到底讲了什么内容呢。其实我在开头先总结以下这本书的主题:即一个良好的政治秩序是由三部分组成的：即强大的国家、法制、和负责制政府，三者缺一不可。福山的整篇书都在围绕这个主题开始进行讨论的。并且是以中国为首，开始再慢慢向欧洲，美国等其他政治体展开。由此我们可以正面的看待中国社会所面临的一些问题。下面我来分几个主题讨论一下这本书，以及我自己的一些见解。\n1、简介 《政治秩序的起源》是弗朗西斯-福山的一部著作，旨在探讨现在政治秩序的起源与演变，福山认为，现代政治秩序由三个独立的制度组成：强大而高效的国家、法治和对所有公民的政府问责。这本书详细描述了这三个元素在不同社会中是如何独立演变的，并在18世纪末首次在英国得以结合。\n福山在书中强调了偶然性的作用，指出现代政治制度的起源是“复杂且依赖于特定背景的”。他还提到了早期欧洲大家庭的地位下降，部分是由于中世纪教会的影响，这意味着“16世纪意大利、英格兰和荷兰新兴的资本主义经济不必克服像印度和中国那样的大型家族组织的阻力”。\n总的来说，这本书提供了对政治秩序起源和发展的深入洞察，弗朗西斯·福山通过详细的历史分析和论证，为我们呈现了现代政治制度的复杂性和多样性。\n2、福山认为现代政治秩序的起源是复杂且依赖于特定背景的，那么在不同的社会背景下，政治秩序是如何演变的呢 在不同的社会背景下，政治秩序的演变受到多种因素影响。但是大主题是不变的：\n国家的发展:在一些社会中，国家可能会通过建立中央集权政府来控制暴力，确保社会秩序。国家的强大和效率对政治秩序的稳定至关重要 法治的确立：在一些社会中，建立起明确的法律体系，使同统治者受到法律的约束，不得随意改变法律以达到其政治目的。法制的建立有助于确保政治秩序的稳定性 政府问责机制:民主问责机制的建立可以确保政府对所有的公民负责，而不仅仅是精英阶层。这种民主问责机制有助于实现现在普遍公民权利，确保哥阶层在决策和控制方面都有发言权 针对以上三点，其实福山在书中都分别举例做了论证。比如中国是世界上最早建立强大国家的政治体。在秦朝的时候就已经建立了非常强大的国家，确保社会的效率，因此秦国可以吞并其他6国，完成统一。但是从秦朝到现代社会，中国并没有建立起真正的现代法治以及问责制政府。目前还是属于威权政府。虽然，在强大的国家带领下的社会效率非常高，但是普通公民的权利无法得到保障，政府的权利无法得到监督。中国自始至终，都是向上管理，人民只能期盼有个好皇帝。坏皇帝的问题始终无法得到有效的解决。\n同时针对其他情况，福山也做了论证。在20世纪的时候，拉丁美洲掀起民主化的浪潮，但是很多并没有给国家和人民的生活水平带来很高的提升，其根本原因就是，虽然拉丁美洲进行了民主化(这里其实也讲了印度，他们属于同一类型)，虽然他们都进行了民主化，有问责制政府和法治，但是没有强大的国家来运行这些法治，没有强大的国家来保障社会的高效运转，因此即使民主化了，也无法改善人民的生活水平。包括印度也是这样。印度的民间政治体非常分散并且众多民族和宗教，导致国家并不是很强大。反而是社会力量比国家强大。\n英国是率先完成这三者结合统一的，因此英国在这之后整个社会，人民的生活和财产得到了很大保障和改善。\n在看到这里之前，我一直认为我所在的国家是没有希望的，因为一直一位是一个极权的国家，我们只能希望有一位明君圣主。但是其实我们良好的政治体系中，我们是有强大的国家的，我们缺的是什么？缺的是法治和负责制政府。只要建立起真正的现代法律，并且政府施行问责制，那么我们也是一个非常不错的政治体。\n之前我和同事有过一次讨论，他说他的家人认为现在中国无法施行全面的民主化，因为假如一人一票的话，如果很多人都投票要你把钱多交点税给他们呢，毕竟中国有6亿多人月收入不到1000块钱。其实这里就涉及到法治的问题，以及国家强制实行法治的问题。只要有健全的法治和强大的国家，就算他们投出这种不在法治上的选票，也是无法生效的。所以，我们无法实行全面民主的原因就是，我们没有健全的现代法治，我们法律的效应无法约束政府的权利，所以无法约束选票不合理的要求。\n3、法治在不同社会背景下的确立过程是怎样的？ 在不同社会背景下，法治的确立过程可能会有所不同。然而，通常情况下，法治的确立包括以下几个主要步骤：\n建立法律体系：首先，社会需要建立一套明确的法律体系，确保法律适用于所有人，无论其社会地位或财富状况。这些法律应当由立法机构制定，并且要公开透明，以便公民了解并遵守。 确保法律的公正执行：法治的确立还需要确保法律得到公正执行。这可能需要建立独立的司法系统，以便法官能够独立地审理案件，并根据法律作出公正的裁决。 保障公民权利：法治还需要保障公民的权利和自由，确保他们不会受到滥用权力的侵害。这可能包括建立宪法和法律保护公民的基本权利。 建立监督和问责机制：最后，法治的确立需要建立监督和问责机制，以确保执法机构和司法机构不会滥用权力。这可能包括建立独立的反腐败机构和监督机构。 其实在不同的社会背景下，法治的建立是有一些相似之处的，无论是在发展中国家还是发达国家，建立法治都需要有一些共同的步骤和规则。\n首先，必须要明确法律体系，无论在何种社会背景之下，建立法治都需要有一个明确的法律体系，确保法律适用于所有人。这些法律应当由立法机构制定，并且要公开透明，以便公民遵守执行。\n其次，要有独立的司法系统，以确保法律得到公正的执行。 我国的司法系统并不独立，比如前几年的修宪，其实完全就是一家之言，根本就没有经过全国人民的同意。\n一些想法 其实总的来说，读完这本书，我还是寄希望于这个国家能够走向一个拥有良好政治秩序的结局的，而不是陷入一次又一次的王朝周期律之中。我也明白了世界其他好的政治体并不是一朝一夕就形成的，内部都经历了无数的变革和战争。就如豆瓣一位读者的评论所说:让我相信了我不是韭菜，\n仅仅有民主是不行的，而我们的大多数人其实是忽略了这一点。\n","permalink":"https://csqread.top/posts/read/%E8%AF%BB%E6%94%BF%E6%B2%BB%E7%A7%A9%E5%BA%8F%E7%9A%84%E8%B5%B7%E6%BA%90-%E4%BB%8E%E5%89%8D%E4%BA%BA%E7%B1%BB%E6%97%B6%E4%BB%A3%E5%88%B0%E6%B3%95%E5%9B%BD%E5%A4%A7%E9%9D%A9%E5%91%BD%E6%9C%89%E6%84%9F/","summary":"历时两个多月，终于把这本书看完了，还是有不少启发的。这本书是如何出名的呢，在2020年疫情开始，武汉封城的时候，一位年轻的小伙子带着口罩在病","title":"读《政治秩序的起源 从前人类时代到法国大革命》有感"},{"content":"Mysql MVCC机制我的一些理解 什么是MVCC? MVCC 全称是 Multi-Version Concurrency Control, 即多版本并发控制。MVCC 在Mysql的 InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读.\n其实我在之前读了很多篇关于MVCC的文章，大多讲的比较模糊，最近在看《Mysql是怎样运行的-从根儿上理解Mysql》这本书讲的非常好。让我理解了MVCC。其实就最简单来讲，用READ COMMIT和 REPERATED COMMIT这两个隔离机制讲解就非常清楚了。\n首先是 读已提交这种隔离级别，这种不能防止脏读，为什么呢？因为它的READ VIEW在每次SELECT的时候会生成一次。比如我一个事务中，第一次查询该记录的时候，生成了一次READ VIEW ，然后这笔记录被另一个事务修改并且提交了，那么当前事务再进行查询的时候，结果会是另一个事务提交后的结果，所以就产生了脏读，同一个事务读取了不同的结果。\n如果是可重复度这种隔离级别呢？这种是可以防止脏读的出现的。顾名思义，可重复读，在同一个事务里，是可以重复读取同一笔记录的并且结果不会变。咋实现的呢？原因就在这个READ VIEW，在该笔事务开始查询之前，也就是SELECT之前，就会生成一个READ VIEW，并且在这笔事务结束之前不会变，一直是这个READ VIEW，所以，不论其他事务对这个记录做任何改动并且提交，它读到的一直会是这笔记录在该事务开始的时候的记录。因此不会产生脏读。\n但是读已提交是没办法阻止幻读的出现的。因为幻读的话，是查询一系列数据，是一个结果集，并不是一个结果，所以其他事务可能会对这个结果集进行插入操作，导致该事务查询的前后结果集数量不一样，就像产生了幻觉一样。那么如何解决幻读呢？其实就是后面所讲的，加NEXT-KEY LOCK和 RECORD LOCK，就是把这个范围内记录的最大值加上间隙锁和记录锁，这样对这个记录内所有记录的修改和插入都无法进行，因为其他事务无法获取到这个区间内记录的锁，所以无法进行修改\n","permalink":"https://csqread.top/posts/tech/%E5%85%B3%E4%BA%8Emvcc%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/","summary":"Mysql MVCC机制我的一些理解 什么是MVCC? MVCC 全称是 Multi-Version Concurrency Control, 即多版本并发控制。MVCC 在Mysql的 InnoDB中的实现主要是为了提高数据库并发","title":"关于MVCC的一些理解"},{"content":"第一章：可靠性，可扩展性，可维护性 1.1 关于数据系统的思考 单个工具已经不能满足应用系统的需求，总体工作被拆分成一系列能被单个工具高效完成的任务，并通过应用代码将它们缝合起来。比如一个缓存、索引、数据库协作的例子：\n一个应用被称为数据密集型的，如果数据是其主要挑战（数据量，数据复杂度、数据变化速度）——与之相对的是计算密集型，即处理器速度是其瓶颈。 软件系统中很重要的三个问题：\n可靠性（Reliability）：系统在困境（硬件故障、软件故障、人为错误）中仍可正常工作 可扩展性（Scalability）：有合理的办法应对系统的增长（数据量、流量、复杂性） 可维护性（Maintainability）：许多不同的人在不同的生命周期，都能高效地在系统上工作。 1.2 可靠性 1.2.1 定义 造成错误的原因叫做故障（fault），能预料并应对故障的系统特性可称为容错（fault-tolerant）或者韧性（resilient）。讨论容错时，只有讨论特定类型的错误 故障（fault）不同于失效（failure）：故障指的是一部分状态偏离标准，而失效则是系统作为一个整体停止向用户提供服务。 通常倾向于容忍错误（而不是阻止错误），但也有预防胜于治疗的情况（比如安全问题） 1.2.2 硬件故障 一般都是增加单个硬件的冗余度 云平台的设计是优先考虑灵活性和弹性，而不是单机可靠性。 1.2.3软件错误 这类软件故障的bug 通常潜伏很长时间，直到被异常情况触发为止。往往是某个假设出于某种原因最后不在成立了。 解决办法：仔细考虑假设和交互；彻底的测试；重启；监控。 1.2.4 人为错误 人是不可靠的，运维配置错误是导致服务中断的首要原因。 解决办法：最小化犯错机会的方式设计系统；容易犯错的地方解耦；测试；监控；培训。 1.3 可扩展性 1.3.1 定义 可扩展性（Scalability）是用来描述系统应对负载增长能力的术语。 1.3.2 描述负载 负载可以用负载参数的数字来描述，取决于系统架构\n推特的发推设计：\na. 推文放在全局推文集合中，查询的时候做 join\nb.推文插入到每个关注者的时间线中，「扇出」比较大，当有千万粉丝的大 V 发推压力大\nc.推特从方案一变成了方案二，然后变成了两者结合的方式\n1.3.3 描述性能 当描述好负载以后，问题变成了：\na. 增加负载参数并保持系统资源不变时，系统性能将受到什么影响？\nb. 增加负载参数并希望性能不变时，需要增加多少系统资源？ 批处理系统，通常关心吞吐量（throughput）；在线系统，通常更关心响应时间（response time） 对于系统响应时间而言，最好用百分位点，比如中位数、p99 等标识。 测量客户端的响应时间非常重要（而不是服务端），比如会出现头部阻塞、网络延迟等。 实践中的百分位点，可以用一个滑动的时间窗口（比如 10 分钟）进行统计。可以对列表进行排序，效率低的话，考虑一下前向衰减，t-digest 等方法近似计算。 1.3.4 应对负载的方法 纵向扩展：转向更强大的机器 横向扩展：将负载分布到多台小机器上 弹性系统：检测到负载增加时自动增加计算资源 跨多台机器部署无状态服务比较简单，但是把带状态的数据系统从单节点变成分布式配置则可能引入许多额外复杂度。因此，应该尽量将数据库放在单个节点上。 1.4 可维护性 在设计之初就尽量考虑尽可能减少维护期间的痛苦，从而避免自己的软件系统变成遗留系统。 三个设计原则：可操作性（Operability）便于运维团队保持系统平稳运行。简单性（Simplicity）从系统中消除尽可能多的复杂度（complexity），使新工程师也能轻松理解系统。（注意这和用户接口的简单性不一样。）可演化性（evolability）使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为可扩展性（extensibility），可修改性（modifiability）或可塑性（plasticity）。 1.4.1 可操作性：人生苦短，关爱运维 ● 尽量自动化\n1.4.2 简单性：管理复杂度 ● 消除额外的（accidental）的复杂度 ● 消除额外复杂度的最好工具之一是抽象（abstraction）\n1.4.3 可演化性：拥抱变化 ● 敏捷（agile） 工作模式为适应变化提供了一个框架\n● 简单易懂的系统通常比复杂系统更容易修改，即可演化性（evolvability）\n第二章：数据模型与查询语言 数据模型可能是软件开发中最重要的部分了，因为它们的影响如此深远：不仅仅影响着软件的编写方式，而且影响着我们的解题思路。 一个复杂的应用程序可能会有更多的中间层次，比如基于API的API，不过基本思想仍然是一样的：每个层都通过提供一个明确的数据模型来隐藏更低层次中的复杂性。这些抽象允许不同的人群有效地协作。\n2.1 关系模型与文档模型 现在最著名的数据模型可能是SQL。它基于Edgar Codd在1970年提出的关系模型【1】：数据被组织成关系（SQL中称作表），其中每个关系是元组（SQL中称作行)的无序集合。\n2.1.1 NoSQL的诞生 NoSQL：不仅是SQL（Not Only SQL） 采用NoSQL数据库的背后有几个驱动因素，其中包括： ○ 需要比关系数据库更好的可扩展性，包括非常大的数据集或非常高的写入吞吐量 ○ 相比商业数据库产品，免费和开源软件更受偏爱。 ○ 关系模型不能很好地支持一些特殊的查询操作 ○ 受挫于关系模型的限制性，渴望一种更具多动态性与表现力的数据模型 在可预见的未来，关系数据库似乎可能会继续与各种非关系数据库一起使用 - 这种想法有时也被称为混合持久化（polyglot persistence） 2.1.2 对象关系不匹配 应用程序使用面向对象的语言，需要一个转换层，才能转成 SQL 数据模型：被称为阻抗不匹配。 Hibernate这样的 对象关系映射（ORM object-relational mapping） 框架可以减少这个转换层所需的样板代码的数量，但是它们不能完全隐藏这两个模型之间的差异。 对于一份简历而言，关系型模型需要一对多（比如工作经历）。 而表述这样的简历，使用 JSON 是非常合适的。JSON 比多表模式有更好的局部性，可以一次查询出一个用户的所有信息。JSON 其实是一棵树。 2.1.3 多对一和多对多的关系 为什么在 SQL 中，地域和公司都以 ID，而不是字符串进行标识呢？ ○ ID 对人类没有任何意义，所以永远不需要改变，可以规范化人类的信息。那么就会存在多对一的关系（多个人对应了同一个 ID）。 ○ 在关系数据库 SQL 中，所有使用它的地方可以用 ID 来引用其他表中的行； ○ 但是文档数据库（比如 JSON），对连接支持很弱。 如果数据库不支持链接，那么就需要在应用代码中，对数据库执行多个查询进行模拟。执行连接的工作从数据库被转移到应用程序代码上。 哪怕最开始的应用适合无连接的文档模型，但是随着功能添加，数据会变得更加互联，比如对简历修改：\n组织和学校作为实体：假如组织和学校有主页 推荐：给别人做推荐，当别人的信息更改的时候，所有地方要同步更新。 2.1.4 文档数据库是否在重蹈覆辙？ 20 世纪 70 年代，最受欢迎的是层次模型（hierarchical model），它与文档数据库使用的JSON模型有一些惊人的相似之处。它将所有数据表示为嵌套在记录中的记录树。虽然能处理一对多的关系，但是很难应对多对多的关系，并且不支持链接。\n提出的解决方案：\n关系模型（relational model）（它变成了SQL，统治了世界） 网络模型（network model）（最初很受关注，但最终变得冷门） 2.1.4.1 网络模型 支持多对多，每条记录可能有多个父节点。 网络模型中记录之间的链接不是外键，而更像编程语言中的指针（同时仍然存储在磁盘上）。访问记录的唯一方法是跟随从根记录起沿这些链路所形成的路径。这被称为访问路径（access path）。 最简单的情况下，访问路径类似遍历链表：从列表头开始，每次查看一条记录，直到找到所需的记录。但在多对多关系的情况中，数条不同的路径可以到达相同的记录，网络模型的程序员必须跟踪这些不同的访问路径。 缺点：查询和更新数据库很麻烦。 2.1.4.2 关系模型 数据：一个 关系（表） 只是一个 元组（行） 的集合，很简单。 在关系数据库中，查询优化器自动决定查询的哪些部分以哪个顺序执行，以及使用哪些索引。这些选择实际上是“访问路径”，但最大的区别在于它们是由查询优化器自动生成的，不需要程序猿考虑。 2.1.4.3 与文档数据库相比 但是，在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为外键，在文档模型中称为文档引用。\n2.1.5 关系型数据库与文档数据库在今日的对比 ● 支持文档数据模型的主要论据是架构灵活性，因局部性而拥有更好的性能，以及对于某些应用程序而言更接近于应用程序使用的数据结构。 ● 关系模型通过为连接提供更好的支持以及支持多对一和多对多的关系来反击。\n2.1.5.1 哪个数据模型更方便写代码？ 文档模型： ● 优点： ○ 如果应用程序中的数据具有类似文档的结构（即，一对多关系树，通常一次性加载整个树），那么使用文档模型可能是一个好主意。 ● 缺点： ○ 不能直接引用文档中的嵌套的项目，而是需要说“用户251的位置列表中的第二项”（很像分层模型中的访问路径）。但是，只要文件嵌套不太深，这通常不是问题。 ○ 文档数据库对连接的糟糕支持也许或也许不是一个问题，这取决于应用程序。 ○ 如果应用程序使用多对多关系，那么文档模型就没有那么吸引人了。 ○ 对于高度相联的数据，选用文档模型是糟糕的，选用关系模型是可接受的，而选用图形模型是最自然的。\n2.1.5.2 文档模型中的架构灵活性 文档模型是「读时模式」 ○ 文档数据库有时称为无模式（schemaless），但这具有误导性，因为读取数据的代码通常假定某种结构——即存在隐式模式，但不由数据库强制执行 ○ 一个更精确的术语是读时模式（schema-on-read）（数据的结构是隐含的，只有在数据被读取时才被解释），相应的是写时模式（schema-on-write）（传统的关系数据库方法中，模式明确，且数据库确保所有的数据都符合其模式） ○ 读时模式类似于编程语言中的动态（运行时）类型检查，而写时模式类似于静态（编译时）类型检查。 模式变更 ○ 读时模式变更字段很容易，只用改应用代码 ○ 写时模式变更字段速度很慢，而且要求停运。它的这种坏名誉并不是完全应得的：大多数关系数据库系统可在几毫秒内执行ALTER TABLE语句。MySQL是一个值得注意的例外，它执行ALTER TABLE时会复制整个表，这可能意味着在更改一个大型表时会花费几分钟甚至几个小时的停机时间，尽管存在各种工具来解决这个限制。 2.1.5.3 查询的数据局部性 ● 文档通常以单个连续字符串形式进行存储，编码为JSON，XML或其二进制变体 ● 读文档： ○ 如果应用程序经常需要访问整个文档（例如，将其渲染至网页），那么存储局部性会带来性能优势。 ○ 局部性仅仅适用于同时需要文档绝大部分内容的情况。 ● 写文档： ○ 更新文档时，通常需要整个重写。只有不改变文档大小的修改才可以容易地原地执行。 ○ 通常建议保持相对小的文档，并避免增加文档大小的写入\n2.1.5.4 文档和关系数据库的融合 ● MySQL 等逐步增加了对 JSON 和 XML 的支持 ● 关系模型和文档模型的混合是未来数据库一条很好的路线。\n2.2 数据查询语言 ● 关系模型包含了一种查询数据的新方法：SQL是一种 声明式 查询语言，而IMS和CODASYL使用 命令式 代码来查询数据库。 ● 命令式语言：告诉计算机以特定顺序执行某些操作，比如常见的编程语言。 ● 声明式查询语言（如SQL或关系代数）：你只需指定所需数据的模式 - 结果必须符合哪些条件，以及如何将数据转换（例如，排序，分组和集合） - 但不是如何实现这一目标。数据库系统的查询优化器决定使用哪些索引和哪些连接方法，以及以何种顺序执行查询的各个部分。 ○ SQL相当有限的功能性为数据库提供了更多自动优化的空间。 ○ 声明式语言往往适合并行执行。\n2.2.1 Web上的声明式查询 ● 声明式语言更加泛化，不用关心底层的数据存储变化 ● 在Web浏览器中，使用声明式CSS样式比使用JavaScript命令式地操作样式要好得多。 ● 类似地，在数据库中，使用像SQL这样的声明式查询语言比使用命令式查询API要好得多。\n2.2.2 MapReduce查询 ● 一些NoSQL数据存储（包括MongoDB和CouchDB）支持有限形式的MapReduce，作为在多个文档中执行只读查询的机制。 ● MapReduce既不是一个声明式的查询语言，也不是一个完全命令式的查询API，而是处于两者之间 ○ 查询的逻辑用代码片断来表示，这些代码片段会被处理框架重复性调用。 ○ 它基于map（也称为collect）和reduce（也称为fold或inject）函数，两个函数存在于许多函数式编程语言中。 ● map和reduce函数在功能上有所限制： ○ 它们必须是纯函数，这意味着它们只使用传递给它们的数据作为输入，它们不能执行额外的数据库查询，也不能有任何副作用。 ○ 这些限制允许数据库以任何顺序运行任何功能，并在失败时重新运行它们。 ○ MapReduce是一个相当底层的编程模型，用于计算机集群上的分布式执行。像SQL这样的更高级的查询语言可以用一系列的MapReduce操作来实现，但是也有很多不使用MapReduce的分布式SQL实现。 ○ MapReduce的一个可用性问题：必须编写两个密切合作的JavaScript函数，这通常比编写单个查询更困难。此外，声明式查询语言为查询优化器提供了更多机会来提高查询的性能。基于这些原因，MongoDB 2.2添加了一种叫做聚合管道的声明式查询语言的支持\n2.3 图数据模型 多对多关系是不同数据模型之间具有区别性的重要特征。\n文档模型：适合数据有一对多关系、不存在关系\n图数据模型：适合多对多关系\n一个图由两种对象组成： a. 顶点（vertices）（也称为节点（nodes） 或实体（entities）） b. 边（edges）（ 也称为关系（relationships）或弧 （arcs） ）。\n举例：社交图谱，网络图谱，公路或铁路网络\n图数据结构示例（以社交网络为例）\n存储方式：属性图，三元组\n2.3.1 属性图 在属性图模型中，每个顶点（vertex）包括： ● 唯一的标识符 ● 一组 出边（outgoing edges） ● 一组 入边（ingoing edges） ● 一组属性（键值对） 每条 边（edge） 包括： ● 唯一标识符 ● 边的起点/尾部顶点（tail vertex） ● 边的终点/头部顶点（head vertex） ● 描述两个顶点之间关系类型的标签 ● 一组属性（键值对） 使用关系模式来表示属性图\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 CREATE TABLE vertices ( vertex_id INTEGER PRIMARY KEY, properties JSON ); CREATE TABLE edges ( edge_id INTEGER PRIMARY KEY, tail_vertex INTEGER REFERENCES vertices (vertex_id), head_vertex INTEGER REFERENCES vertices (vertex_id), label TEXT, properties JSON ); CREATE INDEX edges_tails ON edges (tail_vertex); CREATE INDEX edges_heads ON edges (head_vertex); 关于这个模型的一些重要方面是：\n任何顶点都可以有一条边连接到任何其他顶点。没有模式限制哪种事物可不可以关联。 给定任何顶点，可以高效地找到它的入边和出边，从而遍历图，即沿着一系列顶点的路径前后移动。（这就是为什么例2-2在tail_vertex和head_vertex列上都有索引的原因。） 通过对不同类型的关系使用不同的标签，可以在一个图中存储几种不同的信息，同时仍然保持一个清晰的数据模型。 2.3.2 Cypher查询语言 Cypher是属性图的声明式查询语言，为Neo4j图形数据库而发明 通常对于声明式查询语言来说，在编写查询语句时，不需要指定执行细节：查询优化程序会自动选择预测效率最高的策略，因此你可以继续编写应用程序的其他部分。 查找所有从美国移民到欧洲的人的Cypher查询 1 2 3 4 MATCH (person) -[:BORN_IN]-\u0026gt; () -[:WITHIN*0..]-\u0026gt; (us:Location {name:\u0026#39;United States\u0026#39;}), (person) -[:LIVES_IN]-\u0026gt; () -[:WITHIN*0..]-\u0026gt; (eu:Location {name:\u0026#39;Europe\u0026#39;}) RETURN person.name 2.3.3 SQL中的图查询 用关系数据库表示图数据，那么也可以用SQL，但有些困难。 在关系数据库中，你通常会事先知道在查询中需要哪些连接。在图查询中，你可能需要在找到待查找的顶点之前，遍历可变数量的边。也就是说，连接的数量事先并不确定。 语法很复杂， 2.3.4 三元组存储和SPARQL 在三元组存储中，所有信息都以非常简单的三部分表示形式存储（主语，谓语，宾语）。例如，三元组 (吉姆, 喜欢 ,香蕉) 中，吉姆 是主语，喜欢 是谓语（动词），香蕉 是对象。 三元组的主语相当于图中的一个顶点。而宾语是下面两者之一： a. 原始数据类型中的值，例如字符串或数字。在这种情况下，三元组的谓语和宾语相当于主语顶点上的属性的键和值。例如，(lucy, age, 33)就像属性{“age”：33}的顶点lucy。 b. 图中的另一个顶点。在这种情况下，谓语是图中的一条边，主语是其尾部顶点，而宾语是其头部顶点。例如，在(lucy, marriedTo, alain)中主语和宾语lucy和alain都是顶点，并且谓语marriedTo是连接他们的边的标签。 当主语一样的时候，可以进行省略写法 1 2 3 4 5 @prefix : \u0026lt;urn:example:\u0026gt;. _:lucy a :Person; :name \u0026#34;Lucy\u0026#34;; :bornIn _:idaho. _:idaho a :Location; :name \u0026#34;Idaho\u0026#34;; :type \u0026#34;state\u0026#34;; :within _:usa _:usa a :Loaction; :name \u0026#34;United States\u0026#34;; :type \u0026#34;country\u0026#34;; :within _:namerica. _:namerica a :Location; :name \u0026#34;North America\u0026#34;; :type \u0026#34;continent\u0026#34;. 2.3.4.1 语义网络 语义网是一个简单且合理的想法：网站已经将信息发布为文字和图片供人类阅读，为什么不将信息作为机器可读的数据也发布给计算机呢？ 资源描述框架（RDF）的目的是作为不同网站以一致的格式发布数据的一种机制，允许来自不同网站的数据自动合并成一个数据网络 - 一种互联网范围内的“关于一切的数据库“。 现在已经凉了。 2.3.5 SPARQL查询语言 SPARQL是一种用于三元组存储的面向RDF数据模型的查询语言 查找从美国转移到欧洲的人 1 2 3 4 5 6 PREFIX : \u0026lt;urn:example:\u0026gt; SELECT ?personName WHERE { ?person :name ?personName. ?person :bornIn / :within* / :name \u0026#34;United States\u0026#34;. ?person :livesIn / :within* / :name \u0026#34;Europe\u0026#34;. } 2.3.6 基础：Datalog Datalog是比SPARQL或Cypher更古老的语言，在20世纪80年代被学者广泛研究 2.4 本章小结 在历史上，数据最开始被表示为一棵大树（层次数据模型），但是这不利于表示多对多的关系，所以发明了关系模型来解决这个问题。 最近，开发人员发现一些应用程序也不适合采用关系模型。新的非关系型“NoSQL”数据存储在两个主要方向上存在分歧：\n文档数据库的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。 图形数据库用于相反的场景：任意事物都可能与任何事物相关联。 文档数据库和图数据库有一个共同点，那就是它们通常不会为存储的数据强制一个模式，这可以使应用程序更容易适应不断变化的需求。但是应用程序很可能仍会假定数据具有一定的结构；这只是模式是明确的（写入时强制）还是隐含的（读取时处理）的问题。 每个数据模型都具有各自的查询语言或框架，我们讨论了几个例子：SQL，MapReduce，MongoDB的聚合管道，Cypher，SPARQL和Datalog。我们也谈到了CSS和XSL/XPath，它们不是数据库查询语言，而包含有趣的相似之处。 第三章：存储与检索 本章介绍了传统关系型数据库与“NoSQL”数据库的存储引擎。 我们会研究两大类存储引擎：日志结构（log-structured） 的存储引擎，以及面向页面（page-oriented） 的存储引擎（例如B树）。\n3.1 驱动数据库的数据结构 世界上最简单的数据库可以用两个Bash函数实现：\n1 2 3 4 5 6 7 8 #!/bin/bash db_set () { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get () { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 } 这两个函数实现了键值存储的功能。\n执行 db_set key value ，会将 键（key）和值（value） 存储在数据库中。键和值（几乎）可以是你喜欢的任何东西，例如，值可以是JSON文档。 调用 db_get key ，查找与该键关联的最新值并将其返回。 麻雀虽小，五脏俱全：\n1 2 3 4 5 6 $ db_set 123456 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;London\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Big Ben\u0026#34;,\u0026#34;London Eye\u0026#34;]}\u0026#39; $ $ db_set 42 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]}\u0026#39; $ db_get 42 {\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]} huhu 底层的存储格式非常简单：\n一个文本文件，每行包含一条逗号分隔的键值对（忽略转义问题的话，大致与CSV文件类似）。 每次对 db_set 的调用都会向文件末尾追加记录，所以更新键的时候旧版本的值不会被覆盖。 查找最新值的时候，需要找到文件中键最后一次出现的位置（因此 db_get 中使用了 tail -n 1 ) 1 2 3 4 5 6 7 8 9 $ db_set 42 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Exploratorium\u0026#34;]}\u0026#39; $ db_get 42 {\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Exploratorium\u0026#34;]} $ cat database 123456,{\u0026#34;name\u0026#34;:\u0026#34;London\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Big Ben\u0026#34;,\u0026#34;London Eye\u0026#34;]} 42,{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]} 42,{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Exploratorium\u0026#34;]} db_set 函数对于极其简单的场景其实有非常好的性能，因为在文件尾部追加写入通常是非常高效的。 与db_set做的事情类似，许多数据库在内部使用了日志（log），也就是一个 仅追加（append-only） 的数据文件。 另一方面，如果这个数据库中有着大量记录，则这个db_get 函数的性能会非常糟糕。 每次你想查找一个键时，db_get 必须从头到尾扫描整个数据库文件来查找键的出现。 用算法的语言来说，查找的开销是 O(n) ：如果数据库记录数量 n 翻了一倍，查找时间也要翻一倍。 3.1.1 索引 为了高效查找数据库中特定键的值，我们需要一个数据结构：索引（index）。\n索引背后的大致思想是，保存一些额外的元数据作为路标，帮助你找到想要的数据。 索引是从主数据衍生的附加（additional）结构。 许多数据库允许添加与删除索引，这不会影响数据的内容，它只影响查询的性能。 维护额外的结构会产生开销，特别是在写入时。写入性能很难超过简单地追加写入文件，因为追加写入是最简单的写入操作。 任何类型的索引通常都会减慢写入速度，因为每次写入数据时都需要更新索引。 这是存储系统中一个重要的权衡：精心选择的索引加快了读查询的速度，但是每个索引都会拖慢写入速度。 3.1.2 哈希索引 键值存储与在大多数编程语言中可以找到的字典（dictionary）类型非常相似，通常字典都是用散列映射（hash map）（或哈希表（hash table））实现的。 假设我们的数据存储只是一个追加写入的文件，最简单的索引策略就是：保留一个内存中的哈希映射，其中每个键都映射到一个数据文件中的字节偏移量，指明了可以找到对应值的位置\n新的键值写入文件时，还要更新散列映射。 查找一个值时，使用哈希映射来查找数据文件中的偏移量，寻找（seek） 该位置并读取该值。 Bitcask实际上就是这么做的，非常适合每个键的值频繁更新的情况。 如果一直追加文件，怎么防止用完磁盘空间？ 将日志分为特定大小的段，当日志增长到特定尺寸时关闭当前段文件，并开始写入一个新的段文件。 然后，我们就可以对这些段进行压缩（compaction）。 压缩意味着在日志中丢弃重复的键，只保留每个键的最近更新。 也可以把多个段的内容压缩合并到一起。\n段被写入后永远不会被修改，所以合并的段被写入一个新的文件。 冻结段的合并和压缩可以在后台线程中完成，在进行时，我们仍然可以继续使用旧的段文件来正常提供读写请求。 合并过程完成后，我们将读取请求转换为使用新的合并段而不是旧段 —— 然后可以简单地删除旧的段文件。 每个段都有自己的内存散列表，将键映射到文件偏移量。查找键时，依次遍历所有的散列表。 重要的问题：\n文件格式 a. csv 不好，使用二进制格式更快。 2. 删除记录 a. 删除一个键，则必须在数据文件（有时称为逻辑删除）中附加一个特殊的删除记录。 b. 当日志段被合并时，逻辑删除告诉合并过程放弃删除键的任何以前的值。 3. 崩溃恢复 a. 如果数据库重新启动，则内存散列映射将丢失。 b. 可以根据日志文件重新恢复每个段的哈希映射，但段很大的时候，很费时间。 c. Bitcask通过存储加速恢复磁盘上每个段的哈希映射的快照，可以更快地加载到内存中。 4. 部分写入记录 a. 数据库可能随时崩溃，包括将记录附加到日志中途。 b. Bitcask文件包含校验和，允许检测和忽略日志的这些损坏部分。 5. 并发控制 a. 写操作是以严格顺序的顺序附加到日志中的，所以常见的方法是只有一个写线程。 b. 读操作可以有多个线程同时读取。 为什么采用追加模式，而不是不更新文件，用新值覆盖旧值？ 原因有几个：\n追加和分段合并是顺序写入操作，通常比随机写入快得多，尤其是在磁盘旋转硬盘上。在某种程度上，顺序写入在基于闪存的 固态硬盘（SSD） 上也是优选的。 如果段文件是附加的或不可变的，并发和崩溃恢复就简单多了。 合并旧段可以避免数据文件随着时间的推移而分散的问题。 哈希表索引的局限性：\n散列表必须能放进内存：当有很多键的时候，Hash 冲突，占用内存。 范围查询效率不高：不支持查一个取值区间内的所有键。 3.1.3 SSTables和LSM树 在之前的存储中，每个日志结构存储段都是一系列键值对。这些对按照它们写入的顺序出现，而不是键值对的顺序。 我们做一个简单的改变：我们要求键值对的序列按键排序。把这个格式称为排序字符串表（Sorted String Table），简称 SSTable。同时，要求每个键只在每个合并的段文件中出现一次（压缩过程已经保证）。\nSSTable 与散列索引日志段相比，有几个很大的优势：\n合并段是简单而高效的，即使文件大于可用内存。方法类似于归并排序。 a. 如果在几个输入段中出现相同的键，该怎么办？ ⅰ. 答：保留最近段的值，并丢弃旧段中的值。\n为了在文件中找到一个特定的键，你不再需要保存内存中所有键的索引。因为是有序的，可以先查找出键所处的范围，然后就找到这个键所在的偏移量的区间。比如可以从 handbag 和 handsome 的偏移量找到 handiwork 的区间。 3.1.3.1 构建和维护SSTables 如何让数据首先被按键排序呢？\n在内存中排序简单的多，比如红黑树、AVL 树； 存储工作的操作步骤：\n写入时，将其添加到内存中的平衡树数据结构（例如，红黑树）。这个内存树有时被称为内存表（memtable）。 当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘。这可以高效地完成，因为树已经维护了按键排序的键值对。新的SSTable文件成为数据库的最新部分。当SSTable被写入磁盘时，写入可以继续到一个新的内存表实例。 为了提供读取请求，首先尝试在内存表中找到关键字，然后在最近的磁盘段中，然后在下一个较旧的段中找到该关键字。 有时会在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值。 如何解决数据库崩溃，则最近的写入（在内存表中，但尚未写入磁盘）将丢失的问题？\n我们可以在磁盘上保存一个单独的日志，每个写入都会立即被附加到磁盘上， 该日志不是按排序顺序，但这并不重要，因为它的唯一目的是在崩溃后恢复内存表。 每当内存表写出到SSTable时，相应的日志都可以被丢弃。 3.1.3.2 用SSTables制作LSM树 LSM 树：在 LevelDB 和 RocksDB 使用。\n3.1.3.3 性能优化 当查找数据库中不存在的键时，LSM树算法可能会很慢：您必须检查内存表，然后将这些段一直回到最老的（可能必须从磁盘读取每一个），然后才能确定键不存在。 解决办法：布隆过滤器。 2. SSTables 被压缩和合并的顺序和时间 大小分层压实。 LevelDB和RocksDB使用平坦压缩（LevelDB因此得名）； HBase 使用大小分层； Cassandra 同时支持。 3.1.3.4 B树 像SSTables一样，B树保持按键排序的键值对，这允许高效的键值查找和范围查询。 不同：\n日志结构索引将数据库分解为可变大小的段，通常是几兆字节或更大的大小，并且总是按顺序编写段。 B 树将数据库分解成固定大小的块或页面，传统上大小为4KB（有时会更大），并且一次只能读取或写入一个页面。 这种设计更接近于底层硬件，因为磁盘也被安排在固定大小的块中。 每个页面都可以使用地址或位置来标识，这允许一个页面引用另一个页面 —— 类似于指针，但在磁盘而不是在内存中。\n查找过程： ● 一个页面会被指定为B树的根；在索引中查找一个键时，就从这里开始。 ● 该页面包含几个键和对子页面的引用。 ● 每个子页面负责一段连续范围的键，引用之间的键，指明了引用子页面的键范围。 ● 最后，我们可以看到包含单个键（叶页）的页面，该页面包含每个键的内联值，或者包含对可以找到值的页面的引用。\n更新过程： ● 搜索包含该键的叶页，更改该页中的值，并将该页写回到磁盘原来的位置（对该页的任何引用保持有效）\n插入过程： ● 找到其范围包含新键的页面，并将其添加到该页面。 ● 如果页面中没有足够的可用空间容纳新键，则将其分成两个半满页面，并更新父页面以解释键范围的新分区。 删除过程： ● 删除一个键（同时保持树平衡）就牵扯很多其他东西了。\n深度： ● 该算法确保树保持平衡：具有 n 个键的B树总是具有 $O(log n)$ 的深度。 ● 大多数数据库可以放入一个三到四层的 B 树，所以你不需要遵追踪多页面引用来找到你正在查找的页面。 （分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB 。）\n3.1.3.5 让B树更可靠 ● B 树的基本底层写操作是用新数据覆盖磁盘上的页面。 ● 假定覆盖不改变页面的位置； ● 而日志结构索引（如LSM树）只附加到文件（并最终删除过时的文件），但从不修改文件。\n危险操作： ● 插入导致页面过度而拆分页面，则需要编写已拆分的两个页面，并覆盖其父页面以更新对两个子页面的引用。 ● 这是一个危险的操作，因为如果数据库在仅有一些页面被写入后崩溃，那么最终将导致一个损坏的索引（例如，可能有一个孤儿页面不是任何父项的子项） 。\n预写式日志（WAL） ● 为了使数据库对崩溃具有韧性，B树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log）（也称为重做日志（redo log））。 ● 这是一个仅追加的文件，每个B树修改都可以应用到树本身的页面上。 ● 当数据库在崩溃后恢复时，这个日志被用来使B树恢复到一致的状态.\n并发访问： ● 更新页面时，如果多个线程要同时访问B树，则需要仔细的并发控制，否则可能会看到树处于不一致的状态。 ● 通过使用锁存器（latches）（轻量级锁）保护树的数据结构来完成 ● 而 LSM 比较简单：在后台完成所有的合并，不干扰查询；通过「原子交换」把旧的分段变为新的分段。\n3.1.3.6 B树优化 ● LMDB 数据库中使用「写时复制方案 」，而不是不是覆盖页面并维护 WAL 进行崩溃恢复。 ○ 修改的页面被写入到不同的位置，并且树中的父页面的新版本被创建，指向新的位置。 ○ 这种方法对于并发控制也很有用。 ● 保存键的缩略信息，而不是完整的键。 ○ 键只用保存一个区间，而不是具体的数值（类似于 B+树）。 ○ 可以包含更多的键，减少树的层次。 ● 不方便扫描大部分关键词的范围查找。 ○ 许多B树实现尝试布局树，使得叶子页面按顺序出现在磁盘上。 ○ 但是，随着树的增长，维持这个顺序是很困难的。 ○ 相比之下，由于LSM树在合并过程中一次又一次地重写存储的大部分，所以它们更容易使顺序键在磁盘上彼此靠近。 ● 额外的指针已添加到树中。 ○ 例如，每个叶子页面可以在左边和右边具有对其兄弟页面的引用，这允许不跳回父页面就能顺序扫描。 ● B树的变体如分形树借用一些日志结构的思想来减少磁盘寻道（而且它们与分形无关）。\n3.1.4 比较B树和LSM树 通常LSM树的写入速度更快，而B树的读取速度更快。 LSM树上的读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。\n3.1.4.1 LSM树的优点 ● B树索引必须至少两次写入每一段数据：一次写入预先写入日志，一次写入树页面本身（也许再次分页） ● 即使在该页面中只有几个字节发生了变化，也需要一次编写整个页面的开销。 ● 有些存储引擎甚至会覆盖同一个页面两次，以免在电源故障的情况下导致页面部分更新\n写放大 ● 反复压缩和合并SSTables，日志结构索引也会重写数据。 ● 在数据库的生命周期中写入数据库导致对磁盘的多次写入 —— 被称为写放大（write amplification）。 ● 存储引擎写入磁盘的次数越多，可用磁盘带宽内的每秒写入次数越少。\nLSM树通常能够比B树支持更高的写入吞吐量： ● 部分原因是它们有时具有较低的写放大（尽管这取决于存储引擎配置和工作负载） ● 部分是因为它们顺序地写入紧凑的SSTable文件而不是必须覆盖树中的几个页面 ● 这种差异在磁性硬盘驱动器上尤其重要，顺序写入比随机写入快得多。\n文件碎片： ● LSM树可以被压缩得更好，因此经常比B树在磁盘上产生更小的文件。 ● B树存储引擎会由于分割而留下一些未使用的磁盘空间 ● 由于LSM树不是面向页面的，并且定期重写SSTables以去除碎片，所以它们具有较低的存储开销，特别是当使用平坦压缩时\n3.1.4.2 LSM树的缺点 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。 B树的行为则相对更具可预测性。\n高写入吞吐量： ● 磁盘的有限写入带宽需要在初始写入（记录和刷新内存表到磁盘）和在后台运行的压缩线程之间共享。 ● 写入空数据库时，可以使用全磁盘带宽进行初始写入，但数据库越大，压缩所需的磁盘带宽就越多。\n压缩和读取的速度： ● 如果写入吞吐量很高，并且压缩没有仔细配置，压缩跟不上写入速率。 ● 在这种情况下，磁盘上未合并段的数量不断增加，直到磁盘空间用完，读取速度也会减慢，因为它们需要检查更多段文件。\n键出现的个数： ● B树的一个优点是每个键只存在于索引中的一个位置，而日志结构化的存储引擎可能在不同的段中有相同键的多个副本。 ● 有利于事务语义。 ● 在许多关系数据库中，事务隔离是通过在键范围上使用锁来实现的，在B树索引中，这些锁可以直接连接到树\n3.1.5 其他索引结构 前面讨论的是关键值索引，它们就像关系模型中的主键（primary key） 索引。主键唯一标识关系表中的一行、一个文档、一个顶点。\n二级索引 ● 在关系数据库中，您可以使用 CREATE INDEX 命令在同一个表上创建多个二级索引，而且这些索引通常对于有效地执行联接而言至关重要。 ● 一个二级索引可以很容易地从一个键值索引构建，区别是键不是唯一的。实现方式： ○ 通过使索引中的每个值，成为匹配行标识符的列表（如全文索引中的发布列表） ○ 通过向每个索引添加行标识符来使每个关键字唯一 ○ 无论哪种方式，B树和日志结构索引都可以用作辅助索引。\n3.1.5.1 将值存储在索引中 索引中的关键字是查询搜索的内容，它属于两种之一： ● 实际行（文档，顶点） ● 对存储在别处的行的引用。此时，行被存储的地方被称为堆文件（heap file），并且存储的数据没有特定的顺序 ○ 堆文件很常见。 ○ 它避免了在存在多个二级索引时复制数据 ○ 新值字节数不大于旧值，原地覆盖； ○ 新值更大，需要移到堆中有足够空间的新位置； ■ 此时，要么所有索引都更新指向新堆位置； ■ 要么在旧堆位置留一个转发指针。\n聚集索引 ● 从索引到堆文件的额外跳转性能损失太大，希望可以把索引行直接进存储到索引中。被叫做聚集索引。 ● 在 MySQL 的 InnoDB 存储引擎中，表的主键总是一个聚簇索引，二级索引用主键（而不是堆文件中的位置） ● 在SQL Server中，可以为每个表指定一个聚簇索引。\n包含列的索引或覆盖索引 ● 在 聚集索引（clustered index） （在索引中存储所有行数据）和 非聚集索引（nonclustered index） （仅在索引中存储对数据的引用）之间的折衷被称为 包含列的索引（index with included columns）或覆盖索引（covering index），其存储表的一部分在索引内。 ● 允许通过单独使用索引来回答一些查询。 ● 加快了读取速度，但是增加了额外的存储空间，增加了写入开销，还要事务保证。\n3.1.5.2 多列索引 上面讨论的都是一个 key 对应一个 value，如果需要同时根据一个表中的多个列（或文档中的多个字段）进行查询，则不行。 ● 连接索引（concatenated index） ○ 将一列的值追加到另一列后面，简单地将多个字段组合成一个键。 ○ 但是这不能做复杂查询。 ● 多维索引（multi-dimensional index） ○ 比如需要根据经纬度做二维范围查询，则 B 树和 LSM 树不能高效； ○ 普遍做法是用特殊化的空间索引，比如 R 树（TODO）。 ○ 多维索引除了地理位置，还可以用于其他很多地方：电子网站、天气数据。\n3.1.5.3 全文搜索和模糊索引 上文讨论的索引都是查询确切的值或者确定范围的值，如果搜索类似的键，需要用模糊查询。\n全文搜索引擎 ● 允许搜索一个单词以扩展为包括该单词的同义词，忽略单词的语法变体，并且搜索在相同文档中彼此靠近的单词的出现，并且支持各种其他功能取决于文本的语言分析。 ● 为了处理文档或查询中的拼写错误，Lucene能够在一定的编辑距离内搜索文本（编辑距离1意味着添加，删除或替换了一个字母）\nLucene ● 为其词典使用了一个类似于SSTable的结构。 ● 这个结构需要一个小的内存索引，告诉查询在排序文件中哪个偏移量需要查找关键字。 ● 在 LevelDB 中，这个内存中的索引是一些键的稀疏集合。 ● 但在 Lucene 中，内存中的索引是键中字符的有限状态自动机，类似于trie。 ● 这个自动机可以转换成 Levenshtein 自动机，它支持在给定的编辑距离内有效地搜索单词。\n3.1.5.4 在内存中存储一切 对于磁盘和SSD，如果要在读取和写入时获得良好性能，则需要仔细地布置磁盘上的数据。 磁盘优点：耐用，成本低。 内存变得便宜，促进了内存数据库发展。\n内存数据库 ● 某些内存中的键值存储（如Memcached）仅用于缓存，在重新启动计算机时丢失的数据是可以接受的。 ● 但其他内存数据库的目标是持久性，可以通过特殊的硬件（例如电池供电的RAM），将更改日志写入磁盘，将定时快照写入磁盘或通过复制内存来实现，记忆状态到其他机器。\n实现 ● 内存数据库重新启动时，需要从磁盘或通过网络从副本重新加载其状态（除非使用特殊的硬件）。 ● 尽管写入磁盘，它仍然是一个内存数据库，因为磁盘仅用作耐久性附加日志，读取完全由内存提供。 ● 写入磁盘也具有操作优势：磁盘上的文件可以很容易地由外部实用程序进行备份，检查和分析。\n常见产品 ● VoltDB，MemSQL和Oracle TimesTen等产品是具有关系模型的内存数据库 ● RAM Cloud是一个开源的内存键值存储器，具有持久性（对存储器中的数据以及磁盘上的数据使用日志结构化方法） ● Redis和Couchbase通过异步写入磁盘提供了较弱的持久性。\n内存数据库性能优势到底在哪？ ● 内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。 ● 即使是基于磁盘的存储引擎也可能永远不需要从磁盘读取，因为操作系统缓存最近在内存中使用了磁盘块。 ● 相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。\n除了性能还有什么优势？ ● 提供了难以用基于磁盘的索引实现的数据模型。 ● 例如，Redis为各种数据结构（如优先级队列和集合）提供了类似数据库的接口。因为它将所有数据保存在内存中，所以它的实现相对简单。\n内存不够用怎么办？ ● 反缓存（anti-caching） 方法通过在内存不足的情况下将最近最少使用的数据从内存转移到磁盘，并在将来再次访问时将其重新加载到内存中。 ● 这与操作系统对虚拟内存和交换文件的操作类似，但数据库可以比操作系统更有效地管理内存，因为它可以按单个记录的粒度工作，而不是整个内存页面。 ● 尽管如此，这种方法仍然需要索引能完全放入内存中。\n3.2 事务处理还是分析？ 事务处理 ● 早起的业务处理，典型的数据库写入与一笔商业交易（transaction）相对应，以后交易/事务（transaction） 仍留了下来。 ● 事务不一定具有ACID（原子性，一致性，隔离性和持久性）属性。 ● 事务处理只是意味着允许客户端进行低延迟读取和写入 —— 而不是只能定期运行（例如每天一次）的批量处理作业。 ● 数据库仍然常被用作在线事务处理（OLTP, OnLine Transaction Processing） 。\n数据分析 ● 数据库也开始越来越多地用于数据分析，需要扫描大量记录； ● 为了将这种使用数据库的模式和事务处理区分开，它被称为在线分析处理（OLAP, OnLine Analytice Processing）\n属性 事务处理 OLTP 分析系统 OLAP 主要读取模式 查询少量记录，按键读取 在大批量记录上聚合 主要写入模式 随机访问，写入要求低延时 批量导入（ETL），事件流 主要用户 终端用户，通过Web应用 内部数据分析师，决策支持 处理的数据 数据的最新状态（当前时间点） 随时间推移的历史事件 数据集尺寸 GB ~ TB TB ~ PB/td\u003e 起初，相同的数据库用于事务处理和分析查询，SQL 可以支持 OLTP 和 OLAP。现在有趋势在用数据仓库。 3.2.1 数据仓库 OLTP 系统对业务运作很重要，因而通常会要求 高可用 与 低延迟，不愿意做影响事务性能的分析查询。 数据仓库是一个独立的数据库，分析人员可以查询他们想要的内容而不影响OLTP操作 数据仓库包含公司各种OLTP系统中所有的只读数据副本。 从OLTP数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。将数据存入仓库的过程称为“抽取-转换-加载（ETL）” 使用单独的数据仓库，而不是直接查询OLTP系统进行分析的一大优势是数据仓库可针对分析访问模式进行优化。上文的索引不适合数据仓库，需要单独的存储引擎。 #### OLTP数据库和数据仓库之间的分歧 数据仓库的数据模型通常是关系型的，因为SQL通常很适合分析查询。 表面上，一个数据仓库和一个关系OLTP数据库看起来很相似，因为它们都有一个SQL查询接口。 实际上，内部完全不同，因为对不同的查询模式进行了优化。 一般的数据库都把重点放在支持事务处理或分析工作负载上，而不是两者都支持。 3.2.2 星型和雪花型：分析的模式 事务处理领域中，使用了大量不同的数据模型。 分析型业务中，数据模型的多样性则少得多。许多数据仓库都以相当公式化的方式使用，被称为星型模式（也称为维度建模）。 用于数据仓库的星型模式的示例 在模式的中心是一个所谓的事实表（在这个例子中，它被称为 fact_sales）。 事实表的每一行代表在特定时间发生的事件（这里，每一行代表客户购买的产品）。 周围是维度表。 事实表可能非常大，有万亿行和数PB的数据，列通常超过 100 列。 被称为“星型模式”是因为事实表在中间，维度表在周围，像星星一样。 “雪花模式”：维度表进一步拆分成子维度表。 “星型模式”比较简单，是首选。 3.3 列存储 事实表的高效存储和查询是问题。 维度表比较小，不讨论。 在分析中经常只查询部分列，而不是所有列。 面向列的存储\n不是把每一行的值存储在一起，而是将每一列的所有值存放在一起。 面向列的存储布局依赖于每个列文件包含相同顺序的行。 3.3.1 列压缩 ● 除了仅从磁盘加载查询所需的列以外，我们还可以通过压缩数据来进一步降低对磁盘吞吐量的需求。 ● 面向列的存储通常很适合压缩。\n位图编码 当 n 非常大，大部分位图中将会有很多的零（我们说它们是稀疏的）。 位图可以另外进行游程编码，这可以使列的编码非常紧凑。 位图索引可以很方便的做各种查询：ADN/OR 3.3.1.1 内存带宽和向量处理 ● 需要扫描数百万行的数据仓库查询来说，瓶颈： ○ 是从磁盘获取数据到内存的带宽。 ○ 主存储器带宽到CPU缓存中的带宽，避免CPU指令处理流水线中的分支错误预测和泡沫，以及在现代中使用单指令多数据（SIMD）指令CPU ● 面向列的存储布局： ○ 可以将大量压缩的列数据放在CPU的L1缓存中，然后在紧密的循环中循环（即没有函数调用） ○ 更有利于 CPU 的计算。\n3.3.2 列存储中的排序顺序 ● 在列存储中，存储行的顺序并不一定很重要。 ● 按插入顺序存储它们是最简单的，因为插入一个新行只需要追加到每个列文件。 ● 每列独自排序是没有意义的，因为那样我们就不会知道列中的哪些项属于同一行 ● 即使按列存储数据，也需要一次对整行进行排序。\n好处 ● 速度快：这样数据库的管理员可以根据他们对常用查询的了解来选择表格应该被排序的列。 ● 压缩列：第一个排序键的压缩效果最强。\n3.3.2.1 几个不同的排序顺序 ● 不同的查询受益于不同的排序顺序，而无论如何，数据需要复制到多台机器， ● 在一个面向列的存储中有多个排序顺序有点类似于在一个面向行的存储中有多个二级索引。\n3.3.3 写入列存储 列存储的优点：大部分只用查询；压缩和排序都有助于更快地读取这些查询。 缺点：写入困难。插入必须始终更新所有列。\n解决方案：LSM树。 ● 现在内存中存储，添加到一个已排序的结构中，然后准备写入磁盘。\n3.3.4 聚合：数据立方体和物化视图 并不是每个数据仓库都必定是一个列存储。列存储在迅速普及。\n物化汇总 ● 数据仓库查询通常涉及一个聚合函数，如SQL中的COUNT，SUM，AVG，MIN或MAX。 ● 创建这种缓存的一种方式是物化视图（Materialized View）。\n物化数据立方体的优点是某些查询变得非常快，因为它们已经被有效地预先计算了。\n3.4 本章小结 优化 事务处理（OLTP） 或 在线分析（OLAP） 。这些用例的访问模式之间有很大的区别： ● OLTP系统通常面向用户，这意味着系统可能会收到大量的请求。为了处理负载，应用程序通常只访问每个查询中的少部分记录。应用程序使用某种键来请求记录，存储引擎使用索引来查找所请求的键的数据。磁盘寻道时间往往是这里的瓶颈。 ● 数据仓库和类似的分析系统会低调一些，因为它们主要由业务分析人员使用，而不是由最终用户使用。它们的查询量要比OLTP系统少得多，但通常每个查询开销高昂，需要在短时间内扫描数百万条记录。磁盘带宽（而不是查找时间）往往是瓶颈，列式存储是这种工作负载越来越流行的解决方案。\n在OLTP方面，我们能看到两派主流的存储引擎：\n日志结构学派\n只允许附加到文件和删除过时的文件，但不会更新已经写入的文件。 Bitcask，SSTables，LSM树，LevelDB，Cassandra，HBase，Lucene等都属于这个类别。\n就地更新学派\n将磁盘视为一组可以覆写的固定大小的页面。 B树是这种哲学的典范，用在所有主要的关系数据库中和许多非关系型数据库。 日志结构的存储引擎是相对较新的发展。他们的主要想法是，他们系统地将随机访问写入顺序写入磁盘，由于硬盘驱动器和固态硬盘的性能特点，可以实现更高的写入吞吐量。在完成OLTP方面，我们通过一些更复杂的索引结构和为保留所有数据而优化的数据库做了一个简短的介绍。\n第四章：数据编码与演化 应用程序总是增增改改。 修改程序大多数情况下也在修改存储的数据。\n关系数据库通常假定数据库中的所有数据都遵循一个模式：尽管可以更改该模式（通过模式迁移，即ALTER语句），但是在任何时间点都有且仅有一个正确的模式。 读时模式（schema-on-read）（或 无模式（schemaless））数据库不会强制一个模式，因此数据库可以包含在不同时间写入的新老数据格式的混合。 当数据格式发生改变时，需要代码更改：\n服务端应用程序，会灰度发布； 客户端应用程序，看用户心情。 新旧版本的代码和数据，可能同时共处。 系统需要双向兼容：\n向后兼容：新代码可以读旧数据。容易。 向前兼容：旧代码可以读新数据。难。 4.1 编码数据的格式 程序通常（至少）使用两种形式的数据：\n在内存中，数据保存在对象，结构体，列表，数组，哈希表，树等中。 这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）。 如果要将数据写入文件，或通过网络发送，则必须将其 编码（encode） 为某种自包含的字节序列（例如，JSON文档）。 由于每个进程都有自己独立的地址空间，一个进程中的指针对任何其他进程都没有意义，所以这个字节序列表示会与通常在内存中使用的数据结构完全不同。 所以，需要在两种表示之间进行某种类型的翻译。\n从内存中表示到字节序列的转换称为 编码（Encoding） （也称为序列化（serialization） 或编组（marshalling））； 反过来称为解码（Decoding）ii（解析（Parsing），反序列化（deserialization），反编组( unmarshalling））译i。 4.1.1 语言特定的格式 许多编程语言都内建了将内存对象编码为字节序列的支持。例如，Java有java.io.Serializable ，Ruby有Marshal，Python有pickle .\n这些库很方便，但是有深层次问题：\n与特定的编程语言绑定。 为了恢复相同对象类型的数据，解码过程需要实例化任意类的能力，这是安全问题的来源。 数据版本控制不方便。 效率也不高。 只适合临时使用。\n4.1.2 JSON，XML和二进制变体 跨语言的编码：JSON，XML和CSV，属于文本格式，因此具有人类可读性。 除了语法问题外，还有问题：\n数值编码有歧义：XML 和 CSV 不能区分数字和字符串。JSON 不能区分整数和浮点数。 处理大数值困难。 JSON 和 XML 对 unicode（人类可读的文本）有很好的支持，但是不支持二进制。通过 base64 绕过这个限制。 XML 和 JSON 都有可选的模式支持。 CSV 没有模式，行列的含义完全由应用程序指定。格式模糊。 虽然问题多，但是大家对这些达成了意见一致。\n4.1.2.1 二进制编码 当数据很多的时候，数据格式的选择会有很大影响。 JSON比XML简洁，但与二进制格式相比还是太占空间。现在有很多二进制格式的 JSON（MessagePack，BSON，BJSON，UBJSON，BISON和Smile等）。 JSON 字符串是：\n1 2 3 4 5 6 { \u0026#34;userName\u0026#34;: \u0026#34;Martin\u0026#34;, \u0026#34;favoriteNumber\u0026#34;: 1337, \u0026#34;interests\u0026#34;: [\u0026#34;daydreaming\u0026#34;, \u0026#34;hacking\u0026#34;] } 二进制编码长度为66个字节，仅略小于文本JSON编码所取的81个字节（删除了空白）。\n4.1.3 Thrift与Protocol Buffers Protocol Buffers最初是在Google开发的，Thrift最初是在Facebook开发的，并且在2007~2008年都是开源的，都是二进制编码库。 Thrift和Protocol Buffers都需要一个模式来编码任何数据。 接口定义语言（IDL） 来描述模式。\nThrift 比如： 1 2 3 4 5 struct Person { 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list\u0026lt;string\u0026gt; interests } Protocol Buffers的等效模式定义看起来非常相似： 1 2 3 4 5 message Person { required string user_name = 1; optional int64 favorite_number = 2; repeated string interests = 3; } Thrift和Protocol Buffers每一个都带有一个代码生成工具，可以调用此代码对模式进行编码和解码。 Thrift 编码格式\nThrift 有两种不同的二进制编码格式，分别称为 BinaryProtocol 和 CompactProtocol BinaryProtocol\n\u0026ndash; 对上面的信息编码只需要59个字节\n每个字段都有一个类型注释（用于指示它是一个字符串，整数，列表等），还可以根据需要指定长度（字符串的长度，列表中的项目数） 。 最大的区别是没有字段名，而只有字段标签，即数字 1，2，3，就像别名。 CompactProtocol\n语义上等同于BinaryProtocol 将字段类型和标签号打包到单个字节中，并使用可变长度整数来实现 相同的信息打包成只有 34 个字节 将数字 1337 编码成为 2 个字节，每个字节的最高位标识是否还有更多的字节。 Protocol Buffers\n只有一种二进制编码格式，与Thrift的CompactProtocol非常相似。 同样的记录塞进了33个字节中。 字段是否为必须？\n如果字段没有设置值，则从编码记录中省略。 模式中每个字段标记为是否为必须，但对编码无影响。 区别在于，如果字段设置为必须，但是未设置，那么运行时检查会失败。 4.1.3.1 字段标签和模式演变 字段标记很重要！可以改字段的名字，但是不能改字段标记。 向前兼容：可以添加新字段，只要有一个新的标记号码。 向后兼容：在模式初始部署之后，添加的每个字段必须是可选的或具有默认值。否则之前的代码会检查失败。 删除字段：只能删除可选字段；不能再次使用相同的标签号码。 4.1.3.2 数据类型和模式演变 数据类型可以被改变: int32 升级 int64, 新代码可以读取旧代码写入的数据(补0)；但是旧的代码不能解析新的数据(int32 读取 int64 会被截断) Protobuf 一个细节：没有列表类型，只有 repeated，因此可以把可选字段改为重置字段。 Thrift不能更改为列表参数，但优点是可以嵌套列表. 4.1.4 Avro Apache Avro 是另一种二进制编码格式 Avro 有两种模式语言：一种(Avro IDL) 用于人工编辑，一种（基于JSON）更易于机器读取。 举例:\n1 2 3 4 5 record Person { string userName; union { null, long } favoriteNumber = null; array\u0026lt;string\u0026gt; interests; } 等价的JSON表示:\n1 2 3 4 5 6 7 8 9 { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;userName\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;favoriteNumber\u0026#34;, \u0026#34;type\u0026#34;: [\u0026#34;null\u0026#34;, \u0026#34;long\u0026#34;], \u0026#34;default\u0026#34;: null}, {\u0026#34;name\u0026#34;: \u0026#34;interests\u0026#34;, \u0026#34;type\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: \u0026#34;string\u0026#34;} ] } 注意：没有标签号码。 Avro二进制编码只有32个字节长，最紧凑的。 编码知识连在一起的值，不能识别字段和数据类型。 必须按照顺序遍历字段才能解码。 编码和解码必须使用完全相同的模式。 4.1.4.1 Writer模式与Reader模式 Avro的关键思想是Writer模式和Reader模式不必是相同的 - 他们只需要兼容。 当数据解码（读取）时，Avro库通过并排查看Writer模式和Reader模式并将数据从Writer模式转换到Reader模式来解决差异。（即数据读取的时候，会对比 Writer模式 和 Reader模式 的字段，然后就知道怎么读了） 4.1.4.2 模式演变规则 为了保持兼容性，您只能添加或删除具有默认值的字段。 4.1.4.3 但Writer模式到底是什么？ 对于一段特定的编码数据，Reader如何知道其Writer模式？ 答案取决于Avro使用的上下文。举几个例子：\n有很多记录的大文件\n○ Avro的一个常见用途 - 尤其是在Hadoop环境中 - 用于存储包含数百万条记录的大文件，所有记录都使用相同的模式进行编码。可以在文件的开头只包含一次Writer模式。\n支持独立写入的记录的数据库\n○ 最简单的解决方案是在每个编码记录的开始处包含一个版本号，并在数据库中保留一个模式版本列表。 通过网络连接发送记录 ○ 他们可以在连接设置上协商模式版本，然后在连接的生命周期中使用该模式。 4.1.4.4 动态生成的模式 Avro方法的一个优点是架构不包含任何标签号码。\n但为什么这很重要？在模式中保留一些数字有什么问题？\n不同之处在于Avro对动态生成的模式更友善。 ○ 方便从数据库生成 Avro 模式，导出数据 ○ 当数据库模式发生变化，直接生成新的 Avro 模式，导出数据。自动兼容。 ○ 而用 Thrift 或者 PB，需要手动写字段标签。 4.1.4.5 代码生成和动态类型的语言 Thrift 和 Protobuf 依赖于代码生成 在定义了模式之后，可以使用您选择的编程语言生成实现此模式的代码。 这在Java，C ++或C＃等静态类型语言中很有用，因为它允许将高效的内存中结构用于解码的数据，并且在编写访问数据结构的程序时允许在IDE中进行类型检查和自动完成。 在动态类型编程语言（如JavaScript，Ruby或Python）中，生成代码没有太多意义，因为没有编译时类型检查器来满足。 Avro为静态类型编程语言提供了可选的代码生成功能，但是它也可以在不生成任何代码的情况下使用。 4.1.5 模式的优点 Protocol Buffers，Thrift和Avro都使用模式来描述二进制编码格式。 他们的模式语言比XML模式或者JSON模式简单得多，也支持更详细的验证规则。 许多数据系统（如关系型数据库）也为其数据实现了某种专有的二进制编码。 基于模式的二进制编码相对于JSON，XML和CSV等文本数据格式的优点： 它们可以比各种“二进制JSON”变体更紧凑，因为它们可以省略编码数据中的字段名称。 模式是一种有价值的文档形式，因为模式是解码所必需的，所以可以确定它是最新的（而手动维护的文档可能很容易偏离现实）。 维护一个模式的数据库允许您在部署任何内容之前检查模式更改的向前和向后兼容性。 对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，因为它可以在编译时进行类型检查。 4.2 数据流的类型 数据在流程之间流动的一些常见的方式：\n通过数据库 通过服务调用 通过异步消息传递 4.2.1 数据库中的数据流 如果只有一个进程访问数据库，向后兼容性显然是必要的。 一般来说，会有多个进程访问数据库，可能会有某些进程运行较新代码、某些运行较旧的代码。因此数据库也经常需要向前兼容。 假设增加字段，那么较新的代码会写入把该值吸入数据库。而旧版本的代码将读取记录，理想的行为是旧代码保持领域完整。 用旧代码读取并重新写入数据库时，有可能会导致数据丢失。 4.2.1.1 在不同的时间写入不同的值 单一的数据库中，可能有一些值是五毫秒前写的，而一些值是五年前写的。 架构演变允许整个数据库看起来好像是用单个模式编码的，即使底层存储可能包含用模式的各种历史版本编码的记录。 4.2.1.2 归档存储 建立数据库快照，比如备份或者加载到数据仓库：即使有不同时代的模式版本的混合，但通常使用最新模式进行编码。 由于数据转储是一次写入的，以后不变，所以 Avro 对象容器文件等格式非常适合。 也是很好的机会，把数据编码成面向分析的列式格式。 4.2.2 服务中的数据流：REST与RPC 网络通信方式：常见安排是客户端+服务器 Web 服务：通过 GET 和 POST 请求 服务端可以是另一个服务的客户端：微服务架构。 微服务架构允许某个团队能够经常发布新版本服务，期望服务的新旧版本同时运行。 4.2.2.1 Web服务 当服务使用HTTP作为底层通信协议时，可称之为Web服务。 有两种流行的Web服务方法：REST和SOAP。 REST\n● REST不是一个协议，而是一个基于HTTP原则的设计哲学。 ● 它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制，身份验证和内容类型协商。 ● 与SOAP相比，REST已经越来越受欢迎，至少在跨组织服务集成的背景下，并经常与微服务相关。 ● 根据REST原则设计的API称为RESTful。 SOAP\nSOAP是用于制作网络API请求的基于XML的协议。 它最常用于HTTP，但其目的是独立于HTTP，并避免使用大多数HTTP功能。 SOAP Web服务的API使用称为Web服务描述语言（WSDL）的基于XML的语言来描述。 WSDL支持代码生成，客户端可以使用本地类和方法调用（编码为XML消息并由框架再次解码）访问远程服务。 尽管SOAP及其各种扩展表面上是标准化的，但是不同厂商的实现之间的互操作性往往会造成问题。 尽管许多大型企业仍然使用SOAP，但在大多数小公司中已经不再受到青睐。 4.2.2.2 远程过程调用（RPC）的问题 RPC模型试图向远程网络服务发出请求，看起来与在同一进程中调用编程语言中的函数或方法相同（这种抽象称为位置透明）。\nRPC的缺陷\n本地函数调用是可预测的，并且成功或失败仅取决于受您控制的参数。而网络请求是不可预知的。 本地函数调用要么返回结果，要么抛出异常，或者永远不返回（因为进入无限循环或进程崩溃）。网络请求有另一个可能的结果：由于超时，它可能会返回没有结果。无法得知远程服务的响应发生了什么。 如果您重试失败的网络请求，可能会发生请求实际上正在通过，只有响应丢失。在这种情况下，重试将导致该操作被执行多次，除非您在协议中引入除重（ 幂等（idempotence））机制。本地函数调用没有这个问题。 每次调用本地功能时，通常需要大致相同的时间来执行。网络请求慢得多，不可预知。 调用本地函数时，可以高效地将引用（指针）传递给本地内存中的对象。当你发出一个网络请求时，所有这些参数都需要被编码成可以通过网络发送的一系列字节。如果参数是像数字或字符串这样的基本类型倒是没关系，但是对于较大的对象很快就会变成问题。 客户端和服务端可以用不同的编程语言实现，RPC 框架必须把数据类型做翻译，可能会出问题。 4.2.2.3 RPC的当前方向 RPC 不会消失。\n● Thrift和Avro带有RPC支持 ● gRPC是使用Protocol Buffers的RPC实现 ● Finagle也使用Thrift ● Rest.li使用JSON over HTTP。 当前方向\n这种新一代的RPC框架更加明确的是，远程请求与本地函数调用不同。 其中一些框架还提供服务发现，即允许客户端找出在哪个IP地址和端口号上可以找到特定的服务。 REST似乎是公共API的主要风格。 REST 使用二进制编码性能更好 方便实验和调试 能被所有主流的编程语言和平台支持 大量可用的工具的生态系统 4.2.2.4 数据编码与RPC的演化 可演化性，重要的是可以独立更改和部署RPC客户端和服务器。 我们可以做个假定：假定所有的服务器都会先更新，其次是所有的客户端。 您只需要在请求上具有向后兼容性，并且对响应具有前向兼容性。 RPC方案的前后向兼容性属性从它使用的编码方式中继承：\nThrift，gRPC（Protobuf）和Avro RPC可以根据相应编码格式的兼容性规则进行演变。/li\u003e 在SOAP中，请求和响应是使用XML模式指定的。 RESTful API 通常使用 JSON（没有正式指定的模式）用于响应，以及用于请求的JSON或URI编码/表单编码的请求参数。 服务的提供者无法控制其客户，所以可能无限期保持兼容性。 对于 RESTful API，常用方法是在 URL 或者 HTTP Accept 头部使用版本号。\n4.2.3 消息传递中的数据流 与直接RPC相比，使用消息代理（消息队列）有几个优点：\n如果收件人不可用或过载，可以充当缓冲区，从而提高系统的可靠性。 它可以自动将消息重新发送到已经崩溃的进程，从而防止消息丢失。 避免发件人需要知道收件人的IP地址和端口号（这在虚拟机经常出入的云部署中特别有用）。 它允许将一条消息发送给多个收件人。 将发件人与收件人逻辑分离（发件人只是发布邮件，不关心使用者）。 与 PRC 相比，差异在于\n● 消息传递通常是单向的：发送者通常不期望收到其消息的回复。 ● 通信模式是异步的：发送者不会等待消息被传递，而只是发送它，然后忘记它。 4.2.3.1 消息代理 RabbitMQ，ActiveMQ，HornetQ，NATS和Apache Kafka这样的开源实现已经流行起来。 通常情况下，消息代理的使用方式如下： 一个进程将消息发送到指定的队列或主题； 代理确保将消息传递给那个队列或主题的一个或多个消费者或订阅者。 在同一主题上可以有许多生产者和许多消费者。 一个主题只提供单向数据流。但是，消费者本身可能会将消息发布到另一个主题上，或者发送给原始消息的发送者使用的回复队列（允许请求/响应数据流，类似于RPC）。 消息代理通常不会执行任何特定的数据模型，消息知识包含一些元数据的字节序列，可以用任何编码格式。 如果消费者重新发布消息到另一个主题，则消息保留未知字段，防止前面数据库环境中描述的问题。 4.2.3.2 分布式的Actor框架 Actor模型是单个进程中并发的编程模型。 逻辑被封装在actor中，而不是直接处理线程（以及竞争条件，锁定和死锁的相关问题）。 每个actor通常代表一个客户或实体，它可能有一些本地状态（不与其他任何角色共享），它通过发送和接收异步消息与其他角色通信。 不保证消息传送：在某些错误情况下，消息将丢失。 由于每个角色一次只能处理一条消息，因此不需要担心线程，每个角色可以由框架独立调度。 分布式Actor框架\n在分布式Actor框架中，此编程模型用于跨多个节点伸缩应用程序。 不管发送方和接收方是在同一个节点上还是在不同的节点上，都使用相同的消息传递机制。 如果它们在不同的节点上，则该消息被透明地编码成字节序列，通过网络发送，并在另一侧解码。 位置透明\n位置透明在actor模型中比在RPC中效果更好，因为actor模型已经假定消息可能会丢失，即使在单个进程中也是如此 尽管网络上的延迟可能比同一个进程中的延迟更高，但是在使用actor模型时，本地和远程通信之间的基本不匹配是较少的。 升级\n分布式的Actor框架实质上是将消息代理和actor编程模型集成到一个框架中。 升级仍然要担心向前和向后兼容问题。 三个流行的分布式actor框架处理消息编码如下：\n默认情况下，Akka使用Java的内置序列化，不提供前向或后向兼容性。 但是，你可以用类似Prototol Buffers的东西替代它，从而获得滚动升级的能力。 Orleans 默认使用不支持滚动升级部署的自定义数据编码格式; 要部署新版本的应用程序，您需要设置一个新的集群，将流量从旧集群迁移到新集群，然后关闭旧集群。 像Akka一样，可以使用自定义序列化插件。 在Erlang OTP中，对记录模式进行更改是非常困难的（尽管系统具有许多为高可用性设计的功能）。 滚动升级是可能的，但需要仔细计划。 4.3 本章小结 本章探讨了编码数据结构的方式。 许多服务需要支持滚动升级：向前、向后兼容性。 我们讨论了几种数据编码格式及其兼容性属性： 编程语言特定的编码仅限于单一编程语言，并且往往无法提供前向和后向兼容性。 JSON，XML和CSV等文本格式非常普遍，其兼容性取决于您如何使用它们。他们有可选的模式语言，这有时是有用的，有时是一个障碍。这些格式对于数据类型有些模糊，所以你必须小心数字和二进制字符串。 像Thrift，Protocol Buffers和Avro这样的二进制模式驱动格式允许使用清晰定义的前向和后向兼容性语义进行紧凑，高效的编码。这些模式可以用于静态类型语言的文档和代码生成。但是，他们有一个缺点，就是在数据可读之前需要对数据进行解码。 我们还讨论了数据流的几种模式，说明了数据编码重要性的不同场景： 数据库，写入数据库的进程对数据进行编码，并从数据库读取进程对其进行解码 RPC和REST API，客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码 异步消息传递（使用消息代理或参与者），其中节点之间通过发送消息进行通信，消息由发送者编码并由接收者解码 结论：前向兼容性和滚动升级在某种程度上是可以实现的。\n第五章：数据复制 复制的目的：\n● 使得数据与用户在地理上接近（从而减少延迟）\n● 即使系统的一部分出现故障，系统也能继续工作（从而提高可用性）\n● 伸缩可以接受读请求的机器数量（从而提高读取吞吐量）\n如果复制的数据不会随时间而改变，那复制就很简单：复制一次即可。 复制的难点在于复制数据的变更。 三种流行的变更复制算法：\n● 单领导者\n● 多领导者\n● 无领导者\n复制时的权衡：使用同步复制还是异步复制？如何处理失败的副本？\n5.1 领导者与追随者 ● 存储数据库副本的每个节点称为 副本（replica）。\n● 多副本的问题：如何确保数据都落在了所有的副本上。\n○ 每次对数据库的写入都要传播到所有副本上，否则副本就会有不一样的数据。\n○ 常见的解决方案：基于领导者的复制（主从复制）。 主从复制工作原理：\n副本之一被指定为领导者（leader，也被称作主库）\na. 客户端写数据时，要把请求发送给领导者； b. 领导者把新输入写入本地存储。 2. 其他副本被称为追随者（followers，也被称作只读副本、从库、热备） a. 每当领导者将新数据写入本地存储时，他会把数据变更发送给所有的追随者，称之为复制日志或变更流。 b. 每个追随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照领导者处理的相同顺序应用所有写入。 3. 当客户想要从数据库中读取数据时，它可以向领导者或追随者查询。 但只有领导者才能接受写操作（从客户端的角度来看从库都是只读的）。 5.1.1 同步复制与异步复制 复制系统的一个重要细节是：复制是 同步（synchronously） 发生还是 异步（asynchronously） 发生。 以用户更新头像为例： ● 从库 1 的复制是同步的 ● 从库 2 的复制是异步的\n同步复制： ● 优点：从库保证和主库一直的最新数据副本 ● 缺点：如果从库没有响应（如已崩溃、网络故障），主库就无法处理写入操作。主库必须阻止所有的写入，等待副本再次可用。\n半同步：通常使用一个从库与主库是同步的，而其他从库是异步的。这保证了至少两个节点拥有最新的数据副本。\n通常情况下，基于领导者的复制都配置为完全异步。注意，主库故障可能导致丢失数据。\n5.1.2 设置新从库 有时会增加一个新的从库。\n过程：\n在某个时刻获取主库的一致性快照（如果可能），而不必锁定整个数据库。大多数数据库都具有这个功能，因为它是备份必需的。对于某些场景，可能需要第三方工具，例如MySQL的innobackupex 。 将快照复制到新的从库节点。 从库连接到主库，并拉取快照之后发生的所有数据变更。这要求快照与主库复制日志中的位置精确关联。该位置有不同的名称：例如，PostgreSQL将其称为 日志序列号（log sequence number, LSN），MySQL将其称为 二进制日志坐标（binlog coordinates）。 当从库处理完快照之后积压的数据变更，我们说它 赶上（caught up） 了主库。现在它可以继续处理主库产生的数据变化了。 5.1.3 处理节点宕机 我们的目标：即使个别节点失效，也要能保持整个系统运行，并尽可能控制节点停机带来的影响。\n5.1.3.1 从库失效：追赶恢复 ● 从库可以从日志知道，在发生故障前处理的最后一个事务。 ● 所以从库可以连接到主库，并拉取断开连接后的所有数据变更。 ● 应用完成所有变更之后，它就赶上了主库，继续接收数据变更流。\n5.1.3.2 主库失效：故障切换 ● 故障切换：需要把一个从库提升为新的主库，重新配置客户端，其他从库需要开始拉取来自新主库的变更。 ● 故障切换可以手动或者自动进行。\n自动故障切换：\n确认主库失效。有很多事情可能会出错：崩溃，停电，网络问题等等。没有万无一失的方法来检测出现了什么问题，所以大多数系统只是简单使用 超时（Timeout） ：节点频繁地相互来回传递消息，并且如果一个节点在一段时间内（例如30秒）没有响应，就认为它挂了（因为计划内维护而故意关闭主库不算）。 选择一个新的主库。这可以通过选举过程（主库由剩余副本以多数选举产生）来完成，或者可以由之前选定的控制器节点（controller node） 来指定新的主库。主库的最佳人选通常是拥有旧主库最新数据副本的从库（最小化数据损失）。让所有的节点同意一个新的领导者，是一个共识问题，将在第九章详细讨论。 重新配置系统以启用新的主库。客户端现在需要将它们的写请求发送给新主库（将在“请求路由”中讨论这个问题）。如果老领导回来，可能仍然认为自己是主库，没有意识到其他副本已经让它下台了。系统需要确保老领导认可新领导，成为一个从库。 故障切换会出现很多大麻烦：\n● 如果使用异步复制，则新主库可能没有收到老主库宕机前最后的写入操作。在选出新主库后，如果老主库重新加入集群，新主库在此期间可能会收到冲突的写入，那这些写入该如何处理？最常见的解决方案是简单丢弃老主库未复制的写入，这很可能打破客户对于数据持久性的期望。 ● 如果数据库需要和其他外部存储相协调，那么丢弃写入内容是极其危险的操作。例如在GitHub 【13】的一场事故中，一个过时的MySQL从库被提升为主库。数据库使用自增ID作为主键，因为新主库的计数器落后于老主库的计数器，所以新主库重新分配了一些已经被老主库分配掉的ID作为主键。这些主键也在Redis中使用，主键重用使得MySQL和Redis中数据产生不一致，最后导致一些私有数据泄漏到错误的用户手中。 ● 发生某些故障时（见第八章）可能会出现两个节点都以为自己是主库的情况。这种情况称为 脑裂(split brain)，非常危险：如果两个主库都可以接受写操作，却没有冲突解决机制（请参阅“多主复制”），那么数据就可能丢失或损坏。一些系统采取了安全防范措施：当检测到两个主库节点同时存在时会关闭其中一个节点[1]，但设计粗糙的机制可能最后会导致两个节点都被关闭【14】。 ● 主库被宣告死亡之前的正确超时应该怎么配置？在主库失效的情况下，超时时间越长，意味着恢复时间也越长。但是如果超时设置太短，又可能会出现不必要的故障切换。例如，临时负载峰值可能导致节点的响应时间超时，或网络故障可能导致数据包延迟。如果系统已经处于高负载或网络问题的困扰之中，那么不必要的故障切换可能会让情况变得更糟糕。\n5.1.4 复制日志的实现 基于主库的复制，底层工作有几种不同的复制方式。\n5.1.4.1 基于语句的复制 在最简单的情况下，主库记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库。 问题： ● 任何调用 非确定性函数（nondeterministic） 的语句，可能会在每个副本上生成不同的值。比如 NOW(), RAND()。 ● 如果语句使用了自增列（auto increment），或者依赖于数据库中的现有数据（例如，UPDATE \u0026hellip; WHERE \u0026lt;某些条件\u0026gt;），则必须在每个副本上按照完全相同的顺序执行它们，否则可能会产生不同的效果。影响并发。 ● 有副作用的语句（例如，触发器，存储过程，用户定义的函数）可能会在每个副本上产生不同的副作用，除非副作用是绝对确定的。\n5.1.4.2 传输预写式日志（WAL） 第三章告诉我们，写操作通常追加到日志中： ● 对于日志结构存储引擎（SSTables 和 LSM 树），日志是主要存储位置。日志段在后台压缩，并进行垃圾回收。 ● 覆盖单个磁盘块的 B 树，每次修改会先写入预写式日志（Write Ahead Log, WAL），以便崩溃后索引可以恢复到一个一致的状态。 所以，日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：主库把日志发送给从库。 PostgreSQL和Oracle等使用这种复制方法。 缺点： ● 复制与存储引擎紧密耦合。 ● 不可能使主库和从库上运行不同版本的数据库软件。 ● 运维时如果升级软件版本，有可能会要求停机。\n5.1.4.3 逻辑日志复制（基于行） 采用逻辑日志，可以把复制与存储逻辑分离。 关系型数据库通常以行作为粒度描述数据库写入的记录序列： ● 对于插入的行，日志包含所有列的新值； ● 对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，或者所有列的旧值。 ● 对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列（至少是更新列）的新值。 优点： ● 逻辑日志与存储引擎分离，方便向后兼容。可以让领导者和跟随者运行不同版本的数据库软件。 ● 对于外部应用，逻辑日志也更容易解析。比如复制到数据仓库，或者自定义索引和缓存。被称为数据变更捕获。\n5.1.4.4 基于触发器的复制 ● 上述复制都是数据库自己实现的。也可以自定义复制方法：数据库提供了触发器和存储过程。 ● 允许数据库变更时，自动执行应用的程序代码。 ● 开销更大，更容易出错。但更灵活。\n5.2 复制延迟问题 ● 主从异步同步会有延迟：导致同时对主库和从库的查询，结果可能不同。 ● 因为从库会赶上主库，所以上述效应被称为「最终一致性」。 ● 复制延迟可能超过几秒或者几分钟，下文是 3 个例子。\n5.2.1 读己之写 如果用户把数据提交到了主库，但是主从有延迟，用户马上看数据的时候请求的从库，会感觉到数据丢失。\n此时需要「读写一致性」，也成为读己之写一致性。 技术： ● 读用户可能已经修改过的内容时，都从主库读；比如读个人资料都从主库读，读别人的资料可以读从库。 ● 如果应用的部分内容都可能被用户编辑，上述方法无效。可以指定更新后的时间窗口，比如上次更新的一分钟内从主库读。 ● 客户端记住最近一次写入的时间戳，从库提供查询时，保证该时间戳前的变更都已经传播到了本从库；否则从另外的从库读，或者等待从库追赶上来。（时间戳可以是逻辑时间戳，如日志序列号；或者要有准确的时间同步） ● 如果副本在多个数据中心，则比较复杂。任何需要从领导者提供服务的请求，都必须路由到包含主库的数据中心。 用户有多个设备时，还要考虑的问题： ● 记录更新时间戳变得更困难； ● 不同设备可能路由到不同的数据中心。如果你的方法需要读主库，就需要把同一用户的请求路由到同一个数据中心。\n5.2.2 单调读 用户可能会遇到时光倒流。 第一次请求到从库看到了评论，第二次请求到另外一个从库发现评论消失。\n单调读保证了这种异常不会发生。 方法： ● 确保每个用户总是从同一副本来读取。比如基于用户 ID 的散列来选择副本，而不是随机选。 ● 但是如果该副本失败，则需要路由到另一个副本。\n5.2.3 一致前缀读 一系列事件可能出现前后顺序不一致问题。比如回答可能在提问之前发生。 这是分区（分片）数据库中的一个特殊问题：不同分区之间独立，不存在全局写入顺序。\n需要「一致前缀读」。 方法： ● 任何因果相关的写入都写入相同的分区。\n5.2.4 复制延迟的解决方案 ● 可以信赖数据库：需要事务。 ● 事务（transaction） 存在的原因：数据库通过事务提供强大的保证，所以应用程序可以更加简单。 ● 单节点事务存在了很长时间，但是分布式数据库中，许多系统放弃了事务。“因为事务的代价太高。” ● 本书的其余部分将继续探讨事务。\n5.3 多主复制 ● 单个领导者的复制架构是个常见的方法，也有其他架构。 ● 基于领导者复制的主要缺点：只有一个主库，所有的写入都要通过它。 ● 多个领导者的复制：允许多个节点接受写入，复制仍然是转发给所有其他节点。每个领导者也是其他领导者的追随者。\n5.3.1 多主复制的应用场景 单个数据中心内部使用多个主库没有太大意义。 5.3.1.1 运维多个数据中心 ● 多领导配置允许每个数据中心都有自己的主库。 ● 每个数据中心内部使用常规的主从复制； ● 数据中心之间，每个数据中心的主库都会将其更改复制到其他数据中心的主库中。\n运维多个数据中心时，单主和多主的适应情况比较：\n性能\n● 单主配置中，每个写入都得穿过互联网，进入主库所在的数据中心。会增大写入时间。\n● 多主配置中，每个写操作都可以在本地数据中心进行处理，与其他数据中心异步复制。感觉到性能更好。\n容忍数据中心停机\n● 单主配置中，如果主库所在的数据中心发生故障，必须让另一个数据中心的追随者成为主领导者。\n● 多主配置中，每个数据中心都可以独立于其他数据中心继续运行。若发生故障的数据中心归队，复制会自动赶上。\n容忍网络问题\n● 数据中心之间的网络需要通过公共互联网，不如数据中心之内的本地网络可靠。\n● 单主配置对网络连接问题非常敏感，因为写是同步的。\n● 异步复制的多主配置更好地承受网络问题。\n多主复制的缺点： ● 两个数据中心可能会修改相同的内容，写冲突必须解决。\n● 多主复制比较危险，应尽可能避免。\n5.3.3.2 需要离线操作的客户端 ● 多主复制的另一适用场景：应用程序在断网后仍然需要继续工作。\n● 在这种情况下，每个设备都有一个充当领导者的本地数据库（它接受写请求），并且在所有设备上的日历副本之间同步时，存在异步的多主复制过程。复制延迟可能是几小时甚至几天，具体取决于何时可以访问互联网。\n● 每个设备相当于一个“数据中心”\n5.3.3.3 协同编辑 ● 协作式编辑不能视为数据库复制问题，但是与离线编辑有许多相似\n● 一个用户编辑文档时，所做的更改将立即应用到其本地副本（web 或者客户端），并异步复制到服务器和编辑同一文档的任何其他用户。\n● 如果想要不发生编辑冲突，则应用程序需要先将文档锁定，然后用户才能进行编辑；如果另一用户想编辑，必须等待第一个用户提交修改并释放锁定。这种协作模式相当于主从复制模型下在主节点上执行事务操作。\n● 但是，为了加速写作，可编辑的粒度需要非常小（例如单个按键，甚至全程无锁）。\n● 也会面临所有多主复制都存在的挑战，即如何解决冲突。\n5.3.4 处理写入冲突 ● 多领导者复制的最大问题是可能发生写冲突，因此需要解决冲突。\n● 单主数据库没有这个问题。\n● 假如两个用户同时修改标题：\n5.3.4.1 同步与异步冲突检测 ● 单主数据库：第二个写入被阻塞，并等待第一个写入完成，或被终止；\n● 多主配置：两个写入都成功，稍后的时间点仅仅异步地监测到冲突。\n● 如果想冲突检测同步-等待被写入到所有的副本，那么丢失了多主复制的优点。\n5.3.4.2 避免冲突 ● 处理冲突的最简单策略是避免它们：确保特定记录的写入都通过同一个领导者，就不会有冲突。\n● 但是，如果更改指定的记录主库——比如数据中心故障，需要把流量重新路由；冲突避免会中断，必须处理不同主库同时写入的可能性。\n5.3.4.3 收敛至一致的状态 ● 单主数据库按顺序进行写操作：如果同一个字段有多个更新，则最后一个写操作将决定该字段的最终值。\n● 在多主配置中，没有明确的写入顺序，所以最终值应该是什么并不清楚。\n● 每个复制方案都必须确保数据在所有副本中最终都是相同的。\n● 数据库必须以一种 收敛（convergent） 的方式解决冲突，这意味着所有副本必须在所有变更复制完成时收敛至一个相同的最终值。\n实现冲突合并解决有多种途径：\n● 给每个写入一个唯一的ID（例如，一个时间戳，一个长的随机数，一个UUID或者一个键和值的哈希），挑选最高ID的写入作为胜利者，并丢弃其他写入。\n● 为每个副本分配一个唯一的ID，ID编号更高的写入具有更高的优先级。这种方法也意味着数据丢失。\n● 以某种方式将这些值合并在一起 - 例如，按字母顺序排序，然后连接它们\n● 用一种可保留所有信息的显式数据结构来记录冲突，并编写解决冲突的应用程序代码（也许通过提示用户的方式）。\n5.3.4.4 自定义冲突解决逻辑 解决冲突的最合适方法取决于应用程序。\n写时执行\n● 只要数据库系统检测到复制更改日志中存在冲突，就会调用冲突处理程序。\n读时执行\n● 当检测到冲突时，所有冲突写入被存储。\n● 下一次读取数据时，会将这些多个版本的数据返回给应用程序。\n● 应用程序可能会提示用户或自动解决冲突，并将结果写回数据库。\n5.3.4.5 自动冲突解决 规则复杂，容易出错。\n● 无冲突复制数据类型（Conflict-free replicated datatypes）：是可以由多个用户同时编辑的集合，映射，有序列表，计数器等的一系列数据结构，它们以合理的方式自动解决冲突。一些CRDT已经在Riak 2.0中实现\n● 可合并的持久数据结构（Mergeable persistent data structures）显式跟踪历史记录，类似于Git版本控制系统，并使用三向合并功能（而CRDT使用双向合并）。\n● 可执行的转换（operational transformation）是 Etherpad 和Google Docs 等合作编辑应用背后的冲突解决算法。它是专为同时编辑项目的有序列表而设计的，例如构成文本文档的字符列表。\n5.3.4.6 什么是冲突？ ● 显而易见的冲突：两个写操作并发地修改了同一条记录中的同一个字段。\n● 微秒的冲突：一个房间接受了两个预定。\n5.3.5 多主复制拓扑 ● 复制拓扑（replication topology）描述写入从一个节点传播到另一个节点的通信路径。\n● 只有两个领导者时，只有一个合理的拓扑：互相写入。\n● 当有两个以上的领导，拓扑很多样：\n● 最普遍的是全部到全部；\n● MySQL 仅支持环形拓扑。\n防止无限复制循环：\n● 圆形和星型拓扑，节点需要转发从其他节点收到的数据更改。\n● 防止无限复制循环：每个节点都有唯一的标识符，在复制日志中，每个写入都标记了所有已经过的节点的标识符。\n环形和星形拓扑的问题\n● 一个节点故障，可能中断其他节点之间的复制消息流。\n● 拓扑结构可以重新配置，但是需要手动操作。\n● 全部到全部的容错性更好，避免单点故障。\n全部到全部拓扑的问题\n● 网络问题导致消息顺序错乱\n● 写入时添加时间戳是不够的的。\n● 解决办法是版本向量技术。\n● 有些数据库没有该功能。\n5.4 无主复制 ● 一些数据库放弃主库的概念，允许任何副本直接接收来自客户端的写入。\n● 一些无主配置中，客户端直接写入到几个副本中；\n● 另一些情况下，一个协调者节点代表客户端进行写入。\n5.4.1 当节点故障时写入数据库 无主复制中，故障切换不存在。 如果一个副本故障或下线，重启后提供的数据是落后的。 解决办法：客户端同时请求多个副本，根据版本号确定最新值。 5.4.1.1 读修复和反熵 故障节点重新上线，怎么追上错过的写入? 5.4.1.2 读修复（Read repair） 客户端检测到陈旧的值，客户端将新值写回到该副本。 适合读频繁的值。 5.4.1.3 反熵过程（Anti-entropy process） 数据库的后台进程，不断查找副本之间的数据差异，把缺少的数据进行复制。 反熵过程不会以任何特定的顺序复制写入，复制数据之前可能有显著的延迟。 5.4.1.4 读写的法定人数 如果有副本下线，究竟多少个副本完成才可以认为写成功？ 计算方式\n如果有n个副本，每个写入必须由w节点确认才能被认为是成功的，并且我们必须至少为每个读取查询r个节点。 （只要$w + r\u003e n$，我们期望在读取时获得最新的值，因为r个读取中至少有一个节点是最新的。遵循这些r值，w值的读写称为法定人数（quorum）的读和写】 可以认为，r和w是有效读写所需的最低票数。 5.4.2 法定人数一致性的局限性 但是，即使在 $w + r\u0026gt; n$ 的情况下，也可能存在返回陈旧值的边缘情况。 ● 如果使用了宽松的法定人数，w 个写入和 r 个读取落在完全不同的节点上。\n● 两个写入同时发生，不清楚哪一个先发生。\n● 写操作和读操作同时发生，写操作可能仅反映在某些副本上。\n● 写操作在某些副本上成功，而在其他节点上失败，在小于w个副本上写入成功。\n● 如果携带新值的节点失败，需要读取其他带有旧值的副本。\n● 即使一切工作正常，有时也会不幸地出现关于时序（timing） 的边缘情况。\n不要把 w 和 r 当做绝对的保证，应该看做是概率。 强有力的保证需要事务和共识。\n5.4.2.1 监控陈旧度 ● 基于领导者的复制，数据库会会公开复制滞后的度量标准，可以做监控。\n● 无领导者复制中，没有固定的写入顺序，监控困难。\n● 最终一致性是非常模糊的保证。\n5.4.3 宽松的法定人数与提示移交 ● 合理配置的法定人数可以使数据库无需故障切换即可容忍个别节点的故障。\n● 需要高可用、低延时、且能够容忍偶尔读到陈旧值的应用场景来说，这些特性使无主复制的数据库很有吸引力。\n问题 ● 网络中断导致剩余可用节点可能少于w或r，客户端达不到法定人数。\n权衡\n● 对于所有无法达到w或r节点法定人数的请求，是否返回错误是更好的？\n● 或者我们是否应该接受写入，然后将它们写入一些可达的节点，但不在这些值通常所存在的n个节点上？\n宽松的法定人数（sloppy quorum）\n● 上述的后者是宽松的法定人数（sloppy quorum）。\n● 大型集群中，节点数量明显多于 n 个。\n● 写和读仍然需要 w 和 r 个成功的响应，但是不来自指定的 n 个节点中。\n提示移交（hinted handoff）\n● 网络中断得到解决时，另一个节点临时接收的一个节点的任何写入都被发送到适当的“主”节点。\n优点\n● 提高了写入可用性：任何 w 个节点可用，数据库就可以接收写入。\n缺点\n● 即使当$w + r\u0026gt; n$时，也不能确定读取某个键的最新值，因为最新的值可能已经临时写入了n之外的某些节点。\n在传统意义上，一个宽松的法定人数实际上不是一个法定人数。\n常见使用中，宽松的法定人数是可选的。\n5.4.3.1 运维多个数据中心 ● 无主复制也适用于多数据中心操作，因为它旨在容忍冲突的并发写入，网络中断和延迟尖峰。\n● 无论数据中心如何，每个来自客户端的写入都会发送到所有副本，但客户端通常只等待来自其本地数据中心内的法定节点的确认，从而不会受到跨数据中心链路延迟和中断的影响。\n● 对其他数据中心的高延迟写入通常被配置为异步发生，尽管配置有一定的灵活性.\n5.4.4 检测并发写入 ● 无主复制，允许多个客户端同时写入相同的 key，会冲突。\n● 读修复和提示移交期间也可能会发生冲突。\n写入顺序问题举例：\n5.4.4.1 最后写入胜利（丢弃并发写入） 思路\n● 只需要存储最 “最近” 的值，允许 “更旧” 的值被覆盖和抛弃。\n● 需要有一种明确的方式来确定哪个写是“最近的”，并且每个写入最终都被复制到每个副本，那么复制最终会收敛到相同的值。\n● “最近”的，这个词没有意义，因为是并发的。\n方法：最后写入胜利\n● 可以为每个写入附加一个时间戳，挑选最 “最近” 的最大时间戳，并丢弃具有较早时间戳的任何写入。\n优点\n● 实现了最终收敛的目标\n缺点\n● 以持久性为代价：如果同一个Key有多个并发写入，即使它们报告给客户端的都是成功（因为它们被写入 w 个副本），也只有一个写入将存活，而其他写入将被静默丢弃。\n● 甚至可能会删除不是并发的写入\n● 如果丢失数据不可接受，那么最后写入胜利是个很烂的选择。\n使用场景\n● 唯一安全的方法：每一个键只写入一次，然后视为不变，避免并发更新。\n“此前发生”的关系和并发\n● 只要有两个操作A和B，就有三种可能性：A在B之前发生，或者B在A之前发生，或者A和B并发。\n● 我们需要的是一个算法来告诉我们两个操作是否是并发的。\n● 如果一个操作发生在另一个操作之前，则后面的操作应该覆盖较早的操作，但是如果这些操作是并发的，则存在需要解决的冲突。\n5.4.4.2 捕获\u0026quot;此前发生\u0026quot;关系 一个算法，可以确定两个操作是否是并发的，还是先后关系。 两个客户端同时向一个购物车添加项目，注意版本号：\n操作依赖关系：\n● 客户端永远不会完全掌握服务器上的数据，因为总是有另一个操作同时进行。 ● 但是，旧版本的值最终会被覆盖，并且不会丢失任何写入。\n服务器可以通过查看版本号来确定两个操作是否是并发的，算法的原理：\n● 服务器为每个键保留一个版本号，每次写入键时都增加版本号，并将新版本号与写入的值一起存储。\n● 当客户端读取键时，服务器将返回所有未覆盖的值以及最新的版本号。客户端在写入前必须读取。\n● 客户端写入键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起。 （针对写入请求的响应可以像读取请求一样，返回所有当前值，这使得我们可以像购物车示例那样将多个写入串联起来。）\n● 当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值（因为它知道它们已经被合并到新的值中），但是它必须用更高的版本号来保存所有值（因为这些值与随后的写入是并发的）。\n当一个写入包含前一次读取的版本号时，它会告诉我们的写入是基于之前的哪一种状态。\n5.4.4.3 合并同时写入的值 优点\n● 没有数据被无声地丢弃\n缺点\n● 客户端需要额外工作：客户端必须通过合并并发写入的值来擦屁股。\nRiak 称这些并发值为兄弟。\n合并兄弟值：\n● 与多领导者复制的冲突解决相同的问题。\n● 最简单的是根据版本号或者时间戳最后写入胜利，但会丢失数据。\n● 对于购物车来说，合理的合并方法是集合求并集。\n● 但是如果从购物车中删除东西，那么求并集会出错：一个购物车删除，求并集后，会重新出现在并集终值中。\n● 所以删除操作不能简单删除，需要留下有合适版本号的标记，被称为墓碑。\n容易出错，所以有了一些数据结构设计出来。\n5.4.4.4 版本向量 多个副本，但是没有领导者，该怎么办？\n● 每个副本、每个主键都定义一个版本号。\n● 每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本中看到的版本号。\n● 这个信息指出了要覆盖哪些值，以及保留哪些值作为兄弟。\n版本向量\n● 所有副本的版本号集合称为版本向量（version vector）。\n● 版本向量允许数据库区分覆盖写入和并发写入。\n5.5 本章小结 复制可以用于几个目的：\n高可用性\n即使在一台机器（或多台机器，或整个数据中心）停机的情况下也能保持系统正常运行\n断开连接的操作\n允许应用程序在网络中断时继续工作\n延迟\n将数据放置在距离用户较近的地方，以便用户能够更快地与其交互\n可伸缩性\n能够处理比单个机器更高的读取量可以通过对副本进行读取来处理\n我们讨论了复制的三种主要方法：\n单主复制\n客户端将所有写入操作发送到单个节点（领导者），该节点将数据更改事件流发送到其他副本（追随者）。读取可以在任何副本上执行，但从追随者读取可能是陈旧的。\n多主复制\n客户端发送每个写入到几个领导节点之一，其中任何一个都可以接受写入。领导者将数据更改事件流发送给彼此以及任何跟随者节点。\n无主复制\n客户端发送每个写入到几个节点，并从多个节点并行读取，以检测和纠正具有陈旧数据的节点。\n我们研究了一些可能由复制滞后引起的奇怪效应，我们也讨论了一些有助于决定应用程序在复制滞后时的行为的一致性模型： 写后读\n用户应该总是看到自己提交的数据。\n单调读\n用户在一个时间点看到数据后，他们不应该在某个更早的时间点看到数据。\n一致前缀读\n用户应该将数据视为具有因果意义的状态：例如，按照正确的顺序查看问题及其答复。\n最后，我们讨论了多领导者和无领导者复制方法所固有的并发问题：因为他们允许多个写入并发发生，这可能会导致冲突。我们研究了一个数据库可能使用的算法来确定一个操作是否发生在另一个操作之前，或者它们是否同时发生。我们还谈到了通过合并并发更新来解决冲突的方法。\n第六章: 分区 什么是分区？ ● 对于非常大的数据集，或非常高的吞吐量，仅仅进行复制是不够的：我们需要将数据进行分区（partitions），也称为分片（sharding）。 ● 通常情况下，每条数据（每条记录，每行或每个文档）属于且仅属于一个分区。 ● 每个分区都是自己的小型数据库，尽管数据库可能支持同时进行多个分区的操作。\n分区的优点？ ● 分区主要是为了可伸缩性。 ● 大数据集可以分布在多个磁盘上，并且查询负载可以分布在多个处理器上。 ● 单个分区上运行的查询，每个节点可以独立执行对自己的查询，因此可以通过添加更多的节点来扩大查询吞吐量。 ● 大型、复杂的查询可能会跨越多个节点并行处理，尽管这也带来了新的困难。\n本章内容 ● 分割大型数据集的不同方法 ● 索引如何与分区配合 ● 分区再平衡 ● 数据库如何路由到正确的分区\n分区与复制 ● 分区通常与复制结合使用，使得每个分区的副本存储在多个节点上。 ● 即使每条记录属于同一个分区，但是这个分区仍有多个不同的节点，提高容错。 ● 一个节点有多个分区，如果使用主从复制模型，每个分区领导者被分配给一个节点，追随者被分配个其他节点。 ○ 每个节点可能是某些分区的领导者，同时是其他分区的追随者。\n键值数据的分区 ● 分区目标是将数据和查询负载均匀分布在各个节点上。 ● 如果每个节点公平分享数据和负载，那么理论上10个节点应该能够处理10倍的数据量和10倍的单个节点的读写吞吐量（暂时忽略复制）。 ● 如果分区不公平，被称为偏斜（skew） ○ 数据偏斜的存在使分区效率下降很多。 ○ 在极端的情况下，所有的负载可能压在一个分区上，其余9个节点空闲的，瓶颈落在这一个繁忙的节点上。 ○ 不均衡导致的高负载的分区被称为热点（hot spot）。\n怎么避免热点？ ● 避免热点最简单的方法是将记录随机分配给节点。 ● 缺点： ○ 读特定的值时，不知道在哪个节点上，必须并行查所有的节点。\n根据键的范围分区 一种分区的方法是为每个分区指定一块连续的键范围（从最小值到最大值），类似纸质的百科全书。\n● 可能分布不均匀。 ● 分区边界可以由管理员手动选择，也可以由数据库自动选择 ● 使用该策略的有：Bigtable， HBase，RethinkDB和2.4版本之前的MongoDB\n优点： ● 在每个分区中，我们可以按照一定的顺序保存键。 ● 范围扫描非常简单 ● 可以将键作为联合索引来处理，以便在一次查询中获取多个相关记录 ● 比如获取一段时间内的记录。\n缺点： ● Key Range分区的缺点是某些特定的访问模式会导致热点。 ● 可一个修改主键：比如传感器名称+时间，避免数据打到同一分区。\n根据键的散列分区 ● 很多分布式数据存储使用散列函数来分区。 ● 一个好的散列函数可以将偏斜的数据均匀分布。 ● 注意保证同一个键在不同的进程中有相同的哈希值。\n优点： ● 这种技术擅长在分区之间公平地分配键。 ● 分区边界可以是均匀间隔的，也可以是伪随机选择的（在这种情况下，该技术有时也被称为一致性哈希（consistent hashing））。\n缺点： ● 失去了 高效执行范围查询的能力。 ● 范围查询要么不支持，要么需要查询所有分区。\n组合索引： ● 组合索引方法为一对多关系提供了一个优雅的数据模型。 ● 社交网络的一条更新主键被选择为 (user_id, update_timestamp)，那么可以有效地检索特定用户在某个时间间隔内按时间戳排序的所有更新。\n负载偏斜与热点消除 ● 哈希分区可以帮助减少热点。但是，它不能完全避免它们：在极端情况下，所有的读写操作都是针对同一个键的，所有的请求都会被路由到同一个分区。 ● 比如社交网络的大 V 的评论区。 ● 只能靠应用程序解决： ○ 比如，一个主键如果被认为非常火爆，一个简单的方法是在主键的开始或结尾添加一个随机数。 ○ 只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中。 ○ 缺点： ■ 任何读取都要读取 100 个主键，读取数据并合并。 ■ 还要记录哪些键需要被分割\n分区与次级索引 ● 之前讨论的都是键值数据模型。 ● 次级索引使情况变复杂： ○ 次级索引通常并不能唯一地标识记录，而是一种搜索记录中出现特定值的方式 ● 次级索引是关系型数据库的基础，并且在文档数据库中也很普遍。 ● 许多键值存储（如HBase和Volde-mort）为了减少实现的复杂度而放弃了次级索引； ● 但是一些（如Riak）已经开始添加它们，因为它们对于数据模型实在是太有用了。 ● 并且次级索引也是Solr和Elasticsearch等搜索服务器的基石。\n存在的问题： ● 次级索引的问题是它们不能整齐地映射到分区。 ● 有两种用二级索引对数据库进行分区的方法：基于文档的分区（document-based） 和基于关键词（term-based）的分区。\n基于文档的二级索引进行分区 ● 假如一个销售二手车的网站， 每个列表都有一个唯一的ID——称之为文档ID——并且用文档ID对数据库进行分区 ● 用户搜索汽车，允许他们通过颜色和厂商过滤，所以需要一个在颜色和厂商上的次级索引（文档数据库中这些是字段（field），关系数据库中这些是列（column） ）。\n特点： ● 分区完全独立：每个分区维护自己的二级索引 ● 只需处理包含您正在编写的文档ID的分区即可 ● 文档分区索引也被称为本地索引（local index）\n注意： ● 没有理由把特定颜色或者品牌的汽车放到同一个分区。 ● 查询时需要查询所有的分区，合并所有的结果返回。\n缺点： ● 查询分区数据库的方法有时被称为分散/聚集（scatter/gather）； ● 可能使二级索引的查询代价高。 ● 即使并行查询分区，分散/聚集也容易导致尾部延迟放大。\n然而被广泛使用：MongoDB，Riak ，Cassandra ，Elasticsearch ，SolrCloud 和VoltDB 【19】都使用文档分区二级索引。\n基于关键词(Term)的二级索引进行分区 ● 可以构建一个覆盖所有分区数据的全局索引，而不是给每个分区创建自己的次级索引（本地索引）。 ● 但是，我们不能只把这个索引存储在一个节点上，因为它可能会成为瓶颈，违背了分区的目的。 ● 全局索引也必须进行分区，但可以采用与主键不同的分区方式。 ● 下图是对二级索引按照首字母是否在 \u0026ldquo;[a, r]\u0026rdquo; 之间分区。\n● 这种分区叫做关键词分区。 ● 以通过关键词本身或者它的散列进行索引分区。 ○ 根据关键词本身来分区对于范围扫描非常有用：比如数值类的属性。 ○ 对关键词的哈希分区提供了负载均衡的能力。 优点： ● 读取更有效率：不需要分散/收集所有分区，客户端只需要向包含关键词的分区发出请求。\n缺点： ● 写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区（文档中的每个关键词可能位于不同的分区或者不同的节点上） 。 ● 需要跨分区的分布式事务，并不是所有数据库都支持。 ● 在实践中，对全局二级索引的更新通常是异步的。\n分区再平衡 随着时间的推移，数据库会有各种变化：\n● 查询吞吐量增加，所以您想要添加更多的CPU来处理负载。 ● 数据集大小增加，所以您想添加更多的磁盘和RAM来存储它。 ● 机器出现故障，其他机器需要接管故障机器的责任。\n所有这些更改都需要数据和请求从一个节点移动到另一个节点。 将负载从集群中的一个节点向另一个节点移动的过程称为再平衡（rebalancing）。\n无论使用哪种分区方案，再平衡通常都要满足一些最低要求：\n● 再平衡之后，负载（数据存储，读取和写入请求）应该在集群中的节点之间公平地共享。 ● 再平衡发生时，数据库应该继续接受读取和写入。 ● 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I/O负载。\n再平衡策略 反面教材：hash mod N ● 前面已经讲了，最好将可能的散列分成不同的范围，给每个范围分配一个分区。 ● 取模 mod 运算可以给每个键分配一个节点 问题 ● 当节点数目变化时，使得再平衡过于昂贵。\n固定数量的分区 ● 简单的解决方案：创建比节点更多的分区，并为每个节点分配多个分区。 ● 仍然是取模，但是新增节点之后，总节点数变成了 5 个，只需要把取模 = 4 的部分放到 node 4。\n优点 ● 只有分区在节点中移动。 ● 分区总数不变 ● 键所在的分区也不会改变 ● 唯一改变的是分区所在的节点 ● 变更不是及时的：在传输过程中，原有分区仍然接受读写操作。 ● 甚至可以解决硬件不匹配问题：更强大的节点分配更多的分区。 ● Riak ，Elasticsearch ，Couchbase 和Voldemort 中使用了这种再平衡的方法。\n特点 ● 分区的数量通常在数据库第一次建立时确定，之后不会改变。 ● 一开始配置的分区数就是您可以拥有的最大节点数量，所以您需要选择足够多的分区以适应未来的增长。 ● 但是，每个分区也有管理开销，所以选择太大的数字会适得其反。\n缺点 ● 当数据集的总大小难以预估，选择正确的分区数很难。\n动态分区 采用关键字区间分区的数据库，如果边界设置有问题，可能导致数据倾斜到一个分区中。 ● 按键的范围进行分区的数据库（如HBase和RethinkDB）会动态创建分区。 ● 当分区增长到超过配置的大小时（在HBase上，默认值是10GB），会被分成两个分区，每个分区约占一半的数据。 ● 与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。此过程与B树顶层发生的过程类似。\n特点： ● 每个分区分配给一个节点，每个节点可以处理多个分区，就像固定数量的分区一样。 ● 大型分区拆分后，可以将其中的一半转移到另一个节点，以平衡负载。 ● 在HBase中，分区文件的传输通过HDFS（底层使用的分布式文件系统）来实现。\n优点： ● 分区数量适应总数据量。\n缺点： ● 空数据库从一个分区开始，导致所有写入都必须单个节点处理，其他节点空闲。\n解决方法： ● HBase和MongoDB允许在一个空的数据库上配置一组初始分区（这被称为预分割（pre-splitting））。 ● 在键范围分区的情况中，预分割需要提前知道键是如何进行分配的。\n适用情况： ● 动态分区不仅适用于数据的范围分区，而且也适用于散列分区。\n按节点比例分区 ● 动态分区和固定数量的分区，分区数量都与节点数量无关。 ● Cassandra和Ketama使用的第三种方法是使分区数与节点数成正比：每个节点有固定数量的分区。 ○ 当节点数不变，分区大小与数据集大小成比例增长； ○ 当节点数改变，分区大小将变小。\n操作方式： ● 当一个新节点加入集群时，它随机选择固定数量的现有分区进行拆分，然后占有这些拆分分区中每个分区的一半，同时将每个分区的另一半留在原地。 ● 随机化可能会产生不公平的分割，但是平均在更大数量的分区上时，新节点最终从现有节点获得公平的负载份额。 ● 随机选择分区边界要求使用基于散列的分区（可以从散列函数产生的数字范围中挑选边界）。实际上，这种方法最符合一致性哈希的原始定义。\n运维：手动还是自动再平衡 重要问题：自动还是手动进行？ ● 完全自动重新平衡和完全手动之间有一个过渡阶段：自动生成建议的分区分配，需要管理员提交才能生效。\n完全自动重新平衡的缺点： ● 虽然很方便，但是结果不可预测。 ● 再平衡的代价昂贵，因为它需要重新路由请求并将大量数据从一个节点移动到另一个节点。 ● 如果没有做好，这个过程可能会使网络或节点负载过重，降低其他请求的性能。 ○ 如果全自动重新平衡遇到了自动故障检测：系统判断一个节点过载，然后重新自动平衡，导致情况更糟。\n请求路由 服务发现(service discovery) ● 确定客户发出请求时，知道要连接哪个节点进行读取\n概括来说，这个问题有几种不同的方案（如图6-7所示）:\n允许客户联系任何节点（例如，通过循环策略的负载均衡（Round-Robin Load Balancer））。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求；否则，它将请求转发到适当的节点，接收回复并传递给客户端。 首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求；它仅负责分区的负载均衡。 要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介 关键问题： ● 如何了解分区-节点之间的分配关系变化？ ● 解决方法：所有参与者达成共识。 ○ 分布式系统中有达成共识的协议，但很难被正确实现。\n常见实现 ZooKeeper： ● 依赖于一个独立的协调服务，比如ZooKeeper来跟踪集群元数据 ● 每个节点在ZooKeeper中注册自己，ZooKeeper维护分区到节点的可靠映射。 ● 其他参与者（如路由层或分区感知客户端）可以在ZooKeeper中订阅此信息。 ● 只要分区分配发生了改变，或者集群中添加或删除了一个节点，ZooKeeper就会通知路由层使路由信息保持最新状态。\n应用：\n使用 ZooKeeper ○ LinkedIn的Espresso使用Helix 【31】进行集群管理（依靠ZooKeeper） ○ HBase，SolrCloud和Kafka也使用ZooKeeper来跟踪分区分配。 ○ MongoDB具有类似的体系结构，但它依赖于自己的配置服务器（config server） 实现和mongos守护进程作为路由层。 使用流言协议（gossip protocol） ○ Cassandra和Riak使用流言协议来传播集群状态的变化 ○ 请求可以发送到任意节点，该节点会转发到包含所请求的分区的适当节点 ○ 增加了更多的复杂性，但是避免了对像ZooKeeper这样的外部协调服务的依赖。 不自动重新平衡 ○ Couchbase，简化了设计 ○ 它配置了一个名为moxi的路由层，它会从集群节点了解路由变化 执行并行查询 ● 目前，我们只关注读取或写入单个键的非常简单的查询（加上基于文档分区的二级索引场景下的分散/聚集查询）。也是大多数 NoSQL 分布式数据存储所支持的访问层级。 ● 通常用于分析的大规模并行处理（MPP, Massively parallel processing） 关系型数据库产品在其支持的查询类型方面要复杂得多。 ● 把多个连接，过滤，分组和聚合操作分解成多个执行阶段和分区，分布式并行执行。 ● 见第十章。\n本章小结 ● 数据量非常大的时候，在单台机器上存储和处理不再可行，而分区则十分必要。 ● 分区的目标是在多台机器上均匀分布数据和查询负载，避免出现热点（负载不成比例的节点）。 ● 这需要选择适合于您的数据的分区方案，并在将节点添加到集群或从集群删除时进行分区再平衡。\n两种主要的分区方法：\n键范围分区 ○ 其中键是有序的，并且分区拥有从某个最小值到某个最大值的所有键。 ○ 排序的优势在于可以进行有效的范围查询，但是如果应用程序经常访问相邻的键，则存在热点的风险。 ○ 在这种方法中，当分区变得太大时，通常将分区分成两个子分区，动态地再平衡分区。 散列分区 ○ 散列函数应用于每个键，分区拥有一定范围的散列。 ○ 这种方法破坏了键的排序，使得范围查询效率低下，但可以更均匀地分配负载。 ○ 通过散列进行分区时，通常先提前创建固定数量的分区，为每个节点分配多个分区，并在添加或删除节点时将整个分区从一个节点移动到另一个节点。也可以使用动态分区。 两种方法搭配使用也是可行的，例如使用复合主键： ● 使用键的一部分来标识分区，而使用另一部分作为排序顺序。\n我们还讨论了分区和二级索引之间的相互作用。 次级索引也需要分区，有两种方法： ● 基于文档分区（本地索引），其中二级索引存储在与主键和值相同的分区中。 ○ 这意味着只有一个分区需要在写入时更新 ○ 但是读取二级索引需要在所有分区之间进行分散/收集。 ● 基于关键词分区（全局索引），其中二级索引存在不同的分区中。 ○ 辅助索引中的条目可以包括来自主键的所有分区的记录。 ○ 当文档写入时，需要更新多个分区中的二级索引； ○ 但是可以从单个分区中进行读取。 最后，我们讨论了将查询路由到适当的分区的技术，从简单的分区负载平衡到复杂的并行查询执行引擎。\n第七章：事务 为什么有事务？ ● 分布式数据系统，可能会出各种错误。 ● 实现容错机制工作量巨大。需要仔细考虑所有可能出错的事情，并进行大量的测试，以确保解决方案真正管用。 ● 数十年来，事务（transaction） 一直是简化这些问题的首选机制。\n什么是事务？ ● 事务是应用程序将多个读写操作组合成一个逻辑单元的一种方式。 ● 从概念上讲，事务中的所有读写操作被视作单个操作来执行： ○ 整个事务要么成功（提交（commit））要么失败（中止（abort），回滚（rollback））。 ○ 如果失败，应用程序可以安全地重试。 ○ 对于事务来说，应用程序的错误处理变得简单多了，因为它不用再担心部分失败的情况了，即某些操作成功，某些失败（无论出于何种原因）。\n事务是天然存在的吗？ ● 不是天然存在，是为了简化应用编程模型而创建的。 ● 给应用程序提供了安全保证。\n事务必须存在吗？ ● 不是所有应用都要有事务 ● 有时候弱化事务保证、或完全放弃事务也是有好处的（例如，为了获得更高性能或更高可用性）。 ● 一些安全属性也可以在没有事务的情况下实现。\n怎样知道你是否需要事务？ ● 首先需要确切理解事务可以提供的安全保障，以及它们的代价。 ● 尽管乍看事务似乎很简单，但实际上有许多微妙但重要的细节在起作用。\n事务的棘手概念 ● 几乎所有的关系型数据库和一些非关系数据库都支持事务。 ● 2000 年以后，非关系（NoSQL）数据库开始普及。很多新一代数据库放弃了或者弱化了事务。 ● 事务是一种权衡。\nACID的含义 ● 原子性（Atomicity） ● 一致性（Consistency） ● 隔离性（Isolation） ● 持久性（Durability）\n不同数据库的ACID实现并不相同。\n原子性 原子是指不能分解成小部分的东西。\n多线程编程 ● 如果一个线程执行一个原子操作，这意味着另一个线程无法看到该操作的一半结果。 ● 系统只能看到操作前或者操作后的状态，而不能看到中间状态。\nACID 的原子性 ● ACID的原子性并不是关于 并发（concurrent） 的。 ○ 隔离性 I 才是关于并发的。 ● ACID 的原子性是 能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。\n原子性的用途 ● 原子性描述了当客户想进行多次写入，但在一些写操作处理完之后出现故障的情况 ● 如果这些写操作被分组到一个原子事务中，并且该事务由于错误而不能完成（提交），则该事务将被中止，并且数据库必须丢弃或撤消该事务中迄今为止所做的任何写入。\n为什么要有原子性？ ● 如果没有原子性，在多处更改进行到一半时发生错误，很难知道哪些更改已经生效，哪些没有生效。该应用程序可以再试一次，但冒着进行两次相同变更的风险，可能会导致数据重复或错误的数据。 ● 原子性简化了这个问题：如果事务被中止（abort），应用程序可以确定它没有改变任何东西，所以可以安全地重试。\n一致性 ● ACID一致性的概念是，对数据的一组特定约束必须始终成立。即不变量（invariants）。 ○ 例如在会计系统中，所有账户整体上必须借贷相抵。 ● 如果一个事务开始于一个满足这些不变量的有效数据库，且在事务处理期间的任何写入操作都保持这种有效性，那么可以确定，不变量总是满足的。一致性不属于数据库的属性。 ● 一致性取决于应用程序对不变量的理解，应用程序负责正确定义它的事务，并保持一致性。 ● 这并不是数据库可以保证的事情：如果你写入违反不变量的脏数据，数据库也无法阻止你。—— 数据库只管存储。 ● 原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。因此，字母C不属于ACID。\n隔离性 ● 多个客户端同时访问相同的数据库记录，可能会遇到并发问题。 ● ACID意义上的隔离性意味着，同时执行的事务是相互隔离的：它们不能相互冒犯。 ● 传统的数据库教科书将隔离性形式化为可串行化（Serializability），这意味着每个事务可以假装它是唯一在整个数据库上运行的事务。 ● 数据库确保当多个事务被提交时，结果与它们串行运行（一个接一个）是一样的，尽管实际上它们可能是并发运行的\n持久性 ● 持久性 是一个承诺，即一旦事务成功完成，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。\n在单节点数据库中 ● 持久性通常意味着数据已被写入非易失性存储设备，如硬盘或SSD。 ● 它通常还包括预写日志或类似的文件（请参阅“让B树更可靠”），以便在磁盘上的数据结构损坏时进行恢复。\n在带复制的数据库中 ● 持久性可能意味着数据已成功复制到一些节点。\n如何做到持久性？ ● 为了提供持久性保证，数据库必须等到这些写入或复制完成后，才能报告事务成功提交。 ● 完美的持久性是不存在的：万一所有硬盘和备份同时被销毁。\n单对象和多对象操作 客户端在同一事务中执行多次写入时，数据库应该做的事： 原子性 ○ 不会部分失败——保证 all-or-nothing 隔离性 ○ 同时运行的事务不应该互相干扰。 ■ 事务如果多次写入，要么事务看到全部写入结果，要么什么都看不到。\n通常需要多对象事务（multi-object transaction） 来保持多个数据对象的同步。\n一个邮件应用的例子： ● 执行以下查询来显示用户未读邮件数量：\n1 SELECT COUNT（*）FROM emails WHERE recipient_id = 2 AND unread_flag = true ● 如果邮件太多，觉得查询太慢，于是用了单独的字段存储未读邮件的数量。现在每当一个新消息写入时，必须也增长未读计数器，每当一个消息被标记为已读时，也必须减少未读计数器。 ● 异常情况： ○ 邮件列表里显示有未读消息，但计数器显示为零未读消息，因为计数器增长还没有发生 为了满足原子性：插入邮件和更新未读邮件数目需要状态一致，要么都成功，要么都失败（回滚）：\n多对象事务写入方法？ ● 需要某种方式来确定哪些读写操作属于同一个事务。 ● 在关系型数据库中，通常基于客户端与数据库服务器的TCP连接：在任何特定连接上，BEGIN TRANSACTION 和 COMMIT 语句之间的所有内容，被认为是同一事务的一部分（不完美）。 ● 许多非关系数据库，并没有将这些操作组合在一起的方法。所以可能让数据库处于部分更新的状态。\n单对象写入 ● 当单个对象发生改变时，原子性和隔离性也是适用的。 ● 存储引擎一个几乎普遍的目标是：对单节点上的单个对象（例如键值对）上提供原子性和隔离性。\n实现方法 ● 原子性可以通过使用日志来实现崩溃恢复 ● 可以使用每个对象上的锁来实现隔离（每次只允许一个线程访问对象）\n更高级的原子操作 ● 1. 自增操作。 ● 2. 比较和设置（CAS, compare-and-set） 操作，仅当值没有被其他并发修改过时，才允许执行写操作。 ● 上面两种对但对象操作有用，但不是通常意义上的事务。 ● 事务通常被理解为，将多个对象上的多个操作合并为一个执行单元的机制。\n多对象事务的必要性 为什么许多分布式数据存储已经放弃了多对象事务？ ● 多对象事务很难跨分区实现； ● 而且在需要高可用性或高性能的情况下，它们可能会碍事。\n问题： 我们是否需要多对象事务？是否有可能只用键值数据模型和单对象操作来实现任何应用程序？\n需要协调写入几个不同对象的场景： ● 关系数据模型中，一个表中的行通常具有对另一个表中的行的外键引用。 ● 在文档数据模型中，需要一起更新的字段通常在同一个文档中，这被视为单个对象——更新单个文档时不需要多对象事务。但是，当需要更新非规范化的信息时，需要一次更新多个文档。比如上面邮件未读数目的例子。 ● 在具有二级索引的数据库中（除了纯粹的键值存储以外几乎都有），每次更改值时都需要更新索引。\n没有原子性，错误处理就要复杂得多，缺乏隔离性，就会导致并发问题。\n处理错误和中止 ● 事务的一个关键特性是，如果发生错误，它可以中止并安全地重试。 ● ACID数据库基于这样的哲学：如果数据库有违反其原子性，隔离性或持久性的危险，则宁愿完全放弃事务，而不是留下半成品。 ● 但并不是所有的系统都遵循这个哲学。特别是具有无主复制的数据存储，主要是在“尽力而为”的基础上进行工作。——所以，从错误中恢复是应用程序的责任。\n重试一个中止的事务并不完美： ● 如果事务实际上成功了，但是在服务器试图向客户端确认提交成功时网络发生故障，那么重试事务导致事务执行了两次——除非有额外的应用级除重机制。 ● 如果错误是由于负载过大造成的，则重试事务将使问题变得更糟，而不是更好。需要限制重试次数、采用指数退避算法。 ● 仅在临时性错误（例如，由于死锁，异常情况，临时性网络中断和故障切换）后才值得重试。在发生永久性错误（例如，违反约束）之后重试是毫无意义的。 ● 如果事务在数据库之外也有副作用，即使事务被中止，也可能发生这些副作用。比如更新操作后附带发送电子邮件。（如果想让多个不同的系统同时提交或者放弃，需要两阶段提交。） ● 如果客户端在重试过程中也失败了，并且没有其他人负责重试，那么数据就会丢失。\n弱隔离级别 并发问题发生的条件： ● 如果两个事务不触及相同的数据，那么可以安全的并行执行。 ● 只有两个事务中一读一写或者同时写，才会出现并发问题。\n并发问题很难测试、推理、复现。\n事务隔离（transaction isolation） ● 数据库试图通过事务隔离来解决并发问题 ● 理论上讲，隔离可以假装没有并发，让数据库保证事务的执行结果与串行相同。\n实际上的事务隔离 ● 由于串行隔离会有性能损失，许多数据库不愿意牺牲性能。 ● 因此，系统通常使用较弱的隔离级别来防止一部分，而不是全部的并发问题。 ● 这些隔离级别难以理解，并且会导致微妙的错误，但是它们仍然在实践中被使用\n弱事务隔离级别导致的问题 ● 弱事务隔离级别造成了很多的资金损失，耗费了财务审计人员的调查，并导致客户数据被破坏。 ● 即使是很多流行的关系型数据库系统（通常被认为是“ACID”）也使用弱隔离级别，所以它们也不一定能防止这些错误的发生。\n那到底怎么解决并发问题？ ● 比起盲目地依赖工具，我们应该对存在的并发问题的种类，以及如何防止这些问题有深入的理解。 ● 然后就可以使用我们所掌握的工具来构建可靠和正确的应用程序。\n读已提交 最基本的事务隔离级别是读已提交（Read Committed），它提供了两个保证：\n从数据库读时，只能看到已提交的数据（没有脏读（dirty reads））。 写入数据库时，只会覆盖已经写入的数据（没有脏写（dirty writes））。 没有脏读 什么是脏读？ ● 设想一个事务已经将部分数据写入数据库，但事务还没有提交或中止。另一个事务可以看到未提交的数据吗？如果是的话，那就叫做脏读（dirty reads）。 ● 在读已提交隔离级别运行的事务必须防止脏读。这意味着事务的任何写入操作只有在该事务成功提交后，才能被其他人看到（并且所有的写入操作都会立即变得可见）。 ○ 比如 user1 设置了 x=3， 但是直到 user1 的事务提交前， user2 的 get x 依然返回旧值 2， 为什么要防止脏读？ ● 如果事务需要更新多个对象，脏读取意味着另一个事务可能会只看到一部分更新。比如上文中电子邮件的未读数目的例子。 ● 如果事务中止，则所有写入操作都需要回滚。脏读导致其他事务看到稍后需要回滚的数据。\n没有脏写 什么是脏写？ ● 两个事务同时更新数据库的相同对象，通常是后面的写入覆盖前面的。但如果先前的写入是尚未提交事务的一部分，后面的写入会覆盖一个尚未提交的值？如果是，这被称作脏写（dirty write）。 ● 在读已提交的隔离级别上运行的事务必须防止脏写，通常是延迟第二次写入，直到第一次写入事务提交或中止为止。\n为什么要防止脏写？ ● 如果事务更新多个对象，脏写会导致非预期的错误结果。 ○ Alice 和 Bob 同事购买一辆车，买车需要两次数据库写入：商品列表更新、开发票。 ○ 下图中，Alice 先更新了商品列表，但是被 Bob 覆盖了商品列表；Bob 先更新了开发票，但是被 Alice 覆盖。\n● 但是，读已提交不能防止本章第一个图中的两个计数器增量之间的竞争状态。第二次写入在第一个事务提交后，所以它不是一个脏写。但结果仍然不正确。后文中“防止更新丢失”中将探讨如何使这种计数器安全递增。\n实现读已提交 ● 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置\n怎么实现读已提交？ ● 最常见的情况是，数据库通过使用行锁（row-level lock） 来防止脏写： ○ 当事务想要修改特定对象（行或文档）时，它必须首先获得该对象的锁。然后必须持有该锁直到事务被提交或中止。 ○ 一次只有一个事务可持有任何给定对象的锁； ○ 如果另一个事务要写入同一个对象，则必须等到第一个事务提交或中止后，才能获取该锁并继续。 ○ 这种锁定是读已提交模式（或更强的隔离级别）的数据库自动完成的。\n如何防止脏读？ ● 一种选择是读写使用相同的锁，并要求任何想要读取对象的事务来简单地获取该锁，然后在读取之后立即再次释放该锁。 ● 这能确保在读取进行时，对象不会在脏的、有未提交的值的状态（因为在那段时间锁会被写入该对象的事务持有）。\n读锁的缺点？ ● 读锁在实际上并不可行。 ● 一个长时间运行的写入事务会迫使许多只读事务等到这个慢写入事务完成。 ● 因为等待锁，应用某个部分的迟缓可能由于连锁效应，导致其他部分出现问题。\n实际方法 ● 大多数数据库使用图 7-4 的方法防止脏读 ● 对于写入的每个对象，数据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。 ● 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 ● 只有当新值提交后，事务才会切换到读取新值。\n快照隔离和可重复读 读已提交隔离级别的表现： ● 它允许中止（原子性的要求）； ● 它防止读取不完整的事务结果，并且防止并发写入造成的混乱。\n但，仍然有问题可能导致并发错误：\n● 图7-6 读取偏差：Alice观察数据库处于不一致的状态\n○ Alice 有 1000 美元，分为两个账户 ○ 先查了账户 1，发现有 500 块 ○ 一个事务把账户 2 的钱转了 100 到账户 1 ○ 再查了账户 2，发现只有 400 块 ○ 导致 Alice 误以为总的只有 900 块 ● 这种异常被称为不可重复读（nonrepeatable read） 或读取偏差（read skew） ○ Alice 再次查询账户 1 的时候，会看到与之前不同的值 ○ 在读已提交的隔离条件下，不可重复读被认为是可接受的：Alice看到的帐户余额确实是当时的最新值。\n有些情况不可以接受上述暂时的不一致： 备份 ● 大型数据库备份会几个小时才能完成，如果备份时数据库仍然接受写入操作，那么备份就可能有一些新的部分和旧的部分。 ● 从这样的备份中恢复，那么数据不一致会变成永久的。 分析查询和完整性检查 ● 一个分析需要查询数据库的大部分内容，如果不同时间点的查询结果不一样，那就没意义。\n快照隔离（snapshot isolation） ● 解决上述问题的最常见方案 ● 想法是，每个事务都从数据库的一致快照（consistent snapshot） 中读取。——也就是说，事务可以看到事务开始时在数据库中提交的所有数据。 ● 即使这些数据随后被另一个事务更改，每个事务也只能看到该特定时间点的旧数据。 ● 优点： ○ 快照隔离对长时间运行的只读查询（如备份和分析）非常有用。 ○ 如果查询的数据在查询执行的同时发生变化，则很难理解查询的含义。有快照理解起来就容易了。 ● 快照隔离是一个流行的功能：PostgreSQL，使用InnoDB引擎的MySQL，Oracle，SQL Server等都支持\n实现快照隔离 思路 ● 与读取提交的隔离类似，快照隔离的实现通常使用写锁来防止脏写。 ● 这意味着进行写入的事务会阻止另一个事务修改同一个对象。 ● 但是读取不需要任何锁定。 ● 从性能的角度来看，快照隔离的一个关键原则是：读不阻塞写，写不阻塞读。 ● 这允许数据库在处理一致性快照上的长时间查询时，可以正常地同时处理写入操作。且两者间没有任何锁定争用。\n实现 ● 通常使用防止图 7-4 的脏读 ● 数据库必须可能保留一个对象的几个不同的提交版本，因为各种正在进行的事务可能需要看到数据库在不同的时间点的状态。 ● 因为它同时维护着单个对象的多个版本，所以这种技术被称为多版本并发控制（MVCC, multi-version concurrency control）。\n保留几个版本的快照？ ● 如果一个数据库只需要提供读已提交的隔离级别，而不提供快照隔离，那么保留一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本。 ● 支持快照隔离的存储引擎通常也使用MVCC来实现读已提交隔离级别。一种典型的方法是读已提交为每个查询使用单独的快照，而快照隔离对整个事务使用相同的快照。\n举个例子 ● 下图是 PostgreSQL中实现基于MVCC的快照隔离（其他实现类似） ● 当一个事务开始时，它被赋予一个唯一的，永远增长的事务ID（txid）。 ● 每当事务向数据库写入任何内容时，它所写入的数据都会被标记上写入者的事务ID。\n● 说明： ○ 表中的每一行都有一个 created_by 字段，其中包含将该行插入到表中的的事务ID。 ○ 此外，每行都有一个 deleted_by 字段，最初是空的。 ○ 如果某个事务删除了一行，那么该行实际上并未从数据库中删除，而是通过将 deleted_by 字段设置为请求删除的事务的ID来标记为删除。 ○ 在稍后的时间，当确定没有事务可以再访问已删除的数据时，数据库中的垃圾收集过程会将所有带有删除标记的行移除，并释放其空间。 ○ UPDATE 操作在内部翻译为 DELETE 和 INSERT 。\n观察一致性快照的可见性规则 对于一个事务 ID，哪些对象时可见的？ ● 当一个事务从数据库中读取时，事务ID用于决定它可以看见哪些对象，看不见哪些对象。通过仔细定义可见性规则，数据库可以向应用程序呈现一致的数据库快照。 ● 工作如下： ○ 在每次事务开始时，数据库列出当时所有其他（尚未提交或尚未中止）的事务清单，即使之后提交了，这些事务已执行的任何写入也都会被忽略。 ○ 被中止事务所执行的任何写入都将被忽略。 ○ 由具有较晚事务ID（即，在当前事务开始之后开始的）的事务所做的任何写入都被忽略，而不管这些事务是否已经提交。 ○ 所有其他写入，对应用都是可见的。 ● 这些规则适用于创建和删除对象。 ● 换句话说，如果以下两个条件都成立，则可见一个对象： ○ 读事务开始时，创建该对象的事务已经提交。 ○ 对象未被标记为删除，或如果被标记为删除，请求删除的事务在读事务开始时尚未提交。\n长时间运行的事务看到的记录是新的还是旧的？ ● 长时间运行的事务可能会长时间使用快照，并继续读取（从其他事务的角度来看）早已被覆盖或删除的值。 ● 由于从来不原地更新值，而是每次值改变时创建一个新的版本，数据库可以在提供一致快照的同时只产生很小的额外开销。\n索引和快照隔离 索引如何在多版本数据库中工作？ ● 一种选择是使索引简单地指向对象的所有版本，并且需要索引查询来过滤掉当前事务不可见的任何对象版本。 ● 当垃圾收集删除任何事务不再可见的旧对象版本时，相应的索引条目也可以被删除。\n实践中的索引实现细节决定了多版本并发控制的性能。 ● 如果同一对象的不同版本可以放入同一个页面中，PostgreSQL的优化可以避免更新索引。 ● 在CouchDB，Datomic和LMDB中使用另一种方法。虽然它们也使用B树，但它们使用的是一种仅追加/写时拷贝（append-only/copy-on-write） 的变体，它们在更新时不覆盖树的页面，而为每个修改页面创建一份副本。从父页面直到树根都会级联更新，以指向它们子页面的新版本。任何不受写入影响的页面都不需要被复制，并且保持不变。 ● 使用仅追加的B树，每个写入事务（或一批事务）都会创建一颗新的B树。当创建时，从该特定树根生长的树就是数据库的一个一致性快照。没必要根据事务ID过滤掉对象，因为后续写入不能修改现有的B树；它们只能创建新的树根。但这种方法也需要一个负责压缩和垃圾收集的后台进程。\n可重复读与命名混淆 ● 快照隔离是一个有用的隔离级别，特别对于只读事务而言。 ● 但是，许多数据库实现了它，却用不同的名字来称呼。 ○ 在Oracle中称为可串行化（Serializable） 的 ○ 在PostgreSQL和MySQL中称为可重复读（repeatable read） ● 这种命名混淆的原因是SQL标准没有快照隔离的概念，因为标准是基于System R 1975年定义的隔离级别，那时候快照隔离尚未发明。相反，它定义了可重复读，表面上看起来与快照隔离很相似。 ● 后续虽然有可重复度的正式定义，但是结果现在命名混乱了。\n防止丢失更新 ● 上文讨论了读已提交和快照隔离级别，主要保证了只读事务在并发写入时可以看到什么，另外一个重要的事务并发场景是脏写。 ● 并发事务还有丢失更新（lost update） 问题，如图7-1所示。\n什么情况下会发生丢失更新问题？ ● 从数据库中读取一些值，修改它并写回修改的值（读取-修改-写入序列），则可能会发生丢失更新的问题。 ● 如果两个事务同时执行，则其中一个的修改可能会丢失，因为第二个写入的内容并没有包括第一个事务的修改（有时会说后面写入狠揍（clobber） 了前面的写入）。\n下面是解决方案。\n原子写 ● 很多数据库提供了原子更新操作，从而消除在应用程序代码中执行读取-修改-写入序列的需要。 ● 这通常是最好的解决方案。\n举例，下面的指令在大多数关系数据库中是并发安全的：\n1 UPDATE counters SET value = value + 1 WHERE key = \u0026#39;foo\u0026#39;; 原子写的实现方法 ● 原子操作通常通过在读取对象时，获取其上的排它锁来实现。 ○ 使得更新完成之前，没有其他事务可以读取它。 ○ 这种技术有时被称为游标稳定性（cursor stability） ● 另一个选择是简单地强制所有的原子操作在单一线程上执行\n使用时请注意 ● ORM框架很容易意外地执行不安全的读取-修改-写入序列，而不是使用数据库提供的原子操作。 ● 经常产出很难测出来的微妙 bug\n显式锁定 ● 如果数据库不支持内置原子操作，另一种防止更新丢失的方法是有应用程序显式地锁定将要更新的对象。 ● 然后应用程序可以执行读取-修改-写入序列，如果任何其他事务尝试同时读取同一个对象，则强制等待，直到第一个读取-修改-写入序列完成。\n举例：多人棋子游戏 ● 多个玩家可以同时移动相同的棋子。 ● 一个原子操作可能是不够的，因为应用程序还需要确保玩家的移动符合游戏规则 ● 可以使用锁来防止两名玩家同时移动相同的棋子\n1 2 3 4 5 6 7 8 BEGIN TRANSACTION; SELECT * FROM figures WHERE name = \u0026#39;robot\u0026#39; AND game_id = 222 FOR UPDATE; -- 检查玩家的操作是否有效，然后更新先前SELECT返回棋子的位置。 UPDATE figures SET position = \u0026#39;c4\u0026#39; WHERE id = 1234; COMMIT; ● FOR UPDATE 子句告诉数据库应该对该查询返回的所有行加锁。 这是有效的，但要做对，你需要仔细考虑应用逻辑。忘记在代码某处加锁很容易引入竞争条件。\n自动检测丢失的更新 ● 原子操作和锁是通过强制读取-修改-写入序列按顺序发生，来防止丢失更新的方法。 ● 还可以允许并发执行，如果事务管理器检测到丢失更新，则中止事务并强制它们重试其读取-修改-写入序列。\n优点 ● 数据库可以结合快照隔离高效地执行此检查。 ○ PostgreSQL的可重复读，Oracle的可串行化和SQL Server的快照隔离级别，都会自动检测到丢失更新，并中止惹麻烦的事务。 ○ 但是，MySQL/InnoDB的可重复读并不会检测丢失更新。导致有人认为 MySQL 不提供快照隔离。 ● 数据库自动检查！应用代码不需要任何操作就能使用丢失更新检测。很棒！\n比较并设置（CAS） ● 有些不提供事务的数据库中，提供了一种原子操作：比较并设置（CAS, Compare And Set） ● 此操作的目的是为了避免丢失更新： ○ 只有当前值从上次读取时一直未改变，才允许更新发生。 ○ 如果当前值与先前读取的值不匹配，则更新不起作用，且必须重试读取-修改-写入序列。\n举例： 为了防止两个用户同时更新同一个wiki页面，可以尝试类似这样的方式，只有当页面从上次读取之后没有发生变化时，才会发生更新：\n1 2 3 -- 根据数据库的实现情况，这可能安全也可能不安全 UPDATE wiki_pages SET content = \u0026#39;新内容\u0026#39; WHERE id = 1234 AND content = \u0026#39;旧内容\u0026#39;; 注意 ● 如果更新失败，需要应用层重试。 ● 如果数据库的 WHERE子句从旧快照中读取，则此语句可能无法防止丢失更新，因为即使发生了另一个并发写入，WHERE条件也可能为真。在依赖数据库的CAS操作前要检查其安全运行条件。\n冲突解决和复制 ● 在复制数据库中，防止丢失的更新需要考虑另一个维度：由于在多个节点上存在数据副本，并且在不同节点上的数据可能被并发地修改，因此需要采取一些额外的步骤来防止丢失更新。\n锁和CAS操作的缺点 ● 锁和CAS操作假定只有一个最新的数据副本。 ● 但是多主或无主复制的数据库通常允许多个写入并发执行，并异步复制到副本上，因此无法保证只有一个最新数据的副本。 ● 所以基于锁或CAS操作的技术不适用于这种情况。\n复制数据库解决冲突的常用方法 ● 复制数据库中的一种常见方法是允许并发写入创建多个冲突版本的值（也称为兄弟），并使用应用代码或特殊数据结构在事实发生之后解决和合并这些版本。\n原子操作的适用条件 ● 原子操作可以在复制的上下文中很好地工作，尤其当它们具有可交换性时（即，可以在不同的副本上以不同的顺序应用它们，且仍然可以得到相同的结果）。\n最后写入胜利（LWW）的缺点 ● 最后写入胜利（LWW）的冲突解决方法很容易丢失更新。 ● 不幸的是，LWW是许多复制数据库中的默认方案。\n写入偏斜与幻读 ● 前面讨论的脏写和丢失更新，都是不同事务并发地尝试写入相同的对象时，会出现这两种竞争条件。 ● 除此之外，还有其他场景的并发问题，比如修改不同的对象。\n一个医生轮班管理程序的例子 ● 背景：医院通常会同时要求几位医生待命，但底线是至少有一位医生在待命。医生可以放弃他们的班次（例如，如果他们自己生病了），只要至少有一个同事在这一班中继续工作。 ● 场景：Alice和Bob是两位值班医生，同时请假：\n○ 应用首先检查是否有两个或以上的医生正在值班； ■ 如果是的话，它就假定一名医生可以安全地休班。由于数据库使用快照隔离，两次检查都返回 2 ，所以两个事务都进入下一个阶段。 ■ Alice更新自己的记录休班了，而Bob也做了一样的事情。 ■ 两个事务都成功提交了，现在没有医生值班了。 ■ 违反了至少有一名医生在值班的要求。\n写偏差的特征 ● 这种异常称为写偏差。它既不是脏写，也不是丢失更新，因为这两个事务正在更新两个不同的对象（Alice和Bob各自的待命记录）。\n问题一般化： ● 如果两个事务读取相同的对象，然后更新其中一些对象（不同的事务可能更新不同的对象），则可能发生写入偏差。 ● 在多个事务更新同一个对象的特殊情况下，就会发生脏写或丢失更新（取决于时序）。\n处理写偏差，我们能用的方法很少，原因： ● 由于涉及多个对象，单对象的原子操作不起作用。 ● 不幸的是，在一些快照隔离的实现中，自动检测丢失更新对此并没有帮助。目前的可重复读、快照隔离级别中，都不会自动检测写入偏差。自动防止写入偏差需要真正的可串行化隔离 ● 某些数据库允许配置约束，然后由数据库强制执行（例如，唯一性，外键约束或特定值限制）。但是为了指定至少有一名医生必须在线，需要一个涉及多个对象的约束。大多数数据库没有内置对这种约束的支持，但是你可以使用触发器，或者物化视图来实现它们，这取决于不同的数据库\n解决办法： ● 如果无法使用可串行化的隔离级别，则此情况下的次优选项可能是显式锁定事务所依赖的行。\n1 2 3 4 5 6 7 8 9 10 11 BEGIN TRANSACTION; SELECT * FROM doctors WHERE on_call = TRUE AND shift_id = 1234 FOR UPDATE; UPDATE doctors SET on_call = FALSE WHERE name = \u0026#39;Alice\u0026#39; AND shift_id = 1234; COMMIT; ● 和以前一样，FOR UPDATE告诉数据库锁定返回的所有行以用于更新。\n写偏差的更多例子 会议室预订系统 ● 防止会议室被同一个会议室多次预定，需要检查时间是否有重叠。 ● 快照级别隔离不安全的 SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 BEGIN TRANSACTION; -- 检查所有现存的与12:00~13:00重叠的预定 SELECT COUNT(*) FROM bookings WHERE room_id = 123 AND end_time \u0026gt; \u0026#39;2015-01-01 12:00\u0026#39; AND start_time \u0026lt; \u0026#39;2015-01-01 13:00\u0026#39;; -- 如果之前的查询返回0 INSERT INTO bookings(room_id, start_time, end_time, user_id) VALUES (123, \u0026#39;2015-01-01 12:00\u0026#39;, \u0026#39;2015-01-01 13:00\u0026#39;, 666); COMMIT; 快照隔离并不能防止另一个用户同时插入冲突的会议。为了确保不会遇到调度冲突，你又需要可串行化的隔离级别了。\n多人游戏 ● 可以用锁防止丢失更新（也就是确保两个玩家不能同时移动同一个棋子）。 ● 但是锁定并不妨碍玩家将两个不同的棋子移动到棋盘上的相同位置，或者采取其他违反游戏规则的行为。 ● 按照您正在执行的规则类型，也许可以使用唯一约束（unique constraint），否则您很容易发生写入偏差。\n抢注用户名 ● 在每个用户拥有唯一用户名的网站上，两个用户可能会尝试同时创建具有相同用户名的帐户。 ● 快照隔离下这是不安全的。 ● 幸运的是，唯一约束是一个简单的解决办法（第二个事务在提交时会因为违反用户名唯一约束而被中止）。\n防止双重开支 ● 允许用户花钱或积分的服务，需要检查用户的支付数额不超过其余额。 ● 可以通过在用户的帐户中插入一个试探性的消费项目来实现这一点。 ● 有了写入偏差，可能会发生两个支出项目同时插入，一起导致余额变为负值。但这两个事务各自都不超额。 导致写入偏差的幻读 上述所有例子遵循类似的模式： ● 一个SELECT查询找出符合条件的行，并检查是否符合一些要求。 ● 按照第一个查询的结果，应用代码决定是否继续。 ● 如果应用决定继续操作，就执行写入（插入、更新或删除），并提交事务。 ○ 这个写入的效果改变了步骤2 中的先决条件。换句话说，如果在提交写入后，重复执行一次步骤1 的SELECT查询，将会得到不同的结果。\n解决方法： ● 医生值班的例子中，在步骤3中修改的行，是步骤1中返回的行之一，所以我们可以通过锁定步骤1 中的行（SELECT FOR UPDATE）来使事务安全并避免写入偏差。 ● 但是其他四个例子是不同的：它们检查是否不存在某些满足条件的行，写入会添加一个匹配相同条件的行。如果步骤1中的查询没有返回任何行，则SELECT FOR UPDATE锁不了任何东西。\n幻读 ● 一个事务中的写入改变另一个事务的搜索查询的结果，被称为幻读。 ● 快照隔离避免了只读查询中幻读，但是在像我们讨论的例子那样的读写事务中，幻读会导致特别棘手的写入偏差情况。\n物化冲突 ● 如果幻读的问题是没有对象可以加锁，也许可以人为地在数据库中引入一个锁对象？ ● 例如，在会议室预订的场景中，可以想象创建一个关于时间槽和房间的表。 ● 要创建预订的事务可以锁定（SELECT FOR UPDATE）表中与所需房间和时间段对应的行。在获得锁定之后，它可以检查重叠的预订并像以前一样插入新的预订。 ● 这种方法被称为物化冲突（materializing conflicts），因为它将幻读变为数据库中一组具体行上的锁冲突\n缺点： ● 弄清楚如何物化冲突可能很难，也很容易出错，而让并发控制机制泄漏到应用数据模型是很丑陋的做法 ● 出于这些原因，如果没有其他办法可以实现，物化冲突应被视为最后的手段。\n在大多数情况下。可串行化（Serializable） 的隔离级别是更可取的。\n可串行化 读已提交和快照隔离级别会阻止某些竞争条件，但并非对所有情况都有效。我们遇到了一些特别棘手的例子，写入偏差和幻读。面临的挑战： ● 隔离级别难以理解，并且在不同的数据库中实现的不一致 ● 光检查应用代码很难判断在特定的隔离级别运行是否安全。 特别是在大型应用程序中，您可能并不知道并发发生的所有事情。 ● 没有检测竞争条件的好工具。并发问题的测试是很难的，因为它们通常是非确定性的 —— 只有在倒霉的时序下才会出现问题。\n研究人员给出的答案： ● 使用可串行化（serializable） 的隔离级别！\n可串行化（Serializability） ● 可串行化（Serializability） 隔离通常被认为是最强的隔离级别。 ● 它保证即使事务可以并行执行，最终的结果也是一样的，就好像它们没有任何并发性，连续挨个执行一样。 ● 因此数据库保证，如果事务在单独运行时正常运行，则它们在并发运行时继续保持正确 —— 换句话说，数据库可以防止所有可能的竞争条件。\n本章介绍可串行化技术： ● 字面意义上地串行顺序执行事务 ● 两阶段锁定（2PL, two-phase locking），几十年来唯一可行的选择 ● 乐观并发控制技术，例如可串行化快照隔离（serializable snapshot isolation）\n真的串行执行 ● 避免并发问题的最简单方法就是完全不要并发：在单个线程上按顺序一次只执行一个事务。 ● 但数据库设计人员在2007年左右才决定，单线程循环执行事务是可行的。 ● 原因： ○ RAM足够便宜了，许多场景现在都可以将完整的活跃数据集保存在内存中。 ○ 数据库设计人员意识到OLTP事务通常很短，而且只进行少量的读写操作。而长时间运行的分析查询通常是只读的，因此它们可以在串行执行循环之外的一致快照（使用快照隔离）上运行。 ● 串行执行事务的方法在VoltDB/H-Store，Redis和Datomic中实现\n优点： ● 设计用于单线程执行的系统有时可以比支持并发的系统更好，因为它可以避免锁的协调开销。 缺点： ● 但是其吞吐量仅限于单个CPU核的吞吐量。 ● 为了充分利用单一线程，需要与传统形式的事务不同的结构。\n在存储过程中封装事务 ● 不能把人类做出决定和回应的多个流程操作封装成一个事务（比如搜路线、选机票、付款），因为人类太慢。 ● 交互式的事务中，为了提高吞吐量，必须允许数据库并发处理。 ● 采用单线程串行事务处理的系统不允许交互式的多语句事务。这就要求应用程序必须提前将整个事务代码作为存储过程提交给数据库。 ● 下图表示 交互式事务和存储过程之间的区别（使用图7-8的示例事务）\n存储过程的优点和缺点 存储过程名声不好的原因： ● 每个数据库厂商都有自己的存储过程语言，而不是通用语言如 Java。 ● 数据库代码管理困难，调试困难，版本控制困难。 ● 数据库通常比应用服务器对性能敏感的多，数据库中一个写得不好的存储过程（例如，占用大量内存或CPU时间）会比在应用服务器中相同的代码造成更多的麻烦。\n克服方法： ● 现代的存储过程实现放弃了PL/SQL，而是使用现有的通用编程语言：Java 和 Lua 等。\n单线程执行事务变得可行： ● 存储过程与内存存储，使得在单个线程上执行所有事务变得可行。由于不需要等待I/O，且避免了并发控制机制的开销，它们可以在单个线程上实现相当好的吞吐量。 ● VoltDB还使用存储过程进行复制\n分区 ● 顺序执行导致写入吞吐比较高的应用，单线程事务处理器可能成为一个严重的瓶颈。\n解决方法： ● 分区，每个分区就可以拥有自己独立运行的事务处理线程。\n缺点： ● 需要访问多个分区的任何事务，数据库必须在触及的所有分区之间协调事务。 ● 存储过程需要跨越所有分区锁定执行，以确保整个系统的可串行性。 ● 跨分区事务比单分区事务慢得多！ ● 事务能否分区取决于应用数据的结构：kv 存储容易分区，但是多个二级索引的数据不方便分区。\n串行执行小结 特定情况下，真的串行执行事务，已经成为一种实现可串行化隔离等级的可行办法。 使用条件： ● 每个事务都必须小而快，只要有一个缓慢的事务，就会拖慢所有事务处理。 ● 仅限于活跃数据集可以放入内存的情况。很少访问的数据可能会被移动到磁盘，但如果需要在单线程执行的事务中访问，系统就会变得非常慢。 ● 写入吞吐量必须低到能在单个CPU核上处理，否则需要分区，但最好没有跨分区事务。 ● 跨分区事务也可以支持，但是占比必须小。\n两阶段锁定 ● 大约30年来，在数据库中只有一种广泛使用的串行化算法：两阶段锁定（2PL，two-phase locking） ● 之前我们看到锁通常用于防止脏写； ● 两阶段锁定类似，但是锁的要求更强得多。 ○ 只要没有写入，就允许多个事务同时读取同一个对象。 ○ 但对象只要有写入（修改或删除），就需要独占访问（exclusive access） 权限： ■ 如果事务A读取了一个对象，并且事务B想要写入该对象，那么B必须等到A提交或中止才能继续。 （这确保B不能在A底下意外地改变对象。） ■ 如果事务A写入了一个对象，并且事务B想要读取该对象，则B必须等到A提交或中止才能继续。 （像图7-1那样读取旧版本的对象在2PL下是不可接受的。）\n特点 ● 在2PL中，写入不仅会阻塞其他写入，也会阻塞读，反之亦然。快照隔离使得读不阻塞写，写也不阻塞读，这是2PL和快照隔离之间的关键区别。 ● 另一方面，因为2PL提供了可串行化的性质，它可以防止早先讨论的所有竞争条件，包括丢失更新和写入偏差。\n实现两阶段锁 使用场景 2PL用于MySQL（InnoDB）和SQL Server中的可串行化隔离级别，以及DB2中的可重复读隔离级别 实现方式 读与写的阻塞是通过为数据库中每个对象添加锁来实现的。 锁可以处于共享模式（shared mode） 或独占模式（exclusive mode）。 锁使用如下：（同一个锁有两种模式：共享模式和独占模式，独占模式优先级大于共享模式） 若事务要读取对象，则须先以共享模式获取锁。允许多个事务同时持有共享锁。但如果另一个事务已经在对象上持有独占锁，则这些事务必须等待。 若事务要写入一个对象，它必须首先以独占模式获取该锁。不允许其他事务可以同时持有该锁（无论是共享模式还是独占模式）。换言之，如果对象上存在任何锁，则修改事务必须等待。 如果事务先读取再写入对象，则它可能会将其共享锁升级为独占锁。升级锁的工作等价于直接获得独占锁。 事务获得锁之后，必须继续持有锁直到事务结束（提交或中止）。这就是“两阶段”这个名字的来源：第一阶段（当事务正在执行时）获取锁，第二阶段（在事务结束时）释放所有的锁。 可能会发生死锁： 数据库会自动检测事务之间的死锁，并中止其中一个，以便另一个继续执行。 被中止的事务需要由应用程序重试。 两阶段锁定的性能 两阶段锁定的巨大缺点：性能问题 两阶段锁定下的事务吞吐量与查询响应时间要比弱隔离级别下要差得多。 性能差的原因： 这一部分是由于获取和释放所有这些锁的开销，但更重要的是由于并发性的降低。 按照设计，如果两个并发事务试图做任何可能导致竞争条件的事情，那么必须等待另一个完成。 性能差的表现： 运行2PL的数据库可能具有相当不稳定的延迟，如果在工作负载中存在争用，那么可能高百分位点处的响应会非常的慢 可能只需要一个缓慢的事务，或者一个访问大量数据并获取许多锁的事务，就能把系统的其他部分拖慢，甚至迫使系统停机。当需要稳健的操作时，这种不稳定性是有问题的。 死锁导致的问题： 基于2PL实现的可串行化隔离级别中，死锁会出现的频繁的多（取决于事务的访问模式）。 死锁发生时，需要把事务中止并被重试。这导致额外的性能问题。 谓词锁 具有可串行化隔离级别的数据库必须防止幻读。 如何防止会议室重复预定（即如果一个事务在某个时间窗口内搜索了一个房间的现有预定，则另一个事务不能同时插入或者更新同一个时间窗口内、同一房间的另一个约定） 实现方式 我们需要一个谓词锁（predicate lock）。它类似于前面描述的共享/排它锁，但不属于特定的对象（例如，表中的一行），它属于所有符合某些搜索条件的对象，如：\n1 2 3 4 SELECT * FROM bookings WHERE room_id = 123 AND end_time \u0026gt; \u0026#39;2018-01-01 12:00\u0026#39; AND start_time \u0026lt; \u0026#39;2018-01-01 13:00\u0026#39;; 谓词锁限制访问的方式： ● 如果事务A想要读取匹配某些条件的对象，就像在这个 SELECT 查询中那样，它必须获取查询条件上的共享谓词锁（shared-mode predicate lock）。如果另一个事务B持有任何满足这一查询条件对象的排它锁，那么A必须等到B释放它的锁之后才允许进行查询。 ● 如果事务A想要插入，更新或删除任何对象，则必须首先检查旧值或新值是否与任何现有的谓词锁匹配。如果事务B持有匹配的谓词锁，那么A必须等到B已经提交或中止后才能继续。\n关键思想 ● 谓词锁甚至适用于数据库中尚不存在，但将来可能会添加的对象（幻象）。 ● 如果两阶段锁定包含谓词锁，则数据库将阻止所有形式的写入偏差和其他竞争条件，因此其隔离实现了可串行化。\n索引范围锁 ● 谓词锁性能不佳：如果活跃事务持有很多锁，检查匹配的锁会非常耗时。 ● 大多数使用2PL的数据库实际上实现了索引范围锁（也称为间隙锁（next-key locking）），这是一个简化的近似版谓词锁。\n索引范围锁： ● 对查询对象的索引加锁。 ● 比如，room_id列上有一个索引，并且/或者在start_time 和 end_time上有索引；那么在查询的时候，在查询时，将某个具体对象的索引加上锁，比如给 room_id =123的索引加锁，那么其他事务就没法获取到此索引的锁，导致无法插入、更新、删除。\n优点： ● 这种方法能够有效防止幻读和写入偏差。 ● 虽然索引范围锁并不像谓词锁那样精确（它们可能会锁定更大范围的对象，而不是维持可串行化所必需的范围），但是由于它们的开销较低，所以是一个很好的折衷。\n如果没有索引，怎么加索引范围锁？ ● 退化到整个表上的共享锁 ● 对性能不利，但是比较安全。\n可串行化快照隔离 本章讨论了关于数据库的并发控制的黯淡画面： ● 一方面，我们实现了性能不好（2PL）或者伸缩性不好（串行执行）的可串行化隔离级别。 ● 另一方面，我们有性能良好的弱隔离级别，但容易出现各种竞争条件（丢失更新，写入偏差，幻读等）。\n串行化的隔离级别和高性能是从根本上相互矛盾的吗？ ● 也许不是：一个称为可串行化快照隔离（SSI, serializable snapshot isolation） 的算法是非常有前途的。\n可串行化快照隔离 ● 它提供了完整的可串行化隔离级别，但与快照隔离相比只有很小的性能损失。 ● SSI是相当新的：它在2008年首次被提出。 ● 既用于单节点数据库（PostgreSQL9.1 以后的可串行化隔离级别）和分布式数据库（FoundationDB使用类似的算法）。\n悲观与乐观的并发控制 ● 两阶段锁是一种所谓的悲观并发控制机制（pessimistic） ：它是基于这样的原则：如果有事情可能出错（如另一个事务所持有的锁所表示的），最好等到情况安全后再做任何事情。 ● 串行化快照隔离是一种乐观（optimistic） 的并发控制技术。 ○ 乐观意味着，如果存在潜在的危险也不阻止事务，而是继续执行事务，希望一切都会好起来。 ○ 当一个事务想要提交时，数据库检查是否有什么不好的事情发生（即隔离是否被违反）；如果是的话，事务将被中止，并且必须重试。只有可串行化的事务才被允许提交。\n适用场景的思考： ● 如果存在很多争用（contention）（很多事务试图访问相同的对象），则表现不佳，因为这会导致很大一部分事务需要中止。 ● 但是，如果有足够的备用容量，并且事务之间的争用不是太高，乐观的并发控制技术往往比悲观的要好。\n与早期的乐观并发控制技术的主要区别： ● SSI基于快照隔离——也就是说，事务中的所有读取都是来自数据库的一致性快照。 ● 在快照隔离的基础上，SSI添加了一种算法来检测写入之间的串行化冲突，并确定要中止哪些事务\n基于过时前提的决策 ● 前文讨论的快照隔离中的写入偏差，是由于事务基于一个前提（premise） 采取行动，之后当事务要提交时，原始数据可能已经改变——前提可能不再成立。 ● 更好的办法是由数据库进行判断，而不是应用程序来判断。 ● 数据库如何知道查询结果是否可能已经改变？有两种情况需要考虑： ○ 检测对旧MVCC对象版本的读取（读之前存在未提交的写入） ○ 检测影响先前读取的写入（读之后发生写入）\n检测旧MVCC读取 快照隔离出现写入偏差的原因： ● 快照隔离通常是通过多版本并发控制（MVCC；见图7-10）来实现的。当一个事务从MVCC数据库中的一致快照读时，它将忽略取快照时尚未提交的任何其他事务所做的写入。 ● 图7-10 检测事务何时从MVCC快照读取过时的值（关于医生值班请假的例子）\n如何避免？ ● 数据库需要跟踪一个事务由于MVCC可见性规则而忽略另一个事务的写入。当事务想要提交时，数据库检查是否有任何被忽略的写入现在已经被提交。如果是这样，事务必须中止。\n为什么等到提交时才检查和中止，而不是检测到读取陈旧数据就中止事务 43？ ● 如果事务43 是只读事务，则不需要中止，因为没有写入偏差的风险。\n检测影响之前读取的写入 第二种情况要考虑的是另一个事务在读取数据之后修改数据。 ● 图7-11 在可串行化快照隔离中，检测一个事务何时修改另一个事务的读取。\n实现方法 ● SSI 采用和索引范围锁类似的技术，除了SSI锁不会阻塞其他事务。 ● 事务42 和43 都在班次1234 查找值班医生。如果在shift_id上有索引，则数据库可以使用索引项1234 来记录事务42 和43 读取这个数据的事实。此信息保留到所有事务处理完成即可。 ● 当事务写入数据库时，它必须在索引中查找最近曾读取受影响数据的其他事务。这个过程类似于在受影响的键范围上获取写锁，但锁并不会阻塞事务指导其他读事务完成，而是像警戒线一样只是简单通知其他事务：你们读过的数据可能不是最新的啦。 ● 当事务 43 想要提交时，发现来自事务42 的冲突写入已经被提交，所以事务43 必须中止。\n可串行化快照隔离的性能 与两阶段锁定相比，可串行化快照隔离的优点： ● 一个事务不需要阻塞等待另一个事务所持有的锁。就像在快照隔离下一样，写不会阻塞读，反之亦然。 ● 这种设计原则使得查询延迟更可预测，变量更少。特别是，只读查询可以运行在一致快照上，而不需要任何锁定，这对于读取繁重的工作负载非常有吸引力。\n与串行执行相比，可串行化快照隔离的优点： ● 并不局限于单个CPU核的吞吐量：FoundationDB将检测到的串行化冲突分布在多台机器上，允许扩展到很高的吞吐量。 ● 即使数据可能跨多台机器进行分区，事务也可以在保证可串行化隔离等级的同时读写多个分区中的数据。\n使用场景 ● 中止率显著影响SSI的整体表现。例如，长时间读取和写入数据的事务很可能会发生冲突并中止，因此SSI要求同时读写的事务尽量短（只读的长事务可能没问题）。 ● SSI可能比两阶段锁定或串行执行更能容忍慢事务。\n本章小结 事务的好处？ ● 事务是一个抽象层，允许应用程序假装某些并发问题和某些类型的硬件和软件故障不存在。各式各样的错误被简化为一种简单情况：事务中止（transaction abort），而应用需要的仅仅是重试。\n什么时候需要事务？ ● 具有非常简单访问模式的应用（例如每次读写单条记录）可能无需事务管理。 ● 但是对于更复杂的访问模式，事务可以大大减少需要考虑的潜在错误情景数量。\n本章讨论了什么？ ● 本章深入讨论了并发控制的话题。 ● 我们讨论了几个广泛使用的隔离级别，特别是读已提交，快照隔离（有时称为可重复读）和可串行化。\n竞争条件的例子 脏读 一个客户端读取到另一个客户端尚未提交的写入。读已提交或更强的隔离级别可以防止脏读。 脏写 一个客户端覆盖写入了另一个客户端尚未提交的写入。几乎所有的事务实现都可以防止脏写。 读取偏差（不可重复读） 在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。快照隔离经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。快照隔离通常使用多版本并发控制（MVCC） 来实现。 更新丢失 两个客户端同时执行读取-修改-写入序列。其中一个写操作，在没有合并另一个写入变更情况下，直接覆盖了另一个写操作的结果。所以导致数据丢失。快照隔离的一些实现可以自动防止这种异常，而另一些实现则需要手动锁定（SELECT FOR UPDATE）。 写偏差 一个事务读取一些东西，根据它所看到的值作出决定，并将该决定写入数据库。但是，写入时，该决定的前提不再是真实的。只有可串行化的隔离才能防止这种异常。 幻读 事务读取符合某些搜索条件的对象。另一个客户端进行写入，影响搜索结果。快照隔离可以防止直接的幻像读取，但是写入偏差上下文中的幻读需要特殊处理，例如索引范围锁定。\n弱隔离级别可以防止其中一些异常情况，但要求你，也就是应用程序开发人员手动处理剩余那些（例如，使用显式锁定）。只有可串行化的隔离才能防范所有这些问题。我们讨论了实现可串行化事务的三种不同方法： 字面意义上的串行执行 如果每个事务的执行速度非常快，并且事务吞吐量足够低，足以在单个CPU核上处理，这是一个简单而有效的选择。 两阶段锁定 数十年来，两阶段锁定一直是实现可串行化的标准方式，但是许多应用出于性能问题的考虑避免使用它。 可串行化快照隔离（SSI） 一个相当新的算法，避免了先前方法的大部分缺点。它使用乐观的方法，允许事务执行而无需阻塞。当一个事务想要提交时，它会进行检查，如果执行不可串行化，事务就会被中止。\n第八章： 分布式系统的挑战 分布式系统面临哪些挑战？ ● 前面几章讨论的副本故障切换、复制延迟、事务控制； ● 本章讨论的不可靠网络、时钟和时序问题等等； ● 我们的假设：任何可能出错的东西都会出错。\n故障与部分失效 ● 单机上的软件比较稳定，要么功能完好，要么整个系统故障，而不是介于两者之间。 ● 分布式系统中，尽管系统的其他部分工作正常，但系统的某些部分可能会以某种不可预知的方式被破坏。这被称为部分失效（partial failure）。难点在于部分失效是不确定性的（nonderterministic）。\n云计算与超级计算机 构建大型计算系统的方式： ● 一个极端是高性能计算（HPC）领域，具有数千个CPU的超级计算机通常用于计算密集型科学计算任务，比如天气预报； ● 另一个极端是云计算（cloud computing），通过很多主机相连接； ● 传统企业数据中心位于这两个极端之间。\n超级计算机怎么处理故障？ ● 超级计算机中，作业通常会不时地将计算存盘到持久存储中； ● 如果发生部分故障，那么通过修复、重启、重新加载继续计算的方式。 ● 类似于一个单节点计算机。\n互联网服务的系统与超级计算机系统的区别？\n互联网服务的系统 互联网服务的系统\t超级计算机 在线的，低延迟，不可重启 离线的，批处理，可以重启 基于 IP 和以太网 专门的网络拓扑 故障频发，需要很快的处理故障 可以花较多的时间从错误中恢复 普通硬件，较低成本，较高故障率 专用硬件，节点可靠，节点通过共享内存和远程直接内存访问（RDMA）进行通信 可以容忍发生故障的节点 不能容忍故障节点 地理位置分布发散，通信通过互联网，通信缓慢且不可靠 所有节点都靠近一起 构建分布式系统的思路？ ● 接受部分故障的可能性，并在软件中建立容错机制。\n不可靠的网络 互联网和数据中心（通常是以太网）中的大多数内部网络都是异步分组网络（asynchronous packet networks）。 网络可能出现的错误？ 请求可能已经丢失（可能有人拔掉了网线）。 请求可能正在排队，稍后将交付（也许网络或接收方过载）。 远程节点可能已经失效（可能是崩溃或关机） 远程节点可能暂时停止了响应（可能会遇到长时间的垃圾回收暂停），但稍后会再次响应 远程节点可能已经处理了请求，但是网络上的响应已经丢失（可能是网络交换机配置错误）。 远程节点可能已经处理了请求，但是响应已经被延迟，并且稍后将被传递（可能是网络或者你自己的机器过载）。 怎么处理网络错误？ ● 通常方法是超时（Timeout）：在一段时间之后放弃等待，并且认为响应不会到达。 ● 但是，当发生超时时，你仍然不知道远程节点是否收到了请求（如果请求仍然在某个地方排队，那么即使发送者已经放弃了该请求，仍然可能会将其发送给接收者）。\n真实世界的网络故障 ● 真实世界很复杂，啥样的网络故障都可能发生。 ○ 机器损坏 ○ 人为操作错误\n检测故障 为什么需要自动检测故障节点？ ● 负载平衡器需要停止向已死亡的节点转发请求（即从移出轮询列表（out of rotation））。 ● 在单主复制功能的分布式数据库中，如果主库失效，则需要将从库之一升级为新主库\n怎么判断一个节点是否工作？ ● 网络的不确定性导致很难判断。 ● 特定场景下，故障节点可能有反馈信息： ○ 没有进程正在监听目标端口，操作系统将发送 FIN 或者 RST 关闭并重用 TCP 连接 ○ 节点进程崩溃，但操作系统仍在运行，脚本可以通知其他节点有关该崩溃的信息 ○ 通过数据中心网络交换机的管理界面，检测硬件级别的链路故障 ○ 路由器发现尝试连接的IP地址不可用，则可能会使用ICMP目标不可达数据包回复您。 ● 你不能指望这些信息，必须假设出错时得不到任何回应 ● 通过超时来检测\n超时与无穷的延迟 超时应该得到多久？ ● 没有答案\n过短的超时可以吗？ ● 如果一个节点实际上活着，另一个节点接管，可能造成动作执行了两次 ● 如果因为高负载导致响应缓慢，将其负载转移到其他节点可能会导致级联失效。\n虚构的系统中，合理的超时时间？ ● 假设数据包的最大延迟为 $d$，即要么在 $d$ 内完成交付，要么丢失 ● 假设非故障节点在 $r$ 时间内完成请求处理 ● 在这种情况下，您可以保证每个成功的请求在$2d + r$时间内都能收到响应。 ● $2d + r$ 会是一个合理的超时设置。\n实际上，大多数系统都没有这些保证。\n网络拥塞和排队 计算机网络上数据包延迟的可变性通常是由于排队：\n交换机队列填满 目标机器的 CPU 繁忙 多个虚拟机争抢 CPU TCP执行流量控制（flow control） 怎么解决多租户数据中心的网络拥塞问题？\n原因：在公共云和多租户数据中心中，资源被许多客户共享：网络链接和交换机，甚至每个机器的网卡和CPU（在虚拟机上运行时）。 解决办法：通过实验方式选择超时：在一段较长的时期内、在多台机器上测量网络往返时间的分布，以确定延迟的预期变化。然后，考虑到应用程序的特性，可以确定故障检测延迟与过早超时风险之间的适当折衷。 更好的办法：不是固定的常量超时时间，而是连续测量响应时间及其变化来自动调整超时时间。 同步网络与异步网络 为什么我们不能在硬件层面上解决这个问题，使网络可靠，使软件不必担心呢？\n以非常可靠的传统固定电话网络为例：\n延迟音频帧和掉话是非常罕见的。 在两个呼叫者之间的整个路线上为呼叫分配一个固定的，有保证的带宽量。 网络资源被保留了，因此不会排队。 由于没有排队，网络的最大端到端延迟是固定的。我们称之为有限延迟（bounded delay）。 网络延迟可以预测吗？ ● 电话网络的电路和 TCP 连接很不同： ○ 电路是固定数量的预留带宽 ○ TCP连接的数据包机会性地使用任何可用的网络带宽。 ○ 以太网和 IP 是分组交换协议，不得不忍受排队，以及其导致的无线延迟。 ■ 优点是可以应对不同速率的流量，也最大程度利用网络资源。 ● 当前部署的技术不允许我们对网络的延迟或可靠性作出任何保证：我们必须假设网络拥塞，排队和无限的延迟总是会发生。 ● 因此，超时时间没有“正确”的值——它需要通过实验来确定。\n不可靠的时钟 时钟和时间很重要。应用程序以各种方式依赖于时钟来回答以下问题：\n这个请求是否超时了？ 这项服务的第99百分位响应时间是多少？ 在过去五分钟内，该服务平均每秒处理多少个查询？ 用户在我们的网站上花了多长时间？ 这篇文章在何时发布？ 在什么时间发送提醒邮件？ 这个缓存条目何时到期？ 日志文件中此错误消息的时间戳是什么？ 时钟为什么不可靠？\n● 分布式系统中，时间很棘手，因为通信不是即时的：网络延迟，并且不知道晚了多少时间，导致不知道事件发生的顺序。 ● 每个机器都有自己的时钟，是个硬件设备：石英晶体振荡器。但是该硬件不可靠，需要通过服务器进行同步。\n单调钟与日历时钟 计算机至少有两种目的不一样的时钟： ● 日历时钟（time-of-day clock） ● 单调钟（monotonic clock）\n日历时钟 日历时钟是什么？ ● 直观了解时钟的依据：它根据某个日历（也称为挂钟时间（wall-clock time））返回当前日期和时间。 ● 例如 Linux上的clock_gettime(CLOCK_REALTIME) 和 Java中的System.currentTimeMillis() ● 通常与网络时间协议（NTP）同步\n缺点： ● 不包括闰秒，所以不能测量 经过时间（elapsed time） ● 可能会被强制重置（比如与 NTP 时间差别很大的时候）\n单调钟 是什么？ ● 单调钟适用于测量持续时间（时间间隔） ● 例如超时或服务的响应时间：Linux上的clock_gettime(CLOCK_MONOTONIC)，和Java中的System.nanoTime()都是单调时钟。 ● 名字来源：单调钟保证总是往前走的事实（而日历时钟可以往回跳）\n怎么用？ ● 计算时间差，即测量 经过时间（elapsed time） ● 单调钟的绝对值毫无意义：可能是任意值。\n会修改吗？ ● NTP 检测到计算机的本地石英钟比NTP服务器要更快或更慢，则可以调整单调钟向前走的频率（这称为偏移（skewing） 时钟）。 ● NTP允许时钟速率增加或减慢最高至0.05％，但NTP不能使单调时钟向前或向后跳转。\n精确度？ ● 分辨率很高，很精确 ● 几微秒或者更短的时间内测量时间间隔\n在分布式系统中的作用？ ● 在分布式系统中，使用单调钟测量经过时间（elapsed time）（比如超时）通常很好，因为它不假定不同节点的时钟之间存在任何同步，并且对测量的轻微不准确性不敏感。\n时钟同步与准确性 ● 单调钟不需要同步 ● 日历时钟需要通过 NTP 或者其他外部时间进行同步，但是！获取时钟的方法并不可靠和准确。\n举例： ● 计算机中的石英钟不够精确：它会漂移（drifts）（运行速度快于或慢于预期）。时钟漂移取决于机器的温度。Google 假设如果机器一天同步一次时钟，漂移为 17 秒。 ● 如果计算机的时钟与NTP服务器的时钟差别太大，可能会拒绝同步，或者本地时钟将被强制重置。导致观察重置前后时间的应用程序傻眼了。 ● 如果与 NTP 服务器链接失败（比如防火墙），那么可能很长时间没有留意到错误配置最终导致同步失败。 ● NTP 服务器故障或出现配置错误。 ● 闰秒导致服务器崩溃了。处理闰秒的推荐方法是：NTP 把闰秒摊平均匀分布到一天。 ● 虚拟机中，突然卡了。导致时钟跳跃。 ● 用户故意调整硬件时钟，以规避游戏的时间限制。\n依赖同步时钟 时钟导致的问题： ● 日历时钟可能会前后跳跃\n处理方法： ● 需要健壮的软件来处理不正确的时钟 ● 时钟问题很难被发现：因此仔细监控所有机器之间的时钟偏移，把偏移太远的机器移除。\n有序事件的时间戳 ● 当依赖时钟对多个节点事件排序时，时钟尤其主要。 ● 下图显示了在具有多领导者复制的数据库中对时钟的危险使用：客户端B的写入比客户端A的写入要晚，但是B的写入具有较早的时间戳。\n最后写入胜利（LWW） ● 上述冲突叫做最后写入胜利 ● 时间戳导致的问题： ○ 数据库写入可能会神秘地消失：被滞后时钟节点的数据覆盖了 ○ LWW无法区分高频顺序写入和真正并发写入。需要额外的因果关系跟踪机制（例如版本向量），以防止违背因果关系。 ○ 两个节点很可能独立地生成具有相同时间戳的写入，特别是在时钟仅具有毫秒分辨率的情况下。所以，需要一个额外的决胜值（tiebreaker）（可以简单地是一个大随机数），但这种方法也可能会导致违背因果关系。\n能不能用NTP 同步避免不正确的排序？ ● 不能 ● 精度问题，石英钟漂移，网络时延。\n怎么避免时钟问题呢？ ● 逻辑时钟（logic clock）是基于递增计数器而不是振荡石英晶体，对于排序事件来说是更安全的选择。 ● 逻辑时钟不测量一天中的时间或经过的秒数，而仅测量事件的相对顺序（无论一个事件发生在另一个事件之前还是之后）。 ● 相反，用来测量实际经过时间的日历时钟和单调钟也被称为物理时钟（physical clock）。 ● 将在「顺序保证」章节讨论。\n时钟读数存在置信区间 ● NTP 同步可能有几毫秒到 100 毫秒的偏移。 ● 时钟读数更像是个置信区间：一个系统可能以95％的置信度认为当前时间处于本分钟内的第10.3秒和10.5秒之间，它可能没法比这更精确了。 ● 但是大多数系统不告诉你误差范围查询的接口，你不知道时间的误差是多少！ ● 不过 Spanner中的Google TrueTime API 明确地报告了本地时钟的置信区间：[最早，最晚]。\n全局快照的同步时钟 ● 「快照隔离和可重复读」章节中，讨论了快照隔离。它允许只读事务看到特定时间点的处于一致状态的数据库，且不会锁定和干扰读写事务。 ● 快照隔离最常见的实现需要单调递增的事务ID。如果写入比快照晚（即，写入具有比快照更大的事务ID），则该写入对于快照事务是不可见的。在单节点数据库上，一个简单的计数器就足以生成事务ID。 ● 但是当数据库分布在许多机器上，也许可能在多个数据中心中时，由于需要协调，（跨所有分区）全局单调递增的事务ID会很难生成。\n可以使用同步时钟的时间戳作为事务ID吗？ ● 理论上可以，实际上问题在于时钟精度的不确定性 ● Spanner以这种方式实现跨数据中心的快照隔离，它使用的是时间的置信区间。 ● 除此之外，没有主流数据库在分布式语义中使用时钟同步。\n进程暂停 设想一个单领导者的分布式数据库，一个节点怎么知道自己仍然是领导者？ ● 一种选择是领导者从其他节点获得一个租约（lease），类似一个带超时的锁。 ● 任一时刻只有一个节点可以持有租约——因此，当一个节点获得一个租约时，它知道它在某段时间内自己是领导者，直到租约到期。 ● 为了保持领导地位，节点必须周期性地在租约过期前续期。 ● 如果节点发生故障，就会停止续期，所以当租约过期时，另一个节点可以接管。\n使用租约的问题在哪？\n它依赖于同步时钟 程序执行过程卡顿，导致错过了续租约的时间，并继续处理了一些不安全的请求。而另一个节点接管了领导。 线程为什么会暂停很长时间？ ● 垃圾回收（GC） ● 虚拟机被挂起 ● 用户关闭笔记本电脑盖子 ● 操作系统上下文切换到另一个线程时 ● 应用程序同步读取磁盘，等待 IO ● 页面交换的时候，可能导致页面错误，要求将磁盘的页面装入内存。线程暂停。 ● 可以通过发送SIGSTOP信号来暂停Unix进程，例如通过在shell中按下Ctrl-Z。\n线程暂停的后果？ ● 上述事件都可以随时抢占（preempt） 正在运行的线程，并在稍后的时间恢复运行，而线程甚至不会注意到这一点。 ● 在单机上编码时，可以实现线程安全：互斥量，信号量，原子计数器，无锁数据结构，阻塞队列等等。 ● 不幸的是，这些工具并不能直接转化为分布式系统操作，因为分布式系统没有共享内存，只有通过不可靠网络发送的消息。 ● 分布式系统中的节点，必须假定其执行可能在任意时刻暂停相当长的时间，即使是在一个函数的中间。 ● 在暂停期间，世界的其它部分在继续运转，甚至可能因为该节点没有响应，而宣告暂停节点的死亡。最终暂停的节点可能会继续运行，在再次检查自己的时钟之前，甚至可能不会意识到自己进入了睡眠。\n响应时间保证 如何做到在特定事件响应的保证？ ● 飞机、火箭、机器人、骑车等系统中的软件件必须有一个特定的截止时间（deadline），如果截止时间不满足，可能会导致整个系统的故障。这就是所谓的硬实时（hard real-time） 系统。 ● 实现实时保证需要各级软件的支持： ○ 一个实时操作系统（RTOS），允许在指定的时间间隔内保证CPU时间的分配。 ○ 库函数必须申明最坏情况下的执行时间； ○ 动态内存分配可能受到限制或完全不允许（实时垃圾收集器存在，但是应用程序仍然必须确保它不会给GC太多的负担）； ○ 必须进行大量的测试和测量，以确保达到保证。 ● 实时系统太贵！ ● 因此大多数服务器端数据处理系统，必须承受非实时环境中运行的暂停和时钟不稳定性。\n限制垃圾收集的影响 怎么降低垃圾回收带来的影响？ ● 一种想法是在即将 GC 前发出警告，应用程序停止向该节点发出新的请求；等待其恢复后，再继续处理请求。 ● 另一种想法是垃圾回收处理短命对象（可以快速收集），并定期在积累大量长寿对象（因此需要完整GC）之前重新启动进程。重启时把节点的流量移走。\n知识、真相与谎言 何为真假？感知和测量不可靠，我们怎么确定信息的可靠性？这是个哲学问题。\n真相由多数所定义 真相到底是什么？ ● 节点不能根据自己的信息来判断自身的状态。 ● 因为节点可能随时失效，可能会暂停-假死，可能最终都无法恢复。 ● 相反，许多分布式算法都依赖于法定人数，即在节点之间进行投票：决策需要来自多个节点的最小投票数，以减少对于某个特定节点的依赖。 ● 个体哪怕没死，当被法定数量的节点宣告死亡时，它也必须被认定为死的。个体必须遵守法定决定并下台。\n最常见的法定人数是超过一半的绝对多数（尽管其他类型的法定人数也是可能的）。 第九章将继续讨论共识算法。\n领导者和锁 通常，一些东西在一个系统中只能有一个。如： ● 数据库分区的领导者只能有一个节点，以避免脑裂（split brain） ● 特定资源的锁或对象只允许一个事务/客户端持有，以防同时写入和损坏。 ● 一个特定的用户名只能被一个用户所注册，因为用户名必须唯一标识一个用户。\n分布式系统可能出现「唯一的节点」不止一个！ ● 一个节点认为自己是「唯一的节点」，但是有可能它以前是主节点，但是其他节点宣布它死亡了，此时已经出现了另外一个主节点。 ● 当该节点继续表现为『唯一的节点』，那么可能导致系统异常。\n图8-4 分布式锁的实现不正确：客户端1认为它仍然具有有效的租约，即使它已经过期，从而破坏了存储中的文件 防护令牌 确保一个被误认为自己是「唯一的节点」，不能扰乱系统的其它部分。实现这一目标的一个相当简单的技术就是防护（fencing）。 图8-5 只允许以增加防护令牌的顺序进行写操作，从而保证存储安全 具体做法： ● 每次锁定服务器授予锁或租约时，它还会返回一个防护令牌（fencing token），这个数字在每次授予锁定时都会增加。 ● 然后，我们可以要求客户端每次向存储服务发送写入请求时，都必须包含当前的防护令牌。 ● 当防护令牌已经过期了，那么就拒绝其写入。 ● 如果将ZooKeeper用作锁定服务，则可将事务标识zxid或节点版本cversion用作防护令牌。由于它们保证单调递增，因此它们具有所需的属性\n防护令牌需要注意？ ● 要求资源本身在检查令牌方面发挥积极作用，而不能仅仅依靠客户端检查自己的锁状态。 ● 需要在服务端进行检查令牌。\n防护令牌是缺点还是好事？ ● 好事 ● 服务不能假设客户总是守规矩并且明智的。\n拜占庭故障 防护令牌一定可靠吗？ ● 不一定 ● 果节点有意破坏系统的保证，则可以通过使用假防护令牌发送消息来轻松完成此操作。 ● 上文中都是假设节点是不可靠但诚实的。\n节点会撒谎吗？ ● 这种行为被称为拜占庭故障（Byzantine fault），在不信任的环境中达成共识的问题被称为拜占庭将军问题。 ● 当一个系统在部分节点发生故障、不遵守协议、甚至恶意攻击、扰乱网络时仍然能继续正确工作，称之为拜占庭容错（Byzantine fault-tolerant）\n什么情况下会出现拜占庭容错？ ● 在航空航天环境中，计算机内存或CPU寄存器中的数据可能被辐射破坏，导致其以任意不可预知的方式响应其他节点。 ● 在多个参与组织的系统中，一些参与者可能会试图欺骗或欺骗他人。\n我的系统需要考虑拜占庭故障吗？ ● 一般不需要。 ● 代价昂贵。\n为什么一般不需要考虑拜占庭故障？ ● Web 系统是中心化的，服务器决定客户端的行为。 ● 软件的 bug 可能被认为是拜占庭错误，但是拜占庭算法帮不了你：拜占庭算法要求超过 2/3 的节点正常工作。 ● 大多数系统中，如果攻击者可以渗透进一个节点，那么可能会渗透所有的节点，因为运行着相同的软件。因此，传统机制（认证，访问控制，加密，防火墙等）仍然是抵御攻击者的主要保护措施。\n弱谎言形式 什么是弱谎言？ ● 尽管我们假设节点通常是诚实的，但值得向软件中添加防止“撒谎”弱形式的机制。 ● 例如，由硬件问题导致的无效消息，软件错误和错误配置。 ● 这些保护机制虽然不能抵挡决心坚定的对手，但它们仍然是简单而实用的步骤，以提高可靠性。\n常见的弱谎言以及怎么处理？ ● 由于硬件问题或操作系统、驱动程序、路由器等中的错误，网络数据包有时会受到损坏。 ○ 解决办法： ■ TCP和UDP中的校验和所俘获 ■ 应用程序级协议中的校验和。 ● 可公开访问的应用程序必须仔细清理来自用户的任何输入 ○ 解决办法： ■ 检查值是否在合理的范围内 ■ 限制字符串的大小以防止通过大内存分配的拒绝服务 ● 一个配置错误的NTP服务器报告错误的时间 ○ 解决办法： ■ NTP客户端可以配置多个服务器地址 ■ 客户端联系所有的服务器，估计它们的误差，并检查大多数服务器是否对某个时间范围达成一致\n系统模型与现实 分布式系统问题要求我们以某种方式将我们期望在系统中发生的错误形式化——模型。\n关于时序假设，三种系统模型是常用的： 同步模型 ● 同步模型（synchronous model） 假设网络延迟、进程暂停和和时钟误差都是受限的。 ○ 这并不意味着完全同步的时钟或零网络延迟； ○ 这只意味着你知道网络延迟、暂停和时钟漂移将永远不会超过某个固定的上限。 ○ 同步模型并不是大多数实际系统的现实模型，因为（如本章所讨论的）无限延迟和暂停确实会发生。 部分同步模型 ● 部分同步（partial synchronous） 意味着一个系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟，进程暂停和时钟漂移的界限。 ○ 这是很多系统的现实模型：大多数情况下，网络和进程表现良好，否则我们永远无法完成任何事情。 ○ 但是我们必须承认，在任何时刻都存在时序假设偶然被破坏的事实。发生这种情况时，网络延迟、暂停和时钟错误可能会变得相当大。 异步模型 ● 在这个模型中，一个算法不允许对时序做任何假设——事实上它甚至没有时钟（所以它不能使用超时）。 ○ 一些算法被设计为可用于异步模型，但非常受限。\n除了时序问题，我们还要考虑节点失效。三种最常见的节点系统模型是： 崩溃-停止故障 ● 在崩溃停止（crash-stop） 模型中，算法可能会假设一个节点只能以一种方式失效，即通过崩溃。 ○ 这意味着节点可能在任意时刻突然停止响应，此后该节点永远消失——它永远不会回来。 崩溃-恢复故障 ● 我们假设节点可能会在任何时候崩溃，但也许会在未知的时间之后再次开始响应。 ○ 在崩溃-恢复（crash-recovery） 模型中，假设节点具有稳定的存储（即，非易失性磁盘存储）且会在崩溃中保留，而内存中的状态会丢失。 拜占庭（任意）故障 ● 节点可以做（绝对意义上的）任何事情，包括试图戏弄和欺骗其他节点，如上一节所述。\n对于真实系统的建模，具有崩溃-恢复故障（crash-recovery） 的部分同步模型（partial synchronous） 通常是最有用的模型。\n分布式算法如何应对这种模型？\n算法的正确性 怎么判断算法是正确的？ ● 为了定义算法是正确的，我们可以描述它的属性。 ● 我们可以写下我们想要的分布式算法的属性来定义它的正确含义。\n例如，如果我们正在为一个锁生成防护令牌，我们可能要求算法具有以下属性： 唯一性（uniqueness） ● 没有两个防护令牌请求返回相同的值。 单调序列（monotonic sequence） ● 如果请求 $x$ 返回了令牌 $t_x$，并且请求$y$返回了令牌$t_y$，并且 $x$ 在 $y$ 开始之前已经完成，那么$t_x \u0026lt;t_y$。 可用性（availability） ● 请求防护令牌并且不会崩溃的节点，最终会收到响应。\n如果一个系统模型中的算法总是满足它在所有我们假设可能发生的情况下的性质，那么这个算法是正确的。\n但是如果所有节点都挂了，可用性还有意义吗？\n安全性和活性 有必要区分两种不同的属性：安全（safety）属性和活性（liveness）属性。 ● 刚才的例子中，唯一性和单调序列是安全属性，而可用性是活性属性。\n两种性质的通俗理解/区别？ ● 思路：活性属性通常在定义中通常包括“最终”一词。 （是的，你猜对了——最终一致性是一个活性属性。） ● 安全通常被非正式地定义为：没有坏事发生 ● 活性通常就类似：最终好事发生。 ● 最好不要过度阅读非正式的定义，因为好和坏是主观的。\n安全和活性的实际定义是精确的和数学的： ● 如果安全属性被违反，我们可以指向一个特定的安全属性被破坏的时间点 ○ 例如，如果违反了唯一性属性，我们可以确定重复的防护令牌被返回的特定操作。违反安全属性后，违规行为不能被撤销——损失已经发生。 ● 活性属性反过来：在某个时间点（例如，一个节点可能发送了一个请求，但还没有收到响应），它可能不成立，但总是希望在未来能成立（即通过接受答复）。\n为什么要区分安全属性和活性属性？ ● 可以帮助我们处理困难的系统模型。 ● 对于分布式算法，在系统模型的所有可能情况下，要求始终保持安全属性是常见的。 ○ 也就是说，即使所有节点崩溃，或者整个网络出现故障，算法仍然必须确保它不会返回错误的结果（即保证安全属性得到满足）。 ● 但是，对于活性属性，我们可以提出一些注意事项： ○ 例如，只有在大多数节点没有崩溃的情况下，只有当网络最终从中断中恢复时，我们才可以说请求需要接收响应。 ○ 部分同步模型的定义要求系统最终返回到同步状态——即任何网络中断的时间段只会持续一段有限的时间，然后进行修复。\n将系统模型映射到现实世界 证明算法正确，那么现实系统中一定正确吗？ ● 虽然，安全属性和活性属性以及系统模型对于推理分布式算法的正确性非常有用。 ● 但是，现实的混乱事实再一次地让你咬牙切齿。 ● 很明显系统模型是对现实的简化抽象。\n那么，理论上抽象的系统模型是毫无价值的吗？ ● 恰恰相反。它很有价值。 ● 它们对于将实际系统的复杂性提取成一个个我们可以推理的可处理的错误类型是非常有帮助的，以便我们能够理解这个问题，并试图系统地解决这个问题。 ● 我们可以证明算法是正确的，通过表明它们的属性在某个系统模型中总是成立的。\n实际上该怎么办？ ● 因为理论分析可以发现算法中的问题，这种问题可能会在现实系统中长期潜伏，直到你的假设（例如，时序）因为不寻常的情况被打破。 ● 理论分析与经验测试同样重要。\n本章小结 在本章中，我们讨论了分布式系统中可能发生的各种问题，包括： ● 当您尝试通过网络发送数据包时，数据包可能会丢失或任意延迟。同样，答复可能会丢失或延迟，所以如果你没有得到答复，你不知道消息是否发送成功了。 ● 节点的时钟可能会与其他节点显著不同步（尽管您尽最大努力设置NTP），它可能会突然跳转或跳回，依靠它是很危险的，因为您很可能没有好的方法来测量你的时钟的错误间隔。 ● 一个进程可能会在其执行的任何时候暂停一段相当长的时间（可能是因为停止所有处理的垃圾收集器），被其他节点宣告死亡，然后再次复活，却没有意识到它被暂停了。\n这类部分失效（partial failure） 可能发生的事实是分布式系统的决定性特征。每当软件试图做任何涉及其他节点的事情时，偶尔就有可能会失败，或者随机变慢，或者根本没有响应（最终超时）。在分布式系统中，我们试图在软件中建立部分失效的容错机制，这样整个系统在即使某些组成部分被破坏的情况下，也可以继续运行。\n怎么处理错误？ 为了容忍错误，第一步是检测它们，但即使这样也很难。大多数系统没有检测节点是否发生故障的准确机制，所以大多数分布式算法依靠超时来确定远程节点是否仍然可用。但是，超时无法区分网络失效和节点失效，并且可变的网络延迟有时会导致节点被错误地怀疑发生故障。此外，有时一个节点可能处于降级状态：例如，由于驱动程序错误，千兆网卡可能突然下降到1 Kb/s的吞吐量。这样一个“跛行”而不是死掉的节点可能比一个干净的失效节点更难处理。 一旦检测到故障，使系统容忍它也并不容易：没有全局变量，没有共享内存，没有共同的知识，或机器之间任何其他种类的共享状态。节点甚至不能就现在是什么时间达成一致，就不用说更深奥的了。信息从一个节点流向另一个节点的唯一方法是通过不可靠的网络发送信息。重大决策不能由一个节点安全地完成，因此我们需要一个能从其他节点获得帮助的协议，并争取达到法定人数以达成一致。\n但是，正如在第二部分的介绍中所讨论的那样，可伸缩性并不是使用分布式系统的唯一原因。容错和低延迟（通过将数据放置在距离用户较近的地方）是同等重要的目标，而这些不能用单个节点实现。 在本章中，我们也转换了几次话题，探讨了网络、时钟和进程的不可靠性是否是不可避免的自然规律。我们看到这并不是：有可能给网络提供硬实时的响应保证和有限的延迟，但是这样做非常昂贵，且导致硬件资源的利用率降低。大多数非安全关键系统会选择便宜而不可靠，而不是昂贵和可靠。 我们还谈到了超级计算机，它们采用可靠的组件，因此当组件发生故障时必须完全停止并重新启动。相比之下，分布式系统可以永久运行而不会在服务层面中断，因为所有的错误和维护都可以在节点级别进行处理——至少在理论上是如此。 （实际上，如果一个错误的配置变更被应用到所有的节点，仍然会使分布式系统瘫痪）。 第九章：一致性与共识 构建容错系统的最好方法，是找到一些带有实用保证的通用抽象，实现一次，然后让应用依赖这些保证。比如事务。 我们需要了解系统能力的边界：哪些可行，哪些不可行。\n一致性保证 分布式系统的时序问题：\n在同一时刻查看两个数据库节点，则可能在两个节点上看到不同的数据，因为写请求在不同的时间到达不同的节点。 无论数据库使用何种复制方法（单主复制，多主复制或无主复制），都会出现这些不一致情况。 大多数复制的数据库至少提供了最终一致性，这意味着如果你停止向数据库写入数据并等待一段不确定的时间，那么最终所有的读取请求都会返回相同的值。 换句话说，不一致性是暂时的，最终会自行解决（假设网络中的任何故障最终都会被修复）。最终一致性的一个更好的名字可能是收敛（convergence），因为我们预计所有的副本最终会收敛到相同的值。 最终一致性是非常弱的保证——没有说什么时候会收敛。 在与只提供弱保证的数据库打交道时，你需要始终意识到它的局限性，而不是意外地作出太多假设。（始终不信任它） 除了最终一致性，有没有更强的一致性模型？\n分布式一致性模型 分布式一致性模型和我们之前讨论的事务隔离级别的层次结构有一些相似之处。 不同：事务隔离主要是为了避免由于同时执行事务而导致的竞争状态，而分布式一致性主要关于在面对延迟和故障时如何协调副本间的状态。 线性一致性 线性一致性的想法？\n数据库可以提供只有一个副本的假象（即，只有一个数据副本），那么每个客户端都会有相同的数据视图，且不必担心复制滞后了。 线性一致性（linearizability），也称为原子一致性（atomic consistency），强一致性（strong consistency），立即一致性（immediate consistency） 或外部一致性（external consistency ）。 线性一致性提供了什么保证？\n只要一个客户端成功完成写操作，所有客户端从数据库中读取数据必须能够看到刚刚写入的值。 系统应保障读到的值是最近的、最新的，而不是来自陈旧的缓存或副本。 线性一致性是一个新鲜度保证（recency guarantee）。 图9-1 这个系统是非线性一致的，导致了球迷的困惑 如何使得系统线性一致？ 第十章：批处理 本书的前九章，讨论的都是请求、查询，以及相应的响应和结果。是在线系统，关注响应时间。 三种不同类型的系统： 服务（在线系统） 处理客户的请求或指令。衡量指标：响应时间，可用性。 批处理系统（离线系统） 跑一个作业，处理大量的输入数据，定时运行。衡量指标：吞吐量。 流处理系统（准实时系统） 介于在线系统和离线系统之间。消费输入并产生输出（不需要响应请求），在事件发生不久就对事件进行操作。\n本章讨论批处理系统。\n使用Unix工具的批处理 从一个例子开始。 Web 服务器，每次处理请求，在日志中附加一行。使用nginx默认的访问日志格式。\n1 2 3 216.58.210.78 - - [27/Feb/2015:17:55:11 +0000] \u0026#34;GET /css/typography.css HTTP/1.1\u0026#34; 200 3377 \u0026#34;http://martin.kleppmann.com/\u0026#34; \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115 Safari/537.36\u0026#34; 1 2 $remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34; 简单日志分析 想在你的网站上找到五个最受欢迎的网页：\n1 2 3 4 5 6 cat /var/log/nginx/access.log | #1 awk \u0026#39;{print $7}\u0026#39; | #2 sort | #3 uniq -c | #4 sort -r -n | #5 head -n 5 #6 输出结果：\n1 2 3 4 5 4189 /favicon.ico 3631 /2013/05/24/improving-security-of-ssh-private-keys.html 2124 /2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html 1369 / 915 /css/typography.css 特点：简单且强大。几分钟内完成许多数据分析，性能非常好。\n命令链与自定义程序 除了上述的 Unix 命令链。也可以用程序实现，例如在Ruby中：\n1 2 3 4 5 6 7 8 9 10 counts = Hash.new(0) # 1 File.open(\u0026#39;/var/log/nginx/access.log\u0026#39;) do |file| file.each do |line| url = line.split[6] # 2 counts[url] += 1 # 3 end end top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5] # 4 top5.each{|count, url| puts \u0026#34;#{count} #{url}\u0026#34; } # 5 特点：不简洁，但可读性强。性能较差。\n排序 VS 内存中的聚合 上述两种做法的区别\nRuby 脚本在内存中保存了 URL 的哈希表，保存 URL 和其出现的次数。 Unix 管道没有哈希表，依赖排序。 哪个好？\n工作集较小时，内存散列表表现良好； 如果作业的工作集大于可用内存，则排序的方法优点是可以高效地使用磁盘。 ○ GNU Coreutils（Linux）中的sort程序通过溢出至磁盘的方式来自动应对大于内存的数据集，并能同时使用多个CPU核进行并行排序。 ○ 瓶颈可能是从磁盘读取输入文件的速度。 Unix哲学 Unix管道的发明者道格·麦克罗伊（Doug McIlroy）在1964年说：让数据像水管一样流动。\n让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件时，即使是操作系统，也让它们能够尽早地被试用，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。 这种方法 —— 自动化，快速原型设计，增量式迭代，对实验友好，将大型项目分解成可管理的块 —— 听起来非常像今天的敏捷开发和DevOps运动。奇怪的是，四十年来变化不大。 Unix 怎么实现命令的可组合性？\n统一的接口 为什么要统一的接口？ ● 一个程序的输出作为另外一个程序的输入，那么必然要统一。\n怎么实现统一的接口？\n● 在Unix中，这种接口是一个文件（file）（更准确地说，是一个文件描述符）。 ● 一个文件只是一串有序的字节序列。 ● 这是一个非常简单的接口，所以可以使用相同的接口来表示许多不同的东西： ○ 文件系统上的真实文件， ○ 另一个进程（Unix套接字，stdin，stdout）的通信通道 ○ 设备驱动程序（比如/dev/audio或/dev/lp0） ○ 表示TCP连接的套接字等等。\n每个程序怎么操作？ ● 按照惯例，许多（但不是全部）Unix程序将这个字节序列视为ASCII文本。 ● 将它们的输入文件视为由\\n（换行符，ASCII 0x0A）字符分隔的记录列表。 ● 每条记录（即一行输入）的解析则更加模糊。 Unix工具通常通过空白或制表符将行分割成字段，但也使用CSV（逗号分隔），管道分隔和其他编码。\n今天，像Unix工具一样流畅地运行程序是一种例外，而不是规范。\n逻辑与布线相分离 Unix 怎么做输入输出： ● Unix工具的另一个特点是使用标准输入（stdin）和标准输出（stdout）。 ○ 如果你运行一个程序，而不指定任何其他的东西，标准输入来自键盘，标准输出指向屏幕。 ○ 但是，你也可以从文件输入和/或将输出重定向到文件。 ○ 管道允许你将一个进程的标准输出附加到另一个进程的标准输入（有个小内存缓冲区，而不需要将整个中间数据流写入磁盘）。 ● 将输入/输出布线与程序逻辑分开，可以将小工具组合成更大的系统。\nUnix 输入输出的缺点： ● 需要多个输入或输出的程序虽然可能，却非常棘手。 ● 你没法将程序的输出管道连接至网络连接中。 ● 如果程序直接打开文件进行读取和写入，或者将另一个程序作为子进程启动，或者打开网络连接，那么I/O的布线就取决于程序本身了。 ● 它仍然可以被配置（例如通过命令行选项），但在Shell中对输入和输出进行布线的灵活性就少了。\n透明度和实验 使Unix工具如此成功的部分原因是，它们使查看正在发生的事情变得非常容易： ● Unix命令的输入文件通常被视为不可变的。这意味着你可以随意运行命令，尝试各种命令行选项，而不会损坏输入文件。 ● 你可以在任何时候结束管道，将管道输出到less，然后查看它是否具有预期的形式。这种检查能力对调试非常有用。 ● 你可以将一个流水线阶段的输出写入文件，并将该文件用作下一阶段的输入。这使你可以重新启动后面的阶段，而无需重新运行整个管道。\n优点： ● 与关系数据库的查询优化器相比，即使Unix工具非常简单，但仍然非常有用，特别是对于实验而言。 缺点： ● Unix工具的最大局限在于它们只能在一台机器上运行 —— 而Hadoop这样的工具即应运而生\nMapReduce和分布式文件系统 MapReduce 是什么？ ● 有点像 Unix 工具，不过分布在数千台机器上。 ● 简单、易用 ● 通常不会修改输入，除了生成输出外没有任何副作用。 ● 输出文件以连续的方式一次性写入（一旦写入文件，不会修改任何现有的文件部分）。 ● 读写的是 HDFS 等分布式文件系统。 ○ 基于无共享的原则。 ○ 不需要特殊的硬件。 ○ 每台机器运行了一个守护进程，对外暴露网络服务； ○ 名为 NameNode的中央处理器跟踪哪个文件块存储在哪台机器上； ○ 为了容忍机器故障，文件块会被复制到多台机器上； ○ 可伸缩性很好：上万台机器，PB 级别存储。\nMapReduce作业执行 MapReduce 怎么运行的？ 以上文中的 Web 服务器日志分析为例。\n读取一组输入文件，并将其分解成记录（records）。在Web服务器日志示例中，每条记录都是日志中的一行（即\\n是记录分隔符）。 调用Mapper函数，从每条输入记录中提取一对键值。在前面的例子中，Mapper函数是awk \u0026lsquo;{print $7}\u0026rsquo;：它提取URL（$7）作为键，并将值留空。 按键排序所有的键值对。在日志的例子中，这由第一个sort命令完成。 调用Reducer函数遍历排序后的键值对。如果同一个键出现多次，排序使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。在前面的例子中，Reducer是由uniq -c命令实现的，该命令使用相同的键来统计相邻记录的数量。 步骤 2（Map）和步骤 4 （Reduce）需要自己编程写代码。 步骤 1 由输入格式解析器处理； 步骤 3 隐含在 MapReduce 中——因为Mapper的输出始终在送往Reducer之前进行排序。 如何自定义 Mapper 和 Reducer？ Mapper ● Mapper 会在每条输入记录上调用一次，其工作是从输入记录中提取键值。 ● 对于每个输入，它可以生成任意数量的键值对（包括None）。 ● 它不会保留从一个输入记录到下一个记录的任何状态，因此每个记录都是独立处理的。 Reducer ● MapReduce 框架拉取由 Mapper 生成的键值对，收集属于同一个键的所有值，并在这组值上迭代调用 Reducer。 ● Reducer 可以产生输出记录（例如相同URL的出现次数）。\n如果 reduce 之后还需要再排序怎么办？ ● 再编写第二个 MapReduce 作业并将第一个作业的输出用作第二个作业的输入来实现它。\n分布式执行MapReduce MapReduce 和 Unix 管道的主要区别？ ● MapReduce 在多个机器上并行执行计算，而无需编写代码来显式处理并行问题。 ● Mapper和Reducer一次只能处理一条记录；它们不需要知道它们的输入来自哪里，或者输出去往什么地方，所以框架可以处理在机器之间移动数据的复杂性。\nHadoop MapReduce作业中的数据流\n如上图\nMapper 的分区？\n● 并行化基于分区：作业的输入通常是HDFS中的一个目录，输入目录中的每个文件或文件块都被认为是一个单独的分区，可以单独处理map任务 ● 每个输入文件的大小通常是数百兆字节。 ● MapReduce调度器（图中未显示）试图在其中一台存储输入文件副本的机器上运行每个Mapper，只要该机器有足够的备用RAM和CPU资源来运行Mapper任务。 ● 这个原则被称为将计算放在数据附近：它节省了通过网络复制输入文件的开销，减少网络负载并增加局部性。\nMapper 任务的代码在运行它的机器上还不存在咋办？ ● MapReduce框架首先将代码（例如Java程序中的JAR文件）复制到适当的机器。 ● 然后启动Map任务并开始读取输入文件，一次将一条记录传入Mapper回调函数。 ● Mapper的输出由键值对组成。\nReducer 的分区？ ● 计算的Reduce端也被分区。 ● 虽然Map任务的数量由输入文件块的数量决定，但Reducer的任务的数量是由作业作者配置的（它可以不同于Map任务的数量）。 ● 为了确保具有相同键的所有键值对最终落在相同的Reducer处，框架使用键的散列值来确定哪个Reduce任务应该接收到特定的键值对。\n排序怎么做的？ ● 键值对必须进行排序，但数据集可能太大，无法在单台机器上使用常规排序算法进行排序。 ● 相反，分类是分阶段进行的。首先每个Map任务都按照Reducer对输出进行分区。每个分区都被写入Mapper程序的本地磁盘，使用的技术与我们在“SSTables与LSM树”中讨论的类似。 ● 只要当Mapper读取完输入文件，并写完排序后的输出文件，MapReduce调度器就会通知Reducer可以从该Mapper开始获取输出文件。 ● Reducer连接到每个Mapper，并下载自己相应分区的有序键值对文件。按Reducer分区，排序，从Mapper向Reducer复制分区数据，这一整个过程被称为混洗（shuffle）。（一个容易混淆的术语 —— 不像洗牌，在MapReduce中的混洗没有随机性）。\nReduce 做了什么？ ● Reduce任务从Mapper获取文件，并将它们合并在一起，并保留有序特性。 ● 因此，如果不同的Mapper生成了键相同的记录，则在Reducer的输入中，这些记录将会相邻。 ● Reducer调用时会收到一个键，和一个迭代器作为参数，迭代器会顺序地扫过所有具有该键的记录（因为在某些情况可能无法完全放入内存中）。 ● Reducer可以使用任意逻辑来处理这些记录，并且可以生成任意数量的输出记录。这些输出记录会写入分布式文件系统上的文件中（通常是在跑Reducer的机器本地磁盘上留一份，并在其他机器上留几份副本）。\nMapReduce工作流 单个MapReduce 的局限？ ● 单个MapReduce作业可以解决的问题范围很有限。 ● 以日志分析为例，单个MapReduce作业可以确定每个URL的页面浏览次数，但无法确定最常见的URL，因为这需要第二轮排序。 ● 因此将MapReduce作业链接成为工作流（workflow） 中是极为常见的\nHadoop MapReduce 怎么实现工作流？ ● Hadoop MapReduce框架对工作流没有特殊支持，所以这个链是通过目录名隐式实现的： ○ 第一个作业必须将其输出配置为HDFS中的指定目录； ○ 第二个作业必须将其输入配置为从同一个目录。 ● 从MapReduce框架的角度来看，这是两个独立的作业。 ● 被链接的MapReduce作业并没有那么像Unix命令管道（它直接将一个进程的输出作为另一个进程的输入，仅用一个很小的内存缓冲区）。 ● 它更像是一系列命令，其中每个命令的输出写入临时文件，下一个命令从临时文件中读取。 ● 这种设计有利也有弊，我们将在“物化中间状态”中讨论。\n如何处理工作流中不同作业之间的依赖？ ● 只有当作业成功完成后，批处理作业的输出才会被视为有效的（MapReduce会丢弃失败作业的部分输出）。 ● 因此，工作流中的一项作业只有在先前的作业（即生产其输入的作业）成功完成后才能开始。 ● 为了处理这些作业之间的依赖，有很多针对Hadoop的工作流调度器被开发出来，包括Oozie，Azkaban，Luigi，Airflow和Pinball ● 在维护大量批处理作业时非常有用。在构建推荐系统时，由50到100个MapReduce作业组成的工作流是常见的；大型组织中，许多不同的团队可能运行不同的作业来读取彼此的输出。\nReduce侧Join与分组 第二章讨论过数据数据模型和查询语言的Join(连接)，这里讨论它是如何实现的。\n两条记录存在关联是很常见的： ● 关系模型中的外键，文档模型中的文档引用或图模型中的边。 ● 当你需要同时访问这一关联的两侧（持有引用的记录与被引用的记录）时，join 就是必须的。\nMapReduce 可以通过索引来关联数据吗？ ● 在数据库中，如果执行只涉及少量记录的查询，数据库通常会使用索引来快速定位感兴趣的记录。如果查询涉及到join ，则可能涉及到查找多个索引。 ● 然而MapReduce没有索引的概念 —— 至少在通常意义上没有。\nMapReduce 作业怎么找到想要读的部分数据？ ● 它读取所有这些文件的全部内容；（数据库中称之为全表扫描） ● 如果你只想读取少量的记录，则全表扫描与索引查询相比，代价非常高昂。 ● 但通常是需要计算大量记录的聚合。在这种情况下，特别是如果能在多台机器上并行处理时，扫描整个输入可能是相当合理的事情。 ● 因此，我们在批处理语义中讨论链接时，一般是同时处理所有用户的数据，而非某个特定用户的数据。\n示例：用户活动事件分析 一个批处理作业中join 的典型例子。左侧是事件日志，描述登录用户在网站上做的事情（称为活动事件（activity events） 或点击流数据（clickstream data）），右侧是用户数据库。\n分析任务需要将用户活动与用户档案信息相关联：例如，如果档案包含用户的年龄或出生日期，系统就可以确定哪些页面更受哪些年龄段的用户欢迎。\n有什么简单方法实现上述任务？ ● 逐个遍历活动事件，并为每个遇到的用户ID查询用户数据库（在远程服务器上）。 ○ 缺点：性能很差，吞吐量低，可能压垮数据库。\n为什么批处理任务不用上面的方法？ ● 为了在批处理过程中实现良好的吞吐量，计算必须（尽可能）在单台机器上进行（而不是访问外部数据，如数据库）。 ● 为待处理的每条记录发起随机访问的网络请求实在是太慢了。 ● 查询远程数据库意味着批处理作业变为非确定的（nondeterministic），因为远程数据库中的数据可能会改变。\n批处理任务中，更好的实现方法是什么？ ● 更好的方法是获取用户数据库的副本（ETL，数据仓库），并将它和用户行为日志放入同一个分布式文件系统中，如 HDFS。 ● 然后用MapReduce将所有相关记录集中到同一个地方进行高效处理。\n排序合并连接 join 过程中 Mapper 的工作？ Mapper的目的是从每个输入记录中提取一对键值，在上面 hadoop的 map reduce 的情况下，这个键就是用户ID： ● 一组Mapper会扫过活动事件（提取用户ID作为键，活动事件作为值） ● 而另一组Mapper将会扫过用户数据库（提取用户ID作为键，用户的出生日期作为值）。\n过程如下所示：\njoin 过程中怎么做分区？ ● 当MapReduce框架通过键对Mapper输出进行分区，然后对键值对进行排序时，效果是具有相同ID的所有活动事件和用户记录在Reducer输入中彼此相邻。（在上图中，三个104分区到了parition 1，173 和 103 分到 partition 2） ● Map-Reduce作业甚至可以也让这些记录排序，使Reducer总能先看到来自用户数据库的记录，紧接着是按「出生日期」排序的活动事件 —— 这种技术被称为二次排序（secondary sort）。\njoin 过程中 reducer 的工作？ ● Reducer可以容易地执行实际的join 逻辑：每个用户ID都会被调用一次Reducer函数，且因为二次排序，第一个值应该是来自用户数据库的「出生日期」记录。 ● Reducer将「出生日期」存储在局部变量中，然后使用相同的用户ID遍历活动事件，输出已观看网址和观看者年龄的结果对。随后的Map-Reduce作业可以计算每个URL的查看者年龄分布，并按年龄段进行聚集。\n为什么叫做排序合并连接？ ● 由于Reducer一次处理一个特定用户ID的所有记录，因此一次只需要将一条用户记录保存在内存中，而不需要通过网络发出任何请求。 ● 这个算法被称为排序合并连接（sort-merge join），因为Mapper的输出是按键排序的，然后Reducer将来自join 两侧的有序记录列表合并在一起.\n把相关数据放在一起 为什么需要把相关数据放在一起？ ● 在排序合并join 中，Mapper和排序过程确保了所有对特定用户ID执行join 操作的必须数据都被放在同一个地方：单次调用Reducer的地方。 ● 预先排好了所有需要的数据，Reducer可以是相当简单的单线程代码，能够以高吞吐量和与低内存开销扫过这些记录。\n为什么可以看做“消息”传递？ ● Mapper将“消息”发送给Reducer。 ● 当一个Mapper发出一个「键值对」时，这个「键」的作用就像值应该传递到的目标地址。 ● 即使「键」只是一个任意的字符串（不是像IP地址和端口号那样的实际的网络地址），它表现的就像一个地址：所有具有相同键的键值对将被传递到相同的目标（一次Reducer的调用）。\nMapReduce 编程模型中用户需要考虑网络通信吗？ ● 不用 ● 使用MapReduce编程模型，能将计算的物理网络通信层面（从正确的机器获取数据）从应用逻辑中剥离出来（获取数据后执行处理）。 ● 这种分离与数据库的典型用法形成了鲜明对比，从数据库中获取数据的请求经常出现在应用代码内部。 ● 由于MapReduce处理了所有的网络通信，因此它也避免了让应用代码去担心部分故障，例如另一个节点的崩溃：MapReduce在不影响应用逻辑的情况下能透明地重试失败的任务。\n分组 除了 join(连接) 之外，还有什么“把相关数据放在一起”的方法？ ● 常见的还有：按某个键对记录分组（如SQL中的GROUP BY子句）。 ● 所有带有相同键的记录构成一个组，而下一步往往是在每个组内进行某种聚合操作。比如： ○ 统计每个组中记录的数量（例如在统计PV的例子中，在SQL中表示为COUNT(*)聚合） ○ 对某个特定字段求和（SQL中的SUM(fieldname)） ○ 按某种分级函数取出排名前k条记录。\nMapReduce实现这种「分组」操作？ ● 最简单方法是设置Mapper，以便它们生成的键值对使用所需的分组键。 ● 然后分区和排序过程将所有具有相同分区键的记录导向同一个Reducer。 ● 因此在MapReduce之上实现分组和join 看上去非常相似。\n分组还有什么应用？ ● 分组的另一个常见用途是整理特定用户会话的所有活动事件，以找出用户进行的一系列操作（称为会话化（sessionization））。 ● 例如： ○ 可以使用这种分析来确定显示新版网站的用户是否比那些显示旧版本的用户更有购买欲（A/B测试） ○ 或者计算某个营销活动是否有效。\n当有多个 web 服务器，特定用户活动事件分散在多个不同机器上怎么办？ ● 可以通过使用会话cookie，用户ID或类似的标识符作为分组键，以将特定用户的所有活动事件放在一起来实现会话化 ● 与此同时，不同用户的事件仍然散布在不同的分区中\n处理偏斜 什么是热键？ ● 如果存在与单个键关联的大量数据，则“将具有相同键的所有记录放到相同的位置”这种模式就被破坏了。 ● 这种不成比例的活动数据库记录被称为关键对象（linchpin object）【38】或热键（hot key）。\n什么是倾斜？ ● 在单个Reducer中收集与某个名人相关的所有活动（例如他们发布内容的回复）可能导致严重的偏斜（也称为热点（hot spot））—— 也就是说，一个Reducer必须比其他Reducer处理更多的记录。 ● 由于MapReduce作业只有在所有Mapper和Reducer都完成时才完成，所有后续作业必须等待最慢的Reducer才能启动。\n怎么解决数据倾斜？ ● 如果join 的输入存在热键，可以使用一些算法进行补偿。\n以 Pig 中解决数据倾斜为例： ● 例如，Pig中的偏斜连接（skewed join） 方法首先运行一个抽样作业（Sampling Job）来确定哪些键是热键。 ● join 实际执行时，Mapper会将热键的关联记录随机（相对于传统MapReduce基于键散列的确定性方法）发送到几个Reducer之一。 ● 对于另外一侧的 join 输入，与热键相关的记录需要被复制到所有处理该键的Reducer上。 ● 这种技术将处理热键的工作分散到多个Reducer上，这样可以使其更好地并行化，代价是需要将 join 另一侧的输入记录复制到多个Reducer上。 ○ 优点：将处理热键的工作分散到多个Reducer上，这样可以使其更好地并行化 ○ 缺点：代价是需要将 join 另一侧的输入记录复制到多个Reducer上。\nCrunch处理数据倾斜： ● Crunch中的分片连接（sharded join） 方法与之类似，但需要显式指定热键而不是使用抽样作业。\nHive 处理数据倾斜： ● Hive 偏斜 join 优化采取了另一种方法，它需要在表格元数据中显式指定热键，并将与这些键相关的记录单独存放，与其它文件分开。 ● 当在该表上执行 join 时，对于热键，它会使用Map端 join （请参阅下一节） ● 当按照热键进行分组并聚合时，可以将分组分两个阶段进行： ○ 第一个MapReduce阶段将记录发送到随机Reducer，以便每个Reducer只对热键的子集执行分组，为每个键输出一个更紧凑的中间聚合结果。 ○ 然后，第二个MapReduce作业将所有来自第一阶段Reducer的中间聚合结果合并为每个键一个值。\nMap侧 join 怎么理解上文是 Reducer 侧 join ： ● 上一节中的链接算法都是在 Reducer 中执行的，所以被称为 reduce 侧 join。 ● Mapper 扮演数据预处理的角色，从每个输入记录中提取键值，将键值分配给 Reducer 分区，并按键排序。 ○ 优点：不用对输入数据做任何假设：不用管属性和结构，Mapper 都可以做预处理以备 Join ○ 缺点：排序，复制到 Reducer，合并 Reducer 输入，这些操作可能开销巨大。数据可能要落盘好几次，取决于可用的内存缓冲区。\nMap 侧 Join： ● 如果你能对数据做出某些假设，就可以用 Map 侧 Join来加快速度。 ● 省掉了 Reducer 与排序的 MapReduce 作业，每个 mapper 都是简单的从分布式文件系统中读取一个输入，然后输出到文件系统，仅此而已。\n广播散列连接 广播散列连接（broadcast hash join）： ● 一个最简单场景是大数据集与小数据集连接的情况。要点在于小数据集需要足够小，以便可以将其全部加载到每个Mapper的内存中。 ● 每个 Mapper 在扫描「大数据集」时，简单地从内存散列表中查找每个『小数据集』的数据。 ● 广播：每个 join 较大输入端分区的 Mapper 都会将较小输入端数据集整个读入内存中（所以较小输入实际上“广播”到较大数据的所有分区上） ● 散列：反映了它使用一个散列表。 ● Pig, Hive, Cascading和Crunch 都支持这种 join 。 ● 此外，还可以将较小输入存储在本地磁盘中，索引在内存中。\n分区散列连接 ● 如果Map侧 join 的输入以相同的方式进行分区，则散列连接方法可以独立应用于每个分区。 ● 每个Mapper只需要从输入两端各读取一个分区就足够了。 ● 好处是每个Mapper都可以在内存散列表中少放点数据。 ● 适用场景：这种方法只有当连接两端输入有相同的分区数，且两侧的记录都是使用相同的键与相同的哈希函数做分区时才适用。如果输入是由之前执行过这种分组的MapReduce作业生成的，那么这可能是一个合理的假设。\nMap侧合并连接 ● 如果数据集以相同的方式进行分区、还基于相同的键进行排序，那么还可以用 Map 侧连接的变体。 ● 输入是否小到能放到内存不重要。 ● 因为这时候Mapper同样可以执行归并操作（通常由Reducer执行）：按键递增的顺序依次读取两个输入文件，将具有相同键的记录配对。\nMapReduce工作流与Map侧连接 影响到输出： ● 当下游作业使用MapReduce join 的输出时，Map侧连接或Reduce侧 join 的不同选择会影响输出的结构。 ● Reduce侧连接的输出是按照连接键进行分区和排序的； ● Map端连接的输出则按照与「大数据集」相同的方式进行分区和排序；\n对输入有假设： ● Map侧连接也对输入数据集的大小，有序性和分区方式做出了更多假设。 ● 你必须了解数据按哪些键做的分区和排序，以及分区数量等。\n批处理工作流的输出 一个疑问：MapReduce处理完成之后的最终结果是什么？我们最开始为什么要跑这些作业？\n在数据库查询的场景中，我们将事务处理（OLTP）与分析两种目的区分开来： ● OLTP查询通常根据键查找少量记录，使用索引，并将其呈现给用户（比如在网页上）。 ● 分析查询通常会扫描大量记录，执行分组与聚合，输出通常有着报告的形式：显示某个指标随时间变化的图表，或按照某种排位取前10项，或将一些数字细化为子类。这种报告的消费者通常是需要做出商业决策的分析师或经理。\n批处理放哪里合适？ ● 它不属于事务处理，也不是分析。 ● 它和分析比较接近，因为批处理通常会扫过输入数据集的绝大部分。 ● 但批处理过程的输出通常不是报表，而是一些其他类型的结构。\n建立搜索索引 MapReduce诞生的背景 ● Google 最初使用 MapReduce 是为其搜索引擎建立索引 ● Hadoop MapReduce 仍然是为 Lucene/Solr 构建索引的好方法\nLucene这样的全文搜索索引是如何工作的？ ● 它是一个文件（关键词字典），你可以在其中高效地查找特定关键字，并找到包含该关键字的所有文档ID列表（文章列表）。\n如何用 MapReduce 构建索引？ ● Mapper根据需要对文档集合进行分区，每个Reducer构建该分区的索引，并将索引文件写入分布式文件系统。 ● 构建这样的文档分区索引并行处理效果拔群。\n索引怎么更新？ ● 由于按关键字查询搜索索引是只读操作，因而这些索引文件一旦创建就是不可变的。 ● 如果索引的文档集合发生更改 ○ 一种选择是定期重跑整个索引工作流，并在完成后用新的索引文件批量替换以前的索引文件。 ■ 如果只有少量的文档发生了变化，这种方法的计算成本可能会很高。 ■ 优点：是索引过程很容易理解：文档进，索引出。 ○ 另一种选择是增量建立索引。如果需要索引中添加，删除或更新文档，Lucene会写新的段文件，并在后台异步合并压缩段文件。\n键值存储作为批处理输出 除了建立搜索索引之外，批处理还有什么用途？ ● 构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，图像识别）与推荐系统\n机器学习系统的批处理输出到哪里？ ● 通常是某种数据库，例如可以通过给定 ID 查询其推荐好友的数据库\n这些数据库怎么用？ ● 通常需要被 Web 服务所查询。\n批处理过程的输出到Web应用可以查询的数据库中呢？ ● 一条条插入到数据库\n为什么一条条插入数据库不是好主意呢？ ● 每条记录发起一个网络请求，比批处理的吞吐慢了几个量级 ● 数据库可能被压垮，导致线上故障 ● 当批任务重试的时候，得操心数据库的情况\n如果不一条条插入数据库，还有什么好主意？ ● 在批处理作业内创建一个全新的数据库，并将其作为文件写入分布式文件系统中作业的输出目录，就像上节中的搜索索引一样。 ● 这些数据文件一旦写入就是不可变的，可以批量加载到处理只读查询的服务器中。 ● 不少键值存储都支持在MapReduce作业中构建数据库文件，包括Voldemort ，Terrapin ，ElephantDB 和 HBase 批量加载。\n这么做的优点？ ● 因为文件只读（不再修改），所以数据结构很简单，不用预写式日志（WAL） ● 在Voldemort加载数据时，使用旧文件继续提供服务，当加载完成自动将查询切换到新文件。如果出现问题，则回滚。\n批处理输出的哲学 Unix哲学鼓励以显式指明数据流的方式进行实验：程序读取输入并写入输出。 ● 输入保持不变；没有副作用；可以随意改动或调试；\nMapReduce作业的输出处理遵循同样的原理。 ● 如果代码错误或者输出损坏，可以回滚代码，然后重跑。输出就会被修正。 ○ 数据库没有这个属性：回滚代码无法修复数据库中的数据 ○ 能够从错误代码中恢复的概念被称为人类容错（human fault tolerance） ● 由于回滚容易，可以容忍错误。这种最小化不可逆性（minimizing irreversibility） 的原则有利于敏捷软件开发。 ● 如果Map或Reduce任务失败，MapReduce框架将自动重新调度，并在同样的输入上再次运行它。 ○ 如果是代码错误，那么几次重试后将失败； ○ 如果是临时问题导致的，那么故障被容忍； ○ 由于输入不可变，所以重试是安全的。 ● 同一组文件可用作各种不同作业的输入 ● 与Unix工具类似，MapReduce作业将逻辑与布线（配置输入和输出目录）分离，这使得关注点分离，可以重用代码：一个团队可以专注实现一个做好一件事的作业；而其他团队可以决定何时何地运行这项作业。\nUnix 与 Hadoop 的不同： ● 大多数 Unix 工具都假设输入输出是无类型文本文件，所以它们必须做大量的输入解析工作（本章开头的日志分析示例使用 {print $7} 来提取URL）。 ● 在 Hadoop 上可以通过使用更结构化的文件格式消除一些低价值的语法转换：比如 Avro（请参阅“Avro”）和 Parquet（请参阅“列存储”）经常使用，因为它们提供了基于模式的高效编码，并允许模式随时间推移而演进（见第四章）。\nHadoop与分布式数据库的对比 MapReduce 与 大规模并行处理（MPP， massively parallel processing）的区别？ ● MPP数据库专注于在一组机器上并行执行分析SQL查询 ● 而MapReduce和分布式文件系统的组合则更像是一个可以运行任意程序的通用操作系统。\n存储多样性 分布式文件系统与数据库的区别？ ● 数据库要求你根据特定的模型（例如关系或文档）来构造数据 ● 而分布式文件系统中的文件只是字节序列，可以使用任何数据模型和编码来编写。\n使用原始格式保存数据的优点？ ● 实践经验表明，简单地使数据快速可用 —— 即使它很古怪，难以使用，使用原始格式 —— 也通常要比事先决定理想数据模型要更有价值 ● 以原始形式收集数据，稍后再操心模式的设计，能使数据收集速度加快（有时被称为“数据湖（data lake）”或“企业数据中心（enterprise data hub）” ● 转移了解释数据的负担：数据的解释成为消费者的问题（读时模式），有利于跨团队合作。 ● 这种方法被称为寿司原则（sushi principle）：“原始数据更好”\n处理模型的多样性 MPP 数据库和 MapReduce 在处理模型上的区别？ ● MPP 数据库是单体的，紧密集成的软件，负责磁盘上的存储布局，查询计划，调度和执行。 ○ 优点：可以针对数据库特定调优；可以用 SQL 查询语言表达查询，无需代码。 ○ 缺点：并非所有类型的处理都可以合理地表达为SQL查询（如索引、推荐系统）。 ● MapReduce 能够轻松地在大型数据集上运行自己的代码。 ○ 优点： ■ 语法上：可以建立一个SQL查询执行引擎，如 Hive 项目；也可以编写代码；还可以编写其他模型； ■ 运行上：分布式。\n针对频繁故障设计 MPP 数据库和 MapReduce 在处理故障上的区别？ ● 与在线系统相比，批处理系统对故障不敏感。 ● MPP 数据库： ○ 如果有一个节点执行查询时失败，MPP 数据库会中止整个查询，并让用户重试。 ○ 查询通常在几分钟内，因此这种重试可以接受。 ○ 倾向于内存中保留尽可能多的数据，以避免磁盘读取的开销 ● MapReduce： ○ 可以容忍单个Map或Reduce任务的失败，而不会影响作业的整体，通过以单个任务的粒度重试工作。 ○ 它也会非常急切地将数据写入磁盘，一方面是为了容错，另一部分是因为假设数据集太大而不能适应内存。\nMapReduce 在处理故障上的优点？ ● 更适合大的作业（任务多，易失败） ● 不是因为硬件很不可靠，而是因为任意终止进程的自由有利于提高计算集群中的资源利用率。 ○ 场景：如果优先级较高的任务需要更多的资源，则可以终止（抢占）同一台机器上较低优先级的任务以释放资源。从而提高资源利用率。 ○ 在谷歌，运行一个小时的MapReduce任务有大约有5％的风险被终止，为了给更高优先级的进程挪地方。\nMapReduce之后 MapReduce 是简单，但导致复杂任务从头编写任务繁重。 很多高级编程模型被创造，如 Pig，Hive，Cascading，Crunch； MapReuce 是非常稳健，但其他工具可能快上几个量级。\n物化中间状态 什么是物化中间状态？ ● 每个MapReduce作业都独立于其他任何作业，跨团队合作时，分布式系统的文件只是简单的中间状态（intermediate state） ● 将这个中间状态写入文件的过程称为物化（materialization）。\nMapReduce完全物化中间状态与 Unix 管道的比较？ ● Unix管道将一个命令的输出与另一个命令的输入连接起来。管道并没有完全物化中间状态，而是只使用一个小的内存缓冲区，将输出增量地流（stream） 向输入。 ● MapReduce完全物化中间状态的不足： ○ 慢：MapReduce作业只有在前驱作业（生成其输入）中的所有任务都完成时才能启动（慢节点拖慢整个工作流程），而由Unix管道连接的进程会同时启动，输出一旦生成就会被消费。 ○ Mapper通常是多余的：它们仅仅是读取刚刚由Reducer写入的同样文件，为下一个阶段的分区和排序做准备。 ■ 在许多情况下，Mapper代码可能是前驱Reducer的一部分：如果Reducer和Mapper的输出有着相同的分区与排序方式，那么Reducer就可以直接串在一起，而不用与Mapper相互交织。 ○ 复制很浪费：将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点，对这些临时数据这么搞就比较过分了。\n数据流引擎 为了解决上述问题，开发了数据流引擎：Spark, Tez, Flink。\n数据流引擎与 MapReduce 的区别？ ● 数据流引擎的共同点：把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。 ● 像MapReduce一样，它们在一条线上通过反复调用用户定义的函数来一次处理一条记录，它们通过输入分区来并行化载荷，它们通过网络将一个函数的输出复制到另一个函数的输入。 ● 与MapReduce不同，这些函数不需要严格扮演交织的Map与Reduce的角色，而是可以以更灵活的方式进行组合。我们称这些函数为算子（operators）\n数据流引擎提供了哪些不同的选项来将一个算子的输出连接到另一个算子的输入？ ● 一种选项是对记录按键重新分区并排序，就像在MapReduce的混洗阶段一样。 ● 另一种可能是接受多个输入，并以相同的方式进行分区，但跳过排序。当记录的分区重要但顺序无关紧要时，这省去了分区散列连接的工作，因为构建散列表还是会把顺序随机打乱。 ● 对于广播散列连接，可以将一个算子的输出，发送到连接算子的所有分区。\n与MapReduce模型相比，数据流引擎有什么优点？ ● 排序等昂贵的工作只需要在实际需要的地方执行，而不是默认地在每个Map和Reduce阶段之间出现。 ● 没有不必要的Map任务，因为Mapper所做的工作通常可以合并到前面的Reduce算子中（因为Mapper不会更改数据集的分区）。 ● 调度程序能够利用局部性进行优化，比如消费数据任务与生成数据的任务放在相同的机器上。 ● 算子间的中间状态足以保存在内存中或写入本地磁盘，这比写入HDFS需要更少的I/O（必须将其复制到多台机器，并将每个副本写入磁盘）。 ● 算子可以在输入就绪后立即开始执行；后续阶段无需等待前驱阶段整个完成后再开始。 ● 与MapReduce（为每个任务启动一个新的JVM）相比，现有Java虚拟机（JVM）进程可以重用来运行新算子，从而减少启动开销。\n使用数据流引擎执行与MapReduce工作流同样的计算，通常执行速度要明显快得多。\n容错 完全物化中间状态至 HDFS 的优点？ ● 具有持久性，这使得MapReduce中的容错相当容易，任务失败时可以在另一台机器上重启。\nSpark，Flink和Tez没有将中间状态写入HDFS，怎么容错？ ● 它们采取了不同的方法来容错：如果一台机器发生故障，并且该机器上的中间状态丢失，则它会从其他仍然可用的数据重新计算（在可行的情况下是先前的中间状态，要么就只能是原始输入数据，通常在HDFS上）。 ● 为了实现这种重新计算，框架必须跟踪一个给定的数据是如何计算的 —— 使用了哪些输入分区？应用了哪些算子？ Spark使用弹性分布式数据集（RDD，Resilient Distributed Dataset） 的抽象来跟踪数据的谱系，而Flink对算子状态存档，允许恢复运行在执行过程中遇到错误的算子。\n重新计算数据时，计算有不确定行怎么办？ ● 在重新计算数据时，重要的是要知道计算是否是确定性的（相同的输入数据，算子是否始终有相同的输出？）。对于不确定性算子来说，解决方案通常是杀死下游算子，然后再重跑新数据。 ● 为了避免这种级联故障，最好让算子具有确定性。 ○ 但是非确定性行为，很容易溜进来。比如哈希表的迭代、随机数。 ○ 最好消除掉上述行为，比如随机数设定固定的种子。\n重新计算一定是最佳选择吗？ ● 不是 ● 如果中间状态比原始数据小得多，或者计算量大，那么物化中间状态更好。\n关于物化的讨论 流引擎的输入和输出与物化。 ● 排序算子必须消费全部的输入后才能输出，因子需要排序的算子都需要至少暂时累积状态。 ● 使用数据流引擎时，HDFS 上的物化数据集通常仍是作业的输入和输出。 ● 比起 MapReduce 的改进是，不用自己把中间状态写入文件了。\n图与迭代处理 批处理中为什么会处理图？ ● 目标是在整个图上执行某种离线处理或分析 ● 这种需求经常出现在机器学习应用（如推荐引擎）或排序系统中。如，PageRank。\nSpark, Flink 等流处理引擎，把算子作为有向无环图（DAG）的一部分安排在作业中。 而图处理中，数据本身具有图的性质。\n许多图算法是通过 BFS/DFS 实现的，MapReduce 实现它很低效，因为 MapReduce 是一条条处理的。\nPregel处理模型 针对图批处理的优化 —— 批量同步并行（BSP，Bulk Synchronous Parallel） 计算模型已经开始流行起来。 ● 其中，Apache Giraph ，Spark的GraphX API和Flink的Gelly API 实现了它。 ● 它也被称为Pregel模型，因为Google的Pregel论文推广了这种处理图的方法。\nPregel 是怎么处理图的？（每个顶点是一个处理） ● 在MapReduce中，Mapper在概念上向Reducer的特定调用“发送消息”，因为框架将所有具有相同键的Mapper输出集中在一起。 ● Pregel背后有一个类似的想法：一个顶点可以向另一个顶点“发送消息”，通常这些消息是沿着图的边发送的。 ● 在每次迭代中，为每个顶点调用一个函数，将所有发送给它的消息传递给它 —— 就像调用Reducer一样。 ● 与MapReduce的不同之处在于，在Pregel模型中，顶点在一次迭代到下一次迭代的过程中会记住它的状态，所以这个函数只需要处理新的传入消息。如果图的某个部分没有被发送消息，那里就不需要做任何工作。\n容错 Pregel作业怎么容错？ ● 消息批处理，且等待通信的次数减少了；每次迭代中发送的消息处理完成才能处理下一轮迭代。 ● 网络丢失、重复、延迟消息时，Pregel 能保证消息在其目标顶点恰好处理一次。 ● 迭代结束时，定期存档所有顶点的状态，持久化存储。\n并行执行 ● 图的分区取决于框架——比如顶点运行在哪台机器上，怎么通过网络通信。 ○ 理想情况下，大量通信的顶点最好放在同一台机器上。 ○ 实践上很难做到，因为图通常按照任意分配的 ID 分区。 ● 图通常有跨机器的额外开销，中间状态（节点之间发送的消息）往往比原始图大。网络发送消息的开销，会显著拖慢分布式图算法的速度。 ○ 如果图能放在单机内存中处理，单机算法很可能超过分布式处理。 ○ 分布式处理图的并行算法是一个进行中的研究领域。\n高级API和语言 目前大规模处理的能力已经具备，在研究的是改进编程模型，提高处理效率，扩大这些技术可以解决的问题集。 ● Hive, Pig, Spark, Flink 等都有自己的高级数据流 API，很方便简单高效。\n向声明式查询语言的转变 ● MapReduce 可以自由执行任意代码，但是用户自定义的 UDF 使用起来不方便。 ● 数据流处理引擎发现还是声明式（类 SQL）语言更好，因为内部可以做 join 的优化，列存储，向量化执行等。 ● 批处理框架越来越像 MPP 数据库了（性能也可以媲美）。\n专业化的不同领域 ● 传统上，MPP数据库满足了商业智能分析和业务报表的需求 ● 而现在，随着批处理系统获得各种内置功能以及高级声明式算子，且随着MPP数据库变得更加灵活和易于编程，两者开始看起来相似了：最终，它们都只是存储和处理数据的系统。\n本章小结 输入输出 ● 在Unix世界中，允许程序与程序组合的统一接口是文件与管道； ● 在MapReduce中，该接口是一个分布式文件系统。 ● 数据流引擎添加了自己的管道式数据传输机制，以避免将中间状态物化至分布式文件系统，但作业的初始输入和最终输出通常仍是HDFS。\n分布式批处理框架需要解决的两个主要问题是： 分区 ● 在MapReduce中，Mapper根据输入文件块进行分区。Mapper的输出被重新分区、排序并合并到可配置数量的Reducer分区中。这一过程的目的是把所有的相关数据（例如带有相同键的所有记录）都放在同一个地方。 ● 后MapReduce时代的数据流引擎若非必要会尽量避免排序，但它们也采取了大致类似的分区方法。 容错 ● MapReduce经常写入磁盘，这使得从单个失败的任务恢复很轻松，无需重新启动整个作业，但在无故障的情况下减慢了执行速度。 ● 数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态，这意味着如果节点发生故障，则需要重算更多的数据。 ● 确定性算子减少了需要重算的数据量。\n讨论了几种MapReduce的连接算法： 排序合并连接 每个参与连接的输入都通过一个提取连接键的Mapper。通过分区、排序和合并，具有相同键的所有记录最终都会进入相同的Reducer调用。这个函数能输出连接好的记录。 广播散列连接 两个连接输入之一很小，所以它并没有分区，而且能被完全加载进一个哈希表中。因此，你可以为连接输入大端的每个分区启动一个Mapper，将输入小端的散列表加载到每个Mapper中，然后扫描大端，一次一条记录，并为每条记录查询散列表。 分区散列连接 如果两个连接输入以相同的方式分区（使用相同的键，相同的散列函数和相同数量的分区），则可以独立地对每个分区应用散列表方法。\n批处理作业的显著特点是，它读取一些输入数据并产生一些输出数据，但不修改输入—— 换句话说，输出是从输入衍生出的。最关键的是，输入数据是有界的（bounded）：它有一个已知的，固定的大小（例如，它包含一些时间点的日志文件或数据库内容的快照）。因为它是有界的，一个作业知道自己什么时候完成了整个输入的读取，所以一个工作在做完后，最终总是会完成的。\n","permalink":"https://csqread.top/posts/tech/ddia/","summary":"第一章：可靠性，可扩展性，可维护性 1.1 关于数据系统的思考 单个工具已经不能满足应用系统的需求，总体工作被拆分成一系列能被单个工具高效完成的任务，","title":"DDIA"},{"content":"春节在家，我和胡小蕊约定每人读完一本书，我们在家里的书架上翻找。因为我在上海正在看米兰-昆德拉的《身份》，所以找到了这本《不能承受的生命之轻》来读。这本书是从胡小蕊家带过来的，我并没有买这本书。书页都已经泛黄，看起来是被翻过很多遍似的。这本书可能是高中生喜欢用来写作文摘抄句子材料的书。但是我高中的时候并没有接触到这本书，也不知道米兰昆德拉。\n通过书名顾名思义，我一开始以为这是一本将哲学的书，但是翻了几页之后，发现它在讲爱情和性，前面看的一直很混乱，不知道他的主题思想是什么，一直没有头绪的往下看。就像《苏菲的世界》，我一开始以为是一本小说，但是他实际上是在将西方哲学史通过小说的方式娓娓道来。所以我猜测这本书应该也是要通过一个故事来说明一些哲学道理，所以我并没有浮躁，而是继续看下去。\n《不能承受的生命之轻》是昆德拉小说中最为读者熟悉，为作家赢得声誉最多的一部小说，80年代在中国出版至今，一直被翻译成《生命中不能承受之轻》，直到前几年才有了现在的这个书名，虽然只是一个语序的变化，却使得书名和主题更为贴近。然而即使是改动后的译名，仍然弱化了原名的玄意。昆德拉在一次访谈中说：“许多朋友劝我放弃《不能承受的存在之轻》（《The Unbearable Lightness of Being》）这个书名，难道我就不能至少删去“存在”(Being)一词吗？译者在碰到这个词时，都倾向于用更朴实些的表达予以替换：‘生存’(existence)，‘生活’(life),‘状况’(condition)等等。“存在并非一个具体物，因此，昆德拉认为，哈姆雷特说的”to be or not to be”绝非“活着，还是死去”的问题，而是一个形而上的追问。所以，《不能承受的生命之轻》所要探讨的实质上是“不能承受的存在之轻”。\n存在之轻与存在之重 而说到存在的问题，就可以联想到笛卡尔提出的我思故我在的哲学理论，即为我思考，所以我存在， 确定了“我存在”，笛卡尔想要弄清楚“我”究竟是什么？他考虑以前有关“我”的两种看法。第一种是自己是“有脸、手、胳臂，以及由骨头和肉组合成的这么一架整套机器，即身体。”第二种是自己具有“吃饭、走路、感觉、思维”的行动，他将这些行动归为灵魂部分。身体具有物体性，物体性在笛卡尔这的定义是：有形状；占据空间；能通过触觉、视觉、听觉、味觉、嗅觉感觉到；还能以若干方式被移动。而灵魂所具有的“自动、感觉、思维”不是物体性的。很显然，具有物体性的身体，是有由魔鬼构造出来的幻想的可能性。因而这些东西是不属于之前认识到的“我”。“那么灵魂部分是否有属于“我”的呢？他考察了“吃饭、走路、感觉”三个属性，发现这些属性也不能离开身体。所以唯一属于“我”的只有思维了。笛卡尔明白了“我”是一个思维的东西，除此之外，没有其他。\n尼采认为，我们的世界是“永恒轮回”的。我们生命的每一秒都由无数次的重复。我们的生活是能够被预演的，有朝一日，我们的生活会按照我们经历过的方式再现，而前者中反复还将无限重复下去。如果世界果真如此，我们就会向耶稣一样被钉在永恒色十字架上，无法承受的重负将会沉沉的压在每一个人的身上。然而，这个世界存在的基础恰恰是轮回的不存在，生活无法预演，我们既不能把它与我们以前的生活相比较，也无法使他完美之后再来度过，生命之流只能在偶然性的大地上泛滥，人们肆意的生活，获得了漂浮在半空中的快感，可是，重就真的悲惨，轻就真的美丽吗？\n书中的托马斯正是这一问题的代询人。他是一个离异多年的外科医生，拥有众多的情人，生活风流而快活。然而特里莎的闯入打破了他的自由，托马斯一直在爱恋特里莎和追求自由之间徘徊选择。特雷莎之于他，既非情人，也非妻子，而是一个“被放在树脂深覆的篮子里，顺水漂到他的床第之岸的婴儿。离婚以后的托马斯是愉快自在的，婚姻对他来说是一种责任的束缚，阻碍了他体会生命的快感，在无数的”性友谊“中，他获得了美好的生命之轻。特雷莎无疑是这种生活的终结者，她紧紧握住托马斯的手使他感到了久违的生命的责任并体会到了其中的美好，可是他又不愿意放弃多年来的“自由”。对于托马斯来说，独居还是与特雷莎结合，并不是一个简单的爱情问题，而是关涉到他对存在的可能性的理解。一向轻松的他在六个偶然事件的推动下，选择了“非如此不可”。\n七年之后特雷莎的出走，将托马斯重又置于自由之身，使其身上的重负突然间释放，甚至感到悲伤过后的美好，托马斯嗅到了温馨的生命之轻。可是，随之而来的沉重却将他彻底击倒，他已经学会了感受别人的痛苦，他终于明白，自己再也不可能回到从前虚无缥缈的生命了。他回到了布拉格，追回了特雷莎，也追回了存在的重量。\n轻重选择的对立与两难，构成了人类的一个基本存在境况，我们每个人的生活，都可以在这个哲学命题上找到印证，它与善恶无关，究竟是选择青海是选择重，昆德拉并没有给出明确的答案，他只是提出了这个问题并给与了阐释。在一个极限悖缪的时代，轻与重的界限是模糊不清的，甚至是不存在的，追求意义，选择承担，并不一定就能收到预期的沉重感，反而常常导致不能承受的生命之轻，但是，这轻松之中不也包含着生命的沉重吗？\n政治与媚俗 “媚俗”（Kithcs)是昆德拉作品中的响词，在一次与作家埃尔格雷勃里的谈话中，昆德拉将“Kithcs”阐释为“已讲过一千次的美”，“意味着故作多情的集体谎言”，在昆德拉的笔下，媚俗已并非对每一类任何某个特定情景的描绘，也并非仅仅限于艺术，它已成了政治，社会，文化的一个基本特征，成了人类共同生存状态的一个指称。\n西方批评家普遍认为，媚俗之于昆德拉，已经不单单是一个道德概念，而是一个审美范畴。昆德拉认为媚俗起源于“无条件认可生存”的美学理想。媚俗的人，指定人类生存中一个基本不能接受的范围，并排斥来自这个范围内的一切比如大粪（shit），这个每天与人们生活息息相关的生理现象，却被很多人有意地回避，人们避免谈论它以及和它有关的一切。《不能承受的生命之轻》第六章《伟大的进军》就是一篇讨伐媚俗的檄文，它的理论首先是从“粪便”开始的，昆德拉举了斯大林之子雅可夫的例子，雅可夫在二战期间被德国人俘虏，和一群英国军官关在一起，共用一个厕所。英国人不满他将厕所搞得又臭又乱，诉诸于集中营的德国军官。然而，德国长官拒绝讨论粪便的问题，雅可夫备感羞辱，以扑向电网的自戕方式来表达自己的抗议。在昆德拉看来，人对粪便的厌恶正是一种基本的媚俗。媚俗是人类生存的一个基本情景，它无处不在，不同的媚俗有着不同的内在含义和批判向度，若果说美学媚俗意指英和伤感类作品的低级艺术情趣，那么政治媚俗则只对既定秩序和既定思想的盲从，文化媚俗则指对多数的，流动的，大众的价值观念的认同，人类学媚俗则指人类在无条件的认同生命存在的前提下表现出的乐观盲从和拒绝思考的态度。“媚俗是存在于忘却间的中途停歇站”，因为媚俗，生命在本真与非本真之间徘徊不定，人的自由存在成了值得怀疑的东西，事物失去最初的一面，流向难以把握的虚空。\n政治，是昆德拉小说中人物的基本生存背景。政治媚俗，则又是昆德拉批判的一个重点，他自己亲身经历的政治迫害使他对这个问题有了更深刻的理解。昆德拉说：“政治并不产生媚俗，但它需要媚俗。任何政治运动都以媚俗，以迷惑他人的愿望为基础。”《不能承受的生命之轻》中，美国参议院对孩子的微笑与布拉格广场检阅台上当权者面对游行者的挥手都是媚俗。“媚俗是所有政客的美学理想，也是所有政客党派和政治活动的美学理想。”\n就比如说，政客会抓紧一切可以媚俗的机会，昆德拉书中的美国政客对孩子们微笑又或者是历害国各个领导人掀开老百姓的锅盖。这是政客的美学理想，而在我们普通人看来是却充满了作秀和虚伪。\n托马斯和其情人萨宾娜都是媚俗的自觉抵制者。托马斯，一个用外科手术的思维来对待人生的一生，他的生存目的就是要反抗从众。对于托马斯来说，真正的困难不是抵制那个“非如此不可”，托马斯逃离了第一次婚姻，逃离处于专制统治下的祖国，都说明了这一点，真正难的是抵抗本身，在媚俗的集权统治王国里，左右的答案都是预先给定的，对任何问题都有效。心灵的专政即是最高统治，所以昆德拉又说，媚俗的死敌是“爱提问题的人”，一个问题就像一把刀，会划破舞台的布景，让我们看到藏在背后的东西。同时，媚俗也极有可能成为一个陷阱，对媚俗的抵抗也可能成为媚俗的一部分。对于托马斯来说，当在呼吁当局释放政治犯的生命上千字也称为“非如此不可”的事情的时候，抵抗本身也成了一种媚俗；对于萨宾娜来说，当她的绘画被宣传为反共作品时，她便深深感到了西方世界对她处于深重集权灾难中的祖国的怜悯，然而这种怜悯也是一种媚俗，一场西方建立在“博爱”基础上的政治秀。于是，在众人“同情”的目光中，萨宾娜愤然离场。\n和许多小说家不同，昆德拉的小说直指现代社会人类生存的困境——以怎样的方式存在？托马斯，特里莎，萨宾娜以及弗兰茨都只是以不同方式存在的个体，昆德拉只提出问题，不回答问题，在无法重演的过去和无法预定的未来，我们只能在黑暗中摸索着前进，去寻找属于自己的价值光亮。\n","permalink":"https://csqread.top/posts/read/%E8%AF%BB%E7%B1%B3%E5%85%B0-%E6%98%86%E5%BE%B7%E6%8B%89%E4%B8%8D%E8%83%BD%E6%89%BF%E5%8F%97%E7%9A%84%E7%94%9F%E5%91%BD%E4%B9%8B%E8%BD%BB%E6%9C%89%E6%84%9F/","summary":"春节在家，我和胡小蕊约定每人读完一本书，我们在家里的书架上翻找。因为我在上海正在看米兰-昆德拉的《身份》，所以找到了这本《不能承受的生命之轻","title":"读米兰 昆德拉《不能承受的生命之轻》有感"},{"content":"第十章：批处理 本书的前九章，讨论的都是请求、查询，以及相应的响应和结果。是在线系统，关注响应时间。 三种不同类型的系统： 服务（在线系统） 处理客户的请求或指令。衡量指标：响应时间，可用性。 批处理系统（离线系统） 跑一个作业，处理大量的输入数据，定时运行。衡量指标：吞吐量。 流处理系统（准实时系统） 介于在线系统和离线系统之间。消费输入并产生输出（不需要响应请求），在事件发生不久就对事件进行操作。\n本章讨论批处理系统。\n使用Unix工具的批处理 从一个例子开始。 Web 服务器，每次处理请求，在日志中附加一行。使用nginx默认的访问日志格式。\n1 2 3 216.58.210.78 - - [27/Feb/2015:17:55:11 +0000] \u0026#34;GET /css/typography.css HTTP/1.1\u0026#34; 200 3377 \u0026#34;http://martin.kleppmann.com/\u0026#34; \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115 Safari/537.36\u0026#34; 1 2 $remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; $status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#34;$http_user_agent\u0026#34; 简单日志分析 想在你的网站上找到五个最受欢迎的网页：\n1 2 3 4 5 6 cat /var/log/nginx/access.log | #1 awk \u0026#39;{print $7}\u0026#39; | #2 sort | #3 uniq -c | #4 sort -r -n | #5 head -n 5 #6 输出结果：\n1 2 3 4 5 4189 /favicon.ico 3631 /2013/05/24/improving-security-of-ssh-private-keys.html 2124 /2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html 1369 / 915 /css/typography.css 特点：简单且强大。几分钟内完成许多数据分析，性能非常好。\n命令链与自定义程序 除了上述的 Unix 命令链。也可以用程序实现，例如在Ruby中：\n1 2 3 4 5 6 7 8 9 10 counts = Hash.new(0) # 1 File.open(\u0026#39;/var/log/nginx/access.log\u0026#39;) do |file| file.each do |line| url = line.split[6] # 2 counts[url] += 1 # 3 end end top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5] # 4 top5.each{|count, url| puts \u0026#34;#{count} #{url}\u0026#34; } # 5 特点：不简洁，但可读性强。性能较差。\n排序 VS 内存中的聚合 上述两种做法的区别\nRuby 脚本在内存中保存了 URL 的哈希表，保存 URL 和其出现的次数。 Unix 管道没有哈希表，依赖排序。 哪个好？\n工作集较小时，内存散列表表现良好； 如果作业的工作集大于可用内存，则排序的方法优点是可以高效地使用磁盘。 ○ GNU Coreutils（Linux）中的sort程序通过溢出至磁盘的方式来自动应对大于内存的数据集，并能同时使用多个CPU核进行并行排序。 ○ 瓶颈可能是从磁盘读取输入文件的速度。 Unix哲学 Unix管道的发明者道格·麦克罗伊（Doug McIlroy）在1964年说：让数据像水管一样流动。\n让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件时，即使是操作系统，也让它们能够尽早地被试用，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。 这种方法 —— 自动化，快速原型设计，增量式迭代，对实验友好，将大型项目分解成可管理的块 —— 听起来非常像今天的敏捷开发和DevOps运动。奇怪的是，四十年来变化不大。 Unix 怎么实现命令的可组合性？\n统一的接口 为什么要统一的接口？ ● 一个程序的输出作为另外一个程序的输入，那么必然要统一。\n怎么实现统一的接口？\n● 在Unix中，这种接口是一个文件（file）（更准确地说，是一个文件描述符）。 ● 一个文件只是一串有序的字节序列。 ● 这是一个非常简单的接口，所以可以使用相同的接口来表示许多不同的东西： ○ 文件系统上的真实文件， ○ 另一个进程（Unix套接字，stdin，stdout）的通信通道 ○ 设备驱动程序（比如/dev/audio或/dev/lp0） ○ 表示TCP连接的套接字等等。\n每个程序怎么操作？ ● 按照惯例，许多（但不是全部）Unix程序将这个字节序列视为ASCII文本。 ● 将它们的输入文件视为由\\n（换行符，ASCII 0x0A）字符分隔的记录列表。 ● 每条记录（即一行输入）的解析则更加模糊。 Unix工具通常通过空白或制表符将行分割成字段，但也使用CSV（逗号分隔），管道分隔和其他编码。\n今天，像Unix工具一样流畅地运行程序是一种例外，而不是规范。\n逻辑与布线相分离 Unix 怎么做输入输出： ● Unix工具的另一个特点是使用标准输入（stdin）和标准输出（stdout）。 ○ 如果你运行一个程序，而不指定任何其他的东西，标准输入来自键盘，标准输出指向屏幕。 ○ 但是，你也可以从文件输入和/或将输出重定向到文件。 ○ 管道允许你将一个进程的标准输出附加到另一个进程的标准输入（有个小内存缓冲区，而不需要将整个中间数据流写入磁盘）。 ● 将输入/输出布线与程序逻辑分开，可以将小工具组合成更大的系统。\nUnix 输入输出的缺点： ● 需要多个输入或输出的程序虽然可能，却非常棘手。 ● 你没法将程序的输出管道连接至网络连接中。 ● 如果程序直接打开文件进行读取和写入，或者将另一个程序作为子进程启动，或者打开网络连接，那么I/O的布线就取决于程序本身了。 ● 它仍然可以被配置（例如通过命令行选项），但在Shell中对输入和输出进行布线的灵活性就少了。\n透明度和实验 使Unix工具如此成功的部分原因是，它们使查看正在发生的事情变得非常容易： ● Unix命令的输入文件通常被视为不可变的。这意味着你可以随意运行命令，尝试各种命令行选项，而不会损坏输入文件。 ● 你可以在任何时候结束管道，将管道输出到less，然后查看它是否具有预期的形式。这种检查能力对调试非常有用。 ● 你可以将一个流水线阶段的输出写入文件，并将该文件用作下一阶段的输入。这使你可以重新启动后面的阶段，而无需重新运行整个管道。\n优点： ● 与关系数据库的查询优化器相比，即使Unix工具非常简单，但仍然非常有用，特别是对于实验而言。 缺点： ● Unix工具的最大局限在于它们只能在一台机器上运行 —— 而Hadoop这样的工具即应运而生\nMapReduce和分布式文件系统 MapReduce 是什么？ ● 有点像 Unix 工具，不过分布在数千台机器上。 ● 简单、易用 ● 通常不会修改输入，除了生成输出外没有任何副作用。 ● 输出文件以连续的方式一次性写入（一旦写入文件，不会修改任何现有的文件部分）。 ● 读写的是 HDFS 等分布式文件系统。 ○ 基于无共享的原则。 ○ 不需要特殊的硬件。 ○ 每台机器运行了一个守护进程，对外暴露网络服务； ○ 名为 NameNode的中央处理器跟踪哪个文件块存储在哪台机器上； ○ 为了容忍机器故障，文件块会被复制到多台机器上； ○ 可伸缩性很好：上万台机器，PB 级别存储。\nMapReduce作业执行 MapReduce 怎么运行的？ 以上文中的 Web 服务器日志分析为例。\n读取一组输入文件，并将其分解成记录（records）。在Web服务器日志示例中，每条记录都是日志中的一行（即\\n是记录分隔符）。 调用Mapper函数，从每条输入记录中提取一对键值。在前面的例子中，Mapper函数是awk \u0026lsquo;{print $7}\u0026rsquo;：它提取URL（$7）作为键，并将值留空。 按键排序所有的键值对。在日志的例子中，这由第一个sort命令完成。 调用Reducer函数遍历排序后的键值对。如果同一个键出现多次，排序使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。在前面的例子中，Reducer是由uniq -c命令实现的，该命令使用相同的键来统计相邻记录的数量。 步骤 2（Map）和步骤 4 （Reduce）需要自己编程写代码。 步骤 1 由输入格式解析器处理； 步骤 3 隐含在 MapReduce 中——因为Mapper的输出始终在送往Reducer之前进行排序。 如何自定义 Mapper 和 Reducer？ Mapper ● Mapper 会在每条输入记录上调用一次，其工作是从输入记录中提取键值。 ● 对于每个输入，它可以生成任意数量的键值对（包括None）。 ● 它不会保留从一个输入记录到下一个记录的任何状态，因此每个记录都是独立处理的。 Reducer ● MapReduce 框架拉取由 Mapper 生成的键值对，收集属于同一个键的所有值，并在这组值上迭代调用 Reducer。 ● Reducer 可以产生输出记录（例如相同URL的出现次数）。\n如果 reduce 之后还需要再排序怎么办？ ● 再编写第二个 MapReduce 作业并将第一个作业的输出用作第二个作业的输入来实现它。\n分布式执行MapReduce MapReduce 和 Unix 管道的主要区别？ ● MapReduce 在多个机器上并行执行计算，而无需编写代码来显式处理并行问题。 ● Mapper和Reducer一次只能处理一条记录；它们不需要知道它们的输入来自哪里，或者输出去往什么地方，所以框架可以处理在机器之间移动数据的复杂性。\nHadoop MapReduce作业中的数据流\n如上图\nMapper 的分区？\n● 并行化基于分区：作业的输入通常是HDFS中的一个目录，输入目录中的每个文件或文件块都被认为是一个单独的分区，可以单独处理map任务 ● 每个输入文件的大小通常是数百兆字节。 ● MapReduce调度器（图中未显示）试图在其中一台存储输入文件副本的机器上运行每个Mapper，只要该机器有足够的备用RAM和CPU资源来运行Mapper任务。 ● 这个原则被称为将计算放在数据附近：它节省了通过网络复制输入文件的开销，减少网络负载并增加局部性。\nMapper 任务的代码在运行它的机器上还不存在咋办？ ● MapReduce框架首先将代码（例如Java程序中的JAR文件）复制到适当的机器。 ● 然后启动Map任务并开始读取输入文件，一次将一条记录传入Mapper回调函数。 ● Mapper的输出由键值对组成。\nReducer 的分区？ ● 计算的Reduce端也被分区。 ● 虽然Map任务的数量由输入文件块的数量决定，但Reducer的任务的数量是由作业作者配置的（它可以不同于Map任务的数量）。 ● 为了确保具有相同键的所有键值对最终落在相同的Reducer处，框架使用键的散列值来确定哪个Reduce任务应该接收到特定的键值对。\n排序怎么做的？ ● 键值对必须进行排序，但数据集可能太大，无法在单台机器上使用常规排序算法进行排序。 ● 相反，分类是分阶段进行的。首先每个Map任务都按照Reducer对输出进行分区。每个分区都被写入Mapper程序的本地磁盘，使用的技术与我们在“SSTables与LSM树”中讨论的类似。 ● 只要当Mapper读取完输入文件，并写完排序后的输出文件，MapReduce调度器就会通知Reducer可以从该Mapper开始获取输出文件。 ● Reducer连接到每个Mapper，并下载自己相应分区的有序键值对文件。按Reducer分区，排序，从Mapper向Reducer复制分区数据，这一整个过程被称为混洗（shuffle）。（一个容易混淆的术语 —— 不像洗牌，在MapReduce中的混洗没有随机性）。\nReduce 做了什么？ ● Reduce任务从Mapper获取文件，并将它们合并在一起，并保留有序特性。 ● 因此，如果不同的Mapper生成了键相同的记录，则在Reducer的输入中，这些记录将会相邻。 ● Reducer调用时会收到一个键，和一个迭代器作为参数，迭代器会顺序地扫过所有具有该键的记录（因为在某些情况可能无法完全放入内存中）。 ● Reducer可以使用任意逻辑来处理这些记录，并且可以生成任意数量的输出记录。这些输出记录会写入分布式文件系统上的文件中（通常是在跑Reducer的机器本地磁盘上留一份，并在其他机器上留几份副本）。\nMapReduce工作流 单个MapReduce 的局限？ ● 单个MapReduce作业可以解决的问题范围很有限。 ● 以日志分析为例，单个MapReduce作业可以确定每个URL的页面浏览次数，但无法确定最常见的URL，因为这需要第二轮排序。 ● 因此将MapReduce作业链接成为工作流（workflow） 中是极为常见的\nHadoop MapReduce 怎么实现工作流？ ● Hadoop MapReduce框架对工作流没有特殊支持，所以这个链是通过目录名隐式实现的： ○ 第一个作业必须将其输出配置为HDFS中的指定目录； ○ 第二个作业必须将其输入配置为从同一个目录。 ● 从MapReduce框架的角度来看，这是两个独立的作业。 ● 被链接的MapReduce作业并没有那么像Unix命令管道（它直接将一个进程的输出作为另一个进程的输入，仅用一个很小的内存缓冲区）。 ● 它更像是一系列命令，其中每个命令的输出写入临时文件，下一个命令从临时文件中读取。 ● 这种设计有利也有弊，我们将在“物化中间状态”中讨论。\n如何处理工作流中不同作业之间的依赖？ ● 只有当作业成功完成后，批处理作业的输出才会被视为有效的（MapReduce会丢弃失败作业的部分输出）。 ● 因此，工作流中的一项作业只有在先前的作业（即生产其输入的作业）成功完成后才能开始。 ● 为了处理这些作业之间的依赖，有很多针对Hadoop的工作流调度器被开发出来，包括Oozie，Azkaban，Luigi，Airflow和Pinball ● 在维护大量批处理作业时非常有用。在构建推荐系统时，由50到100个MapReduce作业组成的工作流是常见的；大型组织中，许多不同的团队可能运行不同的作业来读取彼此的输出。\nReduce侧Join与分组 第二章讨论过数据数据模型和查询语言的Join(连接)，这里讨论它是如何实现的。\n两条记录存在关联是很常见的： ● 关系模型中的外键，文档模型中的文档引用或图模型中的边。 ● 当你需要同时访问这一关联的两侧（持有引用的记录与被引用的记录）时，join 就是必须的。\nMapReduce 可以通过索引来关联数据吗？ ● 在数据库中，如果执行只涉及少量记录的查询，数据库通常会使用索引来快速定位感兴趣的记录。如果查询涉及到join ，则可能涉及到查找多个索引。 ● 然而MapReduce没有索引的概念 —— 至少在通常意义上没有。\nMapReduce 作业怎么找到想要读的部分数据？ ● 它读取所有这些文件的全部内容；（数据库中称之为全表扫描） ● 如果你只想读取少量的记录，则全表扫描与索引查询相比，代价非常高昂。 ● 但通常是需要计算大量记录的聚合。在这种情况下，特别是如果能在多台机器上并行处理时，扫描整个输入可能是相当合理的事情。 ● 因此，我们在批处理语义中讨论链接时，一般是同时处理所有用户的数据，而非某个特定用户的数据。\n示例：用户活动事件分析 一个批处理作业中join 的典型例子。左侧是事件日志，描述登录用户在网站上做的事情（称为活动事件（activity events） 或点击流数据（clickstream data）），右侧是用户数据库。\n分析任务需要将用户活动与用户档案信息相关联：例如，如果档案包含用户的年龄或出生日期，系统就可以确定哪些页面更受哪些年龄段的用户欢迎。\n有什么简单方法实现上述任务？ ● 逐个遍历活动事件，并为每个遇到的用户ID查询用户数据库（在远程服务器上）。 ○ 缺点：性能很差，吞吐量低，可能压垮数据库。\n为什么批处理任务不用上面的方法？ ● 为了在批处理过程中实现良好的吞吐量，计算必须（尽可能）在单台机器上进行（而不是访问外部数据，如数据库）。 ● 为待处理的每条记录发起随机访问的网络请求实在是太慢了。 ● 查询远程数据库意味着批处理作业变为非确定的（nondeterministic），因为远程数据库中的数据可能会改变。\n批处理任务中，更好的实现方法是什么？ ● 更好的方法是获取用户数据库的副本（ETL，数据仓库），并将它和用户行为日志放入同一个分布式文件系统中，如 HDFS。 ● 然后用MapReduce将所有相关记录集中到同一个地方进行高效处理。\n排序合并连接 join 过程中 Mapper 的工作？ Mapper的目的是从每个输入记录中提取一对键值，在上面 hadoop的 map reduce 的情况下，这个键就是用户ID： ● 一组Mapper会扫过活动事件（提取用户ID作为键，活动事件作为值） ● 而另一组Mapper将会扫过用户数据库（提取用户ID作为键，用户的出生日期作为值）。\n过程如下所示：\njoin 过程中怎么做分区？ ● 当MapReduce框架通过键对Mapper输出进行分区，然后对键值对进行排序时，效果是具有相同ID的所有活动事件和用户记录在Reducer输入中彼此相邻。（在上图中，三个104分区到了parition 1，173 和 103 分到 partition 2） ● Map-Reduce作业甚至可以也让这些记录排序，使Reducer总能先看到来自用户数据库的记录，紧接着是按「出生日期」排序的活动事件 —— 这种技术被称为二次排序（secondary sort）。\njoin 过程中 reducer 的工作？ ● Reducer可以容易地执行实际的join 逻辑：每个用户ID都会被调用一次Reducer函数，且因为二次排序，第一个值应该是来自用户数据库的「出生日期」记录。 ● Reducer将「出生日期」存储在局部变量中，然后使用相同的用户ID遍历活动事件，输出已观看网址和观看者年龄的结果对。随后的Map-Reduce作业可以计算每个URL的查看者年龄分布，并按年龄段进行聚集。\n为什么叫做排序合并连接？ ● 由于Reducer一次处理一个特定用户ID的所有记录，因此一次只需要将一条用户记录保存在内存中，而不需要通过网络发出任何请求。 ● 这个算法被称为排序合并连接（sort-merge join），因为Mapper的输出是按键排序的，然后Reducer将来自join 两侧的有序记录列表合并在一起.\n把相关数据放在一起 为什么需要把相关数据放在一起？ ● 在排序合并join 中，Mapper和排序过程确保了所有对特定用户ID执行join 操作的必须数据都被放在同一个地方：单次调用Reducer的地方。 ● 预先排好了所有需要的数据，Reducer可以是相当简单的单线程代码，能够以高吞吐量和与低内存开销扫过这些记录。\n为什么可以看做“消息”传递？ ● Mapper将“消息”发送给Reducer。 ● 当一个Mapper发出一个「键值对」时，这个「键」的作用就像值应该传递到的目标地址。 ● 即使「键」只是一个任意的字符串（不是像IP地址和端口号那样的实际的网络地址），它表现的就像一个地址：所有具有相同键的键值对将被传递到相同的目标（一次Reducer的调用）。\nMapReduce 编程模型中用户需要考虑网络通信吗？ ● 不用 ● 使用MapReduce编程模型，能将计算的物理网络通信层面（从正确的机器获取数据）从应用逻辑中剥离出来（获取数据后执行处理）。 ● 这种分离与数据库的典型用法形成了鲜明对比，从数据库中获取数据的请求经常出现在应用代码内部。 ● 由于MapReduce处理了所有的网络通信，因此它也避免了让应用代码去担心部分故障，例如另一个节点的崩溃：MapReduce在不影响应用逻辑的情况下能透明地重试失败的任务。\n分组 除了 join(连接) 之外，还有什么“把相关数据放在一起”的方法？ ● 常见的还有：按某个键对记录分组（如SQL中的GROUP BY子句）。 ● 所有带有相同键的记录构成一个组，而下一步往往是在每个组内进行某种聚合操作。比如： ○ 统计每个组中记录的数量（例如在统计PV的例子中，在SQL中表示为COUNT(*)聚合） ○ 对某个特定字段求和（SQL中的SUM(fieldname)） ○ 按某种分级函数取出排名前k条记录。\nMapReduce实现这种「分组」操作？ ● 最简单方法是设置Mapper，以便它们生成的键值对使用所需的分组键。 ● 然后分区和排序过程将所有具有相同分区键的记录导向同一个Reducer。 ● 因此在MapReduce之上实现分组和join 看上去非常相似。\n分组还有什么应用？ ● 分组的另一个常见用途是整理特定用户会话的所有活动事件，以找出用户进行的一系列操作（称为会话化（sessionization））。 ● 例如： ○ 可以使用这种分析来确定显示新版网站的用户是否比那些显示旧版本的用户更有购买欲（A/B测试） ○ 或者计算某个营销活动是否有效。\n当有多个 web 服务器，特定用户活动事件分散在多个不同机器上怎么办？ ● 可以通过使用会话cookie，用户ID或类似的标识符作为分组键，以将特定用户的所有活动事件放在一起来实现会话化 ● 与此同时，不同用户的事件仍然散布在不同的分区中\n处理偏斜 什么是热键？ ● 如果存在与单个键关联的大量数据，则“将具有相同键的所有记录放到相同的位置”这种模式就被破坏了。 ● 这种不成比例的活动数据库记录被称为关键对象（linchpin object）【38】或热键（hot key）。\n什么是倾斜？ ● 在单个Reducer中收集与某个名人相关的所有活动（例如他们发布内容的回复）可能导致严重的偏斜（也称为热点（hot spot））—— 也就是说，一个Reducer必须比其他Reducer处理更多的记录。 ● 由于MapReduce作业只有在所有Mapper和Reducer都完成时才完成，所有后续作业必须等待最慢的Reducer才能启动。\n怎么解决数据倾斜？ ● 如果join 的输入存在热键，可以使用一些算法进行补偿。\n以 Pig 中解决数据倾斜为例： ● 例如，Pig中的偏斜连接（skewed join） 方法首先运行一个抽样作业（Sampling Job）来确定哪些键是热键。 ● join 实际执行时，Mapper会将热键的关联记录随机（相对于传统MapReduce基于键散列的确定性方法）发送到几个Reducer之一。 ● 对于另外一侧的 join 输入，与热键相关的记录需要被复制到所有处理该键的Reducer上。 ● 这种技术将处理热键的工作分散到多个Reducer上，这样可以使其更好地并行化，代价是需要将 join 另一侧的输入记录复制到多个Reducer上。 ○ 优点：将处理热键的工作分散到多个Reducer上，这样可以使其更好地并行化 ○ 缺点：代价是需要将 join 另一侧的输入记录复制到多个Reducer上。\nCrunch处理数据倾斜： ● Crunch中的分片连接（sharded join） 方法与之类似，但需要显式指定热键而不是使用抽样作业。\nHive 处理数据倾斜： ● Hive 偏斜 join 优化采取了另一种方法，它需要在表格元数据中显式指定热键，并将与这些键相关的记录单独存放，与其它文件分开。 ● 当在该表上执行 join 时，对于热键，它会使用Map端 join （请参阅下一节） ● 当按照热键进行分组并聚合时，可以将分组分两个阶段进行： ○ 第一个MapReduce阶段将记录发送到随机Reducer，以便每个Reducer只对热键的子集执行分组，为每个键输出一个更紧凑的中间聚合结果。 ○ 然后，第二个MapReduce作业将所有来自第一阶段Reducer的中间聚合结果合并为每个键一个值。\nMap侧 join 怎么理解上文是 Reducer 侧 join ： ● 上一节中的链接算法都是在 Reducer 中执行的，所以被称为 reduce 侧 join。 ● Mapper 扮演数据预处理的角色，从每个输入记录中提取键值，将键值分配给 Reducer 分区，并按键排序。 ○ 优点：不用对输入数据做任何假设：不用管属性和结构，Mapper 都可以做预处理以备 Join ○ 缺点：排序，复制到 Reducer，合并 Reducer 输入，这些操作可能开销巨大。数据可能要落盘好几次，取决于可用的内存缓冲区。\nMap 侧 Join： ● 如果你能对数据做出某些假设，就可以用 Map 侧 Join来加快速度。 ● 省掉了 Reducer 与排序的 MapReduce 作业，每个 mapper 都是简单的从分布式文件系统中读取一个输入，然后输出到文件系统，仅此而已。\n广播散列连接 广播散列连接（broadcast hash join）： ● 一个最简单场景是大数据集与小数据集连接的情况。要点在于小数据集需要足够小，以便可以将其全部加载到每个Mapper的内存中。 ● 每个 Mapper 在扫描「大数据集」时，简单地从内存散列表中查找每个『小数据集』的数据。 ● 广播：每个 join 较大输入端分区的 Mapper 都会将较小输入端数据集整个读入内存中（所以较小输入实际上“广播”到较大数据的所有分区上） ● 散列：反映了它使用一个散列表。 ● Pig, Hive, Cascading和Crunch 都支持这种 join 。 ● 此外，还可以将较小输入存储在本地磁盘中，索引在内存中。\n分区散列连接 ● 如果Map侧 join 的输入以相同的方式进行分区，则散列连接方法可以独立应用于每个分区。 ● 每个Mapper只需要从输入两端各读取一个分区就足够了。 ● 好处是每个Mapper都可以在内存散列表中少放点数据。 ● 适用场景：这种方法只有当连接两端输入有相同的分区数，且两侧的记录都是使用相同的键与相同的哈希函数做分区时才适用。如果输入是由之前执行过这种分组的MapReduce作业生成的，那么这可能是一个合理的假设。\nMap侧合并连接 ● 如果数据集以相同的方式进行分区、还基于相同的键进行排序，那么还可以用 Map 侧连接的变体。 ● 输入是否小到能放到内存不重要。 ● 因为这时候Mapper同样可以执行归并操作（通常由Reducer执行）：按键递增的顺序依次读取两个输入文件，将具有相同键的记录配对。\nMapReduce工作流与Map侧连接 影响到输出： ● 当下游作业使用MapReduce join 的输出时，Map侧连接或Reduce侧 join 的不同选择会影响输出的结构。 ● Reduce侧连接的输出是按照连接键进行分区和排序的； ● Map端连接的输出则按照与「大数据集」相同的方式进行分区和排序；\n对输入有假设： ● Map侧连接也对输入数据集的大小，有序性和分区方式做出了更多假设。 ● 你必须了解数据按哪些键做的分区和排序，以及分区数量等。\n批处理工作流的输出 一个疑问：MapReduce处理完成之后的最终结果是什么？我们最开始为什么要跑这些作业？\n在数据库查询的场景中，我们将事务处理（OLTP）与分析两种目的区分开来： ● OLTP查询通常根据键查找少量记录，使用索引，并将其呈现给用户（比如在网页上）。 ● 分析查询通常会扫描大量记录，执行分组与聚合，输出通常有着报告的形式：显示某个指标随时间变化的图表，或按照某种排位取前10项，或将一些数字细化为子类。这种报告的消费者通常是需要做出商业决策的分析师或经理。\n批处理放哪里合适？ ● 它不属于事务处理，也不是分析。 ● 它和分析比较接近，因为批处理通常会扫过输入数据集的绝大部分。 ● 但批处理过程的输出通常不是报表，而是一些其他类型的结构。\n建立搜索索引 MapReduce诞生的背景 ● Google 最初使用 MapReduce 是为其搜索引擎建立索引 ● Hadoop MapReduce 仍然是为 Lucene/Solr 构建索引的好方法\nLucene这样的全文搜索索引是如何工作的？ ● 它是一个文件（关键词字典），你可以在其中高效地查找特定关键字，并找到包含该关键字的所有文档ID列表（文章列表）。\n如何用 MapReduce 构建索引？ ● Mapper根据需要对文档集合进行分区，每个Reducer构建该分区的索引，并将索引文件写入分布式文件系统。 ● 构建这样的文档分区索引并行处理效果拔群。\n索引怎么更新？ ● 由于按关键字查询搜索索引是只读操作，因而这些索引文件一旦创建就是不可变的。 ● 如果索引的文档集合发生更改 ○ 一种选择是定期重跑整个索引工作流，并在完成后用新的索引文件批量替换以前的索引文件。 ■ 如果只有少量的文档发生了变化，这种方法的计算成本可能会很高。 ■ 优点：是索引过程很容易理解：文档进，索引出。 ○ 另一种选择是增量建立索引。如果需要索引中添加，删除或更新文档，Lucene会写新的段文件，并在后台异步合并压缩段文件。\n键值存储作为批处理输出 除了建立搜索索引之外，批处理还有什么用途？ ● 构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，图像识别）与推荐系统\n机器学习系统的批处理输出到哪里？ ● 通常是某种数据库，例如可以通过给定 ID 查询其推荐好友的数据库\n这些数据库怎么用？ ● 通常需要被 Web 服务所查询。\n批处理过程的输出到Web应用可以查询的数据库中呢？ ● 一条条插入到数据库\n为什么一条条插入数据库不是好主意呢？ ● 每条记录发起一个网络请求，比批处理的吞吐慢了几个量级 ● 数据库可能被压垮，导致线上故障 ● 当批任务重试的时候，得操心数据库的情况\n如果不一条条插入数据库，还有什么好主意？ ● 在批处理作业内创建一个全新的数据库，并将其作为文件写入分布式文件系统中作业的输出目录，就像上节中的搜索索引一样。 ● 这些数据文件一旦写入就是不可变的，可以批量加载到处理只读查询的服务器中。 ● 不少键值存储都支持在MapReduce作业中构建数据库文件，包括Voldemort ，Terrapin ，ElephantDB 和 HBase 批量加载。\n这么做的优点？ ● 因为文件只读（不再修改），所以数据结构很简单，不用预写式日志（WAL） ● 在Voldemort加载数据时，使用旧文件继续提供服务，当加载完成自动将查询切换到新文件。如果出现问题，则回滚。\n批处理输出的哲学 Unix哲学鼓励以显式指明数据流的方式进行实验：程序读取输入并写入输出。 ● 输入保持不变；没有副作用；可以随意改动或调试；\nMapReduce作业的输出处理遵循同样的原理。 ● 如果代码错误或者输出损坏，可以回滚代码，然后重跑。输出就会被修正。 ○ 数据库没有这个属性：回滚代码无法修复数据库中的数据 ○ 能够从错误代码中恢复的概念被称为人类容错（human fault tolerance） ● 由于回滚容易，可以容忍错误。这种最小化不可逆性（minimizing irreversibility） 的原则有利于敏捷软件开发。 ● 如果Map或Reduce任务失败，MapReduce框架将自动重新调度，并在同样的输入上再次运行它。 ○ 如果是代码错误，那么几次重试后将失败； ○ 如果是临时问题导致的，那么故障被容忍； ○ 由于输入不可变，所以重试是安全的。 ● 同一组文件可用作各种不同作业的输入 ● 与Unix工具类似，MapReduce作业将逻辑与布线（配置输入和输出目录）分离，这使得关注点分离，可以重用代码：一个团队可以专注实现一个做好一件事的作业；而其他团队可以决定何时何地运行这项作业。\nUnix 与 Hadoop 的不同： ● 大多数 Unix 工具都假设输入输出是无类型文本文件，所以它们必须做大量的输入解析工作（本章开头的日志分析示例使用 {print $7} 来提取URL）。 ● 在 Hadoop 上可以通过使用更结构化的文件格式消除一些低价值的语法转换：比如 Avro（请参阅“Avro”）和 Parquet（请参阅“列存储”）经常使用，因为它们提供了基于模式的高效编码，并允许模式随时间推移而演进（见第四章）。\nHadoop与分布式数据库的对比 MapReduce 与 大规模并行处理（MPP， massively parallel processing）的区别？ ● MPP数据库专注于在一组机器上并行执行分析SQL查询 ● 而MapReduce和分布式文件系统的组合则更像是一个可以运行任意程序的通用操作系统。\n存储多样性 分布式文件系统与数据库的区别？ ● 数据库要求你根据特定的模型（例如关系或文档）来构造数据 ● 而分布式文件系统中的文件只是字节序列，可以使用任何数据模型和编码来编写。\n使用原始格式保存数据的优点？ ● 实践经验表明，简单地使数据快速可用 —— 即使它很古怪，难以使用，使用原始格式 —— 也通常要比事先决定理想数据模型要更有价值 ● 以原始形式收集数据，稍后再操心模式的设计，能使数据收集速度加快（有时被称为“数据湖（data lake）”或“企业数据中心（enterprise data hub）” ● 转移了解释数据的负担：数据的解释成为消费者的问题（读时模式），有利于跨团队合作。 ● 这种方法被称为寿司原则（sushi principle）：“原始数据更好”\n处理模型的多样性 MPP 数据库和 MapReduce 在处理模型上的区别？ ● MPP 数据库是单体的，紧密集成的软件，负责磁盘上的存储布局，查询计划，调度和执行。 ○ 优点：可以针对数据库特定调优；可以用 SQL 查询语言表达查询，无需代码。 ○ 缺点：并非所有类型的处理都可以合理地表达为SQL查询（如索引、推荐系统）。 ● MapReduce 能够轻松地在大型数据集上运行自己的代码。 ○ 优点： ■ 语法上：可以建立一个SQL查询执行引擎，如 Hive 项目；也可以编写代码；还可以编写其他模型； ■ 运行上：分布式。\n针对频繁故障设计 MPP 数据库和 MapReduce 在处理故障上的区别？ ● 与在线系统相比，批处理系统对故障不敏感。 ● MPP 数据库： ○ 如果有一个节点执行查询时失败，MPP 数据库会中止整个查询，并让用户重试。 ○ 查询通常在几分钟内，因此这种重试可以接受。 ○ 倾向于内存中保留尽可能多的数据，以避免磁盘读取的开销 ● MapReduce： ○ 可以容忍单个Map或Reduce任务的失败，而不会影响作业的整体，通过以单个任务的粒度重试工作。 ○ 它也会非常急切地将数据写入磁盘，一方面是为了容错，另一部分是因为假设数据集太大而不能适应内存。\nMapReduce 在处理故障上的优点？ ● 更适合大的作业（任务多，易失败） ● 不是因为硬件很不可靠，而是因为任意终止进程的自由有利于提高计算集群中的资源利用率。 ○ 场景：如果优先级较高的任务需要更多的资源，则可以终止（抢占）同一台机器上较低优先级的任务以释放资源。从而提高资源利用率。 ○ 在谷歌，运行一个小时的MapReduce任务有大约有5％的风险被终止，为了给更高优先级的进程挪地方。\nMapReduce之后 MapReduce 是简单，但导致复杂任务从头编写任务繁重。 很多高级编程模型被创造，如 Pig，Hive，Cascading，Crunch； MapReuce 是非常稳健，但其他工具可能快上几个量级。\n物化中间状态 什么是物化中间状态？ ● 每个MapReduce作业都独立于其他任何作业，跨团队合作时，分布式系统的文件只是简单的中间状态（intermediate state） ● 将这个中间状态写入文件的过程称为物化（materialization）。\nMapReduce完全物化中间状态与 Unix 管道的比较？ ● Unix管道将一个命令的输出与另一个命令的输入连接起来。管道并没有完全物化中间状态，而是只使用一个小的内存缓冲区，将输出增量地流（stream） 向输入。 ● MapReduce完全物化中间状态的不足： ○ 慢：MapReduce作业只有在前驱作业（生成其输入）中的所有任务都完成时才能启动（慢节点拖慢整个工作流程），而由Unix管道连接的进程会同时启动，输出一旦生成就会被消费。 ○ Mapper通常是多余的：它们仅仅是读取刚刚由Reducer写入的同样文件，为下一个阶段的分区和排序做准备。 ■ 在许多情况下，Mapper代码可能是前驱Reducer的一部分：如果Reducer和Mapper的输出有着相同的分区与排序方式，那么Reducer就可以直接串在一起，而不用与Mapper相互交织。 ○ 复制很浪费：将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点，对这些临时数据这么搞就比较过分了。\n数据流引擎 为了解决上述问题，开发了数据流引擎：Spark, Tez, Flink。\n数据流引擎与 MapReduce 的区别？ ● 数据流引擎的共同点：把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。 ● 像MapReduce一样，它们在一条线上通过反复调用用户定义的函数来一次处理一条记录，它们通过输入分区来并行化载荷，它们通过网络将一个函数的输出复制到另一个函数的输入。 ● 与MapReduce不同，这些函数不需要严格扮演交织的Map与Reduce的角色，而是可以以更灵活的方式进行组合。我们称这些函数为算子（operators）\n数据流引擎提供了哪些不同的选项来将一个算子的输出连接到另一个算子的输入？ ● 一种选项是对记录按键重新分区并排序，就像在MapReduce的混洗阶段一样。 ● 另一种可能是接受多个输入，并以相同的方式进行分区，但跳过排序。当记录的分区重要但顺序无关紧要时，这省去了分区散列连接的工作，因为构建散列表还是会把顺序随机打乱。 ● 对于广播散列连接，可以将一个算子的输出，发送到连接算子的所有分区。\n与MapReduce模型相比，数据流引擎有什么优点？ ● 排序等昂贵的工作只需要在实际需要的地方执行，而不是默认地在每个Map和Reduce阶段之间出现。 ● 没有不必要的Map任务，因为Mapper所做的工作通常可以合并到前面的Reduce算子中（因为Mapper不会更改数据集的分区）。 ● 调度程序能够利用局部性进行优化，比如消费数据任务与生成数据的任务放在相同的机器上。 ● 算子间的中间状态足以保存在内存中或写入本地磁盘，这比写入HDFS需要更少的I/O（必须将其复制到多台机器，并将每个副本写入磁盘）。 ● 算子可以在输入就绪后立即开始执行；后续阶段无需等待前驱阶段整个完成后再开始。 ● 与MapReduce（为每个任务启动一个新的JVM）相比，现有Java虚拟机（JVM）进程可以重用来运行新算子，从而减少启动开销。\n使用数据流引擎执行与MapReduce工作流同样的计算，通常执行速度要明显快得多。\n容错 完全物化中间状态至 HDFS 的优点？ ● 具有持久性，这使得MapReduce中的容错相当容易，任务失败时可以在另一台机器上重启。\nSpark，Flink和Tez没有将中间状态写入HDFS，怎么容错？ ● 它们采取了不同的方法来容错：如果一台机器发生故障，并且该机器上的中间状态丢失，则它会从其他仍然可用的数据重新计算（在可行的情况下是先前的中间状态，要么就只能是原始输入数据，通常在HDFS上）。 ● 为了实现这种重新计算，框架必须跟踪一个给定的数据是如何计算的 —— 使用了哪些输入分区？应用了哪些算子？ Spark使用弹性分布式数据集（RDD，Resilient Distributed Dataset） 的抽象来跟踪数据的谱系，而Flink对算子状态存档，允许恢复运行在执行过程中遇到错误的算子。\n重新计算数据时，计算有不确定行怎么办？ ● 在重新计算数据时，重要的是要知道计算是否是确定性的（相同的输入数据，算子是否始终有相同的输出？）。对于不确定性算子来说，解决方案通常是杀死下游算子，然后再重跑新数据。 ● 为了避免这种级联故障，最好让算子具有确定性。 ○ 但是非确定性行为，很容易溜进来。比如哈希表的迭代、随机数。 ○ 最好消除掉上述行为，比如随机数设定固定的种子。\n重新计算一定是最佳选择吗？ ● 不是 ● 如果中间状态比原始数据小得多，或者计算量大，那么物化中间状态更好。\n关于物化的讨论 流引擎的输入和输出与物化。 ● 排序算子必须消费全部的输入后才能输出，因子需要排序的算子都需要至少暂时累积状态。 ● 使用数据流引擎时，HDFS 上的物化数据集通常仍是作业的输入和输出。 ● 比起 MapReduce 的改进是，不用自己把中间状态写入文件了。\n图与迭代处理 批处理中为什么会处理图？ ● 目标是在整个图上执行某种离线处理或分析 ● 这种需求经常出现在机器学习应用（如推荐引擎）或排序系统中。如，PageRank。\nSpark, Flink 等流处理引擎，把算子作为有向无环图（DAG）的一部分安排在作业中。 而图处理中，数据本身具有图的性质。\n许多图算法是通过 BFS/DFS 实现的，MapReduce 实现它很低效，因为 MapReduce 是一条条处理的。\nPregel处理模型 针对图批处理的优化 —— 批量同步并行（BSP，Bulk Synchronous Parallel） 计算模型已经开始流行起来。 ● 其中，Apache Giraph ，Spark的GraphX API和Flink的Gelly API 实现了它。 ● 它也被称为Pregel模型，因为Google的Pregel论文推广了这种处理图的方法。\nPregel 是怎么处理图的？（每个顶点是一个处理） ● 在MapReduce中，Mapper在概念上向Reducer的特定调用“发送消息”，因为框架将所有具有相同键的Mapper输出集中在一起。 ● Pregel背后有一个类似的想法：一个顶点可以向另一个顶点“发送消息”，通常这些消息是沿着图的边发送的。 ● 在每次迭代中，为每个顶点调用一个函数，将所有发送给它的消息传递给它 —— 就像调用Reducer一样。 ● 与MapReduce的不同之处在于，在Pregel模型中，顶点在一次迭代到下一次迭代的过程中会记住它的状态，所以这个函数只需要处理新的传入消息。如果图的某个部分没有被发送消息，那里就不需要做任何工作。\n容错 Pregel作业怎么容错？ ● 消息批处理，且等待通信的次数减少了；每次迭代中发送的消息处理完成才能处理下一轮迭代。 ● 网络丢失、重复、延迟消息时，Pregel 能保证消息在其目标顶点恰好处理一次。 ● 迭代结束时，定期存档所有顶点的状态，持久化存储。\n并行执行 ● 图的分区取决于框架——比如顶点运行在哪台机器上，怎么通过网络通信。 ○ 理想情况下，大量通信的顶点最好放在同一台机器上。 ○ 实践上很难做到，因为图通常按照任意分配的 ID 分区。 ● 图通常有跨机器的额外开销，中间状态（节点之间发送的消息）往往比原始图大。网络发送消息的开销，会显著拖慢分布式图算法的速度。 ○ 如果图能放在单机内存中处理，单机算法很可能超过分布式处理。 ○ 分布式处理图的并行算法是一个进行中的研究领域。\n高级API和语言 目前大规模处理的能力已经具备，在研究的是改进编程模型，提高处理效率，扩大这些技术可以解决的问题集。 ● Hive, Pig, Spark, Flink 等都有自己的高级数据流 API，很方便简单高效。\n向声明式查询语言的转变 ● MapReduce 可以自由执行任意代码，但是用户自定义的 UDF 使用起来不方便。 ● 数据流处理引擎发现还是声明式（类 SQL）语言更好，因为内部可以做 join 的优化，列存储，向量化执行等。 ● 批处理框架越来越像 MPP 数据库了（性能也可以媲美）。\n专业化的不同领域 ● 传统上，MPP数据库满足了商业智能分析和业务报表的需求 ● 而现在，随着批处理系统获得各种内置功能以及高级声明式算子，且随着MPP数据库变得更加灵活和易于编程，两者开始看起来相似了：最终，它们都只是存储和处理数据的系统。\n本章小结 输入输出 ● 在Unix世界中，允许程序与程序组合的统一接口是文件与管道； ● 在MapReduce中，该接口是一个分布式文件系统。 ● 数据流引擎添加了自己的管道式数据传输机制，以避免将中间状态物化至分布式文件系统，但作业的初始输入和最终输出通常仍是HDFS。\n分布式批处理框架需要解决的两个主要问题是： 分区 ● 在MapReduce中，Mapper根据输入文件块进行分区。Mapper的输出被重新分区、排序并合并到可配置数量的Reducer分区中。这一过程的目的是把所有的相关数据（例如带有相同键的所有记录）都放在同一个地方。 ● 后MapReduce时代的数据流引擎若非必要会尽量避免排序，但它们也采取了大致类似的分区方法。 容错 ● MapReduce经常写入磁盘，这使得从单个失败的任务恢复很轻松，无需重新启动整个作业，但在无故障的情况下减慢了执行速度。 ● 数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态，这意味着如果节点发生故障，则需要重算更多的数据。 ● 确定性算子减少了需要重算的数据量。\n讨论了几种MapReduce的连接算法： 排序合并连接 每个参与连接的输入都通过一个提取连接键的Mapper。通过分区、排序和合并，具有相同键的所有记录最终都会进入相同的Reducer调用。这个函数能输出连接好的记录。 广播散列连接 两个连接输入之一很小，所以它并没有分区，而且能被完全加载进一个哈希表中。因此，你可以为连接输入大端的每个分区启动一个Mapper，将输入小端的散列表加载到每个Mapper中，然后扫描大端，一次一条记录，并为每条记录查询散列表。 分区散列连接 如果两个连接输入以相同的方式分区（使用相同的键，相同的散列函数和相同数量的分区），则可以独立地对每个分区应用散列表方法。\n批处理作业的显著特点是，它读取一些输入数据并产生一些输出数据，但不修改输入—— 换句话说，输出是从输入衍生出的。最关键的是，输入数据是有界的（bounded）：它有一个已知的，固定的大小（例如，它包含一些时间点的日志文件或数据库内容的快照）。因为它是有界的，一个作业知道自己什么时候完成了整个输入的读取，所以一个工作在做完后，最终总是会完成的。\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E5%8D%81%E7%AB%A0/","summary":"第十章：批处理 本书的前九章，讨论的都是请求、查询，以及相应的响应和结果。是在线系统，关注响应时间。 三种不同类型的系统： 服务（在线系统） 处理客","title":"DDIA第十章"},{"content":"基于树莓派-piwigo/apache2 的家庭云相册搭建 背景 近期由于拍摄了很多我和胡小蕊在一起的照片，包括生活照片和出去游玩的照片，所以想搞一个家庭云相册，可以用于实时同步手机中的照片到云相册上。因为考虑到公有云相册的隐私安全保障问题，以及我想自己DIY一些功能。还有就是自己的手机内存问题以及手机自带的云相册需要付费申请更大的空间，我不想付费。因此我想可以利用树莓派作为服务器，寻找一个开源的云相册管理系统自己部署到服务器上，最好是带有软件的开源云相册。找来找去发现了这款PiWigo云相册，详细请见： PIWIGO 官网，这里是github地址: PIWIGO github仓库 1、介绍 这篇博客介绍如何在树莓派4上安装PiWigo作为一个web server。 Piwigo是一个开源的相册管理软件，可以轻松的管理我们的照片和相册。我们可以在PC端或者安卓端以及iphone上进行浏览和同步。\n2、要求 下面这些是必须需要提前准备好的：\n树莓派4B 以及安装好Raspberry Pi OS 这个不在本教程之内 树莓派4B的终端，这个一般安装好树莓派OS就会有，但是最好打开SSH连接，远程操作，一般树莓派也就是当作一个服务器 3、配置树莓派4B作为一个WEB 服务器 3.1 确认 Raspberry Pi 4 OS 是最新的 在执行该命令之前，若是中国大陆用户需要将apt源更换，具体更换流程： 如何更换树莓派OS软件源\n1 sudo apt update -y \u0026amp;\u0026amp; sudo apt upgrade -y \u0026amp;\u0026amp; sudo apt autoremove -y 3.2 安装WEB服务 (Apache) 我们知道web服务有很多选择，例如nginx apache,我们这里选择Apache\n1 sudo apt install apache2 -y 等待终端打印字符结束，可以打开本地树莓派ip地址，看到以下网页显示即安装成功 3.3 安装PHP相关依赖 1 sudo apt install php-imagick php-gd ffmpeg php-mbstring php-xml -y 3.4 安装数据库 我们使用MariaDB 代替Mysql, MariaDB是Mysql的一个子分支，但是更小更轻便\n1、输入以下代码安装mariadb\n1 sudo apt install mariadb-server php-mysql -y 2、等待安装完成之后，输入以下命令配置数据库相关信息及环境变量\n1 sudo mysql_secure_installation 执完命令之后，终端将会显示如下 3、依次回答终端上显示的问题如下:\nAs no password has been set yet press enter. Switch to unix_socket authentication [Y/n] –\u003e n Change the root password? [Y/n] –\u003e Y New password: –\u003e type your new root password Make sure you remember/store is for example with the Keepass password manager. Re-enter new password: –\u003e type again your new root password Remove anonymous users? [Y/n] –\u003e Y Info displayed in Terminal window: By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Disallow root login remotely? [Y/n] –\u003e Y Info displayed in Terminal window: Normally, root should only be allowed to connect from ‘localhost’. This ensures that someone cannot guess at the root password from the network. Remove test database and access to it? [Y/n] –\u003e Y Info displayed in Terminal window: By default, MariaDB comes with a database named ‘test’ that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Reload privilege tables now? [Y/n] –\u003e Y Info displayed in Terminal window: Reloading the privilege tables will ensure that all changes made so far will take effect immediately. 4、为了更好的管理我们的数据库我们安装一个phpMyAdmin\n1 sudo apt install phpmyadmin -y 5、在终端显示的设置中，我们进行以下设置： a、使用空格键选择apache2（选择到后会显示一个*号），然后我们使用TAB键选择OK，ENTER,继续下一步: b、选择yes to configure the database for phpmyadmin with dbconfig-common.\nc、下一个终端显示的配置中，配置我们数据库用户phpmyadmin的密码 6、给予 phpMyAdmin 用户权限 a、使用root用户登录 MariaDB\n1 sudo mysql -uroot -p 给予权限\n1 2 3 grant all privileges on *.* to \u0026#39;phpmyadmin\u0026#39;@\u0026#39;localhost\u0026#39;; flush privileges; quit 7、重启树莓派\n1 sudo reboot 8、打开树莓派对应局域网ip:for example http://192.168.2.148/phpmyadmin, 可以见到以下页面 9、使用 phpmyadmin作为用户名，密码为刚刚设置的密码进行登录\n4、安装Piwigo 在安装PiWiGo之前，数据库需要初始化，新建库表等操作\n4.1 设置数据库 1、以root用户名登录数据库\n1 sudo mariadb -u root 2、创建数据库 piwigo_13_dev, 你可以用你喜欢的名称\n1 create database piwigo_13_dev; 3、将 Piwigo 数据库的所有权限授予您将在后续步骤中在 Piwigo 中配置的用户（带密码）\n1 2 grant all privileges on piwigo_13_dev.* to piwigo_13_dev_user@localhost identified by \u0026#39;********\u0026#39;; 4、刷新权限表以使更改生效，然后退出\n1 2 flush privileges; exit; 4.2 安装Piwigo 我们使用手动方法来安装Piwigo。\n1、直接在树莓派中下载安装包并解压\n1 2 curl http://piwigo.org/download/dlcounter.php?code=latest -o piwigo.zip unzip piwigo.zip 2、现在必须将包含解压缩的 Piwigo 文件的文件夹的内容移至 Apache 公共文件夹中。将“PIWIGO”文件夹替换为您喜欢的名称（小写），记住在 URL 和以下命令中都使用您的文件夹名称：\n1 2 sudo mkdir /var/www/html/PIWIGO sudo mv piwigo/{.,}* /var/www/html/PIWIGO/ 就我而言，我使用了\n1 2 sudo mkdir /var/www/html/piwigo13dev sudo mv piwigo/{.,}* /var/www/html/piwigo13dev/ move命令mv会给出警告，；设备或资源繁忙，无法移动\u0026hellip;等, 可以忽略，我们可以直接到目标文件夹中查看，发现已经全部移动过去了\n3、为公共文件夹分配正确的权限，以便 Piwigo 安装程序能够执行其任务：\n1 sudo chown -R www-data:www-data /var/www/html/ 4、删除用于解压 piwigo 文件的文件夹\n1 rmdir piwigo/ 5、我们现在使用浏览器来完成安装步骤。输入您的 Raspberry PI 的 IP 地址作为 URL，后跟步骤 2 中使用的“piwigo”文件夹名称。所以在我的例子中，它变成 http://192.168.2.148/piwigo13dev 将显示 Piwigo 安装页面。 6、添加您的数据库名称、数据库用户和数据库用户密码。将主机变量设置为“localhost”。\n7、选择 piwigo 管理员用户名、密码和电子邮件地址。这些将是您用来访问网络仪表板的。就我而言，我输入了以下内容：\n8、单击“开始安装”。\n5、安装成功后的一些设置 通过照片管理可以进行添加照片等操作，相册管理可以进行相册的增加与删除修改。可以下载相应的APP与该服务端进行交互，设置同步相册可以进行定时同步操作.\n在实际使用中我也遇到了一些问题，比如在ios端设置自动同步相册的时候，不能选择多久同步一次，但是在安卓端就有这个功能，然后在IOS端和安卓端都不能设置多个相册同步，只能选择单个相册同步，在这个项目的issue里好像也没有看到有人吐槽过这个问题，不过这些问题都不属于bug，吐槽了作者估计也不会搭理，后续看看有时间自己fork过来改进一下\u0026hellip;\n自动上传这块可设置的东西太少了！ 6、参考文章: 1、 How to install Piwigo on a Raspberry Pi 4? 2、 How to Install and Use Piwigo on Your Raspberry Pi 3、Piwigo and Raspberry PI: a Private Open Source Photo Management Platform\n","permalink":"https://csqread.top/posts/tech/%E5%9F%BA%E4%BA%8E%E6%A0%91%E8%8E%93%E6%B4%BE-piwigo%E7%9A%84%E5%AE%B6%E5%BA%AD%E4%BA%91%E7%9B%B8%E5%86%8C/","summary":"基于树莓派-piwigo/apache2 的家庭云相册搭建 背景 近期由于拍摄了很多我和胡小蕊在一起的照片，包括生活照片和出去游玩的照片，所以想搞","title":"基于树莓派 Piwigo的家庭云相册"},{"content":"第九章：一致性与共识 构建容错系统的最好方法，是找到一些带有实用保证的通用抽象，实现一次，然后让应用依赖这些保证。比如事务。 我们需要了解系统能力的边界：哪些可行，哪些不可行。\n一致性保证 分布式系统的时序问题：\n在同一时刻查看两个数据库节点，则可能在两个节点上看到不同的数据，因为写请求在不同的时间到达不同的节点。 无论数据库使用何种复制方法（单主复制，多主复制或无主复制），都会出现这些不一致情况。 大多数复制的数据库至少提供了最终一致性，这意味着如果你停止向数据库写入数据并等待一段不确定的时间，那么最终所有的读取请求都会返回相同的值。 换句话说，不一致性是暂时的，最终会自行解决（假设网络中的任何故障最终都会被修复）。最终一致性的一个更好的名字可能是收敛（convergence），因为我们预计所有的副本最终会收敛到相同的值。 最终一致性是非常弱的保证——没有说什么时候会收敛。 在与只提供弱保证的数据库打交道时，你需要始终意识到它的局限性，而不是意外地作出太多假设。（始终不信任它） 除了最终一致性，有没有更强的一致性模型？\n分布式一致性模型 分布式一致性模型和我们之前讨论的事务隔离级别的层次结构有一些相似之处。 不同：事务隔离主要是为了避免由于同时执行事务而导致的竞争状态，而分布式一致性主要关于在面对延迟和故障时如何协调副本间的状态。 线性一致性 线性一致性的想法？\n数据库可以提供只有一个副本的假象（即，只有一个数据副本），那么每个客户端都会有相同的数据视图，且不必担心复制滞后了。 线性一致性（linearizability），也称为原子一致性（atomic consistency），强一致性（strong consistency），立即一致性（immediate consistency） 或外部一致性（external consistency ）。 线性一致性提供了什么保证？\n只要一个客户端成功完成写操作，所有客户端从数据库中读取数据必须能够看到刚刚写入的值。 系统应保障读到的值是最近的、最新的，而不是来自陈旧的缓存或副本。 线性一致性是一个新鲜度保证（recency guarantee）。 图9-1 这个系统是非线性一致的，导致了球迷的困惑 如何使得系统线性一致？ ","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E4%B9%9D%E7%AB%A0/","summary":"第九章：一致性与共识 构建容错系统的最好方法，是找到一些带有实用保证的通用抽象，实现一次，然后让应用依赖这些保证。比如事务。 我们需要了解系统能","title":"DDIA第九章"},{"content":"第八章： 分布式系统的挑战 分布式系统面临哪些挑战？ ● 前面几章讨论的副本故障切换、复制延迟、事务控制； ● 本章讨论的不可靠网络、时钟和时序问题等等； ● 我们的假设：任何可能出错的东西都会出错。\n故障与部分失效 ● 单机上的软件比较稳定，要么功能完好，要么整个系统故障，而不是介于两者之间。 ● 分布式系统中，尽管系统的其他部分工作正常，但系统的某些部分可能会以某种不可预知的方式被破坏。这被称为部分失效（partial failure）。难点在于部分失效是不确定性的（nonderterministic）。\n云计算与超级计算机 构建大型计算系统的方式： ● 一个极端是高性能计算（HPC）领域，具有数千个CPU的超级计算机通常用于计算密集型科学计算任务，比如天气预报； ● 另一个极端是云计算（cloud computing），通过很多主机相连接； ● 传统企业数据中心位于这两个极端之间。\n超级计算机怎么处理故障？ ● 超级计算机中，作业通常会不时地将计算存盘到持久存储中； ● 如果发生部分故障，那么通过修复、重启、重新加载继续计算的方式。 ● 类似于一个单节点计算机。\n互联网服务的系统与超级计算机系统的区别？\n互联网服务的系统 互联网服务的系统\t超级计算机 在线的，低延迟，不可重启 离线的，批处理，可以重启 基于 IP 和以太网 专门的网络拓扑 故障频发，需要很快的处理故障 可以花较多的时间从错误中恢复 普通硬件，较低成本，较高故障率 专用硬件，节点可靠，节点通过共享内存和远程直接内存访问（RDMA）进行通信 可以容忍发生故障的节点 不能容忍故障节点 地理位置分布发散，通信通过互联网，通信缓慢且不可靠 所有节点都靠近一起 构建分布式系统的思路？ ● 接受部分故障的可能性，并在软件中建立容错机制。\n不可靠的网络 互联网和数据中心（通常是以太网）中的大多数内部网络都是异步分组网络（asynchronous packet networks）。 网络可能出现的错误？ 请求可能已经丢失（可能有人拔掉了网线）。 请求可能正在排队，稍后将交付（也许网络或接收方过载）。 远程节点可能已经失效（可能是崩溃或关机） 远程节点可能暂时停止了响应（可能会遇到长时间的垃圾回收暂停），但稍后会再次响应 远程节点可能已经处理了请求，但是网络上的响应已经丢失（可能是网络交换机配置错误）。 远程节点可能已经处理了请求，但是响应已经被延迟，并且稍后将被传递（可能是网络或者你自己的机器过载）。 怎么处理网络错误？ ● 通常方法是超时（Timeout）：在一段时间之后放弃等待，并且认为响应不会到达。 ● 但是，当发生超时时，你仍然不知道远程节点是否收到了请求（如果请求仍然在某个地方排队，那么即使发送者已经放弃了该请求，仍然可能会将其发送给接收者）。\n真实世界的网络故障 ● 真实世界很复杂，啥样的网络故障都可能发生。 ○ 机器损坏 ○ 人为操作错误\n检测故障 为什么需要自动检测故障节点？ ● 负载平衡器需要停止向已死亡的节点转发请求（即从移出轮询列表（out of rotation））。 ● 在单主复制功能的分布式数据库中，如果主库失效，则需要将从库之一升级为新主库\n怎么判断一个节点是否工作？ ● 网络的不确定性导致很难判断。 ● 特定场景下，故障节点可能有反馈信息： ○ 没有进程正在监听目标端口，操作系统将发送 FIN 或者 RST 关闭并重用 TCP 连接 ○ 节点进程崩溃，但操作系统仍在运行，脚本可以通知其他节点有关该崩溃的信息 ○ 通过数据中心网络交换机的管理界面，检测硬件级别的链路故障 ○ 路由器发现尝试连接的IP地址不可用，则可能会使用ICMP目标不可达数据包回复您。 ● 你不能指望这些信息，必须假设出错时得不到任何回应 ● 通过超时来检测\n超时与无穷的延迟 超时应该得到多久？ ● 没有答案\n过短的超时可以吗？ ● 如果一个节点实际上活着，另一个节点接管，可能造成动作执行了两次 ● 如果因为高负载导致响应缓慢，将其负载转移到其他节点可能会导致级联失效。\n虚构的系统中，合理的超时时间？ ● 假设数据包的最大延迟为 $d$，即要么在 $d$ 内完成交付，要么丢失 ● 假设非故障节点在 $r$ 时间内完成请求处理 ● 在这种情况下，您可以保证每个成功的请求在$2d + r$时间内都能收到响应。 ● $2d + r$ 会是一个合理的超时设置。\n实际上，大多数系统都没有这些保证。\n网络拥塞和排队 计算机网络上数据包延迟的可变性通常是由于排队：\n交换机队列填满 目标机器的 CPU 繁忙 多个虚拟机争抢 CPU TCP执行流量控制（flow control） 怎么解决多租户数据中心的网络拥塞问题？\n原因：在公共云和多租户数据中心中，资源被许多客户共享：网络链接和交换机，甚至每个机器的网卡和CPU（在虚拟机上运行时）。 解决办法：通过实验方式选择超时：在一段较长的时期内、在多台机器上测量网络往返时间的分布，以确定延迟的预期变化。然后，考虑到应用程序的特性，可以确定故障检测延迟与过早超时风险之间的适当折衷。 更好的办法：不是固定的常量超时时间，而是连续测量响应时间及其变化来自动调整超时时间。 同步网络与异步网络 为什么我们不能在硬件层面上解决这个问题，使网络可靠，使软件不必担心呢？\n以非常可靠的传统固定电话网络为例：\n延迟音频帧和掉话是非常罕见的。 在两个呼叫者之间的整个路线上为呼叫分配一个固定的，有保证的带宽量。 网络资源被保留了，因此不会排队。 由于没有排队，网络的最大端到端延迟是固定的。我们称之为有限延迟（bounded delay）。 网络延迟可以预测吗？ ● 电话网络的电路和 TCP 连接很不同： ○ 电路是固定数量的预留带宽 ○ TCP连接的数据包机会性地使用任何可用的网络带宽。 ○ 以太网和 IP 是分组交换协议，不得不忍受排队，以及其导致的无线延迟。 ■ 优点是可以应对不同速率的流量，也最大程度利用网络资源。 ● 当前部署的技术不允许我们对网络的延迟或可靠性作出任何保证：我们必须假设网络拥塞，排队和无限的延迟总是会发生。 ● 因此，超时时间没有“正确”的值——它需要通过实验来确定。\n不可靠的时钟 时钟和时间很重要。应用程序以各种方式依赖于时钟来回答以下问题：\n这个请求是否超时了？ 这项服务的第99百分位响应时间是多少？ 在过去五分钟内，该服务平均每秒处理多少个查询？ 用户在我们的网站上花了多长时间？ 这篇文章在何时发布？ 在什么时间发送提醒邮件？ 这个缓存条目何时到期？ 日志文件中此错误消息的时间戳是什么？ 时钟为什么不可靠？\n● 分布式系统中，时间很棘手，因为通信不是即时的：网络延迟，并且不知道晚了多少时间，导致不知道事件发生的顺序。 ● 每个机器都有自己的时钟，是个硬件设备：石英晶体振荡器。但是该硬件不可靠，需要通过服务器进行同步。\n单调钟与日历时钟 计算机至少有两种目的不一样的时钟： ● 日历时钟（time-of-day clock） ● 单调钟（monotonic clock）\n日历时钟 日历时钟是什么？ ● 直观了解时钟的依据：它根据某个日历（也称为挂钟时间（wall-clock time））返回当前日期和时间。 ● 例如 Linux上的clock_gettime(CLOCK_REALTIME) 和 Java中的System.currentTimeMillis() ● 通常与网络时间协议（NTP）同步\n缺点： ● 不包括闰秒，所以不能测量 经过时间（elapsed time） ● 可能会被强制重置（比如与 NTP 时间差别很大的时候）\n单调钟 是什么？ ● 单调钟适用于测量持续时间（时间间隔） ● 例如超时或服务的响应时间：Linux上的clock_gettime(CLOCK_MONOTONIC)，和Java中的System.nanoTime()都是单调时钟。 ● 名字来源：单调钟保证总是往前走的事实（而日历时钟可以往回跳）\n怎么用？ ● 计算时间差，即测量 经过时间（elapsed time） ● 单调钟的绝对值毫无意义：可能是任意值。\n会修改吗？ ● NTP 检测到计算机的本地石英钟比NTP服务器要更快或更慢，则可以调整单调钟向前走的频率（这称为偏移（skewing） 时钟）。 ● NTP允许时钟速率增加或减慢最高至0.05％，但NTP不能使单调时钟向前或向后跳转。\n精确度？ ● 分辨率很高，很精确 ● 几微秒或者更短的时间内测量时间间隔\n在分布式系统中的作用？ ● 在分布式系统中，使用单调钟测量经过时间（elapsed time）（比如超时）通常很好，因为它不假定不同节点的时钟之间存在任何同步，并且对测量的轻微不准确性不敏感。\n时钟同步与准确性 ● 单调钟不需要同步 ● 日历时钟需要通过 NTP 或者其他外部时间进行同步，但是！获取时钟的方法并不可靠和准确。\n举例： ● 计算机中的石英钟不够精确：它会漂移（drifts）（运行速度快于或慢于预期）。时钟漂移取决于机器的温度。Google 假设如果机器一天同步一次时钟，漂移为 17 秒。 ● 如果计算机的时钟与NTP服务器的时钟差别太大，可能会拒绝同步，或者本地时钟将被强制重置。导致观察重置前后时间的应用程序傻眼了。 ● 如果与 NTP 服务器链接失败（比如防火墙），那么可能很长时间没有留意到错误配置最终导致同步失败。 ● NTP 服务器故障或出现配置错误。 ● 闰秒导致服务器崩溃了。处理闰秒的推荐方法是：NTP 把闰秒摊平均匀分布到一天。 ● 虚拟机中，突然卡了。导致时钟跳跃。 ● 用户故意调整硬件时钟，以规避游戏的时间限制。\n依赖同步时钟 时钟导致的问题： ● 日历时钟可能会前后跳跃\n处理方法： ● 需要健壮的软件来处理不正确的时钟 ● 时钟问题很难被发现：因此仔细监控所有机器之间的时钟偏移，把偏移太远的机器移除。\n有序事件的时间戳 ● 当依赖时钟对多个节点事件排序时，时钟尤其主要。 ● 下图显示了在具有多领导者复制的数据库中对时钟的危险使用：客户端B的写入比客户端A的写入要晚，但是B的写入具有较早的时间戳。\n最后写入胜利（LWW） ● 上述冲突叫做最后写入胜利 ● 时间戳导致的问题： ○ 数据库写入可能会神秘地消失：被滞后时钟节点的数据覆盖了 ○ LWW无法区分高频顺序写入和真正并发写入。需要额外的因果关系跟踪机制（例如版本向量），以防止违背因果关系。 ○ 两个节点很可能独立地生成具有相同时间戳的写入，特别是在时钟仅具有毫秒分辨率的情况下。所以，需要一个额外的决胜值（tiebreaker）（可以简单地是一个大随机数），但这种方法也可能会导致违背因果关系。\n能不能用NTP 同步避免不正确的排序？ ● 不能 ● 精度问题，石英钟漂移，网络时延。\n怎么避免时钟问题呢？ ● 逻辑时钟（logic clock）是基于递增计数器而不是振荡石英晶体，对于排序事件来说是更安全的选择。 ● 逻辑时钟不测量一天中的时间或经过的秒数，而仅测量事件的相对顺序（无论一个事件发生在另一个事件之前还是之后）。 ● 相反，用来测量实际经过时间的日历时钟和单调钟也被称为物理时钟（physical clock）。 ● 将在「顺序保证」章节讨论。\n时钟读数存在置信区间 ● NTP 同步可能有几毫秒到 100 毫秒的偏移。 ● 时钟读数更像是个置信区间：一个系统可能以95％的置信度认为当前时间处于本分钟内的第10.3秒和10.5秒之间，它可能没法比这更精确了。 ● 但是大多数系统不告诉你误差范围查询的接口，你不知道时间的误差是多少！ ● 不过 Spanner中的Google TrueTime API 明确地报告了本地时钟的置信区间：[最早，最晚]。\n全局快照的同步时钟 ● 「快照隔离和可重复读」章节中，讨论了快照隔离。它允许只读事务看到特定时间点的处于一致状态的数据库，且不会锁定和干扰读写事务。 ● 快照隔离最常见的实现需要单调递增的事务ID。如果写入比快照晚（即，写入具有比快照更大的事务ID），则该写入对于快照事务是不可见的。在单节点数据库上，一个简单的计数器就足以生成事务ID。 ● 但是当数据库分布在许多机器上，也许可能在多个数据中心中时，由于需要协调，（跨所有分区）全局单调递增的事务ID会很难生成。\n可以使用同步时钟的时间戳作为事务ID吗？ ● 理论上可以，实际上问题在于时钟精度的不确定性 ● Spanner以这种方式实现跨数据中心的快照隔离，它使用的是时间的置信区间。 ● 除此之外，没有主流数据库在分布式语义中使用时钟同步。\n进程暂停 设想一个单领导者的分布式数据库，一个节点怎么知道自己仍然是领导者？ ● 一种选择是领导者从其他节点获得一个租约（lease），类似一个带超时的锁。 ● 任一时刻只有一个节点可以持有租约——因此，当一个节点获得一个租约时，它知道它在某段时间内自己是领导者，直到租约到期。 ● 为了保持领导地位，节点必须周期性地在租约过期前续期。 ● 如果节点发生故障，就会停止续期，所以当租约过期时，另一个节点可以接管。\n使用租约的问题在哪？\n它依赖于同步时钟 程序执行过程卡顿，导致错过了续租约的时间，并继续处理了一些不安全的请求。而另一个节点接管了领导。 线程为什么会暂停很长时间？ ● 垃圾回收（GC） ● 虚拟机被挂起 ● 用户关闭笔记本电脑盖子 ● 操作系统上下文切换到另一个线程时 ● 应用程序同步读取磁盘，等待 IO ● 页面交换的时候，可能导致页面错误，要求将磁盘的页面装入内存。线程暂停。 ● 可以通过发送SIGSTOP信号来暂停Unix进程，例如通过在shell中按下Ctrl-Z。\n线程暂停的后果？ ● 上述事件都可以随时抢占（preempt） 正在运行的线程，并在稍后的时间恢复运行，而线程甚至不会注意到这一点。 ● 在单机上编码时，可以实现线程安全：互斥量，信号量，原子计数器，无锁数据结构，阻塞队列等等。 ● 不幸的是，这些工具并不能直接转化为分布式系统操作，因为分布式系统没有共享内存，只有通过不可靠网络发送的消息。 ● 分布式系统中的节点，必须假定其执行可能在任意时刻暂停相当长的时间，即使是在一个函数的中间。 ● 在暂停期间，世界的其它部分在继续运转，甚至可能因为该节点没有响应，而宣告暂停节点的死亡。最终暂停的节点可能会继续运行，在再次检查自己的时钟之前，甚至可能不会意识到自己进入了睡眠。\n响应时间保证 如何做到在特定事件响应的保证？ ● 飞机、火箭、机器人、骑车等系统中的软件件必须有一个特定的截止时间（deadline），如果截止时间不满足，可能会导致整个系统的故障。这就是所谓的硬实时（hard real-time） 系统。 ● 实现实时保证需要各级软件的支持： ○ 一个实时操作系统（RTOS），允许在指定的时间间隔内保证CPU时间的分配。 ○ 库函数必须申明最坏情况下的执行时间； ○ 动态内存分配可能受到限制或完全不允许（实时垃圾收集器存在，但是应用程序仍然必须确保它不会给GC太多的负担）； ○ 必须进行大量的测试和测量，以确保达到保证。 ● 实时系统太贵！ ● 因此大多数服务器端数据处理系统，必须承受非实时环境中运行的暂停和时钟不稳定性。\n限制垃圾收集的影响 怎么降低垃圾回收带来的影响？ ● 一种想法是在即将 GC 前发出警告，应用程序停止向该节点发出新的请求；等待其恢复后，再继续处理请求。 ● 另一种想法是垃圾回收处理短命对象（可以快速收集），并定期在积累大量长寿对象（因此需要完整GC）之前重新启动进程。重启时把节点的流量移走。\n知识、真相与谎言 何为真假？感知和测量不可靠，我们怎么确定信息的可靠性？这是个哲学问题。\n真相由多数所定义 真相到底是什么？ ● 节点不能根据自己的信息来判断自身的状态。 ● 因为节点可能随时失效，可能会暂停-假死，可能最终都无法恢复。 ● 相反，许多分布式算法都依赖于法定人数，即在节点之间进行投票：决策需要来自多个节点的最小投票数，以减少对于某个特定节点的依赖。 ● 个体哪怕没死，当被法定数量的节点宣告死亡时，它也必须被认定为死的。个体必须遵守法定决定并下台。\n最常见的法定人数是超过一半的绝对多数（尽管其他类型的法定人数也是可能的）。 第九章将继续讨论共识算法。\n领导者和锁 通常，一些东西在一个系统中只能有一个。如： ● 数据库分区的领导者只能有一个节点，以避免脑裂（split brain） ● 特定资源的锁或对象只允许一个事务/客户端持有，以防同时写入和损坏。 ● 一个特定的用户名只能被一个用户所注册，因为用户名必须唯一标识一个用户。\n分布式系统可能出现「唯一的节点」不止一个！ ● 一个节点认为自己是「唯一的节点」，但是有可能它以前是主节点，但是其他节点宣布它死亡了，此时已经出现了另外一个主节点。 ● 当该节点继续表现为『唯一的节点』，那么可能导致系统异常。\n图8-4 分布式锁的实现不正确：客户端1认为它仍然具有有效的租约，即使它已经过期，从而破坏了存储中的文件 防护令牌 确保一个被误认为自己是「唯一的节点」，不能扰乱系统的其它部分。实现这一目标的一个相当简单的技术就是防护（fencing）。 图8-5 只允许以增加防护令牌的顺序进行写操作，从而保证存储安全 具体做法： ● 每次锁定服务器授予锁或租约时，它还会返回一个防护令牌（fencing token），这个数字在每次授予锁定时都会增加。 ● 然后，我们可以要求客户端每次向存储服务发送写入请求时，都必须包含当前的防护令牌。 ● 当防护令牌已经过期了，那么就拒绝其写入。 ● 如果将ZooKeeper用作锁定服务，则可将事务标识zxid或节点版本cversion用作防护令牌。由于它们保证单调递增，因此它们具有所需的属性\n防护令牌需要注意？ ● 要求资源本身在检查令牌方面发挥积极作用，而不能仅仅依靠客户端检查自己的锁状态。 ● 需要在服务端进行检查令牌。\n防护令牌是缺点还是好事？ ● 好事 ● 服务不能假设客户总是守规矩并且明智的。\n拜占庭故障 防护令牌一定可靠吗？ ● 不一定 ● 果节点有意破坏系统的保证，则可以通过使用假防护令牌发送消息来轻松完成此操作。 ● 上文中都是假设节点是不可靠但诚实的。\n节点会撒谎吗？ ● 这种行为被称为拜占庭故障（Byzantine fault），在不信任的环境中达成共识的问题被称为拜占庭将军问题。 ● 当一个系统在部分节点发生故障、不遵守协议、甚至恶意攻击、扰乱网络时仍然能继续正确工作，称之为拜占庭容错（Byzantine fault-tolerant）\n什么情况下会出现拜占庭容错？ ● 在航空航天环境中，计算机内存或CPU寄存器中的数据可能被辐射破坏，导致其以任意不可预知的方式响应其他节点。 ● 在多个参与组织的系统中，一些参与者可能会试图欺骗或欺骗他人。\n我的系统需要考虑拜占庭故障吗？ ● 一般不需要。 ● 代价昂贵。\n为什么一般不需要考虑拜占庭故障？ ● Web 系统是中心化的，服务器决定客户端的行为。 ● 软件的 bug 可能被认为是拜占庭错误，但是拜占庭算法帮不了你：拜占庭算法要求超过 2/3 的节点正常工作。 ● 大多数系统中，如果攻击者可以渗透进一个节点，那么可能会渗透所有的节点，因为运行着相同的软件。因此，传统机制（认证，访问控制，加密，防火墙等）仍然是抵御攻击者的主要保护措施。\n弱谎言形式 什么是弱谎言？ ● 尽管我们假设节点通常是诚实的，但值得向软件中添加防止“撒谎”弱形式的机制。 ● 例如，由硬件问题导致的无效消息，软件错误和错误配置。 ● 这些保护机制虽然不能抵挡决心坚定的对手，但它们仍然是简单而实用的步骤，以提高可靠性。\n常见的弱谎言以及怎么处理？ ● 由于硬件问题或操作系统、驱动程序、路由器等中的错误，网络数据包有时会受到损坏。 ○ 解决办法： ■ TCP和UDP中的校验和所俘获 ■ 应用程序级协议中的校验和。 ● 可公开访问的应用程序必须仔细清理来自用户的任何输入 ○ 解决办法： ■ 检查值是否在合理的范围内 ■ 限制字符串的大小以防止通过大内存分配的拒绝服务 ● 一个配置错误的NTP服务器报告错误的时间 ○ 解决办法： ■ NTP客户端可以配置多个服务器地址 ■ 客户端联系所有的服务器，估计它们的误差，并检查大多数服务器是否对某个时间范围达成一致\n系统模型与现实 分布式系统问题要求我们以某种方式将我们期望在系统中发生的错误形式化——模型。\n关于时序假设，三种系统模型是常用的： 同步模型 ● 同步模型（synchronous model） 假设网络延迟、进程暂停和和时钟误差都是受限的。 ○ 这并不意味着完全同步的时钟或零网络延迟； ○ 这只意味着你知道网络延迟、暂停和时钟漂移将永远不会超过某个固定的上限。 ○ 同步模型并不是大多数实际系统的现实模型，因为（如本章所讨论的）无限延迟和暂停确实会发生。 部分同步模型 ● 部分同步（partial synchronous） 意味着一个系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟，进程暂停和时钟漂移的界限。 ○ 这是很多系统的现实模型：大多数情况下，网络和进程表现良好，否则我们永远无法完成任何事情。 ○ 但是我们必须承认，在任何时刻都存在时序假设偶然被破坏的事实。发生这种情况时，网络延迟、暂停和时钟错误可能会变得相当大。 异步模型 ● 在这个模型中，一个算法不允许对时序做任何假设——事实上它甚至没有时钟（所以它不能使用超时）。 ○ 一些算法被设计为可用于异步模型，但非常受限。\n除了时序问题，我们还要考虑节点失效。三种最常见的节点系统模型是： 崩溃-停止故障 ● 在崩溃停止（crash-stop） 模型中，算法可能会假设一个节点只能以一种方式失效，即通过崩溃。 ○ 这意味着节点可能在任意时刻突然停止响应，此后该节点永远消失——它永远不会回来。 崩溃-恢复故障 ● 我们假设节点可能会在任何时候崩溃，但也许会在未知的时间之后再次开始响应。 ○ 在崩溃-恢复（crash-recovery） 模型中，假设节点具有稳定的存储（即，非易失性磁盘存储）且会在崩溃中保留，而内存中的状态会丢失。 拜占庭（任意）故障 ● 节点可以做（绝对意义上的）任何事情，包括试图戏弄和欺骗其他节点，如上一节所述。\n对于真实系统的建模，具有崩溃-恢复故障（crash-recovery） 的部分同步模型（partial synchronous） 通常是最有用的模型。\n分布式算法如何应对这种模型？\n算法的正确性 怎么判断算法是正确的？ ● 为了定义算法是正确的，我们可以描述它的属性。 ● 我们可以写下我们想要的分布式算法的属性来定义它的正确含义。\n例如，如果我们正在为一个锁生成防护令牌，我们可能要求算法具有以下属性： 唯一性（uniqueness） ● 没有两个防护令牌请求返回相同的值。 单调序列（monotonic sequence） ● 如果请求 $x$ 返回了令牌 $t_x$，并且请求$y$返回了令牌$t_y$，并且 $x$ 在 $y$ 开始之前已经完成，那么$t_x \u0026lt;t_y$。 可用性（availability） ● 请求防护令牌并且不会崩溃的节点，最终会收到响应。\n如果一个系统模型中的算法总是满足它在所有我们假设可能发生的情况下的性质，那么这个算法是正确的。\n但是如果所有节点都挂了，可用性还有意义吗？\n安全性和活性 有必要区分两种不同的属性：安全（safety）属性和活性（liveness）属性。 ● 刚才的例子中，唯一性和单调序列是安全属性，而可用性是活性属性。\n两种性质的通俗理解/区别？ ● 思路：活性属性通常在定义中通常包括“最终”一词。 （是的，你猜对了——最终一致性是一个活性属性。） ● 安全通常被非正式地定义为：没有坏事发生 ● 活性通常就类似：最终好事发生。 ● 最好不要过度阅读非正式的定义，因为好和坏是主观的。\n安全和活性的实际定义是精确的和数学的： ● 如果安全属性被违反，我们可以指向一个特定的安全属性被破坏的时间点 ○ 例如，如果违反了唯一性属性，我们可以确定重复的防护令牌被返回的特定操作。违反安全属性后，违规行为不能被撤销——损失已经发生。 ● 活性属性反过来：在某个时间点（例如，一个节点可能发送了一个请求，但还没有收到响应），它可能不成立，但总是希望在未来能成立（即通过接受答复）。\n为什么要区分安全属性和活性属性？ ● 可以帮助我们处理困难的系统模型。 ● 对于分布式算法，在系统模型的所有可能情况下，要求始终保持安全属性是常见的。 ○ 也就是说，即使所有节点崩溃，或者整个网络出现故障，算法仍然必须确保它不会返回错误的结果（即保证安全属性得到满足）。 ● 但是，对于活性属性，我们可以提出一些注意事项： ○ 例如，只有在大多数节点没有崩溃的情况下，只有当网络最终从中断中恢复时，我们才可以说请求需要接收响应。 ○ 部分同步模型的定义要求系统最终返回到同步状态——即任何网络中断的时间段只会持续一段有限的时间，然后进行修复。\n将系统模型映射到现实世界 证明算法正确，那么现实系统中一定正确吗？ ● 虽然，安全属性和活性属性以及系统模型对于推理分布式算法的正确性非常有用。 ● 但是，现实的混乱事实再一次地让你咬牙切齿。 ● 很明显系统模型是对现实的简化抽象。\n那么，理论上抽象的系统模型是毫无价值的吗？ ● 恰恰相反。它很有价值。 ● 它们对于将实际系统的复杂性提取成一个个我们可以推理的可处理的错误类型是非常有帮助的，以便我们能够理解这个问题，并试图系统地解决这个问题。 ● 我们可以证明算法是正确的，通过表明它们的属性在某个系统模型中总是成立的。\n实际上该怎么办？ ● 因为理论分析可以发现算法中的问题，这种问题可能会在现实系统中长期潜伏，直到你的假设（例如，时序）因为不寻常的情况被打破。 ● 理论分析与经验测试同样重要。\n本章小结 在本章中，我们讨论了分布式系统中可能发生的各种问题，包括： ● 当您尝试通过网络发送数据包时，数据包可能会丢失或任意延迟。同样，答复可能会丢失或延迟，所以如果你没有得到答复，你不知道消息是否发送成功了。 ● 节点的时钟可能会与其他节点显著不同步（尽管您尽最大努力设置NTP），它可能会突然跳转或跳回，依靠它是很危险的，因为您很可能没有好的方法来测量你的时钟的错误间隔。 ● 一个进程可能会在其执行的任何时候暂停一段相当长的时间（可能是因为停止所有处理的垃圾收集器），被其他节点宣告死亡，然后再次复活，却没有意识到它被暂停了。\n这类部分失效（partial failure） 可能发生的事实是分布式系统的决定性特征。每当软件试图做任何涉及其他节点的事情时，偶尔就有可能会失败，或者随机变慢，或者根本没有响应（最终超时）。在分布式系统中，我们试图在软件中建立部分失效的容错机制，这样整个系统在即使某些组成部分被破坏的情况下，也可以继续运行。\n怎么处理错误？ 为了容忍错误，第一步是检测它们，但即使这样也很难。大多数系统没有检测节点是否发生故障的准确机制，所以大多数分布式算法依靠超时来确定远程节点是否仍然可用。但是，超时无法区分网络失效和节点失效，并且可变的网络延迟有时会导致节点被错误地怀疑发生故障。此外，有时一个节点可能处于降级状态：例如，由于驱动程序错误，千兆网卡可能突然下降到1 Kb/s的吞吐量。这样一个“跛行”而不是死掉的节点可能比一个干净的失效节点更难处理。 一旦检测到故障，使系统容忍它也并不容易：没有全局变量，没有共享内存，没有共同的知识，或机器之间任何其他种类的共享状态。节点甚至不能就现在是什么时间达成一致，就不用说更深奥的了。信息从一个节点流向另一个节点的唯一方法是通过不可靠的网络发送信息。重大决策不能由一个节点安全地完成，因此我们需要一个能从其他节点获得帮助的协议，并争取达到法定人数以达成一致。\n但是，正如在第二部分的介绍中所讨论的那样，可伸缩性并不是使用分布式系统的唯一原因。容错和低延迟（通过将数据放置在距离用户较近的地方）是同等重要的目标，而这些不能用单个节点实现。 在本章中，我们也转换了几次话题，探讨了网络、时钟和进程的不可靠性是否是不可避免的自然规律。我们看到这并不是：有可能给网络提供硬实时的响应保证和有限的延迟，但是这样做非常昂贵，且导致硬件资源的利用率降低。大多数非安全关键系统会选择便宜而不可靠，而不是昂贵和可靠。 我们还谈到了超级计算机，它们采用可靠的组件，因此当组件发生故障时必须完全停止并重新启动。相比之下，分布式系统可以永久运行而不会在服务层面中断，因为所有的错误和维护都可以在节点级别进行处理——至少在理论上是如此。 （实际上，如果一个错误的配置变更被应用到所有的节点，仍然会使分布式系统瘫痪）。 ","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E5%85%AB%E7%AB%A0/","summary":"第八章： 分布式系统的挑战 分布式系统面临哪些挑战？ ● 前面几章讨论的副本故障切换、复制延迟、事务控制； ● 本章讨论的不可靠网络、时钟和时序问题等等","title":"DDIA第八章"},{"content":"没有供应，美元就是废纸 美元和鱼挂钩的故事 上个周末花了一个下午把《小岛经济学》这本书看完了。这本书讲的非常有意思，由浅入深的带你了解经济学的一点基本知识。不过，我觉得也只能用来图一乐，并不能代表主流看法。实际上学习经济学我觉得还是需要把一些基础理论过一遍。比如曼昆的《经济学原理》，这本书也是我最近正在看的。\n《小岛经济学》是彼得·希夫、安德鲁·希夫。从最简单的生产消费关系开始讲起，捕鱼-生产，吃鱼-消费，讲到生产力提升之后所产生的一系列“经济化学反应”。后面发布了纸币与鱼挂钩。以此来比喻美元与世界交易挂钩，这里的交易包括石油等所有生产出来的物品。鱼代表的是实实在在的商品；美元就是货币，就是一张纸；契约关系搭建了美元与鱼的关系，没有鱼的支撑美元就是废纸一张，所以，作者更强调供给。在整本书中，作者都在强调美索尼亚国是个玩金融的国家，他们的公民已经不太参与社会生产来完成财富积累了，而是通过金融通过以及债券来收割所有其他岛的资产。只要人们相信他们发行的债券是可以去其他地方买到东西的，那么他们就永远可以只靠发行债券过日子。但是作者强调了总会有一天靠这种方式赚钱的运气会用光，到时候还是需要参与到社会生产中来的。书中的中岛帝国，其实指的就是中国，中国持有了很多美国债券，是美国第一大债券持有国，因此中国也不希望美国债券贬值，但是可以抛售美债用来作为贸易战筹码之一吧。\n美国用金融游戏，就可以获得我们生产的商品，我们自己生产的商品自己却不能享受。作者在书中的后半部分也说了，关于中岛帝国如何脱钩的问题，其实就是我们现在所说的内循环。我们自己生产的商品，自己消费。\n所以当一个货币能够成为世界交易货币的时候，那么他确实就可以进行收割，通过金融游戏来空手套白狼。这也是为什么美元一定要和石油挂钩，为什么美国当时为什么要打那个仗。这涉及到他们的核心利益。\n通货紧缩，印美元就可以了吗 作者认为通货紧缩其实是经济运行的一部分，是必经阶段，也是经济恢复平衡的必要阶段，某种程度上是好事，是经济自我疗伤的阶段。而政府部门却认为价格下降是经济下行，会超发货币供应来应对，其实是不对的，应该顺应规律，进行供给侧改革。他在书中举例论证：通货紧缩会导致商品价格下降，价格下降到一定程度的话会有人去购买的。人们并不是不买了，而是人们在通货紧缩的状况下都会降低预算。\n当局者担心通货紧缩或者楼市大跌带来的风险，所以会干预经济，但是当全民都把房产作为优质资产时，尤其是政府鼓励主导房地产作为刺激经济的手段时就会对其他产业产生不公平的影响，就会阻碍其他资源的有效发挥，比如生产竹子或绳子的企业，本来可以用到其他新兴行业，但是房地产是最赚钱的，自然就会用到房地产行业。\n但是房地产行业已经饱和了，已经没有什么提高生产力的可能了，根本提高不了生产效率，所以对房市的扶持就是对未来机会的扼杀。\n反观现在，情况比较乐观，因为当前是供给侧改革，要改就必须要创新，就必须提高生产率，必须扶持提高生产力的企业，而不是房产，从这一角度讲，未来科技才是重中之重！\n作者认为一国的经济不会因为消费增长而增长，而是经济的增长而增长也就是生产力，生产效率的增长而增长\n在楼市。为了刺激消费，让本没有太大支付能力的人，通过贷款，让人拥有了假象般的繁荣的购买力，这种刺激消费，这种毕其功力于一役的做法，导致了一辈子不能再去进行其他投资，抑制了创新\n棚屋价格上涨的问题 棚屋的价格是如何上涨的 书中，作者专门化了几个章节来讲述了小岛中人们因为生产率的提高，经济繁荣，利率降低，人们开始想要住上更新，更大，更加美观的棚屋。以前，岛民需要存储很多年的积蓄才能购买棚屋，但是现在有了贷款，即使借款人现在的储蓄低于棚屋价格也没有关系，他们也可以立即购买。但是银行为了抵押物，需要他们先付一笔首付。即使后面贷款还不上了，也可以没收棚屋来以资抵债。作者在书中也写道了，岛中的人们是如何通过棚屋置换来实现资产的快速增值的。信心使得人们相信，棚屋价格是一定会上涨的，这也导致了各种装修行业的繁荣。但是作者也在书中说明了后面的危机，当人们某一天对棚屋上涨失去信心的时候，这个时候也许是某个政策，某个突发事件等等，就会导致棚屋价格泡沫的破裂。\n棚屋价格泡沫是如何破裂的 作者在书中指出，当房市达到巅峰时，多年来涌入经济体中的低息贷款就会停止，即便是在房市进入萧条之后没有其他经济问题，没有了那些自由的现金流，经济也会进入萎缩，为了恢复经济，经济衰退不是必须的，确实必要的。就算政府做了很多的刺激经济的政策，经济也不会见的好转。经济有其自身规律，经济增长才是关键。\n中美贸易战问题 该书成书早于中美贸易战，但是书中却预测到了中美贸易战的问题，也就是书中中岛帝国和美索尼亚国之间的贸易问题。书中也说到中岛帝国最后会想到内循环的问题。\n奥地利学派与凯尔斯主义 奥地利经济学派：起源于19世纪70年代。主张自由经济，即政府不应该插手经济发展。\n与之相对的凯恩斯主义: 起源于20世纪30年代经济大萧条时期。\n他们的主张是，国家应干预和调节经济并使经济平衡发展，也就是传说中的那只看不见的手\n其实这两个学派的观点的产生，都有其特定的时代与国家背景。经济学界常年争论不休，也许但是各有道理吧。但是呢，我觉得政府调控是有必要的，不过对于经济规律政府的调控是没有用的。\n","permalink":"https://csqread.top/posts/read/%E8%AF%BB%E5%B0%8F%E5%B2%9B%E7%BB%8F%E6%B5%8E%E5%AD%A6%E6%9C%89%E6%84%9F/","summary":"没有供应，美元就是废纸 美元和鱼挂钩的故事 上个周末花了一个下午把《小岛经济学》这本书看完了。这本书讲的非常有意思，由浅入深的带你了解经济学的一","title":"读《小岛经济学》有感"},{"content":"背景 原因 首先说明一下相关背景，因为最近整个社会对于经济预期不高，整体经济出现通缩迹象，楼市萎靡不振，各个城市的楼价出现不同程度的下滑。因此在各大机构和个人媒体中都充斥着各种经济分析的视频与文章。但是这些与我的实际生活其实相差比遥远。所以，我想对我身边农村的中老年人收入做一个分析。看看现在的中老年人的收入来源有哪些，他们不在大城市，又面临着即将过退休年龄与过退休年龄的问题。他们的基本的经济生活状况如何得到保证呢？\n城市背景 我的家乡是在皖南的一个小县城，并不代表大多数人的情况，调查中的结果经供参考，没有太大的价值，也是我自己做一个记录，以及我与父母长辈聊天过程中所产生的一些思考。\n中年人的经济来源 中年人，我这里指的是在退休年龄之前并且他们的子女已经步入社会，有劳动能力的人\n1、干装修 我们那边有一个传统手艺，就是干装修。父辈基本上都是做这个的，从泥瓦匠到木工到油漆工，有的一个家族几个兄弟各自在自己的领域都有一门装修手艺。在十几年前，大家都在全国各地奔波，但是现在很多人已经步入中年，因此也不再出门奔波，在家乡附近做做装修，但是工资远没有在大城市高，一般木工一天只有300左右，油漆工200多，泥瓦工大概400，这是在镇上或者村里的价格，县城的工价更低。其中有好几个原因。一是县城的工人也比较多，有价格竞争。二是县城有装修公司，也会有互相竞价行为。所以散户没有优势。\n2、县城流水线工作 这些年我们县城承接了一部分长三角过来的流水线工厂，包括新能源汽车零部件加工，床上四件套，口罩等轻工业、手工业类产品的工厂。这些工厂一般是白天和晚上两班倒。白天的工价大概130，晚上150.有些工厂比较有技术门槛一点，一天会有200多。工作时长一般是在12小时。一般不会签约劳动合同，基本上是靠介绍进去工作，老板会给员工交工伤保险，这也是为了保护老板自己，但是没有五险一金。在这些工厂流水线作业的中年妇女居多。一般是孩子在县城读书或者想挣钱补贴家用。\n3、新兴产业园区工作 这种工作一般在指定的时间点才会有\n旅游业 在各种节假日的时候，旅游景点其他地区过来卖饮料，小吃的会缺少帮手，有些就会通过介绍等去做这样一些景区卖烧烤，冷饮等的工作，一天工价60-80不等。比如景区人流量较大的时候，就需要帮忙烤烧烤的，需要帮忙做冷饮汁的，帮忙吆喝的，景区各个游玩入口收门票的，这些都是本地人在做。\n新兴农产业 夏季的时候会有一些新兴农产业需要人手，比如蓝莓、草莓的采摘、分拣、装箱，这些工作大概120一天。一天的工作时长10个小时，没有保险，没有合同。并不是每天都有，只是在对应的季节才会有。\n4、乡村教师 这群人在我的亲戚中是过的比较舒服与滋润的，也是父辈同辈中家底比较充裕的。据我了解，乡村教师现在每个月大概能有4500元的基本工资，五险一金的情况不清楚，每年年终大概还能拿到4-5万元的年终奖金。\n以上是我所接触到的普通最底层大众的一些能够挣到钱的工作与机会了。其实乡村教师应该不算在其内的，因为我想讨论的并不是这类人群，包括县县城乡镇的公务员，领导机关干部，企业老板等。这类人群的退休生活是有所保障的。我不想去讨论这些人群不是因为我没有机会接触到这些人群，而是关注这些人的工作与机会情况并没有太大的意义，我国的基本情况还是大多数人的收入每月不足1000元，在底层老百姓中，每月高于3000元的收入已经非常多了。这些人才是影响整个社会稳定与国家兴衰的关键。\n这次先写这么多，后面想到了再补充\n","permalink":"https://csqread.top/posts/life/%E5%AE%B6%E4%B9%A1%E4%B8%AD%E8%80%81%E5%B9%B4%E4%BA%BA%E6%94%B6%E5%85%A5%E8%B0%83%E6%9F%A5%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A/","summary":"背景 原因 首先说明一下相关背景，因为最近整个社会对于经济预期不高，整体经济出现通缩迹象，楼市萎靡不振，各个城市的楼价出现不同程度的下滑。因此在","title":"家乡中老年人收入调查分析报告"},{"content":"String 如何提升性能？ 这几天我在看《Effective Java》,其中有一章提到我们在使用String的时候要慎用正则表达式，因为在注重性能的场景，这种方法不适用。我不懂是个什么情况，就去google了一下。于是把所有相关String的操作全部了解了一遍，也算是大概明白了为什么要慎用正则表达式。因此也来做个记录\n字符串的特性 想要了解 String 的特性就必须从它的源码入手，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 源码基于 JDK 1.8 public final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { // String 值的实际存储容器 private final char value[]; public String() { this.value = \u0026#34;\u0026#34;.value; } public String(String original) { this.value = original.value; this.hash = original.hash; } // 忽略其他信息 } 从他的源码我们可以看出，String 类以及它的 value[] 属性都被 final 修饰了，其中 value[] 是实现字符串存储的最终结构，而 final 则表示“最后的、最终的”。 我们知道，被 final 修饰的类是不能被继承的，也就是说此类将不能拥有子类，而被 final 修饰的变量即为常量，它的值是不能被改变的。这也就说当 String 一旦被创建之后，就不能被修改了。\nString 为什么不能被修改？ String 的类和属性 value[] 都被定义为 final 了，这样做的好处有以下三点：\n安全性：当你在调用其他方法时，比如调用一些系统级操作指令之前，可能会有一系列校验，如果是可变类的话，可能在你校验过后，它的内部的值又被改变了，这样有可能会引起严重的系统崩溃问题，所以迫使 String 设计为 final 类的一个重要原因就是出于安全考虑； 高性能：String 不可变之后就保证的 hash 值的唯一性，这样它就更加高效，并且更适合做 HashMap 的 key- value 缓存； 节约内存：String 的不可变性是它实现字符串常量池的基础，字符串常量池指的是字符串在创建时，先去“常量池”查找是否有此“字符串”，如果有，则不会开辟新空间创作字符串，而是直接把常量池中的引用返回给此对象，这样就能更加节省空间。例如，通常情况下 String 创建有两种方式，直接赋值的方式，如 String str=\"Java\"；另一种是 new 形式的创建，如 String str = new String(\"Java\")。当代码中使用第一种方式创建字符串对象时，JVM 首先会检查该对象是否在字符串常量池中，如果在，就返回该对象引用，否则新的字符串将在常量池中被创建。这种方式可以减少同一个值的字符串对象的重复创建，节约内存。String str = new String(\"Java\") 这种方式，首先在编译类文件时，“Java”常量字符串将会放入到常量结构中，在类加载时，“Java”将会在常量池中创建；其次，在调用 new 时，JVM 命令将会调用 String 的构造函数，同时引用常量池中的“Java”字符串，在堆内存中创建一个 String 对象，最后 str 将引用 String 对象。 不要直接+=字符串 通过上面的内容，我们知道了 String 类是不可变的，那么在使用 String 时就不能频繁的 += 字符串了。\n优化前代码：\n1 2 3 4 5 6 7 public static String doAdd() { String result = \u0026#34;\u0026#34;; for (int i = 0; i \u0026lt; 10000; i++) { result += (\u0026#34; i:\u0026#34; + i); } return result; } 有人可能会问，我的业务需求是这样的，那我该如何实现？ 官方为我们提供了两种字符串拼加的方案：StringBuffer 和 StringBuilder，其中 StringBuilder 为非线程安全的，而 StringBuffer 则是线程安全的，StringBuffer 的拼加方法使用了关键字 synchronized 来保证线程的安全，源码如下：\n1 2 3 4 5 6 @Override public synchronized StringBuffer append(CharSequence s) { toStringCache = null; super.append(s); return this; } 也因为使用 synchronized 修饰，所以 StringBuffer 的拼加性能会比 StringBuilder 低。 那我们就用 StringBuilder 来实现字符串的拼加，优化后代码：\n1 2 3 4 5 6 7 public static String doAppend() { StringBuilder sb = new StringBuilder(); for (int i = 0; i \u0026lt; 10000; i++) { sb.append(\u0026#34; i:\u0026#34; + i); } return sb.toString(); } 接下来，我们要思考一个问题：为什么 StringBuilder.append() 方法比 += 的性能高？而且拼接的次数越多性能的差距也越大？\n当我们打开 StringBuilder 的源码，就可以发现其中的“小秘密”了，StringBuilder 父类 AbstractStringBuilder 的实现源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 abstract class AbstractStringBuilder implements Appendable, CharSequence { char[] value; int count; @Override public AbstractStringBuilder append(CharSequence s, int start, int end) { if (s == null) s = \u0026#34;null\u0026#34;; if ((start \u0026lt; 0) || (start \u0026gt; end) || (end \u0026gt; s.length())) throw new IndexOutOfBoundsException( \u0026#34;start \u0026#34; + start + \u0026#34;, end \u0026#34; + end + \u0026#34;, s.length() \u0026#34; + s.length()); int len = end - start; ensureCapacityInternal(count + len); for (int i = start, j = count; i \u0026lt; end; i++, j++) value[j] = s.charAt(i); count += len; return this; } // 忽略其他信息... } 而 StringBuilder 使用了父类提供的 char[] 作为自己值的实际存储单元，每次在拼加时会修改 char[] 数组，StringBuilder toString() 源码如下：\n1 2 3 4 5 @Override public String toString() { // Create a copy, don\u0026#39;t share the array return new String(value, 0, count); } 综合以上源码可以看出：StringBuilder 使用了 char[] 作为实际存储单元，每次在拼加时只需要修改 char[] 数组即可，只是在 toString() 时创建了一个字符串；而 String 一旦创建之后就不能被修改，因此在每次拼加时，都需要重新创建新的字符串，所以 StringBuilder.append() 的性能就会比字符串的 += 性能高很多。\n善用 intern 方法 善用 String.intern() 方法可以有效的节约内存并提升字符串的运行效率，先来看 intern() 方法的定义与源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /** * Returns a canonical representation for the string object. * \u0026lt;p\u0026gt; * A pool of strings, initially empty, is maintained privately by the * class {@code String}. * \u0026lt;p\u0026gt; * When the intern method is invoked, if the pool already contains a * string equal to this {@code String} object as determined by * the {@link #equals(Object)} method, then the string from the pool is * returned. Otherwise, this {@code String} object is added to the * pool and a reference to this {@code String} object is returned. * \u0026lt;p\u0026gt; * It follows that for any two strings {@code s} and {@code t}, * {@code s.intern() == t.intern()} is {@code true} * if and only if {@code s.equals(t)} is {@code true}. * \u0026lt;p\u0026gt; * All literal strings and string-valued constant expressions are * interned. String literals are defined in section 3.10.5 of the * \u0026lt;cite\u0026gt;The Java\u0026amp;trade; Language Specification\u0026lt;/cite\u0026gt;. * * @return a string that has the same contents as this string, but is * guaranteed to be from a pool of unique strings. */ public native String intern(); 可以看出 intern() 是一个高效的本地方法，它的定义中说的是，当调用 intern 方法时，如果字符串常量池中已经包含此字符串，则直接返回此字符串的引用，如果不包含此字符串，先将字符串添加到常量池中，再返回此对象的引用。 那什么情况下适合使用 intern() 方法？ Twitter 工程师曾分享过一个 String.intern() 的使用示例，Twitter 每次发布消息状态的时候，都会产生一个地址信息，以当时 Twitter 用户的规模预估，服务器需要 32G 的内存来存储地址信息。\n1 2 3 4 5 6 7 public class Location { private String city; private String region; private String countryCode; private double longitude; private double latitude; } 考虑到其中有很多用户在地址信息上是有重合的，比如，国家、省份、城市等，这时就可以将这部分信息单独列出一个类，以减少重复，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class SharedLocation { private String city; private String region; private String countryCode; } public class Location { private SharedLocation sharedLocation; double longitude; double latitude; } 通过优化，数据存储大小减到了 20G 左右。但对于内存存储这个数据来说，依然很大，怎么办呢？ Twitter 工程师使用 String.intern() 使重复性非常高的地址信息存储大小从 20G 降到几百兆，从而优化了 String 对象的存储。 实现的核心代码如下：\n1 2 3 4 SharedLocation sharedLocation = new SharedLocation(); sharedLocation.setCity(messageInfo.getCity().intern()); sharedLocation.setCountryCode(messageInfo.getRegion().intern()); sharedLocation.setRegion(messageInfo.getCountryCode().intern()); 从 JDK1.7 版本以后，常量池已经合并到了堆中，所以不会复制字符串副本，只是会把首次遇到的字符串的引用添加到常量池中。此时只会判断常量池中是否已经有此字符串，如果有就返回常量池中的字符串引用。 这就相当于以下代码：\n1 2 3 String s1 = new String(\u0026#34;Java中文社群\u0026#34;).intern(); String s2 = new String(\u0026#34;Java中文社群\u0026#34;).intern(); System.out.println(s1 == s2); 慎重使用 Split 方法 这里就是我想知道的为什么要慎用正则表达式，以防止其影响性能\n之所以要劝各位慎用 Split 方法，是因为 Split 方法大多数情况下使用的是正则表达式，这种分割方式本身没有什么问题，但是由于正则表达式的性能是非常不稳定的，使用不恰当会引起回溯问题，很可能导致 CPU 居高不下。\n例如以下正则表达式：\n1 2 3 4 5 6 7 String badRegex = \u0026#34;^([hH][tT]{2}[pP]://|[hH][tT]{2}[pP][sS]://)(([A-Za-z0-9-~]+).)+([A-Za-z0-9-~\\\\\\\\/])+$\u0026#34;; String bugUrl = \u0026#34;http://www.apigo.com/dddp-web/pdf/download?request=6e7JGxxxxx4ILd-kExxxxxxxqJ4-CHLmqVnenXC692m74H38sdfdsazxcUmfcOH2fAfY1Vw__%5EDadIfJgiEf\u0026#34;; if (bugUrl.matches(badRegex)) { System.out.println(\u0026#34;match!!\u0026#34;); } else { System.out.println(\u0026#34;no match!!\u0026#34;); } Java 正则表达式使用的引擎实现是 NFA（Non deterministic Finite Automaton，不确定型有穷自动机）自动机，这种正则表达式引擎在进行字符匹配时会发生回溯（backtracking），而一旦发生回溯，那其消耗的时间就会变得很长，有可能是几分钟，也有可能是几个小时，时间长短取决于回溯的次数和复杂度。\n为了更好地解释什么是回溯，我们使用以下面例子进行解释：\n1 2 text = \u0026#34;abbc\u0026#34;; regex = \u0026#34;ab{1,3}c\u0026#34;; 上面的这个例子的目的比较简单，匹配以 a 开头，以 c 结尾，中间有 1-3 个 b 字符的字符串。 NFA 引擎对其解析的过程是这样子的：\n首先，读取正则表达式第一个匹配符 a 和 字符串第一个字符 a 比较，匹配上了，于是读取正则表达式第二个字符； 读取正则表达式第二个匹配符 b{1,3} 和字符串的第二个字符 b 比较，匹配上了。但因为 b{1,3} 表示 1-3 个 b 字符串，以及 NFA 自动机的贪婪特性（也就是说要尽可能多地匹配），所以此时并不会再去读取下一个正则表达式的匹配符，而是依旧使用 b{1,3} 和字符串的第三个字符 b 比较，发现还是匹配上了，于是继续使用 b{1,3} 和字符串的第四个字符 c 比较，发现不匹配了，此时就会发生回溯； 发生回溯后，我们已经读取的字符串第四个字符 c 将被吐出去，指针回到第三个字符串的位置，之后程序读取正则表达式的下一个操作符 c，然后再读取当前指针的下一个字符 c 进行对比，发现匹配上了，于是读取下一个操作符，然后发现已经结束了。 这就是正则匹配执行的流程和简单的回溯执行流程，而上面的示例在匹配到“com/dzfp-web/pdf/download?request=6e7JGm38jf\u0026hellip;..”时因为贪婪匹配的原因，所以程序会一直读后面的字符串进行匹配，最后发现没有点号，于是就一个个字符回溯回去了，于是就会导致了 CPU 运行过高。\n所以我们应该慎重使用 Split() 方法，我们可以用 String.indexOf() 方法代替 Split() 方法完成字符串的分割。如果实在无法满足需求，你就在使用 Split() 方法时，对回溯问题加以重视就可以了。\n通过这里，我也是明白了《Effective Java》中所说的，慎用正则表达式的原因，感谢这篇博文 String性能提升10倍的几个方法\n参考文章： 1、String性能提升10倍的几个方法\n","permalink":"https://csqread.top/posts/tech/%E5%85%B3%E4%BA%8Ejava-string%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD/","summary":"String 如何提升性能？ 这几天我在看《Effective Java》,其中有一章提到我们在使用String的时候要慎用正则表达式，因为在注重性能的场景","title":"关于Java String如何提升性能"},{"content":"第七章：事务 为什么有事务？ ● 分布式数据系统，可能会出各种错误。 ● 实现容错机制工作量巨大。需要仔细考虑所有可能出错的事情，并进行大量的测试，以确保解决方案真正管用。 ● 数十年来，事务（transaction） 一直是简化这些问题的首选机制。\n什么是事务？ ● 事务是应用程序将多个读写操作组合成一个逻辑单元的一种方式。 ● 从概念上讲，事务中的所有读写操作被视作单个操作来执行： ○ 整个事务要么成功（提交（commit））要么失败（中止（abort），回滚（rollback））。 ○ 如果失败，应用程序可以安全地重试。 ○ 对于事务来说，应用程序的错误处理变得简单多了，因为它不用再担心部分失败的情况了，即某些操作成功，某些失败（无论出于何种原因）。\n事务是天然存在的吗？ ● 不是天然存在，是为了简化应用编程模型而创建的。 ● 给应用程序提供了安全保证。\n事务必须存在吗？ ● 不是所有应用都要有事务 ● 有时候弱化事务保证、或完全放弃事务也是有好处的（例如，为了获得更高性能或更高可用性）。 ● 一些安全属性也可以在没有事务的情况下实现。\n怎样知道你是否需要事务？ ● 首先需要确切理解事务可以提供的安全保障，以及它们的代价。 ● 尽管乍看事务似乎很简单，但实际上有许多微妙但重要的细节在起作用。\n事务的棘手概念 ● 几乎所有的关系型数据库和一些非关系数据库都支持事务。 ● 2000 年以后，非关系（NoSQL）数据库开始普及。很多新一代数据库放弃了或者弱化了事务。 ● 事务是一种权衡。\nACID的含义 ● 原子性（Atomicity） ● 一致性（Consistency） ● 隔离性（Isolation） ● 持久性（Durability）\n不同数据库的ACID实现并不相同。\n原子性 原子是指不能分解成小部分的东西。\n多线程编程 ● 如果一个线程执行一个原子操作，这意味着另一个线程无法看到该操作的一半结果。 ● 系统只能看到操作前或者操作后的状态，而不能看到中间状态。\nACID 的原子性 ● ACID的原子性并不是关于 并发（concurrent） 的。 ○ 隔离性 I 才是关于并发的。 ● ACID 的原子性是 能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。\n原子性的用途 ● 原子性描述了当客户想进行多次写入，但在一些写操作处理完之后出现故障的情况 ● 如果这些写操作被分组到一个原子事务中，并且该事务由于错误而不能完成（提交），则该事务将被中止，并且数据库必须丢弃或撤消该事务中迄今为止所做的任何写入。\n为什么要有原子性？ ● 如果没有原子性，在多处更改进行到一半时发生错误，很难知道哪些更改已经生效，哪些没有生效。该应用程序可以再试一次，但冒着进行两次相同变更的风险，可能会导致数据重复或错误的数据。 ● 原子性简化了这个问题：如果事务被中止（abort），应用程序可以确定它没有改变任何东西，所以可以安全地重试。\n一致性 ● ACID一致性的概念是，对数据的一组特定约束必须始终成立。即不变量（invariants）。 ○ 例如在会计系统中，所有账户整体上必须借贷相抵。 ● 如果一个事务开始于一个满足这些不变量的有效数据库，且在事务处理期间的任何写入操作都保持这种有效性，那么可以确定，不变量总是满足的。一致性不属于数据库的属性。 ● 一致性取决于应用程序对不变量的理解，应用程序负责正确定义它的事务，并保持一致性。 ● 这并不是数据库可以保证的事情：如果你写入违反不变量的脏数据，数据库也无法阻止你。—— 数据库只管存储。 ● 原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。因此，字母C不属于ACID。\n隔离性 ● 多个客户端同时访问相同的数据库记录，可能会遇到并发问题。 ● ACID意义上的隔离性意味着，同时执行的事务是相互隔离的：它们不能相互冒犯。 ● 传统的数据库教科书将隔离性形式化为可串行化（Serializability），这意味着每个事务可以假装它是唯一在整个数据库上运行的事务。 ● 数据库确保当多个事务被提交时，结果与它们串行运行（一个接一个）是一样的，尽管实际上它们可能是并发运行的\n持久性 ● 持久性 是一个承诺，即一旦事务成功完成，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。\n在单节点数据库中 ● 持久性通常意味着数据已被写入非易失性存储设备，如硬盘或SSD。 ● 它通常还包括预写日志或类似的文件（请参阅“让B树更可靠”），以便在磁盘上的数据结构损坏时进行恢复。\n在带复制的数据库中 ● 持久性可能意味着数据已成功复制到一些节点。\n如何做到持久性？ ● 为了提供持久性保证，数据库必须等到这些写入或复制完成后，才能报告事务成功提交。 ● 完美的持久性是不存在的：万一所有硬盘和备份同时被销毁。\n单对象和多对象操作 客户端在同一事务中执行多次写入时，数据库应该做的事： 原子性 ○ 不会部分失败——保证 all-or-nothing 隔离性 ○ 同时运行的事务不应该互相干扰。 ■ 事务如果多次写入，要么事务看到全部写入结果，要么什么都看不到。\n通常需要多对象事务（multi-object transaction） 来保持多个数据对象的同步。\n一个邮件应用的例子： ● 执行以下查询来显示用户未读邮件数量：\n1 SELECT COUNT（*）FROM emails WHERE recipient_id = 2 AND unread_flag = true ● 如果邮件太多，觉得查询太慢，于是用了单独的字段存储未读邮件的数量。现在每当一个新消息写入时，必须也增长未读计数器，每当一个消息被标记为已读时，也必须减少未读计数器。 ● 异常情况： ○ 邮件列表里显示有未读消息，但计数器显示为零未读消息，因为计数器增长还没有发生 为了满足原子性：插入邮件和更新未读邮件数目需要状态一致，要么都成功，要么都失败（回滚）：\n多对象事务写入方法？ ● 需要某种方式来确定哪些读写操作属于同一个事务。 ● 在关系型数据库中，通常基于客户端与数据库服务器的TCP连接：在任何特定连接上，BEGIN TRANSACTION 和 COMMIT 语句之间的所有内容，被认为是同一事务的一部分（不完美）。 ● 许多非关系数据库，并没有将这些操作组合在一起的方法。所以可能让数据库处于部分更新的状态。\n单对象写入 ● 当单个对象发生改变时，原子性和隔离性也是适用的。 ● 存储引擎一个几乎普遍的目标是：对单节点上的单个对象（例如键值对）上提供原子性和隔离性。\n实现方法 ● 原子性可以通过使用日志来实现崩溃恢复 ● 可以使用每个对象上的锁来实现隔离（每次只允许一个线程访问对象）\n更高级的原子操作 ● 1. 自增操作。 ● 2. 比较和设置（CAS, compare-and-set） 操作，仅当值没有被其他并发修改过时，才允许执行写操作。 ● 上面两种对但对象操作有用，但不是通常意义上的事务。 ● 事务通常被理解为，将多个对象上的多个操作合并为一个执行单元的机制。\n多对象事务的必要性 为什么许多分布式数据存储已经放弃了多对象事务？ ● 多对象事务很难跨分区实现； ● 而且在需要高可用性或高性能的情况下，它们可能会碍事。\n问题： 我们是否需要多对象事务？是否有可能只用键值数据模型和单对象操作来实现任何应用程序？\n需要协调写入几个不同对象的场景： ● 关系数据模型中，一个表中的行通常具有对另一个表中的行的外键引用。 ● 在文档数据模型中，需要一起更新的字段通常在同一个文档中，这被视为单个对象——更新单个文档时不需要多对象事务。但是，当需要更新非规范化的信息时，需要一次更新多个文档。比如上面邮件未读数目的例子。 ● 在具有二级索引的数据库中（除了纯粹的键值存储以外几乎都有），每次更改值时都需要更新索引。\n没有原子性，错误处理就要复杂得多，缺乏隔离性，就会导致并发问题。\n处理错误和中止 ● 事务的一个关键特性是，如果发生错误，它可以中止并安全地重试。 ● ACID数据库基于这样的哲学：如果数据库有违反其原子性，隔离性或持久性的危险，则宁愿完全放弃事务，而不是留下半成品。 ● 但并不是所有的系统都遵循这个哲学。特别是具有无主复制的数据存储，主要是在“尽力而为”的基础上进行工作。——所以，从错误中恢复是应用程序的责任。\n重试一个中止的事务并不完美： ● 如果事务实际上成功了，但是在服务器试图向客户端确认提交成功时网络发生故障，那么重试事务导致事务执行了两次——除非有额外的应用级除重机制。 ● 如果错误是由于负载过大造成的，则重试事务将使问题变得更糟，而不是更好。需要限制重试次数、采用指数退避算法。 ● 仅在临时性错误（例如，由于死锁，异常情况，临时性网络中断和故障切换）后才值得重试。在发生永久性错误（例如，违反约束）之后重试是毫无意义的。 ● 如果事务在数据库之外也有副作用，即使事务被中止，也可能发生这些副作用。比如更新操作后附带发送电子邮件。（如果想让多个不同的系统同时提交或者放弃，需要两阶段提交。） ● 如果客户端在重试过程中也失败了，并且没有其他人负责重试，那么数据就会丢失。\n弱隔离级别 并发问题发生的条件： ● 如果两个事务不触及相同的数据，那么可以安全的并行执行。 ● 只有两个事务中一读一写或者同时写，才会出现并发问题。\n并发问题很难测试、推理、复现。\n事务隔离（transaction isolation） ● 数据库试图通过事务隔离来解决并发问题 ● 理论上讲，隔离可以假装没有并发，让数据库保证事务的执行结果与串行相同。\n实际上的事务隔离 ● 由于串行隔离会有性能损失，许多数据库不愿意牺牲性能。 ● 因此，系统通常使用较弱的隔离级别来防止一部分，而不是全部的并发问题。 ● 这些隔离级别难以理解，并且会导致微妙的错误，但是它们仍然在实践中被使用\n弱事务隔离级别导致的问题 ● 弱事务隔离级别造成了很多的资金损失，耗费了财务审计人员的调查，并导致客户数据被破坏。 ● 即使是很多流行的关系型数据库系统（通常被认为是“ACID”）也使用弱隔离级别，所以它们也不一定能防止这些错误的发生。\n那到底怎么解决并发问题？ ● 比起盲目地依赖工具，我们应该对存在的并发问题的种类，以及如何防止这些问题有深入的理解。 ● 然后就可以使用我们所掌握的工具来构建可靠和正确的应用程序。\n读已提交 最基本的事务隔离级别是读已提交（Read Committed），它提供了两个保证：\n从数据库读时，只能看到已提交的数据（没有脏读（dirty reads））。 写入数据库时，只会覆盖已经写入的数据（没有脏写（dirty writes））。 没有脏读 什么是脏读？ ● 设想一个事务已经将部分数据写入数据库，但事务还没有提交或中止。另一个事务可以看到未提交的数据吗？如果是的话，那就叫做脏读（dirty reads）。 ● 在读已提交隔离级别运行的事务必须防止脏读。这意味着事务的任何写入操作只有在该事务成功提交后，才能被其他人看到（并且所有的写入操作都会立即变得可见）。 ○ 比如 user1 设置了 x=3， 但是直到 user1 的事务提交前， user2 的 get x 依然返回旧值 2， 为什么要防止脏读？ ● 如果事务需要更新多个对象，脏读取意味着另一个事务可能会只看到一部分更新。比如上文中电子邮件的未读数目的例子。 ● 如果事务中止，则所有写入操作都需要回滚。脏读导致其他事务看到稍后需要回滚的数据。\n没有脏写 什么是脏写？ ● 两个事务同时更新数据库的相同对象，通常是后面的写入覆盖前面的。但如果先前的写入是尚未提交事务的一部分，后面的写入会覆盖一个尚未提交的值？如果是，这被称作脏写（dirty write）。 ● 在读已提交的隔离级别上运行的事务必须防止脏写，通常是延迟第二次写入，直到第一次写入事务提交或中止为止。\n为什么要防止脏写？ ● 如果事务更新多个对象，脏写会导致非预期的错误结果。 ○ Alice 和 Bob 同事购买一辆车，买车需要两次数据库写入：商品列表更新、开发票。 ○ 下图中，Alice 先更新了商品列表，但是被 Bob 覆盖了商品列表；Bob 先更新了开发票，但是被 Alice 覆盖。\n● 但是，读已提交不能防止本章第一个图中的两个计数器增量之间的竞争状态。第二次写入在第一个事务提交后，所以它不是一个脏写。但结果仍然不正确。后文中“防止更新丢失”中将探讨如何使这种计数器安全递增。\n实现读已提交 ● 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置\n怎么实现读已提交？ ● 最常见的情况是，数据库通过使用行锁（row-level lock） 来防止脏写： ○ 当事务想要修改特定对象（行或文档）时，它必须首先获得该对象的锁。然后必须持有该锁直到事务被提交或中止。 ○ 一次只有一个事务可持有任何给定对象的锁； ○ 如果另一个事务要写入同一个对象，则必须等到第一个事务提交或中止后，才能获取该锁并继续。 ○ 这种锁定是读已提交模式（或更强的隔离级别）的数据库自动完成的。\n如何防止脏读？ ● 一种选择是读写使用相同的锁，并要求任何想要读取对象的事务来简单地获取该锁，然后在读取之后立即再次释放该锁。 ● 这能确保在读取进行时，对象不会在脏的、有未提交的值的状态（因为在那段时间锁会被写入该对象的事务持有）。\n读锁的缺点？ ● 读锁在实际上并不可行。 ● 一个长时间运行的写入事务会迫使许多只读事务等到这个慢写入事务完成。 ● 因为等待锁，应用某个部分的迟缓可能由于连锁效应，导致其他部分出现问题。\n实际方法 ● 大多数数据库使用图 7-4 的方法防止脏读 ● 对于写入的每个对象，数据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。 ● 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 ● 只有当新值提交后，事务才会切换到读取新值。\n快照隔离和可重复读 读已提交隔离级别的表现： ● 它允许中止（原子性的要求）； ● 它防止读取不完整的事务结果，并且防止并发写入造成的混乱。\n但，仍然有问题可能导致并发错误：\n● 图7-6 读取偏差：Alice观察数据库处于不一致的状态\n○ Alice 有 1000 美元，分为两个账户 ○ 先查了账户 1，发现有 500 块 ○ 一个事务把账户 2 的钱转了 100 到账户 1 ○ 再查了账户 2，发现只有 400 块 ○ 导致 Alice 误以为总的只有 900 块 ● 这种异常被称为不可重复读（nonrepeatable read） 或读取偏差（read skew） ○ Alice 再次查询账户 1 的时候，会看到与之前不同的值 ○ 在读已提交的隔离条件下，不可重复读被认为是可接受的：Alice看到的帐户余额确实是当时的最新值。\n有些情况不可以接受上述暂时的不一致： 备份 ● 大型数据库备份会几个小时才能完成，如果备份时数据库仍然接受写入操作，那么备份就可能有一些新的部分和旧的部分。 ● 从这样的备份中恢复，那么数据不一致会变成永久的。 分析查询和完整性检查 ● 一个分析需要查询数据库的大部分内容，如果不同时间点的查询结果不一样，那就没意义。\n快照隔离（snapshot isolation） ● 解决上述问题的最常见方案 ● 想法是，每个事务都从数据库的一致快照（consistent snapshot） 中读取。——也就是说，事务可以看到事务开始时在数据库中提交的所有数据。 ● 即使这些数据随后被另一个事务更改，每个事务也只能看到该特定时间点的旧数据。 ● 优点： ○ 快照隔离对长时间运行的只读查询（如备份和分析）非常有用。 ○ 如果查询的数据在查询执行的同时发生变化，则很难理解查询的含义。有快照理解起来就容易了。 ● 快照隔离是一个流行的功能：PostgreSQL，使用InnoDB引擎的MySQL，Oracle，SQL Server等都支持\n实现快照隔离 思路 ● 与读取提交的隔离类似，快照隔离的实现通常使用写锁来防止脏写。 ● 这意味着进行写入的事务会阻止另一个事务修改同一个对象。 ● 但是读取不需要任何锁定。 ● 从性能的角度来看，快照隔离的一个关键原则是：读不阻塞写，写不阻塞读。 ● 这允许数据库在处理一致性快照上的长时间查询时，可以正常地同时处理写入操作。且两者间没有任何锁定争用。\n实现 ● 通常使用防止图 7-4 的脏读 ● 数据库必须可能保留一个对象的几个不同的提交版本，因为各种正在进行的事务可能需要看到数据库在不同的时间点的状态。 ● 因为它同时维护着单个对象的多个版本，所以这种技术被称为多版本并发控制（MVCC, multi-version concurrency control）。\n保留几个版本的快照？ ● 如果一个数据库只需要提供读已提交的隔离级别，而不提供快照隔离，那么保留一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本。 ● 支持快照隔离的存储引擎通常也使用MVCC来实现读已提交隔离级别。一种典型的方法是读已提交为每个查询使用单独的快照，而快照隔离对整个事务使用相同的快照。\n举个例子 ● 下图是 PostgreSQL中实现基于MVCC的快照隔离（其他实现类似） ● 当一个事务开始时，它被赋予一个唯一的，永远增长的事务ID（txid）。 ● 每当事务向数据库写入任何内容时，它所写入的数据都会被标记上写入者的事务ID。\n● 说明： ○ 表中的每一行都有一个 created_by 字段，其中包含将该行插入到表中的的事务ID。 ○ 此外，每行都有一个 deleted_by 字段，最初是空的。 ○ 如果某个事务删除了一行，那么该行实际上并未从数据库中删除，而是通过将 deleted_by 字段设置为请求删除的事务的ID来标记为删除。 ○ 在稍后的时间，当确定没有事务可以再访问已删除的数据时，数据库中的垃圾收集过程会将所有带有删除标记的行移除，并释放其空间。 ○ UPDATE 操作在内部翻译为 DELETE 和 INSERT 。\n观察一致性快照的可见性规则 对于一个事务 ID，哪些对象时可见的？ ● 当一个事务从数据库中读取时，事务ID用于决定它可以看见哪些对象，看不见哪些对象。通过仔细定义可见性规则，数据库可以向应用程序呈现一致的数据库快照。 ● 工作如下： ○ 在每次事务开始时，数据库列出当时所有其他（尚未提交或尚未中止）的事务清单，即使之后提交了，这些事务已执行的任何写入也都会被忽略。 ○ 被中止事务所执行的任何写入都将被忽略。 ○ 由具有较晚事务ID（即，在当前事务开始之后开始的）的事务所做的任何写入都被忽略，而不管这些事务是否已经提交。 ○ 所有其他写入，对应用都是可见的。 ● 这些规则适用于创建和删除对象。 ● 换句话说，如果以下两个条件都成立，则可见一个对象： ○ 读事务开始时，创建该对象的事务已经提交。 ○ 对象未被标记为删除，或如果被标记为删除，请求删除的事务在读事务开始时尚未提交。\n长时间运行的事务看到的记录是新的还是旧的？ ● 长时间运行的事务可能会长时间使用快照，并继续读取（从其他事务的角度来看）早已被覆盖或删除的值。 ● 由于从来不原地更新值，而是每次值改变时创建一个新的版本，数据库可以在提供一致快照的同时只产生很小的额外开销。\n索引和快照隔离 索引如何在多版本数据库中工作？ ● 一种选择是使索引简单地指向对象的所有版本，并且需要索引查询来过滤掉当前事务不可见的任何对象版本。 ● 当垃圾收集删除任何事务不再可见的旧对象版本时，相应的索引条目也可以被删除。\n实践中的索引实现细节决定了多版本并发控制的性能。 ● 如果同一对象的不同版本可以放入同一个页面中，PostgreSQL的优化可以避免更新索引。 ● 在CouchDB，Datomic和LMDB中使用另一种方法。虽然它们也使用B树，但它们使用的是一种仅追加/写时拷贝（append-only/copy-on-write） 的变体，它们在更新时不覆盖树的页面，而为每个修改页面创建一份副本。从父页面直到树根都会级联更新，以指向它们子页面的新版本。任何不受写入影响的页面都不需要被复制，并且保持不变。 ● 使用仅追加的B树，每个写入事务（或一批事务）都会创建一颗新的B树。当创建时，从该特定树根生长的树就是数据库的一个一致性快照。没必要根据事务ID过滤掉对象，因为后续写入不能修改现有的B树；它们只能创建新的树根。但这种方法也需要一个负责压缩和垃圾收集的后台进程。\n可重复读与命名混淆 ● 快照隔离是一个有用的隔离级别，特别对于只读事务而言。 ● 但是，许多数据库实现了它，却用不同的名字来称呼。 ○ 在Oracle中称为可串行化（Serializable） 的 ○ 在PostgreSQL和MySQL中称为可重复读（repeatable read） ● 这种命名混淆的原因是SQL标准没有快照隔离的概念，因为标准是基于System R 1975年定义的隔离级别，那时候快照隔离尚未发明。相反，它定义了可重复读，表面上看起来与快照隔离很相似。 ● 后续虽然有可重复度的正式定义，但是结果现在命名混乱了。\n防止丢失更新 ● 上文讨论了读已提交和快照隔离级别，主要保证了只读事务在并发写入时可以看到什么，另外一个重要的事务并发场景是脏写。 ● 并发事务还有丢失更新（lost update） 问题，如图7-1所示。\n什么情况下会发生丢失更新问题？ ● 从数据库中读取一些值，修改它并写回修改的值（读取-修改-写入序列），则可能会发生丢失更新的问题。 ● 如果两个事务同时执行，则其中一个的修改可能会丢失，因为第二个写入的内容并没有包括第一个事务的修改（有时会说后面写入狠揍（clobber） 了前面的写入）。\n下面是解决方案。\n原子写 ● 很多数据库提供了原子更新操作，从而消除在应用程序代码中执行读取-修改-写入序列的需要。 ● 这通常是最好的解决方案。\n举例，下面的指令在大多数关系数据库中是并发安全的：\n1 UPDATE counters SET value = value + 1 WHERE key = \u0026#39;foo\u0026#39;; 原子写的实现方法 ● 原子操作通常通过在读取对象时，获取其上的排它锁来实现。 ○ 使得更新完成之前，没有其他事务可以读取它。 ○ 这种技术有时被称为游标稳定性（cursor stability） ● 另一个选择是简单地强制所有的原子操作在单一线程上执行\n使用时请注意 ● ORM框架很容易意外地执行不安全的读取-修改-写入序列，而不是使用数据库提供的原子操作。 ● 经常产出很难测出来的微妙 bug\n显式锁定 ● 如果数据库不支持内置原子操作，另一种防止更新丢失的方法是有应用程序显式地锁定将要更新的对象。 ● 然后应用程序可以执行读取-修改-写入序列，如果任何其他事务尝试同时读取同一个对象，则强制等待，直到第一个读取-修改-写入序列完成。\n举例：多人棋子游戏 ● 多个玩家可以同时移动相同的棋子。 ● 一个原子操作可能是不够的，因为应用程序还需要确保玩家的移动符合游戏规则 ● 可以使用锁来防止两名玩家同时移动相同的棋子\n1 2 3 4 5 6 7 8 BEGIN TRANSACTION; SELECT * FROM figures WHERE name = \u0026#39;robot\u0026#39; AND game_id = 222 FOR UPDATE; -- 检查玩家的操作是否有效，然后更新先前SELECT返回棋子的位置。 UPDATE figures SET position = \u0026#39;c4\u0026#39; WHERE id = 1234; COMMIT; ● FOR UPDATE 子句告诉数据库应该对该查询返回的所有行加锁。 这是有效的，但要做对，你需要仔细考虑应用逻辑。忘记在代码某处加锁很容易引入竞争条件。\n自动检测丢失的更新 ● 原子操作和锁是通过强制读取-修改-写入序列按顺序发生，来防止丢失更新的方法。 ● 还可以允许并发执行，如果事务管理器检测到丢失更新，则中止事务并强制它们重试其读取-修改-写入序列。\n优点 ● 数据库可以结合快照隔离高效地执行此检查。 ○ PostgreSQL的可重复读，Oracle的可串行化和SQL Server的快照隔离级别，都会自动检测到丢失更新，并中止惹麻烦的事务。 ○ 但是，MySQL/InnoDB的可重复读并不会检测丢失更新。导致有人认为 MySQL 不提供快照隔离。 ● 数据库自动检查！应用代码不需要任何操作就能使用丢失更新检测。很棒！\n比较并设置（CAS） ● 有些不提供事务的数据库中，提供了一种原子操作：比较并设置（CAS, Compare And Set） ● 此操作的目的是为了避免丢失更新： ○ 只有当前值从上次读取时一直未改变，才允许更新发生。 ○ 如果当前值与先前读取的值不匹配，则更新不起作用，且必须重试读取-修改-写入序列。\n举例： 为了防止两个用户同时更新同一个wiki页面，可以尝试类似这样的方式，只有当页面从上次读取之后没有发生变化时，才会发生更新：\n1 2 3 -- 根据数据库的实现情况，这可能安全也可能不安全 UPDATE wiki_pages SET content = \u0026#39;新内容\u0026#39; WHERE id = 1234 AND content = \u0026#39;旧内容\u0026#39;; 注意 ● 如果更新失败，需要应用层重试。 ● 如果数据库的 WHERE子句从旧快照中读取，则此语句可能无法防止丢失更新，因为即使发生了另一个并发写入，WHERE条件也可能为真。在依赖数据库的CAS操作前要检查其安全运行条件。\n冲突解决和复制 ● 在复制数据库中，防止丢失的更新需要考虑另一个维度：由于在多个节点上存在数据副本，并且在不同节点上的数据可能被并发地修改，因此需要采取一些额外的步骤来防止丢失更新。\n锁和CAS操作的缺点 ● 锁和CAS操作假定只有一个最新的数据副本。 ● 但是多主或无主复制的数据库通常允许多个写入并发执行，并异步复制到副本上，因此无法保证只有一个最新数据的副本。 ● 所以基于锁或CAS操作的技术不适用于这种情况。\n复制数据库解决冲突的常用方法 ● 复制数据库中的一种常见方法是允许并发写入创建多个冲突版本的值（也称为兄弟），并使用应用代码或特殊数据结构在事实发生之后解决和合并这些版本。\n原子操作的适用条件 ● 原子操作可以在复制的上下文中很好地工作，尤其当它们具有可交换性时（即，可以在不同的副本上以不同的顺序应用它们，且仍然可以得到相同的结果）。\n最后写入胜利（LWW）的缺点 ● 最后写入胜利（LWW）的冲突解决方法很容易丢失更新。 ● 不幸的是，LWW是许多复制数据库中的默认方案。\n写入偏斜与幻读 ● 前面讨论的脏写和丢失更新，都是不同事务并发地尝试写入相同的对象时，会出现这两种竞争条件。 ● 除此之外，还有其他场景的并发问题，比如修改不同的对象。\n一个医生轮班管理程序的例子 ● 背景：医院通常会同时要求几位医生待命，但底线是至少有一位医生在待命。医生可以放弃他们的班次（例如，如果他们自己生病了），只要至少有一个同事在这一班中继续工作。 ● 场景：Alice和Bob是两位值班医生，同时请假：\n○ 应用首先检查是否有两个或以上的医生正在值班； ■ 如果是的话，它就假定一名医生可以安全地休班。由于数据库使用快照隔离，两次检查都返回 2 ，所以两个事务都进入下一个阶段。 ■ Alice更新自己的记录休班了，而Bob也做了一样的事情。 ■ 两个事务都成功提交了，现在没有医生值班了。 ■ 违反了至少有一名医生在值班的要求。\n写偏差的特征 ● 这种异常称为写偏差。它既不是脏写，也不是丢失更新，因为这两个事务正在更新两个不同的对象（Alice和Bob各自的待命记录）。\n问题一般化： ● 如果两个事务读取相同的对象，然后更新其中一些对象（不同的事务可能更新不同的对象），则可能发生写入偏差。 ● 在多个事务更新同一个对象的特殊情况下，就会发生脏写或丢失更新（取决于时序）。\n处理写偏差，我们能用的方法很少，原因： ● 由于涉及多个对象，单对象的原子操作不起作用。 ● 不幸的是，在一些快照隔离的实现中，自动检测丢失更新对此并没有帮助。目前的可重复读、快照隔离级别中，都不会自动检测写入偏差。自动防止写入偏差需要真正的可串行化隔离 ● 某些数据库允许配置约束，然后由数据库强制执行（例如，唯一性，外键约束或特定值限制）。但是为了指定至少有一名医生必须在线，需要一个涉及多个对象的约束。大多数数据库没有内置对这种约束的支持，但是你可以使用触发器，或者物化视图来实现它们，这取决于不同的数据库\n解决办法： ● 如果无法使用可串行化的隔离级别，则此情况下的次优选项可能是显式锁定事务所依赖的行。\n1 2 3 4 5 6 7 8 9 10 11 BEGIN TRANSACTION; SELECT * FROM doctors WHERE on_call = TRUE AND shift_id = 1234 FOR UPDATE; UPDATE doctors SET on_call = FALSE WHERE name = \u0026#39;Alice\u0026#39; AND shift_id = 1234; COMMIT; ● 和以前一样，FOR UPDATE告诉数据库锁定返回的所有行以用于更新。\n写偏差的更多例子 会议室预订系统 ● 防止会议室被同一个会议室多次预定，需要检查时间是否有重叠。 ● 快照级别隔离不安全的 SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 BEGIN TRANSACTION; -- 检查所有现存的与12:00~13:00重叠的预定 SELECT COUNT(*) FROM bookings WHERE room_id = 123 AND end_time \u0026gt; \u0026#39;2015-01-01 12:00\u0026#39; AND start_time \u0026lt; \u0026#39;2015-01-01 13:00\u0026#39;; -- 如果之前的查询返回0 INSERT INTO bookings(room_id, start_time, end_time, user_id) VALUES (123, \u0026#39;2015-01-01 12:00\u0026#39;, \u0026#39;2015-01-01 13:00\u0026#39;, 666); COMMIT; 快照隔离并不能防止另一个用户同时插入冲突的会议。为了确保不会遇到调度冲突，你又需要可串行化的隔离级别了。\n多人游戏 ● 可以用锁防止丢失更新（也就是确保两个玩家不能同时移动同一个棋子）。 ● 但是锁定并不妨碍玩家将两个不同的棋子移动到棋盘上的相同位置，或者采取其他违反游戏规则的行为。 ● 按照您正在执行的规则类型，也许可以使用唯一约束（unique constraint），否则您很容易发生写入偏差。\n抢注用户名 ● 在每个用户拥有唯一用户名的网站上，两个用户可能会尝试同时创建具有相同用户名的帐户。 ● 快照隔离下这是不安全的。 ● 幸运的是，唯一约束是一个简单的解决办法（第二个事务在提交时会因为违反用户名唯一约束而被中止）。\n防止双重开支 ● 允许用户花钱或积分的服务，需要检查用户的支付数额不超过其余额。 ● 可以通过在用户的帐户中插入一个试探性的消费项目来实现这一点。 ● 有了写入偏差，可能会发生两个支出项目同时插入，一起导致余额变为负值。但这两个事务各自都不超额。 导致写入偏差的幻读 上述所有例子遵循类似的模式： ● 一个SELECT查询找出符合条件的行，并检查是否符合一些要求。 ● 按照第一个查询的结果，应用代码决定是否继续。 ● 如果应用决定继续操作，就执行写入（插入、更新或删除），并提交事务。 ○ 这个写入的效果改变了步骤2 中的先决条件。换句话说，如果在提交写入后，重复执行一次步骤1 的SELECT查询，将会得到不同的结果。\n解决方法： ● 医生值班的例子中，在步骤3中修改的行，是步骤1中返回的行之一，所以我们可以通过锁定步骤1 中的行（SELECT FOR UPDATE）来使事务安全并避免写入偏差。 ● 但是其他四个例子是不同的：它们检查是否不存在某些满足条件的行，写入会添加一个匹配相同条件的行。如果步骤1中的查询没有返回任何行，则SELECT FOR UPDATE锁不了任何东西。\n幻读 ● 一个事务中的写入改变另一个事务的搜索查询的结果，被称为幻读。 ● 快照隔离避免了只读查询中幻读，但是在像我们讨论的例子那样的读写事务中，幻读会导致特别棘手的写入偏差情况。\n物化冲突 ● 如果幻读的问题是没有对象可以加锁，也许可以人为地在数据库中引入一个锁对象？ ● 例如，在会议室预订的场景中，可以想象创建一个关于时间槽和房间的表。 ● 要创建预订的事务可以锁定（SELECT FOR UPDATE）表中与所需房间和时间段对应的行。在获得锁定之后，它可以检查重叠的预订并像以前一样插入新的预订。 ● 这种方法被称为物化冲突（materializing conflicts），因为它将幻读变为数据库中一组具体行上的锁冲突\n缺点： ● 弄清楚如何物化冲突可能很难，也很容易出错，而让并发控制机制泄漏到应用数据模型是很丑陋的做法 ● 出于这些原因，如果没有其他办法可以实现，物化冲突应被视为最后的手段。\n在大多数情况下。可串行化（Serializable） 的隔离级别是更可取的。\n可串行化 读已提交和快照隔离级别会阻止某些竞争条件，但并非对所有情况都有效。我们遇到了一些特别棘手的例子，写入偏差和幻读。面临的挑战： ● 隔离级别难以理解，并且在不同的数据库中实现的不一致 ● 光检查应用代码很难判断在特定的隔离级别运行是否安全。 特别是在大型应用程序中，您可能并不知道并发发生的所有事情。 ● 没有检测竞争条件的好工具。并发问题的测试是很难的，因为它们通常是非确定性的 —— 只有在倒霉的时序下才会出现问题。\n研究人员给出的答案： ● 使用可串行化（serializable） 的隔离级别！\n可串行化（Serializability） ● 可串行化（Serializability） 隔离通常被认为是最强的隔离级别。 ● 它保证即使事务可以并行执行，最终的结果也是一样的，就好像它们没有任何并发性，连续挨个执行一样。 ● 因此数据库保证，如果事务在单独运行时正常运行，则它们在并发运行时继续保持正确 —— 换句话说，数据库可以防止所有可能的竞争条件。\n本章介绍可串行化技术： ● 字面意义上地串行顺序执行事务 ● 两阶段锁定（2PL, two-phase locking），几十年来唯一可行的选择 ● 乐观并发控制技术，例如可串行化快照隔离（serializable snapshot isolation）\n真的串行执行 ● 避免并发问题的最简单方法就是完全不要并发：在单个线程上按顺序一次只执行一个事务。 ● 但数据库设计人员在2007年左右才决定，单线程循环执行事务是可行的。 ● 原因： ○ RAM足够便宜了，许多场景现在都可以将完整的活跃数据集保存在内存中。 ○ 数据库设计人员意识到OLTP事务通常很短，而且只进行少量的读写操作。而长时间运行的分析查询通常是只读的，因此它们可以在串行执行循环之外的一致快照（使用快照隔离）上运行。 ● 串行执行事务的方法在VoltDB/H-Store，Redis和Datomic中实现\n优点： ● 设计用于单线程执行的系统有时可以比支持并发的系统更好，因为它可以避免锁的协调开销。 缺点： ● 但是其吞吐量仅限于单个CPU核的吞吐量。 ● 为了充分利用单一线程，需要与传统形式的事务不同的结构。\n在存储过程中封装事务 ● 不能把人类做出决定和回应的多个流程操作封装成一个事务（比如搜路线、选机票、付款），因为人类太慢。 ● 交互式的事务中，为了提高吞吐量，必须允许数据库并发处理。 ● 采用单线程串行事务处理的系统不允许交互式的多语句事务。这就要求应用程序必须提前将整个事务代码作为存储过程提交给数据库。 ● 下图表示 交互式事务和存储过程之间的区别（使用图7-8的示例事务）\n存储过程的优点和缺点 存储过程名声不好的原因： ● 每个数据库厂商都有自己的存储过程语言，而不是通用语言如 Java。 ● 数据库代码管理困难，调试困难，版本控制困难。 ● 数据库通常比应用服务器对性能敏感的多，数据库中一个写得不好的存储过程（例如，占用大量内存或CPU时间）会比在应用服务器中相同的代码造成更多的麻烦。\n克服方法： ● 现代的存储过程实现放弃了PL/SQL，而是使用现有的通用编程语言：Java 和 Lua 等。\n单线程执行事务变得可行： ● 存储过程与内存存储，使得在单个线程上执行所有事务变得可行。由于不需要等待I/O，且避免了并发控制机制的开销，它们可以在单个线程上实现相当好的吞吐量。 ● VoltDB还使用存储过程进行复制\n分区 ● 顺序执行导致写入吞吐比较高的应用，单线程事务处理器可能成为一个严重的瓶颈。\n解决方法： ● 分区，每个分区就可以拥有自己独立运行的事务处理线程。\n缺点： ● 需要访问多个分区的任何事务，数据库必须在触及的所有分区之间协调事务。 ● 存储过程需要跨越所有分区锁定执行，以确保整个系统的可串行性。 ● 跨分区事务比单分区事务慢得多！ ● 事务能否分区取决于应用数据的结构：kv 存储容易分区，但是多个二级索引的数据不方便分区。\n串行执行小结 特定情况下，真的串行执行事务，已经成为一种实现可串行化隔离等级的可行办法。 使用条件： ● 每个事务都必须小而快，只要有一个缓慢的事务，就会拖慢所有事务处理。 ● 仅限于活跃数据集可以放入内存的情况。很少访问的数据可能会被移动到磁盘，但如果需要在单线程执行的事务中访问，系统就会变得非常慢。 ● 写入吞吐量必须低到能在单个CPU核上处理，否则需要分区，但最好没有跨分区事务。 ● 跨分区事务也可以支持，但是占比必须小。\n两阶段锁定 ● 大约30年来，在数据库中只有一种广泛使用的串行化算法：两阶段锁定（2PL，two-phase locking） ● 之前我们看到锁通常用于防止脏写； ● 两阶段锁定类似，但是锁的要求更强得多。 ○ 只要没有写入，就允许多个事务同时读取同一个对象。 ○ 但对象只要有写入（修改或删除），就需要独占访问（exclusive access） 权限： ■ 如果事务A读取了一个对象，并且事务B想要写入该对象，那么B必须等到A提交或中止才能继续。 （这确保B不能在A底下意外地改变对象。） ■ 如果事务A写入了一个对象，并且事务B想要读取该对象，则B必须等到A提交或中止才能继续。 （像图7-1那样读取旧版本的对象在2PL下是不可接受的。）\n特点 ● 在2PL中，写入不仅会阻塞其他写入，也会阻塞读，反之亦然。快照隔离使得读不阻塞写，写也不阻塞读，这是2PL和快照隔离之间的关键区别。 ● 另一方面，因为2PL提供了可串行化的性质，它可以防止早先讨论的所有竞争条件，包括丢失更新和写入偏差。\n实现两阶段锁 使用场景 2PL用于MySQL（InnoDB）和SQL Server中的可串行化隔离级别，以及DB2中的可重复读隔离级别 实现方式 读与写的阻塞是通过为数据库中每个对象添加锁来实现的。 锁可以处于共享模式（shared mode） 或独占模式（exclusive mode）。 锁使用如下：（同一个锁有两种模式：共享模式和独占模式，独占模式优先级大于共享模式） 若事务要读取对象，则须先以共享模式获取锁。允许多个事务同时持有共享锁。但如果另一个事务已经在对象上持有独占锁，则这些事务必须等待。 若事务要写入一个对象，它必须首先以独占模式获取该锁。不允许其他事务可以同时持有该锁（无论是共享模式还是独占模式）。换言之，如果对象上存在任何锁，则修改事务必须等待。 如果事务先读取再写入对象，则它可能会将其共享锁升级为独占锁。升级锁的工作等价于直接获得独占锁。 事务获得锁之后，必须继续持有锁直到事务结束（提交或中止）。这就是“两阶段”这个名字的来源：第一阶段（当事务正在执行时）获取锁，第二阶段（在事务结束时）释放所有的锁。 可能会发生死锁： 数据库会自动检测事务之间的死锁，并中止其中一个，以便另一个继续执行。 被中止的事务需要由应用程序重试。 两阶段锁定的性能 两阶段锁定的巨大缺点：性能问题 两阶段锁定下的事务吞吐量与查询响应时间要比弱隔离级别下要差得多。 性能差的原因： 这一部分是由于获取和释放所有这些锁的开销，但更重要的是由于并发性的降低。 按照设计，如果两个并发事务试图做任何可能导致竞争条件的事情，那么必须等待另一个完成。 性能差的表现： 运行2PL的数据库可能具有相当不稳定的延迟，如果在工作负载中存在争用，那么可能高百分位点处的响应会非常的慢 可能只需要一个缓慢的事务，或者一个访问大量数据并获取许多锁的事务，就能把系统的其他部分拖慢，甚至迫使系统停机。当需要稳健的操作时，这种不稳定性是有问题的。 死锁导致的问题： 基于2PL实现的可串行化隔离级别中，死锁会出现的频繁的多（取决于事务的访问模式）。 死锁发生时，需要把事务中止并被重试。这导致额外的性能问题。 谓词锁 具有可串行化隔离级别的数据库必须防止幻读。 如何防止会议室重复预定（即如果一个事务在某个时间窗口内搜索了一个房间的现有预定，则另一个事务不能同时插入或者更新同一个时间窗口内、同一房间的另一个约定） 实现方式 我们需要一个谓词锁（predicate lock）。它类似于前面描述的共享/排它锁，但不属于特定的对象（例如，表中的一行），它属于所有符合某些搜索条件的对象，如：\n1 2 3 4 SELECT * FROM bookings WHERE room_id = 123 AND end_time \u0026gt; \u0026#39;2018-01-01 12:00\u0026#39; AND start_time \u0026lt; \u0026#39;2018-01-01 13:00\u0026#39;; 谓词锁限制访问的方式： ● 如果事务A想要读取匹配某些条件的对象，就像在这个 SELECT 查询中那样，它必须获取查询条件上的共享谓词锁（shared-mode predicate lock）。如果另一个事务B持有任何满足这一查询条件对象的排它锁，那么A必须等到B释放它的锁之后才允许进行查询。 ● 如果事务A想要插入，更新或删除任何对象，则必须首先检查旧值或新值是否与任何现有的谓词锁匹配。如果事务B持有匹配的谓词锁，那么A必须等到B已经提交或中止后才能继续。\n关键思想 ● 谓词锁甚至适用于数据库中尚不存在，但将来可能会添加的对象（幻象）。 ● 如果两阶段锁定包含谓词锁，则数据库将阻止所有形式的写入偏差和其他竞争条件，因此其隔离实现了可串行化。\n索引范围锁 ● 谓词锁性能不佳：如果活跃事务持有很多锁，检查匹配的锁会非常耗时。 ● 大多数使用2PL的数据库实际上实现了索引范围锁（也称为间隙锁（next-key locking）），这是一个简化的近似版谓词锁。\n索引范围锁： ● 对查询对象的索引加锁。 ● 比如，room_id列上有一个索引，并且/或者在start_time 和 end_time上有索引；那么在查询的时候，在查询时，将某个具体对象的索引加上锁，比如给 room_id =123的索引加锁，那么其他事务就没法获取到此索引的锁，导致无法插入、更新、删除。\n优点： ● 这种方法能够有效防止幻读和写入偏差。 ● 虽然索引范围锁并不像谓词锁那样精确（它们可能会锁定更大范围的对象，而不是维持可串行化所必需的范围），但是由于它们的开销较低，所以是一个很好的折衷。\n如果没有索引，怎么加索引范围锁？ ● 退化到整个表上的共享锁 ● 对性能不利，但是比较安全。\n可串行化快照隔离 本章讨论了关于数据库的并发控制的黯淡画面： ● 一方面，我们实现了性能不好（2PL）或者伸缩性不好（串行执行）的可串行化隔离级别。 ● 另一方面，我们有性能良好的弱隔离级别，但容易出现各种竞争条件（丢失更新，写入偏差，幻读等）。\n串行化的隔离级别和高性能是从根本上相互矛盾的吗？ ● 也许不是：一个称为可串行化快照隔离（SSI, serializable snapshot isolation） 的算法是非常有前途的。\n可串行化快照隔离 ● 它提供了完整的可串行化隔离级别，但与快照隔离相比只有很小的性能损失。 ● SSI是相当新的：它在2008年首次被提出。 ● 既用于单节点数据库（PostgreSQL9.1 以后的可串行化隔离级别）和分布式数据库（FoundationDB使用类似的算法）。\n悲观与乐观的并发控制 ● 两阶段锁是一种所谓的悲观并发控制机制（pessimistic） ：它是基于这样的原则：如果有事情可能出错（如另一个事务所持有的锁所表示的），最好等到情况安全后再做任何事情。 ● 串行化快照隔离是一种乐观（optimistic） 的并发控制技术。 ○ 乐观意味着，如果存在潜在的危险也不阻止事务，而是继续执行事务，希望一切都会好起来。 ○ 当一个事务想要提交时，数据库检查是否有什么不好的事情发生（即隔离是否被违反）；如果是的话，事务将被中止，并且必须重试。只有可串行化的事务才被允许提交。\n适用场景的思考： ● 如果存在很多争用（contention）（很多事务试图访问相同的对象），则表现不佳，因为这会导致很大一部分事务需要中止。 ● 但是，如果有足够的备用容量，并且事务之间的争用不是太高，乐观的并发控制技术往往比悲观的要好。\n与早期的乐观并发控制技术的主要区别： ● SSI基于快照隔离——也就是说，事务中的所有读取都是来自数据库的一致性快照。 ● 在快照隔离的基础上，SSI添加了一种算法来检测写入之间的串行化冲突，并确定要中止哪些事务\n基于过时前提的决策 ● 前文讨论的快照隔离中的写入偏差，是由于事务基于一个前提（premise） 采取行动，之后当事务要提交时，原始数据可能已经改变——前提可能不再成立。 ● 更好的办法是由数据库进行判断，而不是应用程序来判断。 ● 数据库如何知道查询结果是否可能已经改变？有两种情况需要考虑： ○ 检测对旧MVCC对象版本的读取（读之前存在未提交的写入） ○ 检测影响先前读取的写入（读之后发生写入）\n检测旧MVCC读取 快照隔离出现写入偏差的原因： ● 快照隔离通常是通过多版本并发控制（MVCC；见图7-10）来实现的。当一个事务从MVCC数据库中的一致快照读时，它将忽略取快照时尚未提交的任何其他事务所做的写入。 ● 图7-10 检测事务何时从MVCC快照读取过时的值（关于医生值班请假的例子）\n如何避免？ ● 数据库需要跟踪一个事务由于MVCC可见性规则而忽略另一个事务的写入。当事务想要提交时，数据库检查是否有任何被忽略的写入现在已经被提交。如果是这样，事务必须中止。\n为什么等到提交时才检查和中止，而不是检测到读取陈旧数据就中止事务 43？ ● 如果事务43 是只读事务，则不需要中止，因为没有写入偏差的风险。\n检测影响之前读取的写入 第二种情况要考虑的是另一个事务在读取数据之后修改数据。 ● 图7-11 在可串行化快照隔离中，检测一个事务何时修改另一个事务的读取。\n实现方法 ● SSI 采用和索引范围锁类似的技术，除了SSI锁不会阻塞其他事务。 ● 事务42 和43 都在班次1234 查找值班医生。如果在shift_id上有索引，则数据库可以使用索引项1234 来记录事务42 和43 读取这个数据的事实。此信息保留到所有事务处理完成即可。 ● 当事务写入数据库时，它必须在索引中查找最近曾读取受影响数据的其他事务。这个过程类似于在受影响的键范围上获取写锁，但锁并不会阻塞事务指导其他读事务完成，而是像警戒线一样只是简单通知其他事务：你们读过的数据可能不是最新的啦。 ● 当事务 43 想要提交时，发现来自事务42 的冲突写入已经被提交，所以事务43 必须中止。\n可串行化快照隔离的性能 与两阶段锁定相比，可串行化快照隔离的优点： ● 一个事务不需要阻塞等待另一个事务所持有的锁。就像在快照隔离下一样，写不会阻塞读，反之亦然。 ● 这种设计原则使得查询延迟更可预测，变量更少。特别是，只读查询可以运行在一致快照上，而不需要任何锁定，这对于读取繁重的工作负载非常有吸引力。\n与串行执行相比，可串行化快照隔离的优点： ● 并不局限于单个CPU核的吞吐量：FoundationDB将检测到的串行化冲突分布在多台机器上，允许扩展到很高的吞吐量。 ● 即使数据可能跨多台机器进行分区，事务也可以在保证可串行化隔离等级的同时读写多个分区中的数据。\n使用场景 ● 中止率显著影响SSI的整体表现。例如，长时间读取和写入数据的事务很可能会发生冲突并中止，因此SSI要求同时读写的事务尽量短（只读的长事务可能没问题）。 ● SSI可能比两阶段锁定或串行执行更能容忍慢事务。\n本章小结 事务的好处？ ● 事务是一个抽象层，允许应用程序假装某些并发问题和某些类型的硬件和软件故障不存在。各式各样的错误被简化为一种简单情况：事务中止（transaction abort），而应用需要的仅仅是重试。\n什么时候需要事务？ ● 具有非常简单访问模式的应用（例如每次读写单条记录）可能无需事务管理。 ● 但是对于更复杂的访问模式，事务可以大大减少需要考虑的潜在错误情景数量。\n本章讨论了什么？ ● 本章深入讨论了并发控制的话题。 ● 我们讨论了几个广泛使用的隔离级别，特别是读已提交，快照隔离（有时称为可重复读）和可串行化。\n竞争条件的例子 脏读 一个客户端读取到另一个客户端尚未提交的写入。读已提交或更强的隔离级别可以防止脏读。 脏写 一个客户端覆盖写入了另一个客户端尚未提交的写入。几乎所有的事务实现都可以防止脏写。 读取偏差（不可重复读） 在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。快照隔离经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。快照隔离通常使用多版本并发控制（MVCC） 来实现。 更新丢失 两个客户端同时执行读取-修改-写入序列。其中一个写操作，在没有合并另一个写入变更情况下，直接覆盖了另一个写操作的结果。所以导致数据丢失。快照隔离的一些实现可以自动防止这种异常，而另一些实现则需要手动锁定（SELECT FOR UPDATE）。 写偏差 一个事务读取一些东西，根据它所看到的值作出决定，并将该决定写入数据库。但是，写入时，该决定的前提不再是真实的。只有可串行化的隔离才能防止这种异常。 幻读 事务读取符合某些搜索条件的对象。另一个客户端进行写入，影响搜索结果。快照隔离可以防止直接的幻像读取，但是写入偏差上下文中的幻读需要特殊处理，例如索引范围锁定。\n弱隔离级别可以防止其中一些异常情况，但要求你，也就是应用程序开发人员手动处理剩余那些（例如，使用显式锁定）。只有可串行化的隔离才能防范所有这些问题。我们讨论了实现可串行化事务的三种不同方法： 字面意义上的串行执行 如果每个事务的执行速度非常快，并且事务吞吐量足够低，足以在单个CPU核上处理，这是一个简单而有效的选择。 两阶段锁定 数十年来，两阶段锁定一直是实现可串行化的标准方式，但是许多应用出于性能问题的考虑避免使用它。 可串行化快照隔离（SSI） 一个相当新的算法，避免了先前方法的大部分缺点。它使用乐观的方法，允许事务执行而无需阻塞。当一个事务想要提交时，它会进行检查，如果执行不可串行化，事务就会被中止。\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E4%B8%83%E7%AB%A0/","summary":"第七章：事务 为什么有事务？ ● 分布式数据系统，可能会出各种错误。 ● 实现容错机制工作量巨大。需要仔细考虑所有可能出错的事情，并进行大量的测试，以","title":"DDIA第七章"},{"content":"第六章: 分区 什么是分区？ ● 对于非常大的数据集，或非常高的吞吐量，仅仅进行复制是不够的：我们需要将数据进行分区（partitions），也称为分片（sharding）。 ● 通常情况下，每条数据（每条记录，每行或每个文档）属于且仅属于一个分区。 ● 每个分区都是自己的小型数据库，尽管数据库可能支持同时进行多个分区的操作。\n分区的优点？ ● 分区主要是为了可伸缩性。 ● 大数据集可以分布在多个磁盘上，并且查询负载可以分布在多个处理器上。 ● 单个分区上运行的查询，每个节点可以独立执行对自己的查询，因此可以通过添加更多的节点来扩大查询吞吐量。 ● 大型、复杂的查询可能会跨越多个节点并行处理，尽管这也带来了新的困难。\n本章内容 ● 分割大型数据集的不同方法 ● 索引如何与分区配合 ● 分区再平衡 ● 数据库如何路由到正确的分区\n分区与复制 ● 分区通常与复制结合使用，使得每个分区的副本存储在多个节点上。 ● 即使每条记录属于同一个分区，但是这个分区仍有多个不同的节点，提高容错。 ● 一个节点有多个分区，如果使用主从复制模型，每个分区领导者被分配给一个节点，追随者被分配个其他节点。 ○ 每个节点可能是某些分区的领导者，同时是其他分区的追随者。\n键值数据的分区 ● 分区目标是将数据和查询负载均匀分布在各个节点上。 ● 如果每个节点公平分享数据和负载，那么理论上10个节点应该能够处理10倍的数据量和10倍的单个节点的读写吞吐量（暂时忽略复制）。 ● 如果分区不公平，被称为偏斜（skew） ○ 数据偏斜的存在使分区效率下降很多。 ○ 在极端的情况下，所有的负载可能压在一个分区上，其余9个节点空闲的，瓶颈落在这一个繁忙的节点上。 ○ 不均衡导致的高负载的分区被称为热点（hot spot）。\n怎么避免热点？ ● 避免热点最简单的方法是将记录随机分配给节点。 ● 缺点： ○ 读特定的值时，不知道在哪个节点上，必须并行查所有的节点。\n根据键的范围分区 一种分区的方法是为每个分区指定一块连续的键范围（从最小值到最大值），类似纸质的百科全书。\n● 可能分布不均匀。 ● 分区边界可以由管理员手动选择，也可以由数据库自动选择 ● 使用该策略的有：Bigtable， HBase，RethinkDB和2.4版本之前的MongoDB\n优点： ● 在每个分区中，我们可以按照一定的顺序保存键。 ● 范围扫描非常简单 ● 可以将键作为联合索引来处理，以便在一次查询中获取多个相关记录 ● 比如获取一段时间内的记录。\n缺点： ● Key Range分区的缺点是某些特定的访问模式会导致热点。 ● 可一个修改主键：比如传感器名称+时间，避免数据打到同一分区。\n根据键的散列分区 ● 很多分布式数据存储使用散列函数来分区。 ● 一个好的散列函数可以将偏斜的数据均匀分布。 ● 注意保证同一个键在不同的进程中有相同的哈希值。\n优点： ● 这种技术擅长在分区之间公平地分配键。 ● 分区边界可以是均匀间隔的，也可以是伪随机选择的（在这种情况下，该技术有时也被称为一致性哈希（consistent hashing））。\n缺点： ● 失去了 高效执行范围查询的能力。 ● 范围查询要么不支持，要么需要查询所有分区。\n组合索引： ● 组合索引方法为一对多关系提供了一个优雅的数据模型。 ● 社交网络的一条更新主键被选择为 (user_id, update_timestamp)，那么可以有效地检索特定用户在某个时间间隔内按时间戳排序的所有更新。\n负载偏斜与热点消除 ● 哈希分区可以帮助减少热点。但是，它不能完全避免它们：在极端情况下，所有的读写操作都是针对同一个键的，所有的请求都会被路由到同一个分区。 ● 比如社交网络的大 V 的评论区。 ● 只能靠应用程序解决： ○ 比如，一个主键如果被认为非常火爆，一个简单的方法是在主键的开始或结尾添加一个随机数。 ○ 只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中。 ○ 缺点： ■ 任何读取都要读取 100 个主键，读取数据并合并。 ■ 还要记录哪些键需要被分割\n分区与次级索引 ● 之前讨论的都是键值数据模型。 ● 次级索引使情况变复杂： ○ 次级索引通常并不能唯一地标识记录，而是一种搜索记录中出现特定值的方式 ● 次级索引是关系型数据库的基础，并且在文档数据库中也很普遍。 ● 许多键值存储（如HBase和Volde-mort）为了减少实现的复杂度而放弃了次级索引； ● 但是一些（如Riak）已经开始添加它们，因为它们对于数据模型实在是太有用了。 ● 并且次级索引也是Solr和Elasticsearch等搜索服务器的基石。\n存在的问题： ● 次级索引的问题是它们不能整齐地映射到分区。 ● 有两种用二级索引对数据库进行分区的方法：基于文档的分区（document-based） 和基于关键词（term-based）的分区。\n基于文档的二级索引进行分区 ● 假如一个销售二手车的网站， 每个列表都有一个唯一的ID——称之为文档ID——并且用文档ID对数据库进行分区 ● 用户搜索汽车，允许他们通过颜色和厂商过滤，所以需要一个在颜色和厂商上的次级索引（文档数据库中这些是字段（field），关系数据库中这些是列（column） ）。\n特点： ● 分区完全独立：每个分区维护自己的二级索引 ● 只需处理包含您正在编写的文档ID的分区即可 ● 文档分区索引也被称为本地索引（local index）\n注意： ● 没有理由把特定颜色或者品牌的汽车放到同一个分区。 ● 查询时需要查询所有的分区，合并所有的结果返回。\n缺点： ● 查询分区数据库的方法有时被称为分散/聚集（scatter/gather）； ● 可能使二级索引的查询代价高。 ● 即使并行查询分区，分散/聚集也容易导致尾部延迟放大。\n然而被广泛使用：MongoDB，Riak ，Cassandra ，Elasticsearch ，SolrCloud 和VoltDB 【19】都使用文档分区二级索引。\n基于关键词(Term)的二级索引进行分区 ● 可以构建一个覆盖所有分区数据的全局索引，而不是给每个分区创建自己的次级索引（本地索引）。 ● 但是，我们不能只把这个索引存储在一个节点上，因为它可能会成为瓶颈，违背了分区的目的。 ● 全局索引也必须进行分区，但可以采用与主键不同的分区方式。 ● 下图是对二级索引按照首字母是否在 \u0026ldquo;[a, r]\u0026rdquo; 之间分区。\n● 这种分区叫做关键词分区。 ● 以通过关键词本身或者它的散列进行索引分区。 ○ 根据关键词本身来分区对于范围扫描非常有用：比如数值类的属性。 ○ 对关键词的哈希分区提供了负载均衡的能力。 优点： ● 读取更有效率：不需要分散/收集所有分区，客户端只需要向包含关键词的分区发出请求。\n缺点： ● 写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区（文档中的每个关键词可能位于不同的分区或者不同的节点上） 。 ● 需要跨分区的分布式事务，并不是所有数据库都支持。 ● 在实践中，对全局二级索引的更新通常是异步的。\n分区再平衡 随着时间的推移，数据库会有各种变化：\n● 查询吞吐量增加，所以您想要添加更多的CPU来处理负载。 ● 数据集大小增加，所以您想添加更多的磁盘和RAM来存储它。 ● 机器出现故障，其他机器需要接管故障机器的责任。\n所有这些更改都需要数据和请求从一个节点移动到另一个节点。 将负载从集群中的一个节点向另一个节点移动的过程称为再平衡（rebalancing）。\n无论使用哪种分区方案，再平衡通常都要满足一些最低要求：\n● 再平衡之后，负载（数据存储，读取和写入请求）应该在集群中的节点之间公平地共享。 ● 再平衡发生时，数据库应该继续接受读取和写入。 ● 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I/O负载。\n再平衡策略 反面教材：hash mod N ● 前面已经讲了，最好将可能的散列分成不同的范围，给每个范围分配一个分区。 ● 取模 mod 运算可以给每个键分配一个节点 问题 ● 当节点数目变化时，使得再平衡过于昂贵。\n固定数量的分区 ● 简单的解决方案：创建比节点更多的分区，并为每个节点分配多个分区。 ● 仍然是取模，但是新增节点之后，总节点数变成了 5 个，只需要把取模 = 4 的部分放到 node 4。\n优点 ● 只有分区在节点中移动。 ● 分区总数不变 ● 键所在的分区也不会改变 ● 唯一改变的是分区所在的节点 ● 变更不是及时的：在传输过程中，原有分区仍然接受读写操作。 ● 甚至可以解决硬件不匹配问题：更强大的节点分配更多的分区。 ● Riak ，Elasticsearch ，Couchbase 和Voldemort 中使用了这种再平衡的方法。\n特点 ● 分区的数量通常在数据库第一次建立时确定，之后不会改变。 ● 一开始配置的分区数就是您可以拥有的最大节点数量，所以您需要选择足够多的分区以适应未来的增长。 ● 但是，每个分区也有管理开销，所以选择太大的数字会适得其反。\n缺点 ● 当数据集的总大小难以预估，选择正确的分区数很难。\n动态分区 采用关键字区间分区的数据库，如果边界设置有问题，可能导致数据倾斜到一个分区中。 ● 按键的范围进行分区的数据库（如HBase和RethinkDB）会动态创建分区。 ● 当分区增长到超过配置的大小时（在HBase上，默认值是10GB），会被分成两个分区，每个分区约占一半的数据。 ● 与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。此过程与B树顶层发生的过程类似。\n特点： ● 每个分区分配给一个节点，每个节点可以处理多个分区，就像固定数量的分区一样。 ● 大型分区拆分后，可以将其中的一半转移到另一个节点，以平衡负载。 ● 在HBase中，分区文件的传输通过HDFS（底层使用的分布式文件系统）来实现。\n优点： ● 分区数量适应总数据量。\n缺点： ● 空数据库从一个分区开始，导致所有写入都必须单个节点处理，其他节点空闲。\n解决方法： ● HBase和MongoDB允许在一个空的数据库上配置一组初始分区（这被称为预分割（pre-splitting））。 ● 在键范围分区的情况中，预分割需要提前知道键是如何进行分配的。\n适用情况： ● 动态分区不仅适用于数据的范围分区，而且也适用于散列分区。\n按节点比例分区 ● 动态分区和固定数量的分区，分区数量都与节点数量无关。 ● Cassandra和Ketama使用的第三种方法是使分区数与节点数成正比：每个节点有固定数量的分区。 ○ 当节点数不变，分区大小与数据集大小成比例增长； ○ 当节点数改变，分区大小将变小。\n操作方式： ● 当一个新节点加入集群时，它随机选择固定数量的现有分区进行拆分，然后占有这些拆分分区中每个分区的一半，同时将每个分区的另一半留在原地。 ● 随机化可能会产生不公平的分割，但是平均在更大数量的分区上时，新节点最终从现有节点获得公平的负载份额。 ● 随机选择分区边界要求使用基于散列的分区（可以从散列函数产生的数字范围中挑选边界）。实际上，这种方法最符合一致性哈希的原始定义。\n运维：手动还是自动再平衡 重要问题：自动还是手动进行？ ● 完全自动重新平衡和完全手动之间有一个过渡阶段：自动生成建议的分区分配，需要管理员提交才能生效。\n完全自动重新平衡的缺点： ● 虽然很方便，但是结果不可预测。 ● 再平衡的代价昂贵，因为它需要重新路由请求并将大量数据从一个节点移动到另一个节点。 ● 如果没有做好，这个过程可能会使网络或节点负载过重，降低其他请求的性能。 ○ 如果全自动重新平衡遇到了自动故障检测：系统判断一个节点过载，然后重新自动平衡，导致情况更糟。\n请求路由 服务发现(service discovery) ● 确定客户发出请求时，知道要连接哪个节点进行读取\n概括来说，这个问题有几种不同的方案（如图6-7所示）:\n允许客户联系任何节点（例如，通过循环策略的负载均衡（Round-Robin Load Balancer））。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求；否则，它将请求转发到适当的节点，接收回复并传递给客户端。 首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求；它仅负责分区的负载均衡。 要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介 关键问题： ● 如何了解分区-节点之间的分配关系变化？ ● 解决方法：所有参与者达成共识。 ○ 分布式系统中有达成共识的协议，但很难被正确实现。\n常见实现 ZooKeeper： ● 依赖于一个独立的协调服务，比如ZooKeeper来跟踪集群元数据 ● 每个节点在ZooKeeper中注册自己，ZooKeeper维护分区到节点的可靠映射。 ● 其他参与者（如路由层或分区感知客户端）可以在ZooKeeper中订阅此信息。 ● 只要分区分配发生了改变，或者集群中添加或删除了一个节点，ZooKeeper就会通知路由层使路由信息保持最新状态。\n应用：\n使用 ZooKeeper ○ LinkedIn的Espresso使用Helix 【31】进行集群管理（依靠ZooKeeper） ○ HBase，SolrCloud和Kafka也使用ZooKeeper来跟踪分区分配。 ○ MongoDB具有类似的体系结构，但它依赖于自己的配置服务器（config server） 实现和mongos守护进程作为路由层。 使用流言协议（gossip protocol） ○ Cassandra和Riak使用流言协议来传播集群状态的变化 ○ 请求可以发送到任意节点，该节点会转发到包含所请求的分区的适当节点 ○ 增加了更多的复杂性，但是避免了对像ZooKeeper这样的外部协调服务的依赖。 不自动重新平衡 ○ Couchbase，简化了设计 ○ 它配置了一个名为moxi的路由层，它会从集群节点了解路由变化 执行并行查询 ● 目前，我们只关注读取或写入单个键的非常简单的查询（加上基于文档分区的二级索引场景下的分散/聚集查询）。也是大多数 NoSQL 分布式数据存储所支持的访问层级。 ● 通常用于分析的大规模并行处理（MPP, Massively parallel processing） 关系型数据库产品在其支持的查询类型方面要复杂得多。 ● 把多个连接，过滤，分组和聚合操作分解成多个执行阶段和分区，分布式并行执行。 ● 见第十章。\n本章小结 ● 数据量非常大的时候，在单台机器上存储和处理不再可行，而分区则十分必要。 ● 分区的目标是在多台机器上均匀分布数据和查询负载，避免出现热点（负载不成比例的节点）。 ● 这需要选择适合于您的数据的分区方案，并在将节点添加到集群或从集群删除时进行分区再平衡。\n两种主要的分区方法：\n键范围分区 ○ 其中键是有序的，并且分区拥有从某个最小值到某个最大值的所有键。 ○ 排序的优势在于可以进行有效的范围查询，但是如果应用程序经常访问相邻的键，则存在热点的风险。 ○ 在这种方法中，当分区变得太大时，通常将分区分成两个子分区，动态地再平衡分区。 散列分区 ○ 散列函数应用于每个键，分区拥有一定范围的散列。 ○ 这种方法破坏了键的排序，使得范围查询效率低下，但可以更均匀地分配负载。 ○ 通过散列进行分区时，通常先提前创建固定数量的分区，为每个节点分配多个分区，并在添加或删除节点时将整个分区从一个节点移动到另一个节点。也可以使用动态分区。 两种方法搭配使用也是可行的，例如使用复合主键： ● 使用键的一部分来标识分区，而使用另一部分作为排序顺序。\n我们还讨论了分区和二级索引之间的相互作用。 次级索引也需要分区，有两种方法： ● 基于文档分区（本地索引），其中二级索引存储在与主键和值相同的分区中。 ○ 这意味着只有一个分区需要在写入时更新 ○ 但是读取二级索引需要在所有分区之间进行分散/收集。 ● 基于关键词分区（全局索引），其中二级索引存在不同的分区中。 ○ 辅助索引中的条目可以包括来自主键的所有分区的记录。 ○ 当文档写入时，需要更新多个分区中的二级索引； ○ 但是可以从单个分区中进行读取。 最后，我们讨论了将查询路由到适当的分区的技术，从简单的分区负载平衡到复杂的并行查询执行引擎。\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E5%85%AD%E7%AB%A0/","summary":"第六章: 分区 什么是分区？ ● 对于非常大的数据集，或非常高的吞吐量，仅仅进行复制是不够的：我们需要将数据进行分区（partitions），也称为","title":"DDIA第六章"},{"content":"听算命的一些感想 由于最近国庆订了婚，我家老母亲就想着去给我算个命，看看我和胡小蕊合不合。我也一直催着赶紧去给我们算，别耽误我们的时间，所以今天一大早她五点多就给我发消息问我胡小蕊的出生时辰，我没听到，就打电话给我，我还是睡眼朦胧的状态，极其不耐烦的回答了她。\n一直以来我都是不信命的，什么名由天定，命中注定，我觉得都是扯淡。但是她要去算命我也不会拦着，她们有她们的小世界，我们的世界也只不过比他们大一点点，其实也没必要去嘲笑这件事情。所以就由我妈去算了命。\n上午十点多，我还在公司写代码，她便把算命说的话全部录下来发给我说让我听，但是我还在上班，因此留到下班回来之后再听。大概的内容就是根据我和胡小蕊的生辰八字做一些推测和预测，顺便卖一些小商品。回来后，我和胡小蕊一起把这段长达十六分钟的录音听了一遍，我充当翻译，我们大概听了三十分钟。\n水命 第一个要点就是 那位算命先生从我的生辰八字开始剖析，丁丑年，寅巳月，更辰更寅，己丑日，甲戌时啥啥的 ，说我是水命，从小就有水灾。这倒不假但是不至于是水灾，我小时候确实落水过，小时候外婆在洗衣服的时候，我在旁边玩耍，不小心就掉水里了，然后被我外婆一把从水里提了起来，我就呛了几口水。若说是水灾，倒也是，但是说是水灾也不至于成灾祸的地步。只是我母亲从小会算命，就说我有水灾，因此我小时候在水边玩耍时会格外注意安全。或许是因如此，我才免得水灾吧。然后说我头上受过两次伤，这个算的确实很准，就受过两次伤。一次在三岁的时候，现在还有伤疤，一次是在高中的时候，打篮球受的伤。就在我觉得他算的很准的时候，他又说我没有读研究生是因为我不想读，是我选择去上班而不是读研。但是我是因为考研没考上才上班的。\n接着剖析了我为什么是水命，从周易和八卦来说的，具体的我也听不明白。 然后水命是水财。水温和而内敛，说我比较内向，不太爱说话，不太爱与父母沟通。这点对也不对，我并不是一个内向的人，但是也不是一个外向的人。接着说我应该与西北或北边的结婚。说蚌埠就是北边的。而且胡小蕊家是五河，五条河，是水，说啥特别合\n杨绛先生说算命 当杨绛提到“走到人生边上”时，她可能在表达一个人在生命的晚年或关键时刻，更加关注生命的真谛和人生的意义。对于很多人来说，年老或者经历了很多人生风风雨雨的阶段，他们会更加思考自己的生命轨迹和命运。在这种时候，一些人可能会寻求算命或者其他方式来探索自己的未来或者过去，寻找生命的方向或者指导。\n然而，杨绛的思考也强调了生命的不确定性和无法预测性。算命可以提供一些参考，但它并不是绝对可信的预测工具。生命中的很多事情是无法预测的，也许正是这种未知性赋予了生命以价值和意义。\n杨绛可能会认为，不管我们是否选择通过算命来探索人生的奥秘，都应该保持一种开放的心态，不断学习和成长，因为生活的真正价值可能不在于预测未来，而在于我们如何面对和回应生命中的挑战和机遇。\n综上所述，杨绛的思考可能强调了生命的不确定性和变化，同时也强调了人们应该以开放的心态去探索人生的智慧和意义。算命可以是一种方式，但不应该是唯一的方式，而人们应该通过自己的经验和反思来理解自己的生命。\n钱 算命据我妈所说，一共花了200，算命100.然后买他的产品100.因为算命的说我家门口有根电线柱子，有影响我家的风水，要么给他拔了，要么就买他的产品。我妈也是深信不疑啊，就买了。据我妈所说啊，在她之前有个做生意的小伙子，算命先生说有个什么东西影响他做生意的风水，需要买他的产品，才会让他财源广进，结果那个小伙子就买了啊。一共花了六百块。\n好家伙，现在算命，不仅仅要把周易八卦背的滚瓜烂熟啊，还得学会社会工程学和带货的技术。因为我妈看起来就是不会为了风水去花600的人，所以同样价值的产品，卖给我妈就是100，卖给那位做生意的小伙子就是600。算命先生是可以通过观察人的行为举止来判断出这个人家境和性格的。而且经过那么多次实战，已经能够做到很熟练和精准的判断了\n","permalink":"https://csqread.top/posts/life/%E5%90%AC%E8%80%81%E5%A6%88%E7%AE%97%E5%91%BD%E6%84%9F%E6%83%B3/","summary":"听算命的一些感想 由于最近国庆订了婚，我家老母亲就想着去给我算个命，看看我和胡小蕊合不合。我也一直催着赶紧去给我们算，别耽误我们的时间，所以今","title":"听老妈算命感想"},{"content":"中秋国庆·蚌埠 活动 蚌精 一年一度的中秋国庆假期来临，这次我的目的地是蚌埠，一个曾经的安徽第三大城市。\n从上海到蚌埠只要两个小时，虽然上海到安庆和上海到蚌埠的距离是一样的，但是京沪高铁就是不一样。上海回安庆要四个小时，哎，没办法，谁让他们是京爷和沪爷呢。不过，从理性的角度来分析下，上海到蚌埠中间仅仅停靠三站，而且都是大平原地区，时速非常快，而到安庆的后半段基本上是山区，而且要停靠很多站，所以导致时速非常慢。\n蚌埠给我的感觉就是一望无际的大平原，视野非常的开阔，稻田里都种满了水稻，这个时候稻子都已成熟。作为一个皖南人，第一次在皖北平原确实有一种全新的体验，难怪说安徽，是一个被强行分割的省份。皖北和皖南是完全不一样的气质。\n一望无际的稻田 在胡小蕊家干的第一件事情就是和叔叔去摘梨子，作为美丽乡村之一，这里的梨树很多：\n摘梨子 中秋的时候，还是有不少人从外地回来的。虽然是蚌埠，作为曾经的安徽第三大城市，但是村里还是有很多人出门去打工挣钱的。在农村里是赚不到什么钱的。但是他们这边的土地还是很值钱，平均每家都有十几亩地，每亩地还能租出去1千块钱一年。而在皖南丘陵地区，每亩地只能租出去两百块钱一年。\n在蚌埠这边的土地很多都是用来养殖水产品，比如螃蟹，而我们那边也是用来养殖水产品，比如龙虾。\n习俗 皖北这边习俗还是有很多不同的。比如说这边中秋的时候，中午吃饭前要放鞭炮，然后才可以吃饭，每家每户都是这样。然后到了晚上还要放烟花。而且中国传统节日这边都要放鞭炮，清明，端午，中秋，春节。这里做买鞭炮生意的，岂不是要发财？！\n递烟习俗，如果有客人来了，需要拿两根烟放在手上，一根在上边，一根在下边，如果，客人的辈分或者年纪比你大，那么他就拿上面的那根。我们就可以把下边的那根放回去，如果备份或者年纪比你小，那么他就会拿下面的那根。而在我们皖南就没有这么多规矩，基本上就是拿一根递给客人。而且我们皖南喜欢请客人喝茶，茶叶是会客之道。\n皖北早上喜欢吃馍，喜欢大馍就着菜吃，而皖南的早上基本上是喝粥。皖北的主食是面，皖南的主食是米饭。这点区别我在蚌埠这体验感觉很明显，因为我这几天早上都是吃馍，没有粥，我就感觉难以下咽，太硬了。\n总结 在皖北逛了蚌埠，给我的整体感觉是安徽还是太穷了，作为曾经的第三大城市，大家也都是出门打工，家里都没有人（我说的是农村），不管是皖南还是皖北大多数人如果想挣钱还是要出省打工。虽然这几年一直在集全省之力发展合肥，但是安徽其他的城市还是太拉跨了。后面几天回到了安庆，家乡这几年已经开始发展旅游业了，虽然也没有怎么发展起来。俗话说的好，如果一个地方开始发展旅游业了，那么这个地方就没有什么牌可以打了。经济凋敝只是时间问题。\n还有一些观察：在蚌埠和安庆的路上，汽车还是燃油车居多，鲜有几辆绿牌车，在大城市呆久了就会有种错觉，就是觉得国家的新能源汽车发展的非常好，满大街都是新能源汽车，但是一离开大城市就会发现，大家在家里开的还是燃油车。这里当然有几种原因：一是城市的发展是具有时间传递性的。在上海这边普及了新能源，也许要过几年才会在内陆出现大量的新能源汽车。二是在安徽蚌埠或者说安庆，已经有汽车的也不会再花钱去买新能源汽车，没有汽车的优先考虑也不会是新能源汽车，虽然油价很贵，但是我和村里人聊天以及大家的闲聊中都会体现出，不会优先选择新能源汽车，包括混动都不会选择。原因是非常多的，包括对新能源技术的不信任以及里程焦虑等问题。\n还有一项就是蚌埠村里人都比较勤奋，大家都会出去挣钱，如果有人在家里不出去挣钱，就会有人说他整天在家里游手好闲，不出门挣钱，大家的攀比心放在挣钱上，看谁挣得钱多谁就有话语权。而在安庆村里却恰恰相反，大家都很少出去挣钱，都在家门口，县城或者镇上，市里找一些工作。大家攀比的不是谁挣的钱多，而是谁花的钱多谁就有话语权，非常的浪费，钱都花在面子上。其实大家都是虚荣的，只不过，虚荣心放在正确的地方和放在错误的地方往往会决定着不同的后果。\n","permalink":"https://csqread.top/posts/life/%E8%9A%8C%E5%9F%A0%E4%B9%8B%E6%97%85/","summary":"中秋国庆·蚌埠 活动 蚌精 一年一度的中秋国庆假期来临，这次我的目的地是蚌埠，一个曾经的安徽第三大城市。 从上海到蚌埠只要两个小时，虽然上海到安庆和","title":"蚌埠之旅"},{"content":"这是一个计划 其实这本书我已经看了两遍了，只能说第二次比第一次收获更多，可能是第二次读的时候是已经工作了一段时间，读起来再也不是纸上谈兵，而是能够联系到工作上的实际场景，脑子中有了图像。但是这本案牍之书，读两遍肯定是远远不够的。因此最近我想开始读第三遍，这个时候边读边做一个读书笔记以此来鞭策自己，能够真的深入理解JVM。\n但是在开始这个计划之前，我需要把DDIA的篇幅弄完。虽然DDIA后续也会进行二刷。感觉最近我工作之后的工作量有点大。还有一个小小的比赛要参加。\n计划是在10月份读完深入理解Java虚拟机，边做完读书笔记，因为有个国庆小长假，我可以在家里宅着看看。所以也会在10月份结束做完这本书的读书笔记。\n","permalink":"https://csqread.top/posts/tech/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%B3%BB%E5%88%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E8%AE%A1%E5%88%92/","summary":"这是一个计划 其实这本书我已经看了两遍了，只能说第二次比第一次收获更多，可能是第二次读的时候是已经工作了一段时间，读起来再也不是纸上谈兵，而是","title":"深入理解Java虚拟机系列读书笔记计划"},{"content":"第五章：数据复制 复制的目的：\n● 使得数据与用户在地理上接近（从而减少延迟）\n● 即使系统的一部分出现故障，系统也能继续工作（从而提高可用性）\n● 伸缩可以接受读请求的机器数量（从而提高读取吞吐量）\n如果复制的数据不会随时间而改变，那复制就很简单：复制一次即可。 复制的难点在于复制数据的变更。 三种流行的变更复制算法：\n● 单领导者\n● 多领导者\n● 无领导者\n复制时的权衡：使用同步复制还是异步复制？如何处理失败的副本？\n领导者与追随者 ● 存储数据库副本的每个节点称为 副本（replica）。\n● 多副本的问题：如何确保数据都落在了所有的副本上。\n○ 每次对数据库的写入都要传播到所有副本上，否则副本就会有不一样的数据。\n○ 常见的解决方案：基于领导者的复制（主从复制）。 主从复制工作原理：\n副本之一被指定为领导者（leader，也被称作主库）\na. 客户端写数据时，要把请求发送给领导者； b. 领导者把新输入写入本地存储。 2. 其他副本被称为追随者（followers，也被称作只读副本、从库、热备） a. 每当领导者将新数据写入本地存储时，他会把数据变更发送给所有的追随者，称之为复制日志或变更流。 b. 每个追随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照领导者处理的相同顺序应用所有写入。 3. 当客户想要从数据库中读取数据时，它可以向领导者或追随者查询。 但只有领导者才能接受写操作（从客户端的角度来看从库都是只读的）。 同步复制与异步复制 复制系统的一个重要细节是：复制是 同步（synchronously） 发生还是 异步（asynchronously） 发生。 以用户更新头像为例： ● 从库 1 的复制是同步的 ● 从库 2 的复制是异步的\n同步复制： ● 优点：从库保证和主库一直的最新数据副本 ● 缺点：如果从库没有响应（如已崩溃、网络故障），主库就无法处理写入操作。主库必须阻止所有的写入，等待副本再次可用。\n半同步：通常使用一个从库与主库是同步的，而其他从库是异步的。这保证了至少两个节点拥有最新的数据副本。\n通常情况下，基于领导者的复制都配置为完全异步。注意，主库故障可能导致丢失数据。\n设置新从库 有时会增加一个新的从库。\n过程：\n在某个时刻获取主库的一致性快照（如果可能），而不必锁定整个数据库。大多数数据库都具有这个功能，因为它是备份必需的。对于某些场景，可能需要第三方工具，例如MySQL的innobackupex 。 将快照复制到新的从库节点。 从库连接到主库，并拉取快照之后发生的所有数据变更。这要求快照与主库复制日志中的位置精确关联。该位置有不同的名称：例如，PostgreSQL将其称为 日志序列号（log sequence number, LSN），MySQL将其称为 二进制日志坐标（binlog coordinates）。 当从库处理完快照之后积压的数据变更，我们说它 赶上（caught up） 了主库。现在它可以继续处理主库产生的数据变化了。 处理节点宕机 我们的目标：即使个别节点失效，也要能保持整个系统运行，并尽可能控制节点停机带来的影响。\n从库失效：追赶恢复 ● 从库可以从日志知道，在发生故障前处理的最后一个事务。 ● 所以从库可以连接到主库，并拉取断开连接后的所有数据变更。 ● 应用完成所有变更之后，它就赶上了主库，继续接收数据变更流。\n主库失效：故障切换 ● 故障切换：需要把一个从库提升为新的主库，重新配置客户端，其他从库需要开始拉取来自新主库的变更。 ● 故障切换可以手动或者自动进行。\n自动故障切换：\n确认主库失效。有很多事情可能会出错：崩溃，停电，网络问题等等。没有万无一失的方法来检测出现了什么问题，所以大多数系统只是简单使用 超时（Timeout） ：节点频繁地相互来回传递消息，并且如果一个节点在一段时间内（例如30秒）没有响应，就认为它挂了（因为计划内维护而故意关闭主库不算）。 选择一个新的主库。这可以通过选举过程（主库由剩余副本以多数选举产生）来完成，或者可以由之前选定的控制器节点（controller node） 来指定新的主库。主库的最佳人选通常是拥有旧主库最新数据副本的从库（最小化数据损失）。让所有的节点同意一个新的领导者，是一个共识问题，将在第九章详细讨论。 重新配置系统以启用新的主库。客户端现在需要将它们的写请求发送给新主库（将在“请求路由”中讨论这个问题）。如果老领导回来，可能仍然认为自己是主库，没有意识到其他副本已经让它下台了。系统需要确保老领导认可新领导，成为一个从库。 故障切换会出现很多大麻烦：\n● 如果使用异步复制，则新主库可能没有收到老主库宕机前最后的写入操作。在选出新主库后，如果老主库重新加入集群，新主库在此期间可能会收到冲突的写入，那这些写入该如何处理？最常见的解决方案是简单丢弃老主库未复制的写入，这很可能打破客户对于数据持久性的期望。 ● 如果数据库需要和其他外部存储相协调，那么丢弃写入内容是极其危险的操作。例如在GitHub 【13】的一场事故中，一个过时的MySQL从库被提升为主库。数据库使用自增ID作为主键，因为新主库的计数器落后于老主库的计数器，所以新主库重新分配了一些已经被老主库分配掉的ID作为主键。这些主键也在Redis中使用，主键重用使得MySQL和Redis中数据产生不一致，最后导致一些私有数据泄漏到错误的用户手中。 ● 发生某些故障时（见第八章）可能会出现两个节点都以为自己是主库的情况。这种情况称为 脑裂(split brain)，非常危险：如果两个主库都可以接受写操作，却没有冲突解决机制（请参阅“多主复制”），那么数据就可能丢失或损坏。一些系统采取了安全防范措施：当检测到两个主库节点同时存在时会关闭其中一个节点[1]，但设计粗糙的机制可能最后会导致两个节点都被关闭【14】。 ● 主库被宣告死亡之前的正确超时应该怎么配置？在主库失效的情况下，超时时间越长，意味着恢复时间也越长。但是如果超时设置太短，又可能会出现不必要的故障切换。例如，临时负载峰值可能导致节点的响应时间超时，或网络故障可能导致数据包延迟。如果系统已经处于高负载或网络问题的困扰之中，那么不必要的故障切换可能会让情况变得更糟糕。\n复制日志的实现 基于主库的复制，底层工作有几种不同的复制方式。\n基于语句的复制 在最简单的情况下，主库记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库。 问题： ● 任何调用 非确定性函数（nondeterministic） 的语句，可能会在每个副本上生成不同的值。比如 NOW(), RAND()。 ● 如果语句使用了自增列（auto increment），或者依赖于数据库中的现有数据（例如，UPDATE \u0026hellip; WHERE \u0026lt;某些条件\u0026gt;），则必须在每个副本上按照完全相同的顺序执行它们，否则可能会产生不同的效果。影响并发。 ● 有副作用的语句（例如，触发器，存储过程，用户定义的函数）可能会在每个副本上产生不同的副作用，除非副作用是绝对确定的。\n传输预写式日志（WAL） 第三章告诉我们，写操作通常追加到日志中： ● 对于日志结构存储引擎（SSTables 和 LSM 树），日志是主要存储位置。日志段在后台压缩，并进行垃圾回收。 ● 覆盖单个磁盘块的 B 树，每次修改会先写入预写式日志（Write Ahead Log, WAL），以便崩溃后索引可以恢复到一个一致的状态。 所以，日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：主库把日志发送给从库。 PostgreSQL和Oracle等使用这种复制方法。 缺点： ● 复制与存储引擎紧密耦合。 ● 不可能使主库和从库上运行不同版本的数据库软件。 ● 运维时如果升级软件版本，有可能会要求停机。\n逻辑日志复制（基于行） 采用逻辑日志，可以把复制与存储逻辑分离。 关系型数据库通常以行作为粒度描述数据库写入的记录序列： ● 对于插入的行，日志包含所有列的新值； ● 对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，或者所有列的旧值。 ● 对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列（至少是更新列）的新值。 优点： ● 逻辑日志与存储引擎分离，方便向后兼容。可以让领导者和跟随者运行不同版本的数据库软件。 ● 对于外部应用，逻辑日志也更容易解析。比如复制到数据仓库，或者自定义索引和缓存。被称为数据变更捕获。\n基于触发器的复制 ● 上述复制都是数据库自己实现的。也可以自定义复制方法：数据库提供了触发器和存储过程。 ● 允许数据库变更时，自动执行应用的程序代码。 ● 开销更大，更容易出错。但更灵活。\n复制延迟问题 ● 主从异步同步会有延迟：导致同时对主库和从库的查询，结果可能不同。 ● 因为从库会赶上主库，所以上述效应被称为「最终一致性」。 ● 复制延迟可能超过几秒或者几分钟，下文是 3 个例子。\n读己之写 如果用户把数据提交到了主库，但是主从有延迟，用户马上看数据的时候请求的从库，会感觉到数据丢失。\n此时需要「读写一致性」，也成为读己之写一致性。 技术： ● 读用户可能已经修改过的内容时，都从主库读；比如读个人资料都从主库读，读别人的资料可以读从库。 ● 如果应用的部分内容都可能被用户编辑，上述方法无效。可以指定更新后的时间窗口，比如上次更新的一分钟内从主库读。 ● 客户端记住最近一次写入的时间戳，从库提供查询时，保证该时间戳前的变更都已经传播到了本从库；否则从另外的从库读，或者等待从库追赶上来。（时间戳可以是逻辑时间戳，如日志序列号；或者要有准确的时间同步） ● 如果副本在多个数据中心，则比较复杂。任何需要从领导者提供服务的请求，都必须路由到包含主库的数据中心。 用户有多个设备时，还要考虑的问题： ● 记录更新时间戳变得更困难； ● 不同设备可能路由到不同的数据中心。如果你的方法需要读主库，就需要把同一用户的请求路由到同一个数据中心。\n单调读 用户可能会遇到时光倒流。 第一次请求到从库看到了评论，第二次请求到另外一个从库发现评论消失。\n单调读保证了这种异常不会发生。 方法： ● 确保每个用户总是从同一副本来读取。比如基于用户 ID 的散列来选择副本，而不是随机选。 ● 但是如果该副本失败，则需要路由到另一个副本。\n一致前缀读 一系列事件可能出现前后顺序不一致问题。比如回答可能在提问之前发生。 这是分区（分片）数据库中的一个特殊问题：不同分区之间独立，不存在全局写入顺序。\n需要「一致前缀读」。 方法： ● 任何因果相关的写入都写入相同的分区。\n复制延迟的解决方案 ● 可以信赖数据库：需要事务。 ● 事务（transaction） 存在的原因：数据库通过事务提供强大的保证，所以应用程序可以更加简单。 ● 单节点事务存在了很长时间，但是分布式数据库中，许多系统放弃了事务。“因为事务的代价太高。” ● 本书的其余部分将继续探讨事务。\n多主复制 ● 单个领导者的复制架构是个常见的方法，也有其他架构。 ● 基于领导者复制的主要缺点：只有一个主库，所有的写入都要通过它。 ● 多个领导者的复制：允许多个节点接受写入，复制仍然是转发给所有其他节点。每个领导者也是其他领导者的追随者。\n多主复制的应用场景 单个数据中心内部使用多个主库没有太大意义。 运维多个数据中心 ● 多领导配置允许每个数据中心都有自己的主库。 ● 每个数据中心内部使用常规的主从复制； ● 数据中心之间，每个数据中心的主库都会将其更改复制到其他数据中心的主库中。\n运维多个数据中心时，单主和多主的适应情况比较：\n性能\n● 单主配置中，每个写入都得穿过互联网，进入主库所在的数据中心。会增大写入时间。\n● 多主配置中，每个写操作都可以在本地数据中心进行处理，与其他数据中心异步复制。感觉到性能更好。\n容忍数据中心停机\n● 单主配置中，如果主库所在的数据中心发生故障，必须让另一个数据中心的追随者成为主领导者。\n● 多主配置中，每个数据中心都可以独立于其他数据中心继续运行。若发生故障的数据中心归队，复制会自动赶上。\n容忍网络问题\n● 数据中心之间的网络需要通过公共互联网，不如数据中心之内的本地网络可靠。\n● 单主配置对网络连接问题非常敏感，因为写是同步的。\n● 异步复制的多主配置更好地承受网络问题。\n多主复制的缺点： ● 两个数据中心可能会修改相同的内容，写冲突必须解决。\n● 多主复制比较危险，应尽可能避免。\n需要离线操作的客户端 ● 多主复制的另一适用场景：应用程序在断网后仍然需要继续工作。\n● 在这种情况下，每个设备都有一个充当领导者的本地数据库（它接受写请求），并且在所有设备上的日历副本之间同步时，存在异步的多主复制过程。复制延迟可能是几小时甚至几天，具体取决于何时可以访问互联网。\n● 每个设备相当于一个“数据中心”\n协同编辑 ● 协作式编辑不能视为数据库复制问题，但是与离线编辑有许多相似\n● 一个用户编辑文档时，所做的更改将立即应用到其本地副本（web 或者客户端），并异步复制到服务器和编辑同一文档的任何其他用户。\n● 如果想要不发生编辑冲突，则应用程序需要先将文档锁定，然后用户才能进行编辑；如果另一用户想编辑，必须等待第一个用户提交修改并释放锁定。这种协作模式相当于主从复制模型下在主节点上执行事务操作。\n● 但是，为了加速写作，可编辑的粒度需要非常小（例如单个按键，甚至全程无锁）。\n● 也会面临所有多主复制都存在的挑战，即如何解决冲突。\n处理写入冲突 ● 多领导者复制的最大问题是可能发生写冲突，因此需要解决冲突。\n● 单主数据库没有这个问题。\n● 假如两个用户同时修改标题：\n同步与异步冲突检测 ● 单主数据库：第二个写入被阻塞，并等待第一个写入完成，或被终止；\n● 多主配置：两个写入都成功，稍后的时间点仅仅异步地监测到冲突。\n● 如果想冲突检测同步-等待被写入到所有的副本，那么丢失了多主复制的优点。\n避免冲突 ● 处理冲突的最简单策略是避免它们：确保特定记录的写入都通过同一个领导者，就不会有冲突。\n● 但是，如果更改指定的记录主库——比如数据中心故障，需要把流量重新路由；冲突避免会中断，必须处理不同主库同时写入的可能性。\n收敛至一致的状态 ● 单主数据库按顺序进行写操作：如果同一个字段有多个更新，则最后一个写操作将决定该字段的最终值。\n● 在多主配置中，没有明确的写入顺序，所以最终值应该是什么并不清楚。\n● 每个复制方案都必须确保数据在所有副本中最终都是相同的。\n● 数据库必须以一种 收敛（convergent） 的方式解决冲突，这意味着所有副本必须在所有变更复制完成时收敛至一个相同的最终值。\n实现冲突合并解决有多种途径：\n● 给每个写入一个唯一的ID（例如，一个时间戳，一个长的随机数，一个UUID或者一个键和值的哈希），挑选最高ID的写入作为胜利者，并丢弃其他写入。\n● 为每个副本分配一个唯一的ID，ID编号更高的写入具有更高的优先级。这种方法也意味着数据丢失。\n● 以某种方式将这些值合并在一起 - 例如，按字母顺序排序，然后连接它们\n● 用一种可保留所有信息的显式数据结构来记录冲突，并编写解决冲突的应用程序代码（也许通过提示用户的方式）。\n自定义冲突解决逻辑 解决冲突的最合适方法取决于应用程序。\n写时执行\n● 只要数据库系统检测到复制更改日志中存在冲突，就会调用冲突处理程序。\n读时执行\n● 当检测到冲突时，所有冲突写入被存储。\n● 下一次读取数据时，会将这些多个版本的数据返回给应用程序。\n● 应用程序可能会提示用户或自动解决冲突，并将结果写回数据库。\n自动冲突解决 规则复杂，容易出错。\n● 无冲突复制数据类型（Conflict-free replicated datatypes）：是可以由多个用户同时编辑的集合，映射，有序列表，计数器等的一系列数据结构，它们以合理的方式自动解决冲突。一些CRDT已经在Riak 2.0中实现\n● 可合并的持久数据结构（Mergeable persistent data structures）显式跟踪历史记录，类似于Git版本控制系统，并使用三向合并功能（而CRDT使用双向合并）。\n● 可执行的转换（operational transformation）是 Etherpad 和Google Docs 等合作编辑应用背后的冲突解决算法。它是专为同时编辑项目的有序列表而设计的，例如构成文本文档的字符列表。\n什么是冲突？ ● 显而易见的冲突：两个写操作并发地修改了同一条记录中的同一个字段。\n● 微秒的冲突：一个房间接受了两个预定。\n多主复制拓扑 ● 复制拓扑（replication topology）描述写入从一个节点传播到另一个节点的通信路径。\n● 只有两个领导者时，只有一个合理的拓扑：互相写入。\n● 当有两个以上的领导，拓扑很多样：\n● 最普遍的是全部到全部；\n● MySQL 仅支持环形拓扑。\n防止无限复制循环：\n● 圆形和星型拓扑，节点需要转发从其他节点收到的数据更改。\n● 防止无限复制循环：每个节点都有唯一的标识符，在复制日志中，每个写入都标记了所有已经过的节点的标识符。\n环形和星形拓扑的问题\n● 一个节点故障，可能中断其他节点之间的复制消息流。\n● 拓扑结构可以重新配置，但是需要手动操作。\n● 全部到全部的容错性更好，避免单点故障。\n全部到全部拓扑的问题\n● 网络问题导致消息顺序错乱\n● 写入时添加时间戳是不够的的。\n● 解决办法是版本向量技术。\n● 有些数据库没有该功能。\n无主复制 ● 一些数据库放弃主库的概念，允许任何副本直接接收来自客户端的写入。\n● 一些无主配置中，客户端直接写入到几个副本中；\n● 另一些情况下，一个协调者节点代表客户端进行写入。\n当节点故障时写入数据库 无主复制中，故障切换不存在。 如果一个副本故障或下线，重启后提供的数据是落后的。 解决办法：客户端同时请求多个副本，根据版本号确定最新值。 读修复和反熵 故障节点重新上线，怎么追上错过的写入? 读修复（Read repair） 客户端检测到陈旧的值，客户端将新值写回到该副本。 适合读频繁的值。 反熵过程（Anti-entropy process） 数据库的后台进程，不断查找副本之间的数据差异，把缺少的数据进行复制。 反熵过程不会以任何特定的顺序复制写入，复制数据之前可能有显著的延迟。 读写的法定人数 如果有副本下线，究竟多少个副本完成才可以认为写成功？ 计算方式\n如果有n个副本，每个写入必须由w节点确认才能被认为是成功的，并且我们必须至少为每个读取查询r个节点。 （只要$w + r\u003e n$，我们期望在读取时获得最新的值，因为r个读取中至少有一个节点是最新的。遵循这些r值，w值的读写称为法定人数（quorum）的读和写】 可以认为，r和w是有效读写所需的最低票数。 法定人数一致性的局限性 但是，即使在 $w + r\u0026gt; n$ 的情况下，也可能存在返回陈旧值的边缘情况。 ● 如果使用了宽松的法定人数，w 个写入和 r 个读取落在完全不同的节点上。\n● 两个写入同时发生，不清楚哪一个先发生。\n● 写操作和读操作同时发生，写操作可能仅反映在某些副本上。\n● 写操作在某些副本上成功，而在其他节点上失败，在小于w个副本上写入成功。\n● 如果携带新值的节点失败，需要读取其他带有旧值的副本。\n● 即使一切工作正常，有时也会不幸地出现关于时序（timing） 的边缘情况。\n不要把 w 和 r 当做绝对的保证，应该看做是概率。 强有力的保证需要事务和共识。\n监控陈旧度 ● 基于领导者的复制，数据库会会公开复制滞后的度量标准，可以做监控。\n● 无领导者复制中，没有固定的写入顺序，监控困难。\n● 最终一致性是非常模糊的保证。\n宽松的法定人数与提示移交 ● 合理配置的法定人数可以使数据库无需故障切换即可容忍个别节点的故障。\n● 需要高可用、低延时、且能够容忍偶尔读到陈旧值的应用场景来说，这些特性使无主复制的数据库很有吸引力。\n问题 ● 网络中断导致剩余可用节点可能少于w或r，客户端达不到法定人数。\n权衡\n● 对于所有无法达到w或r节点法定人数的请求，是否返回错误是更好的？\n● 或者我们是否应该接受写入，然后将它们写入一些可达的节点，但不在这些值通常所存在的n个节点上？\n宽松的法定人数（sloppy quorum）\n● 上述的后者是宽松的法定人数（sloppy quorum）。\n● 大型集群中，节点数量明显多于 n 个。\n● 写和读仍然需要 w 和 r 个成功的响应，但是不来自指定的 n 个节点中。\n提示移交（hinted handoff）\n● 网络中断得到解决时，另一个节点临时接收的一个节点的任何写入都被发送到适当的“主”节点。\n优点\n● 提高了写入可用性：任何 w 个节点可用，数据库就可以接收写入。\n缺点\n● 即使当$w + r\u0026gt; n$时，也不能确定读取某个键的最新值，因为最新的值可能已经临时写入了n之外的某些节点。\n在传统意义上，一个宽松的法定人数实际上不是一个法定人数。\n常见使用中，宽松的法定人数是可选的。\n运维多个数据中心 ● 无主复制也适用于多数据中心操作，因为它旨在容忍冲突的并发写入，网络中断和延迟尖峰。\n● 无论数据中心如何，每个来自客户端的写入都会发送到所有副本，但客户端通常只等待来自其本地数据中心内的法定节点的确认，从而不会受到跨数据中心链路延迟和中断的影响。\n● 对其他数据中心的高延迟写入通常被配置为异步发生，尽管配置有一定的灵活性.\n检测并发写入 ● 无主复制，允许多个客户端同时写入相同的 key，会冲突。\n● 读修复和提示移交期间也可能会发生冲突。\n写入顺序问题举例：\n最后写入胜利（丢弃并发写入） 思路\n● 只需要存储最 “最近” 的值，允许 “更旧” 的值被覆盖和抛弃。\n● 需要有一种明确的方式来确定哪个写是“最近的”，并且每个写入最终都被复制到每个副本，那么复制最终会收敛到相同的值。\n● “最近”的，这个词没有意义，因为是并发的。\n方法：最后写入胜利\n● 可以为每个写入附加一个时间戳，挑选最 “最近” 的最大时间戳，并丢弃具有较早时间戳的任何写入。\n优点\n● 实现了最终收敛的目标\n缺点\n● 以持久性为代价：如果同一个Key有多个并发写入，即使它们报告给客户端的都是成功（因为它们被写入 w 个副本），也只有一个写入将存活，而其他写入将被静默丢弃。\n● 甚至可能会删除不是并发的写入\n● 如果丢失数据不可接受，那么最后写入胜利是个很烂的选择。\n使用场景\n● 唯一安全的方法：每一个键只写入一次，然后视为不变，避免并发更新。\n“此前发生”的关系和并发\n● 只要有两个操作A和B，就有三种可能性：A在B之前发生，或者B在A之前发生，或者A和B并发。\n● 我们需要的是一个算法来告诉我们两个操作是否是并发的。\n● 如果一个操作发生在另一个操作之前，则后面的操作应该覆盖较早的操作，但是如果这些操作是并发的，则存在需要解决的冲突。\n捕获\u0026quot;此前发生\u0026quot;关系 一个算法，可以确定两个操作是否是并发的，还是先后关系。 两个客户端同时向一个购物车添加项目，注意版本号：\n操作依赖关系：\n● 客户端永远不会完全掌握服务器上的数据，因为总是有另一个操作同时进行。 ● 但是，旧版本的值最终会被覆盖，并且不会丢失任何写入。\n服务器可以通过查看版本号来确定两个操作是否是并发的，算法的原理：\n● 服务器为每个键保留一个版本号，每次写入键时都增加版本号，并将新版本号与写入的值一起存储。\n● 当客户端读取键时，服务器将返回所有未覆盖的值以及最新的版本号。客户端在写入前必须读取。\n● 客户端写入键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起。 （针对写入请求的响应可以像读取请求一样，返回所有当前值，这使得我们可以像购物车示例那样将多个写入串联起来。）\n● 当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值（因为它知道它们已经被合并到新的值中），但是它必须用更高的版本号来保存所有值（因为这些值与随后的写入是并发的）。\n当一个写入包含前一次读取的版本号时，它会告诉我们的写入是基于之前的哪一种状态。\n合并同时写入的值 优点\n● 没有数据被无声地丢弃\n缺点\n● 客户端需要额外工作：客户端必须通过合并并发写入的值来擦屁股。\nRiak 称这些并发值为兄弟。\n合并兄弟值：\n● 与多领导者复制的冲突解决相同的问题。\n● 最简单的是根据版本号或者时间戳最后写入胜利，但会丢失数据。\n● 对于购物车来说，合理的合并方法是集合求并集。\n● 但是如果从购物车中删除东西，那么求并集会出错：一个购物车删除，求并集后，会重新出现在并集终值中。\n● 所以删除操作不能简单删除，需要留下有合适版本号的标记，被称为墓碑。\n容易出错，所以有了一些数据结构设计出来。\n版本向量 多个副本，但是没有领导者，该怎么办？\n● 每个副本、每个主键都定义一个版本号。\n● 每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本中看到的版本号。\n● 这个信息指出了要覆盖哪些值，以及保留哪些值作为兄弟。\n版本向量\n● 所有副本的版本号集合称为版本向量（version vector）。\n● 版本向量允许数据库区分覆盖写入和并发写入。\n本章小结 复制可以用于几个目的：\n高可用性\n即使在一台机器（或多台机器，或整个数据中心）停机的情况下也能保持系统正常运行\n断开连接的操作\n允许应用程序在网络中断时继续工作\n延迟\n将数据放置在距离用户较近的地方，以便用户能够更快地与其交互\n可伸缩性\n能够处理比单个机器更高的读取量可以通过对副本进行读取来处理\n我们讨论了复制的三种主要方法：\n单主复制\n客户端将所有写入操作发送到单个节点（领导者），该节点将数据更改事件流发送到其他副本（追随者）。读取可以在任何副本上执行，但从追随者读取可能是陈旧的。\n多主复制\n客户端发送每个写入到几个领导节点之一，其中任何一个都可以接受写入。领导者将数据更改事件流发送给彼此以及任何跟随者节点。\n无主复制\n客户端发送每个写入到几个节点，并从多个节点并行读取，以检测和纠正具有陈旧数据的节点。\n我们研究了一些可能由复制滞后引起的奇怪效应，我们也讨论了一些有助于决定应用程序在复制滞后时的行为的一致性模型： 写后读\n用户应该总是看到自己提交的数据。\n单调读\n用户在一个时间点看到数据后，他们不应该在某个更早的时间点看到数据。\n一致前缀读\n用户应该将数据视为具有因果意义的状态：例如，按照正确的顺序查看问题及其答复。\n最后，我们讨论了多领导者和无领导者复制方法所固有的并发问题：因为他们允许多个写入并发发生，这可能会导致冲突。我们研究了一个数据库可能使用的算法来确定一个操作是否发生在另一个操作之前，或者它们是否同时发生。我们还谈到了通过合并并发更新来解决冲突的方法。\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E4%BA%94%E7%AB%A0/","summary":"第五章：数据复制 复制的目的： ● 使得数据与用户在地理上接近（从而减少延迟） ● 即使系统的一部分出现故障，系统也能继续工作（从而提高可用性） ● 伸缩","title":"DDIA第五章"},{"content":"最近有一些原因，导致我想把我的小米11Ultra刷个MIUI GLOBAL， 想起来上一次刷机还是在大学的时候用的redmi k20 pro, 当时只是为了获取到root权限然后使用模拟定位打卡软件避免早起跑操打卡。\n这次折腾完之后，我又用上了我的iphone XR, 11 ultra成为了我的备用机。\n而这次刷机是因为工作上软件强制使用入职时候的证件照作为头像，并且你改成自己的头像后每天晚上12点就会强制刷新回证件照。所以我在想能不能想想办法可以一直使用自己的头像。\n然后我的思路大概就是这样的：其实他们定时改头像就是服务端发到客户端的一个请求，我是不是把这个请求给拦截掉就可以了？或者说我把这个请求的·返回报文里的 改成我自己的头像。总之是个模糊的想法。但是手机肯定是要先root掉。\n后面就是对手机的一系列操作，在这次root的过程中，其实还发现了一个问题，就是有一个自己的NAS服务器还是挺重要的。否则我前面的那么多东西备份起来是真的麻烦。所以后续我还会自己建一个NAS服务器专门用来备份我的照片和视频什么的。\n其实这不是一个刷机的教学博客，只是我的一些碎碎念。工作上遇到的一些糟心的事情罢了，只不过我想的是，我是否还有刚刚毕业时候那种遇到问题就动手解决的热情和动力。包括这种糟心的强制使用证件照做头像。\n如果有一天，我再也不想折腾了，那样的生活会不会很无趣\n","permalink":"https://csqread.top/posts/tech/%E5%8F%88%E4%B8%80%E6%AC%A1%E7%9A%84%E5%88%B7%E6%9C%BA%E4%B9%8B%E6%97%85/","summary":"最近有一些原因，导致我想把我的小米11Ultra刷个MIUI GLOBAL， 想起来上一次刷机还是在大学的时候用的redmi k20 pro, 当时只是为了获取","title":"又一次的刷机之旅"},{"content":"第四章：数据编码与演化 应用程序总是增增改改。 修改程序大多数情况下也在修改存储的数据。\n关系数据库通常假定数据库中的所有数据都遵循一个模式：尽管可以更改该模式（通过模式迁移，即ALTER语句），但是在任何时间点都有且仅有一个正确的模式。 读时模式（schema-on-read）（或 无模式（schemaless））数据库不会强制一个模式，因此数据库可以包含在不同时间写入的新老数据格式的混合。 当数据格式发生改变时，需要代码更改：\n服务端应用程序，会灰度发布； 客户端应用程序，看用户心情。 新旧版本的代码和数据，可能同时共处。 系统需要双向兼容：\n向后兼容：新代码可以读旧数据。容易。 向前兼容：旧代码可以读新数据。难。 编码数据的格式 程序通常（至少）使用两种形式的数据：\n在内存中，数据保存在对象，结构体，列表，数组，哈希表，树等中。 这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）。 如果要将数据写入文件，或通过网络发送，则必须将其 编码（encode） 为某种自包含的字节序列（例如，JSON文档）。 由于每个进程都有自己独立的地址空间，一个进程中的指针对任何其他进程都没有意义，所以这个字节序列表示会与通常在内存中使用的数据结构完全不同。 所以，需要在两种表示之间进行某种类型的翻译。\n从内存中表示到字节序列的转换称为 编码（Encoding） （也称为序列化（serialization） 或编组（marshalling））； 反过来称为解码（Decoding）ii（解析（Parsing），反序列化（deserialization），反编组( unmarshalling））译i。 语言特定的格式 许多编程语言都内建了将内存对象编码为字节序列的支持。例如，Java有java.io.Serializable ，Ruby有Marshal，Python有pickle .\n这些库很方便，但是有深层次问题：\n与特定的编程语言绑定。 为了恢复相同对象类型的数据，解码过程需要实例化任意类的能力，这是安全问题的来源。 数据版本控制不方便。 效率也不高。 只适合临时使用。\nJSON，XML和二进制变体 跨语言的编码：JSON，XML和CSV，属于文本格式，因此具有人类可读性。 除了语法问题外，还有问题：\n数值编码有歧义：XML 和 CSV 不能区分数字和字符串。JSON 不能区分整数和浮点数。 处理大数值困难。 JSON 和 XML 对 unicode（人类可读的文本）有很好的支持，但是不支持二进制。通过 base64 绕过这个限制。 XML 和 JSON 都有可选的模式支持。 CSV 没有模式，行列的含义完全由应用程序指定。格式模糊。 虽然问题多，但是大家对这些达成了意见一致。\n二进制编码 当数据很多的时候，数据格式的选择会有很大影响。 JSON比XML简洁，但与二进制格式相比还是太占空间。现在有很多二进制格式的 JSON（MessagePack，BSON，BJSON，UBJSON，BISON和Smile等）。 JSON 字符串是：\n1 2 3 4 5 6 { \u0026#34;userName\u0026#34;: \u0026#34;Martin\u0026#34;, \u0026#34;favoriteNumber\u0026#34;: 1337, \u0026#34;interests\u0026#34;: [\u0026#34;daydreaming\u0026#34;, \u0026#34;hacking\u0026#34;] } 二进制编码长度为66个字节，仅略小于文本JSON编码所取的81个字节（删除了空白）。\nThrift与Protocol Buffers Protocol Buffers最初是在Google开发的，Thrift最初是在Facebook开发的，并且在2007~2008年都是开源的，都是二进制编码库。 Thrift和Protocol Buffers都需要一个模式来编码任何数据。 接口定义语言（IDL） 来描述模式。\nThrift 比如： 1 2 3 4 5 struct Person { 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list\u0026lt;string\u0026gt; interests } Protocol Buffers的等效模式定义看起来非常相似： 1 2 3 4 5 message Person { required string user_name = 1; optional int64 favorite_number = 2; repeated string interests = 3; } Thrift和Protocol Buffers每一个都带有一个代码生成工具，可以调用此代码对模式进行编码和解码。 Thrift 编码格式\nThrift 有两种不同的二进制编码格式，分别称为 BinaryProtocol 和 CompactProtocol BinaryProtocol\n\u0026ndash; 对上面的信息编码只需要59个字节\n每个字段都有一个类型注释（用于指示它是一个字符串，整数，列表等），还可以根据需要指定长度（字符串的长度，列表中的项目数） 。 最大的区别是没有字段名，而只有字段标签，即数字 1，2，3，就像别名。 CompactProtocol\n语义上等同于BinaryProtocol 将字段类型和标签号打包到单个字节中，并使用可变长度整数来实现 相同的信息打包成只有 34 个字节 将数字 1337 编码成为 2 个字节，每个字节的最高位标识是否还有更多的字节。 Protocol Buffers\n只有一种二进制编码格式，与Thrift的CompactProtocol非常相似。 同样的记录塞进了33个字节中。 字段是否为必须？\n如果字段没有设置值，则从编码记录中省略。 模式中每个字段标记为是否为必须，但对编码无影响。 区别在于，如果字段设置为必须，但是未设置，那么运行时检查会失败。 字段标签和模式演变 字段标记很重要！可以改字段的名字，但是不能改字段标记。 向前兼容：可以添加新字段，只要有一个新的标记号码。 向后兼容：在模式初始部署之后，添加的每个字段必须是可选的或具有默认值。否则之前的代码会检查失败。 删除字段：只能删除可选字段；不能再次使用相同的标签号码。 数据类型和模式演变 数据类型可以被改变: int32 升级 int64, 新代码可以读取旧代码写入的数据(补0)；但是旧的代码不能解析新的数据(int32 读取 int64 会被截断) Protobuf 一个细节：没有列表类型，只有 repeated，因此可以把可选字段改为重置字段。 Thrift不能更改为列表参数，但优点是可以嵌套列表. Avro Apache Avro 是另一种二进制编码格式 Avro 有两种模式语言：一种(Avro IDL) 用于人工编辑，一种（基于JSON）更易于机器读取。 举例:\n1 2 3 4 5 record Person { string userName; union { null, long } favoriteNumber = null; array\u0026lt;string\u0026gt; interests; } 等价的JSON表示:\n1 2 3 4 5 6 7 8 9 { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;userName\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;favoriteNumber\u0026#34;, \u0026#34;type\u0026#34;: [\u0026#34;null\u0026#34;, \u0026#34;long\u0026#34;], \u0026#34;default\u0026#34;: null}, {\u0026#34;name\u0026#34;: \u0026#34;interests\u0026#34;, \u0026#34;type\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: \u0026#34;string\u0026#34;} ] } 注意：没有标签号码。 Avro二进制编码只有32个字节长，最紧凑的。 编码知识连在一起的值，不能识别字段和数据类型。 必须按照顺序遍历字段才能解码。 编码和解码必须使用完全相同的模式。 Writer模式与Reader模式 Avro的关键思想是Writer模式和Reader模式不必是相同的 - 他们只需要兼容。 当数据解码（读取）时，Avro库通过并排查看Writer模式和Reader模式并将数据从Writer模式转换到Reader模式来解决差异。（即数据读取的时候，会对比 Writer模式 和 Reader模式 的字段，然后就知道怎么读了） 模式演变规则 为了保持兼容性，您只能添加或删除具有默认值的字段。 但Writer模式到底是什么？ 对于一段特定的编码数据，Reader如何知道其Writer模式？ 答案取决于Avro使用的上下文。举几个例子：\n有很多记录的大文件\n○ Avro的一个常见用途 - 尤其是在Hadoop环境中 - 用于存储包含数百万条记录的大文件，所有记录都使用相同的模式进行编码。可以在文件的开头只包含一次Writer模式。\n支持独立写入的记录的数据库\n○ 最简单的解决方案是在每个编码记录的开始处包含一个版本号，并在数据库中保留一个模式版本列表。 通过网络连接发送记录 ○ 他们可以在连接设置上协商模式版本，然后在连接的生命周期中使用该模式。 动态生成的模式 Avro方法的一个优点是架构不包含任何标签号码。\n但为什么这很重要？在模式中保留一些数字有什么问题？\n不同之处在于Avro对动态生成的模式更友善。 ○ 方便从数据库生成 Avro 模式，导出数据 ○ 当数据库模式发生变化，直接生成新的 Avro 模式，导出数据。自动兼容。 ○ 而用 Thrift 或者 PB，需要手动写字段标签。 代码生成和动态类型的语言 Thrift 和 Protobuf 依赖于代码生成 在定义了模式之后，可以使用您选择的编程语言生成实现此模式的代码。 这在Java，C ++或C＃等静态类型语言中很有用，因为它允许将高效的内存中结构用于解码的数据，并且在编写访问数据结构的程序时允许在IDE中进行类型检查和自动完成。 在动态类型编程语言（如JavaScript，Ruby或Python）中，生成代码没有太多意义，因为没有编译时类型检查器来满足。 Avro为静态类型编程语言提供了可选的代码生成功能，但是它也可以在不生成任何代码的情况下使用。 模式的优点 Protocol Buffers，Thrift和Avro都使用模式来描述二进制编码格式。 他们的模式语言比XML模式或者JSON模式简单得多，也支持更详细的验证规则。 许多数据系统（如关系型数据库）也为其数据实现了某种专有的二进制编码。 基于模式的二进制编码相对于JSON，XML和CSV等文本数据格式的优点： 它们可以比各种“二进制JSON”变体更紧凑，因为它们可以省略编码数据中的字段名称。 模式是一种有价值的文档形式，因为模式是解码所必需的，所以可以确定它是最新的（而手动维护的文档可能很容易偏离现实）。 维护一个模式的数据库允许您在部署任何内容之前检查模式更改的向前和向后兼容性。 对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，因为它可以在编译时进行类型检查。 数据流的类型 数据在流程之间流动的一些常见的方式：\n通过数据库 通过服务调用 通过异步消息传递 数据库中的数据流 如果只有一个进程访问数据库，向后兼容性显然是必要的。 一般来说，会有多个进程访问数据库，可能会有某些进程运行较新代码、某些运行较旧的代码。因此数据库也经常需要向前兼容。 假设增加字段，那么较新的代码会写入把该值吸入数据库。而旧版本的代码将读取记录，理想的行为是旧代码保持领域完整。 用旧代码读取并重新写入数据库时，有可能会导致数据丢失。 在不同的时间写入不同的值 单一的数据库中，可能有一些值是五毫秒前写的，而一些值是五年前写的。 架构演变允许整个数据库看起来好像是用单个模式编码的，即使底层存储可能包含用模式的各种历史版本编码的记录。 归档存储 建立数据库快照，比如备份或者加载到数据仓库：即使有不同时代的模式版本的混合，但通常使用最新模式进行编码。 由于数据转储是一次写入的，以后不变，所以 Avro 对象容器文件等格式非常适合。 也是很好的机会，把数据编码成面向分析的列式格式。 服务中的数据流：REST与RPC 网络通信方式：常见安排是客户端+服务器 Web 服务：通过 GET 和 POST 请求 服务端可以是另一个服务的客户端：微服务架构。 微服务架构允许某个团队能够经常发布新版本服务，期望服务的新旧版本同时运行。 Web服务 当服务使用HTTP作为底层通信协议时，可称之为Web服务。 有两种流行的Web服务方法：REST和SOAP。 REST\n● REST不是一个协议，而是一个基于HTTP原则的设计哲学。 ● 它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制，身份验证和内容类型协商。 ● 与SOAP相比，REST已经越来越受欢迎，至少在跨组织服务集成的背景下，并经常与微服务相关。 ● 根据REST原则设计的API称为RESTful。 SOAP\nSOAP是用于制作网络API请求的基于XML的协议。 它最常用于HTTP，但其目的是独立于HTTP，并避免使用大多数HTTP功能。 SOAP Web服务的API使用称为Web服务描述语言（WSDL）的基于XML的语言来描述。 WSDL支持代码生成，客户端可以使用本地类和方法调用（编码为XML消息并由框架再次解码）访问远程服务。 尽管SOAP及其各种扩展表面上是标准化的，但是不同厂商的实现之间的互操作性往往会造成问题。 尽管许多大型企业仍然使用SOAP，但在大多数小公司中已经不再受到青睐。 远程过程调用（RPC）的问题 RPC模型试图向远程网络服务发出请求，看起来与在同一进程中调用编程语言中的函数或方法相同（这种抽象称为位置透明）。\nRPC的缺陷\n本地函数调用是可预测的，并且成功或失败仅取决于受您控制的参数。而网络请求是不可预知的。 本地函数调用要么返回结果，要么抛出异常，或者永远不返回（因为进入无限循环或进程崩溃）。网络请求有另一个可能的结果：由于超时，它可能会返回没有结果。无法得知远程服务的响应发生了什么。 如果您重试失败的网络请求，可能会发生请求实际上正在通过，只有响应丢失。在这种情况下，重试将导致该操作被执行多次，除非您在协议中引入除重（ 幂等（idempotence））机制。本地函数调用没有这个问题。 每次调用本地功能时，通常需要大致相同的时间来执行。网络请求慢得多，不可预知。 调用本地函数时，可以高效地将引用（指针）传递给本地内存中的对象。当你发出一个网络请求时，所有这些参数都需要被编码成可以通过网络发送的一系列字节。如果参数是像数字或字符串这样的基本类型倒是没关系，但是对于较大的对象很快就会变成问题。 客户端和服务端可以用不同的编程语言实现，RPC 框架必须把数据类型做翻译，可能会出问题。 RPC的当前方向 RPC 不会消失。\n● Thrift和Avro带有RPC支持 ● gRPC是使用Protocol Buffers的RPC实现 ● Finagle也使用Thrift ● Rest.li使用JSON over HTTP。 当前方向\n这种新一代的RPC框架更加明确的是，远程请求与本地函数调用不同。 其中一些框架还提供服务发现，即允许客户端找出在哪个IP地址和端口号上可以找到特定的服务。 REST似乎是公共API的主要风格。 REST 使用二进制编码性能更好 方便实验和调试 能被所有主流的编程语言和平台支持 大量可用的工具的生态系统 数据编码与RPC的演化 可演化性，重要的是可以独立更改和部署RPC客户端和服务器。 我们可以做个假定：假定所有的服务器都会先更新，其次是所有的客户端。 您只需要在请求上具有向后兼容性，并且对响应具有前向兼容性。 RPC方案的前后向兼容性属性从它使用的编码方式中继承：\nThrift，gRPC（Protobuf）和Avro RPC可以根据相应编码格式的兼容性规则进行演变。/li\u003e 在SOAP中，请求和响应是使用XML模式指定的。 RESTful API 通常使用 JSON（没有正式指定的模式）用于响应，以及用于请求的JSON或URI编码/表单编码的请求参数。 服务的提供者无法控制其客户，所以可能无限期保持兼容性。 对于 RESTful API，常用方法是在 URL 或者 HTTP Accept 头部使用版本号。\n消息传递中的数据流 与直接RPC相比，使用消息代理（消息队列）有几个优点：\n如果收件人不可用或过载，可以充当缓冲区，从而提高系统的可靠性。 它可以自动将消息重新发送到已经崩溃的进程，从而防止消息丢失。 避免发件人需要知道收件人的IP地址和端口号（这在虚拟机经常出入的云部署中特别有用）。 它允许将一条消息发送给多个收件人。 将发件人与收件人逻辑分离（发件人只是发布邮件，不关心使用者）。 与 PRC 相比，差异在于\n● 消息传递通常是单向的：发送者通常不期望收到其消息的回复。 ● 通信模式是异步的：发送者不会等待消息被传递，而只是发送它，然后忘记它。 消息代理 RabbitMQ，ActiveMQ，HornetQ，NATS和Apache Kafka这样的开源实现已经流行起来。 通常情况下，消息代理的使用方式如下： 一个进程将消息发送到指定的队列或主题； 代理确保将消息传递给那个队列或主题的一个或多个消费者或订阅者。 在同一主题上可以有许多生产者和许多消费者。 一个主题只提供单向数据流。但是，消费者本身可能会将消息发布到另一个主题上，或者发送给原始消息的发送者使用的回复队列（允许请求/响应数据流，类似于RPC）。 消息代理通常不会执行任何特定的数据模型，消息知识包含一些元数据的字节序列，可以用任何编码格式。 如果消费者重新发布消息到另一个主题，则消息保留未知字段，防止前面数据库环境中描述的问题。 分布式的Actor框架 Actor模型是单个进程中并发的编程模型。 逻辑被封装在actor中，而不是直接处理线程（以及竞争条件，锁定和死锁的相关问题）。 每个actor通常代表一个客户或实体，它可能有一些本地状态（不与其他任何角色共享），它通过发送和接收异步消息与其他角色通信。 不保证消息传送：在某些错误情况下，消息将丢失。 由于每个角色一次只能处理一条消息，因此不需要担心线程，每个角色可以由框架独立调度。 分布式Actor框架\n在分布式Actor框架中，此编程模型用于跨多个节点伸缩应用程序。 不管发送方和接收方是在同一个节点上还是在不同的节点上，都使用相同的消息传递机制。 如果它们在不同的节点上，则该消息被透明地编码成字节序列，通过网络发送，并在另一侧解码。 位置透明\n位置透明在actor模型中比在RPC中效果更好，因为actor模型已经假定消息可能会丢失，即使在单个进程中也是如此 尽管网络上的延迟可能比同一个进程中的延迟更高，但是在使用actor模型时，本地和远程通信之间的基本不匹配是较少的。 升级\n分布式的Actor框架实质上是将消息代理和actor编程模型集成到一个框架中。 升级仍然要担心向前和向后兼容问题。 三个流行的分布式actor框架处理消息编码如下：\n默认情况下，Akka使用Java的内置序列化，不提供前向或后向兼容性。 但是，你可以用类似Prototol Buffers的东西替代它，从而获得滚动升级的能力。 Orleans 默认使用不支持滚动升级部署的自定义数据编码格式; 要部署新版本的应用程序，您需要设置一个新的集群，将流量从旧集群迁移到新集群，然后关闭旧集群。 像Akka一样，可以使用自定义序列化插件。 在Erlang OTP中，对记录模式进行更改是非常困难的（尽管系统具有许多为高可用性设计的功能）。 滚动升级是可能的，但需要仔细计划。 本章小结 本章探讨了编码数据结构的方式。 许多服务需要支持滚动升级：向前、向后兼容性。 我们讨论了几种数据编码格式及其兼容性属性： 编程语言特定的编码仅限于单一编程语言，并且往往无法提供前向和后向兼容性。 JSON，XML和CSV等文本格式非常普遍，其兼容性取决于您如何使用它们。他们有可选的模式语言，这有时是有用的，有时是一个障碍。这些格式对于数据类型有些模糊，所以你必须小心数字和二进制字符串。 像Thrift，Protocol Buffers和Avro这样的二进制模式驱动格式允许使用清晰定义的前向和后向兼容性语义进行紧凑，高效的编码。这些模式可以用于静态类型语言的文档和代码生成。但是，他们有一个缺点，就是在数据可读之前需要对数据进行解码。 我们还讨论了数据流的几种模式，说明了数据编码重要性的不同场景： 数据库，写入数据库的进程对数据进行编码，并从数据库读取进程对其进行解码 RPC和REST API，客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码 异步消息传递（使用消息代理或参与者），其中节点之间通过发送消息进行通信，消息由发送者编码并由接收者解码 结论：前向兼容性和滚动升级在某种程度上是可以实现的。\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E5%9B%9B%E7%AB%A0/","summary":"第四章：数据编码与演化 应用程序总是增增改改。 修改程序大多数情况下也在修改存储的数据。 关系数据库通常假定数据库中的所有数据都遵循一个模式：尽管","title":"DDIA第四章"},{"content":"单向度的人：探寻马尔库塞的思想之旅 单向度社会：异化与标准化 《单向度的人》于20世纪60年代问世，正值工业和科技带来的变革迅猛发展。然而，马尔库塞并不乐观，他提出了“单向度”的概念，指的是人们的思想、欲望和行为受到同质化、标准化的社会结构制约，使个体丧失多样性和独立性。在单向度社会中，个体日益成为机械的、被规范化的社会工具，从而失去了真正的自由。\n马尔库塞强调了现代社会的异化现象，即个体与生产活动、社会关系和人性之间的脱节。在单向度社会中，人们似乎不断追逐着物质的满足，却忽视了更深层次的人类需求和价值。他以“欧洲人的追求”为例，揭示了虚假的欲望满足，以及消费主义背后的虚幻与空洞。\n思想控制：媒体与信息的角色 在《单向度的人》中，马尔库塞对媒体的影响进行了深入探讨。他指出，媒体在单向度社会中具有重要地位，通过传播大众化、标准化的信息，操控着人们的思想和意识。这种思想控制使个体丧失了独立思考和批判性思维的能力，成为被动、易于控制的群体。\n他特别强调了“幸福的自我放纵”现象，即媒体通过满足人们的消费和娱乐需求，将个体引入肤浅的享乐境界，导致他们远离深层次的社会问题和权力结构。这种自我放纵不仅削弱了人们的社会责任感，还进一步加深了个体与社会的脱节。\n解放与反抗的可能性 尽管《单向度的人》对现代社会进行了深刻的批判，马尔库塞并未认为个体完全无法摆脱单向度的束缚。他认为，解放与反抗的可能性依然存在。他呼吁个体通过重塑批判性思维、自由意志和人性的方式，寻找反抗和解放的途径。\n马尔库塞主张个体摆脱消费主义的诱惑，重拾对真正人类价值的关注。他认为，个体应通过文化创造和自我认知，唤醒批判性意识，看清社会中的虚假与异化。只有在个体不断地反思和行动中，社会的变革与进步才能实现。\n反思与重建：平衡个体与社会 《单向度的人》是一部充满洞察力的作品，揭示了现代社会中个体与社会之间的复杂关系。面对信息过载和消费主义的压力，我们应该保持独立思考的能力，不被虚假的追求所迷惑。通过个体的反思与行动，或许我们能够找到一条通向解放与平衡的道路。\n在当下，我们也可以从《单向度的人》中获得启示。以批判性思维审视自己的生活，重新思考个体与社会的关系，或许能够帮助我们摆脱单向度的束缚，追求更深层次的人类价值。\n一些摘录 ”可以肯定，”事物的客观秩序“本身是统治的结果；但同样的真实是，统治也正在产生更高的合理性，即一边维护等级结构，一边又更有效地剥削自然资源和智力资源，并在更大范围内分配剥削所得。“\n”他们相信他们正在为阶级而死，他们却是为党的儿子而死。他们相信自己正在为祖国而死，他们却是在为实业家而死。他们相信自己正在为人的自由而死，他们却是在为红利的自由而死。他们会相信自己正在为无产阶级而死，他们却是在为无产阶级的官僚而死“\n”不是工作的自由就是挨饿的自由，它给绝大多数人带来了艰辛、不安和焦虑。假如个人不再作为一个自由的经济主体被迫在市场上出售他自身，那么，这种自由的消失将是文明的最大成就之一。 社会要求个人在多大程度上作抑制性的发展，个人的需要本身及满足这种需要的权利就在多大程度上服从于凌驾其上的批判标准。 一切解放都有赖于对奴役状态的觉悟，而这种觉悟的出现却往往被占主导地位的需要和满足所阻碍，这些需要和满足在很大程度上已成为个人自己的需要和满足。发展的过程往往是用另一种制度取代预定的制度；而最可去的目标则是用真实的需要代替虚假的需要，抛弃异质性的满足。 决定人类自由程度的决定性因素，不是可供个人选择的范围，而是个人能够选择的是什么和实际选择的是什么。 何况个人自发地重复所强加的需要并不说明他的意志自由，而只能证明控制的有效性。 诚然，在当代社会最高度发达的地区，把社会需要移植成个人的需要是如此地有效，以致它们之间的差别似乎纯粹是理论上的事情。人们当真能对作为新闻与娱乐的工具和作为灌输与操纵力量的大众传播媒介作出区分吗？当真能对制造公害的汽车和提供方便的汽车作出区分吗？当真能对实用建筑的恐怖与舒适作出区分吗？当真能对为保卫国防和为公司营利的手段作出区分吗？当真能对提高生育率方面私人的乐趣和商业上、政治上的功能作出区分吗？ 小轿车、高清晰度的传真装置、错层式家庭住宅以及厨房设备成了人们生活的灵魂。把个人束缚于社会的机制已经改变，而社会控制就是在它所产生的新的需要中得以稳定的。 为了和平的组织不同于为了战争的组织；为了生存斗争服务的制度不能为生存和平服务。作为目的的生活本质上不同于作为手段的生活。 技术的合理性展示出它的政治特性，因为它变成更有效统治的得力工具，并创造出一个真正的极权主义领域，在这个领域中，社会和自然、精神和肉体为保卫这一领域而保持着持久动员的状态。“\n”当竞选领袖和政治家在电视、电台和舞台上说出自由、完善这些伟大的字眼的时候，这些字眼就变成了毫无疑义的声音，它们只有在宣传、商业、训练和消遣中才能获得意义。理想与现实同化到这种程度，说明理想已被超越。它被从心灵、精神或内心世界的高尚领域里拽了出来，并被转换为操作型术语和问题。“\n”今天的新奇之处是通过消除高层文化中对立的、异己的和超越性的因素——它们借助高层文化而构成现实的另一种向度——来消除文化和社会现实之间的对立。清除双向度文化的办法，不是否定和拒斥各种“文化价值”，而是把它们全部纳入已确立的秩序，并大规模地复制和显示它们。“\nEND 这部著作的中心论题是：当代工业社会是一个新型的极权主义社会，因为它成功地压制了这个社会中的反对派和反对意见，压制了人们内心中的否定性、批判性和超越性的向度，从而使这个社会成了单向度的社会，使生活于其中的人成了单向度的人。 在马尔库塞看来，极权主义的共同特征主要不是表现为是否施行恐怖与暴力，而是表现为是否允许对立派对、对立意见、对立向度的存在。 简而言之，由于技术进步的作用，发达工业社会虽是一个不自由的社会，但毕竟是一个舒舒服服的不自由社会；虽是一个更有效地控制着人的极权主义社会，但毕竟是一个使人安然自得的极权主义社会。\n推荐这本马尔库塞的《单向度的人》，虽然里边有很多看不懂的地方，但是看他的社会批判真的很过瘾。\n","permalink":"https://csqread.top/posts/read/%E5%8D%95%E5%90%91%E5%BA%A6%E7%9A%84%E4%BA%BA/","summary":"单向度的人：探寻马尔库塞的思想之旅 单向度社会：异化与标准化 《单向度的人》于20世纪60年代问世，正值工业和科技带来的变革迅猛发展。然而，马尔","title":"单向度的人"},{"content":"第三章：存储与检索 本章介绍了传统关系型数据库与“NoSQL”数据库的存储引擎。 我们会研究两大类存储引擎：日志结构（log-structured） 的存储引擎，以及面向页面（page-oriented） 的存储引擎（例如B树）。\n驱动数据库的数据结构 世界上最简单的数据库可以用两个Bash函数实现：\n1 2 3 4 5 6 7 8 #!/bin/bash db_set () { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get () { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 } 这两个函数实现了键值存储的功能。\n执行 db_set key value ，会将 键（key）和值（value） 存储在数据库中。键和值（几乎）可以是你喜欢的任何东西，例如，值可以是JSON文档。 调用 db_get key ，查找与该键关联的最新值并将其返回。 麻雀虽小，五脏俱全：\n1 2 3 4 5 6 $ db_set 123456 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;London\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Big Ben\u0026#34;,\u0026#34;London Eye\u0026#34;]}\u0026#39; $ $ db_set 42 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]}\u0026#39; $ db_get 42 {\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]} huhu 底层的存储格式非常简单：\n一个文本文件，每行包含一条逗号分隔的键值对（忽略转义问题的话，大致与CSV文件类似）。 每次对 db_set 的调用都会向文件末尾追加记录，所以更新键的时候旧版本的值不会被覆盖。 查找最新值的时候，需要找到文件中键最后一次出现的位置（因此 db_get 中使用了 tail -n 1 ) 1 2 3 4 5 6 7 8 9 $ db_set 42 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Exploratorium\u0026#34;]}\u0026#39; $ db_get 42 {\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Exploratorium\u0026#34;]} $ cat database 123456,{\u0026#34;name\u0026#34;:\u0026#34;London\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Big Ben\u0026#34;,\u0026#34;London Eye\u0026#34;]} 42,{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]} 42,{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Exploratorium\u0026#34;]} db_set 函数对于极其简单的场景其实有非常好的性能，因为在文件尾部追加写入通常是非常高效的。 与db_set做的事情类似，许多数据库在内部使用了日志（log），也就是一个 仅追加（append-only） 的数据文件。 另一方面，如果这个数据库中有着大量记录，则这个db_get 函数的性能会非常糟糕。 每次你想查找一个键时，db_get 必须从头到尾扫描整个数据库文件来查找键的出现。 用算法的语言来说，查找的开销是 O(n) ：如果数据库记录数量 n 翻了一倍，查找时间也要翻一倍。 索引 为了高效查找数据库中特定键的值，我们需要一个数据结构：索引（index）。\n索引背后的大致思想是，保存一些额外的元数据作为路标，帮助你找到想要的数据。 索引是从主数据衍生的附加（additional）结构。 许多数据库允许添加与删除索引，这不会影响数据的内容，它只影响查询的性能。 维护额外的结构会产生开销，特别是在写入时。写入性能很难超过简单地追加写入文件，因为追加写入是最简单的写入操作。 任何类型的索引通常都会减慢写入速度，因为每次写入数据时都需要更新索引。 这是存储系统中一个重要的权衡：精心选择的索引加快了读查询的速度，但是每个索引都会拖慢写入速度。 哈希索引 键值存储与在大多数编程语言中可以找到的字典（dictionary）类型非常相似，通常字典都是用散列映射（hash map）（或哈希表（hash table））实现的。 假设我们的数据存储只是一个追加写入的文件，最简单的索引策略就是：保留一个内存中的哈希映射，其中每个键都映射到一个数据文件中的字节偏移量，指明了可以找到对应值的位置\n新的键值写入文件时，还要更新散列映射。 查找一个值时，使用哈希映射来查找数据文件中的偏移量，寻找（seek） 该位置并读取该值。 Bitcask实际上就是这么做的，非常适合每个键的值频繁更新的情况。 如果一直追加文件，怎么防止用完磁盘空间？ 将日志分为特定大小的段，当日志增长到特定尺寸时关闭当前段文件，并开始写入一个新的段文件。 然后，我们就可以对这些段进行压缩（compaction）。 压缩意味着在日志中丢弃重复的键，只保留每个键的最近更新。 也可以把多个段的内容压缩合并到一起。\n段被写入后永远不会被修改，所以合并的段被写入一个新的文件。 冻结段的合并和压缩可以在后台线程中完成，在进行时，我们仍然可以继续使用旧的段文件来正常提供读写请求。 合并过程完成后，我们将读取请求转换为使用新的合并段而不是旧段 —— 然后可以简单地删除旧的段文件。 每个段都有自己的内存散列表，将键映射到文件偏移量。查找键时，依次遍历所有的散列表。 重要的问题：\n文件格式 a. csv 不好，使用二进制格式更快。 2. 删除记录 a. 删除一个键，则必须在数据文件（有时称为逻辑删除）中附加一个特殊的删除记录。 b. 当日志段被合并时，逻辑删除告诉合并过程放弃删除键的任何以前的值。 3. 崩溃恢复 a. 如果数据库重新启动，则内存散列映射将丢失。 b. 可以根据日志文件重新恢复每个段的哈希映射，但段很大的时候，很费时间。 c. Bitcask通过存储加速恢复磁盘上每个段的哈希映射的快照，可以更快地加载到内存中。 4. 部分写入记录 a. 数据库可能随时崩溃，包括将记录附加到日志中途。 b. Bitcask文件包含校验和，允许检测和忽略日志的这些损坏部分。 5. 并发控制 a. 写操作是以严格顺序的顺序附加到日志中的，所以常见的方法是只有一个写线程。 b. 读操作可以有多个线程同时读取。 为什么采用追加模式，而不是不更新文件，用新值覆盖旧值？ 原因有几个：\n追加和分段合并是顺序写入操作，通常比随机写入快得多，尤其是在磁盘旋转硬盘上。在某种程度上，顺序写入在基于闪存的 固态硬盘（SSD） 上也是优选的。 如果段文件是附加的或不可变的，并发和崩溃恢复就简单多了。 合并旧段可以避免数据文件随着时间的推移而分散的问题。 哈希表索引的局限性：\n散列表必须能放进内存：当有很多键的时候，Hash 冲突，占用内存。 范围查询效率不高：不支持查一个取值区间内的所有键。 SSTables和LSM树 在之前的存储中，每个日志结构存储段都是一系列键值对。这些对按照它们写入的顺序出现，而不是键值对的顺序。 我们做一个简单的改变：我们要求键值对的序列按键排序。把这个格式称为排序字符串表（Sorted String Table），简称 SSTable。同时，要求每个键只在每个合并的段文件中出现一次（压缩过程已经保证）。\nSSTable 与散列索引日志段相比，有几个很大的优势：\n合并段是简单而高效的，即使文件大于可用内存。方法类似于归并排序。 a. 如果在几个输入段中出现相同的键，该怎么办？ ⅰ. 答：保留最近段的值，并丢弃旧段中的值。\n为了在文件中找到一个特定的键，你不再需要保存内存中所有键的索引。因为是有序的，可以先查找出键所处的范围，然后就找到这个键所在的偏移量的区间。比如可以从 handbag 和 handsome 的偏移量找到 handiwork 的区间。 构建和维护SSTables 如何让数据首先被按键排序呢？\n在内存中排序简单的多，比如红黑树、AVL 树； 存储工作的操作步骤：\n写入时，将其添加到内存中的平衡树数据结构（例如，红黑树）。这个内存树有时被称为内存表（memtable）。 当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘。这可以高效地完成，因为树已经维护了按键排序的键值对。新的SSTable文件成为数据库的最新部分。当SSTable被写入磁盘时，写入可以继续到一个新的内存表实例。 为了提供读取请求，首先尝试在内存表中找到关键字，然后在最近的磁盘段中，然后在下一个较旧的段中找到该关键字。 有时会在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值。 如何解决数据库崩溃，则最近的写入（在内存表中，但尚未写入磁盘）将丢失的问题？\n我们可以在磁盘上保存一个单独的日志，每个写入都会立即被附加到磁盘上， 该日志不是按排序顺序，但这并不重要，因为它的唯一目的是在崩溃后恢复内存表。 每当内存表写出到SSTable时，相应的日志都可以被丢弃。 用SSTables制作LSM树 LSM 树：在 LevelDB 和 RocksDB 使用。\n性能优化 当查找数据库中不存在的键时，LSM树算法可能会很慢：您必须检查内存表，然后将这些段一直回到最老的（可能必须从磁盘读取每一个），然后才能确定键不存在。 解决办法：布隆过滤器。 2. SSTables 被压缩和合并的顺序和时间 大小分层压实。 LevelDB和RocksDB使用平坦压缩（LevelDB因此得名）； HBase 使用大小分层； Cassandra 同时支持。 B树 像SSTables一样，B树保持按键排序的键值对，这允许高效的键值查找和范围查询。 不同：\n日志结构索引将数据库分解为可变大小的段，通常是几兆字节或更大的大小，并且总是按顺序编写段。 B 树将数据库分解成固定大小的块或页面，传统上大小为4KB（有时会更大），并且一次只能读取或写入一个页面。 这种设计更接近于底层硬件，因为磁盘也被安排在固定大小的块中。 每个页面都可以使用地址或位置来标识，这允许一个页面引用另一个页面 —— 类似于指针，但在磁盘而不是在内存中。\n查找过程： ● 一个页面会被指定为B树的根；在索引中查找一个键时，就从这里开始。 ● 该页面包含几个键和对子页面的引用。 ● 每个子页面负责一段连续范围的键，引用之间的键，指明了引用子页面的键范围。 ● 最后，我们可以看到包含单个键（叶页）的页面，该页面包含每个键的内联值，或者包含对可以找到值的页面的引用。\n更新过程： ● 搜索包含该键的叶页，更改该页中的值，并将该页写回到磁盘原来的位置（对该页的任何引用保持有效）\n插入过程： ● 找到其范围包含新键的页面，并将其添加到该页面。 ● 如果页面中没有足够的可用空间容纳新键，则将其分成两个半满页面，并更新父页面以解释键范围的新分区。 删除过程： ● 删除一个键（同时保持树平衡）就牵扯很多其他东西了。\n深度： ● 该算法确保树保持平衡：具有 n 个键的B树总是具有 $O(log n)$ 的深度。 ● 大多数数据库可以放入一个三到四层的 B 树，所以你不需要遵追踪多页面引用来找到你正在查找的页面。 （分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB 。）\n让B树更可靠 ● B 树的基本底层写操作是用新数据覆盖磁盘上的页面。 ● 假定覆盖不改变页面的位置； ● 而日志结构索引（如LSM树）只附加到文件（并最终删除过时的文件），但从不修改文件。\n危险操作： ● 插入导致页面过度而拆分页面，则需要编写已拆分的两个页面，并覆盖其父页面以更新对两个子页面的引用。 ● 这是一个危险的操作，因为如果数据库在仅有一些页面被写入后崩溃，那么最终将导致一个损坏的索引（例如，可能有一个孤儿页面不是任何父项的子项） 。\n预写式日志（WAL） ● 为了使数据库对崩溃具有韧性，B树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log）（也称为重做日志（redo log））。 ● 这是一个仅追加的文件，每个B树修改都可以应用到树本身的页面上。 ● 当数据库在崩溃后恢复时，这个日志被用来使B树恢复到一致的状态.\n并发访问： ● 更新页面时，如果多个线程要同时访问B树，则需要仔细的并发控制，否则可能会看到树处于不一致的状态。 ● 通过使用锁存器（latches）（轻量级锁）保护树的数据结构来完成 ● 而 LSM 比较简单：在后台完成所有的合并，不干扰查询；通过「原子交换」把旧的分段变为新的分段。\nB树优化 ● LMDB 数据库中使用「写时复制方案 」，而不是不是覆盖页面并维护 WAL 进行崩溃恢复。 ○ 修改的页面被写入到不同的位置，并且树中的父页面的新版本被创建，指向新的位置。 ○ 这种方法对于并发控制也很有用。 ● 保存键的缩略信息，而不是完整的键。 ○ 键只用保存一个区间，而不是具体的数值（类似于 B+树）。 ○ 可以包含更多的键，减少树的层次。 ● 不方便扫描大部分关键词的范围查找。 ○ 许多B树实现尝试布局树，使得叶子页面按顺序出现在磁盘上。 ○ 但是，随着树的增长，维持这个顺序是很困难的。 ○ 相比之下，由于LSM树在合并过程中一次又一次地重写存储的大部分，所以它们更容易使顺序键在磁盘上彼此靠近。 ● 额外的指针已添加到树中。 ○ 例如，每个叶子页面可以在左边和右边具有对其兄弟页面的引用，这允许不跳回父页面就能顺序扫描。 ● B树的变体如分形树借用一些日志结构的思想来减少磁盘寻道（而且它们与分形无关）。\n比较B树和LSM树 通常LSM树的写入速度更快，而B树的读取速度更快。 LSM树上的读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。\nLSM树的优点 ● B树索引必须至少两次写入每一段数据：一次写入预先写入日志，一次写入树页面本身（也许再次分页） ● 即使在该页面中只有几个字节发生了变化，也需要一次编写整个页面的开销。 ● 有些存储引擎甚至会覆盖同一个页面两次，以免在电源故障的情况下导致页面部分更新\n写放大 ● 反复压缩和合并SSTables，日志结构索引也会重写数据。 ● 在数据库的生命周期中写入数据库导致对磁盘的多次写入 —— 被称为写放大（write amplification）。 ● 存储引擎写入磁盘的次数越多，可用磁盘带宽内的每秒写入次数越少。\nLSM树通常能够比B树支持更高的写入吞吐量： ● 部分原因是它们有时具有较低的写放大（尽管这取决于存储引擎配置和工作负载） ● 部分是因为它们顺序地写入紧凑的SSTable文件而不是必须覆盖树中的几个页面 ● 这种差异在磁性硬盘驱动器上尤其重要，顺序写入比随机写入快得多。\n文件碎片： ● LSM树可以被压缩得更好，因此经常比B树在磁盘上产生更小的文件。 ● B树存储引擎会由于分割而留下一些未使用的磁盘空间 ● 由于LSM树不是面向页面的，并且定期重写SSTables以去除碎片，所以它们具有较低的存储开销，特别是当使用平坦压缩时\nLSM树的缺点 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。 B树的行为则相对更具可预测性。\n高写入吞吐量： ● 磁盘的有限写入带宽需要在初始写入（记录和刷新内存表到磁盘）和在后台运行的压缩线程之间共享。 ● 写入空数据库时，可以使用全磁盘带宽进行初始写入，但数据库越大，压缩所需的磁盘带宽就越多。\n压缩和读取的速度： ● 如果写入吞吐量很高，并且压缩没有仔细配置，压缩跟不上写入速率。 ● 在这种情况下，磁盘上未合并段的数量不断增加，直到磁盘空间用完，读取速度也会减慢，因为它们需要检查更多段文件。\n键出现的个数： ● B树的一个优点是每个键只存在于索引中的一个位置，而日志结构化的存储引擎可能在不同的段中有相同键的多个副本。 ● 有利于事务语义。 ● 在许多关系数据库中，事务隔离是通过在键范围上使用锁来实现的，在B树索引中，这些锁可以直接连接到树\n其他索引结构 前面讨论的是关键值索引，它们就像关系模型中的主键（primary key） 索引。主键唯一标识关系表中的一行、一个文档、一个顶点。\n二级索引 ● 在关系数据库中，您可以使用 CREATE INDEX 命令在同一个表上创建多个二级索引，而且这些索引通常对于有效地执行联接而言至关重要。 ● 一个二级索引可以很容易地从一个键值索引构建，区别是键不是唯一的。实现方式： ○ 通过使索引中的每个值，成为匹配行标识符的列表（如全文索引中的发布列表） ○ 通过向每个索引添加行标识符来使每个关键字唯一 ○ 无论哪种方式，B树和日志结构索引都可以用作辅助索引。\n将值存储在索引中 索引中的关键字是查询搜索的内容，它属于两种之一： ● 实际行（文档，顶点） ● 对存储在别处的行的引用。此时，行被存储的地方被称为堆文件（heap file），并且存储的数据没有特定的顺序 ○ 堆文件很常见。 ○ 它避免了在存在多个二级索引时复制数据 ○ 新值字节数不大于旧值，原地覆盖； ○ 新值更大，需要移到堆中有足够空间的新位置； ■ 此时，要么所有索引都更新指向新堆位置； ■ 要么在旧堆位置留一个转发指针。\n聚集索引 ● 从索引到堆文件的额外跳转性能损失太大，希望可以把索引行直接进存储到索引中。被叫做聚集索引。 ● 在 MySQL 的 InnoDB 存储引擎中，表的主键总是一个聚簇索引，二级索引用主键（而不是堆文件中的位置） ● 在SQL Server中，可以为每个表指定一个聚簇索引。\n包含列的索引或覆盖索引 ● 在 聚集索引（clustered index） （在索引中存储所有行数据）和 非聚集索引（nonclustered index） （仅在索引中存储对数据的引用）之间的折衷被称为 包含列的索引（index with included columns）或覆盖索引（covering index），其存储表的一部分在索引内。 ● 允许通过单独使用索引来回答一些查询。 ● 加快了读取速度，但是增加了额外的存储空间，增加了写入开销，还要事务保证。\n多列索引 上面讨论的都是一个 key 对应一个 value，如果需要同时根据一个表中的多个列（或文档中的多个字段）进行查询，则不行。 ● 连接索引（concatenated index） ○ 将一列的值追加到另一列后面，简单地将多个字段组合成一个键。 ○ 但是这不能做复杂查询。 ● 多维索引（multi-dimensional index） ○ 比如需要根据经纬度做二维范围查询，则 B 树和 LSM 树不能高效； ○ 普遍做法是用特殊化的空间索引，比如 R 树（TODO）。 ○ 多维索引除了地理位置，还可以用于其他很多地方：电子网站、天气数据。\n全文搜索和模糊索引 上文讨论的索引都是查询确切的值或者确定范围的值，如果搜索类似的键，需要用模糊查询。\n全文搜索引擎 ● 允许搜索一个单词以扩展为包括该单词的同义词，忽略单词的语法变体，并且搜索在相同文档中彼此靠近的单词的出现，并且支持各种其他功能取决于文本的语言分析。 ● 为了处理文档或查询中的拼写错误，Lucene能够在一定的编辑距离内搜索文本（编辑距离1意味着添加，删除或替换了一个字母）\nLucene ● 为其词典使用了一个类似于SSTable的结构。 ● 这个结构需要一个小的内存索引，告诉查询在排序文件中哪个偏移量需要查找关键字。 ● 在 LevelDB 中，这个内存中的索引是一些键的稀疏集合。 ● 但在 Lucene 中，内存中的索引是键中字符的有限状态自动机，类似于trie。 ● 这个自动机可以转换成 Levenshtein 自动机，它支持在给定的编辑距离内有效地搜索单词。\n在内存中存储一切 对于磁盘和SSD，如果要在读取和写入时获得良好性能，则需要仔细地布置磁盘上的数据。 磁盘优点：耐用，成本低。 内存变得便宜，促进了内存数据库发展。\n内存数据库 ● 某些内存中的键值存储（如Memcached）仅用于缓存，在重新启动计算机时丢失的数据是可以接受的。 ● 但其他内存数据库的目标是持久性，可以通过特殊的硬件（例如电池供电的RAM），将更改日志写入磁盘，将定时快照写入磁盘或通过复制内存来实现，记忆状态到其他机器。\n实现 ● 内存数据库重新启动时，需要从磁盘或通过网络从副本重新加载其状态（除非使用特殊的硬件）。 ● 尽管写入磁盘，它仍然是一个内存数据库，因为磁盘仅用作耐久性附加日志，读取完全由内存提供。 ● 写入磁盘也具有操作优势：磁盘上的文件可以很容易地由外部实用程序进行备份，检查和分析。\n常见产品 ● VoltDB，MemSQL和Oracle TimesTen等产品是具有关系模型的内存数据库 ● RAM Cloud是一个开源的内存键值存储器，具有持久性（对存储器中的数据以及磁盘上的数据使用日志结构化方法） ● Redis和Couchbase通过异步写入磁盘提供了较弱的持久性。\n内存数据库性能优势到底在哪？ ● 内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。 ● 即使是基于磁盘的存储引擎也可能永远不需要从磁盘读取，因为操作系统缓存最近在内存中使用了磁盘块。 ● 相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。\n除了性能还有什么优势？ ● 提供了难以用基于磁盘的索引实现的数据模型。 ● 例如，Redis为各种数据结构（如优先级队列和集合）提供了类似数据库的接口。因为它将所有数据保存在内存中，所以它的实现相对简单。\n内存不够用怎么办？ ● 反缓存（anti-caching） 方法通过在内存不足的情况下将最近最少使用的数据从内存转移到磁盘，并在将来再次访问时将其重新加载到内存中。 ● 这与操作系统对虚拟内存和交换文件的操作类似，但数据库可以比操作系统更有效地管理内存，因为它可以按单个记录的粒度工作，而不是整个内存页面。 ● 尽管如此，这种方法仍然需要索引能完全放入内存中。\n事务处理还是分析？ 事务处理 ● 早起的业务处理，典型的数据库写入与一笔商业交易（transaction）相对应，以后交易/事务（transaction） 仍留了下来。 ● 事务不一定具有ACID（原子性，一致性，隔离性和持久性）属性。 ● 事务处理只是意味着允许客户端进行低延迟读取和写入 —— 而不是只能定期运行（例如每天一次）的批量处理作业。 ● 数据库仍然常被用作在线事务处理（OLTP, OnLine Transaction Processing） 。\n数据分析 ● 数据库也开始越来越多地用于数据分析，需要扫描大量记录； ● 为了将这种使用数据库的模式和事务处理区分开，它被称为在线分析处理（OLAP, OnLine Analytice Processing）\n属性 事务处理 OLTP 分析系统 OLAP 主要读取模式 查询少量记录，按键读取 在大批量记录上聚合 主要写入模式 随机访问，写入要求低延时 批量导入（ETL），事件流 主要用户 终端用户，通过Web应用 内部数据分析师，决策支持 处理的数据 数据的最新状态（当前时间点） 随时间推移的历史事件 数据集尺寸 GB ~ TB TB ~ PB/td\u003e 起初，相同的数据库用于事务处理和分析查询，SQL 可以支持 OLTP 和 OLAP。现在有趋势在用数据仓库。 数据仓库 OLTP 系统对业务运作很重要，因而通常会要求 高可用 与 低延迟，不愿意做影响事务性能的分析查询。 数据仓库是一个独立的数据库，分析人员可以查询他们想要的内容而不影响OLTP操作 数据仓库包含公司各种OLTP系统中所有的只读数据副本。 从OLTP数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。将数据存入仓库的过程称为“抽取-转换-加载（ETL）” 使用单独的数据仓库，而不是直接查询OLTP系统进行分析的一大优势是数据仓库可针对分析访问模式进行优化。上文的索引不适合数据仓库，需要单独的存储引擎。 #### OLTP数据库和数据仓库之间的分歧 数据仓库的数据模型通常是关系型的，因为SQL通常很适合分析查询。 表面上，一个数据仓库和一个关系OLTP数据库看起来很相似，因为它们都有一个SQL查询接口。 实际上，内部完全不同，因为对不同的查询模式进行了优化。 一般的数据库都把重点放在支持事务处理或分析工作负载上，而不是两者都支持。 星型和雪花型：分析的模式 事务处理领域中，使用了大量不同的数据模型。 分析型业务中，数据模型的多样性则少得多。许多数据仓库都以相当公式化的方式使用，被称为星型模式（也称为维度建模）。 用于数据仓库的星型模式的示例 在模式的中心是一个所谓的事实表（在这个例子中，它被称为 fact_sales）。 事实表的每一行代表在特定时间发生的事件（这里，每一行代表客户购买的产品）。 周围是维度表。 事实表可能非常大，有万亿行和数PB的数据，列通常超过 100 列。 被称为“星型模式”是因为事实表在中间，维度表在周围，像星星一样。 “雪花模式”：维度表进一步拆分成子维度表。 “星型模式”比较简单，是首选。 列存储 事实表的高效存储和查询是问题。 维度表比较小，不讨论。 在分析中经常只查询部分列，而不是所有列。 面向列的存储\n不是把每一行的值存储在一起，而是将每一列的所有值存放在一起。 面向列的存储布局依赖于每个列文件包含相同顺序的行。 列压缩 ● 除了仅从磁盘加载查询所需的列以外，我们还可以通过压缩数据来进一步降低对磁盘吞吐量的需求。 ● 面向列的存储通常很适合压缩。\n位图编码 当 n 非常大，大部分位图中将会有很多的零（我们说它们是稀疏的）。 位图可以另外进行游程编码，这可以使列的编码非常紧凑。 位图索引可以很方便的做各种查询：ADN/OR 内存带宽和向量处理 ● 需要扫描数百万行的数据仓库查询来说，瓶颈： ○ 是从磁盘获取数据到内存的带宽。 ○ 主存储器带宽到CPU缓存中的带宽，避免CPU指令处理流水线中的分支错误预测和泡沫，以及在现代中使用单指令多数据（SIMD）指令CPU ● 面向列的存储布局： ○ 可以将大量压缩的列数据放在CPU的L1缓存中，然后在紧密的循环中循环（即没有函数调用） ○ 更有利于 CPU 的计算。\n列存储中的排序顺序 ● 在列存储中，存储行的顺序并不一定很重要。 ● 按插入顺序存储它们是最简单的，因为插入一个新行只需要追加到每个列文件。 ● 每列独自排序是没有意义的，因为那样我们就不会知道列中的哪些项属于同一行 ● 即使按列存储数据，也需要一次对整行进行排序。\n好处 ● 速度快：这样数据库的管理员可以根据他们对常用查询的了解来选择表格应该被排序的列。 ● 压缩列：第一个排序键的压缩效果最强。\n几个不同的排序顺序 ● 不同的查询受益于不同的排序顺序，而无论如何，数据需要复制到多台机器， ● 在一个面向列的存储中有多个排序顺序有点类似于在一个面向行的存储中有多个二级索引。\n写入列存储 列存储的优点：大部分只用查询；压缩和排序都有助于更快地读取这些查询。 缺点：写入困难。插入必须始终更新所有列。\n解决方案：LSM树。 ● 现在内存中存储，添加到一个已排序的结构中，然后准备写入磁盘。\n聚合：数据立方体和物化视图 并不是每个数据仓库都必定是一个列存储。列存储在迅速普及。\n物化汇总 ● 数据仓库查询通常涉及一个聚合函数，如SQL中的COUNT，SUM，AVG，MIN或MAX。 ● 创建这种缓存的一种方式是物化视图（Materialized View）。\n物化数据立方体的优点是某些查询变得非常快，因为它们已经被有效地预先计算了。\n本章小结 优化 事务处理（OLTP） 或 在线分析（OLAP） 。这些用例的访问模式之间有很大的区别： ● OLTP系统通常面向用户，这意味着系统可能会收到大量的请求。为了处理负载，应用程序通常只访问每个查询中的少部分记录。应用程序使用某种键来请求记录，存储引擎使用索引来查找所请求的键的数据。磁盘寻道时间往往是这里的瓶颈。 ● 数据仓库和类似的分析系统会低调一些，因为它们主要由业务分析人员使用，而不是由最终用户使用。它们的查询量要比OLTP系统少得多，但通常每个查询开销高昂，需要在短时间内扫描数百万条记录。磁盘带宽（而不是查找时间）往往是瓶颈，列式存储是这种工作负载越来越流行的解决方案。\n在OLTP方面，我们能看到两派主流的存储引擎：\n日志结构学派\n只允许附加到文件和删除过时的文件，但不会更新已经写入的文件。 Bitcask，SSTables，LSM树，LevelDB，Cassandra，HBase，Lucene等都属于这个类别。\n就地更新学派\n将磁盘视为一组可以覆写的固定大小的页面。 B树是这种哲学的典范，用在所有主要的关系数据库中和许多非关系型数据库。 日志结构的存储引擎是相对较新的发展。他们的主要想法是，他们系统地将随机访问写入顺序写入磁盘，由于硬盘驱动器和固态硬盘的性能特点，可以实现更高的写入吞吐量。在完成OLTP方面，我们通过一些更复杂的索引结构和为保留所有数据而优化的数据库做了一个简短的介绍。\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E4%B8%89%E7%AB%A0/","summary":"第三章：存储与检索 本章介绍了传统关系型数据库与“NoSQL”数据库的存储引擎。 我们会研究两大类存储引擎：日志结构（log-structure","title":"DDIA第三章"},{"content":"第二章：数据模型与查询语言 数据模型可能是软件开发中最重要的部分了，因为它们的影响如此深远：不仅仅影响着软件的编写方式，而且影响着我们的解题思路。 一个复杂的应用程序可能会有更多的中间层次，比如基于API的API，不过基本思想仍然是一样的：每个层都通过提供一个明确的数据模型来隐藏更低层次中的复杂性。这些抽象允许不同的人群有效地协作。\n关系模型与文档模型 现在最著名的数据模型可能是SQL。它基于Edgar Codd在1970年提出的关系模型【1】：数据被组织成关系（SQL中称作表），其中每个关系是元组（SQL中称作行)的无序集合。\nNoSQL的诞生 NoSQL：不仅是SQL（Not Only SQL） 采用NoSQL数据库的背后有几个驱动因素，其中包括： ○ 需要比关系数据库更好的可扩展性，包括非常大的数据集或非常高的写入吞吐量 ○ 相比商业数据库产品，免费和开源软件更受偏爱。 ○ 关系模型不能很好地支持一些特殊的查询操作 ○ 受挫于关系模型的限制性，渴望一种更具多动态性与表现力的数据模型 在可预见的未来，关系数据库似乎可能会继续与各种非关系数据库一起使用 - 这种想法有时也被称为混合持久化（polyglot persistence） 对象关系不匹配 应用程序使用面向对象的语言，需要一个转换层，才能转成 SQL 数据模型：被称为阻抗不匹配。 Hibernate这样的 对象关系映射（ORM object-relational mapping） 框架可以减少这个转换层所需的样板代码的数量，但是它们不能完全隐藏这两个模型之间的差异。 对于一份简历而言，关系型模型需要一对多（比如工作经历）。 而表述这样的简历，使用 JSON 是非常合适的。JSON 比多表模式有更好的局部性，可以一次查询出一个用户的所有信息。JSON 其实是一棵树。 多对一和多对多的关系 为什么在 SQL 中，地域和公司都以 ID，而不是字符串进行标识呢？ ○ ID 对人类没有任何意义，所以永远不需要改变，可以规范化人类的信息。那么就会存在多对一的关系（多个人对应了同一个 ID）。 ○ 在关系数据库 SQL 中，所有使用它的地方可以用 ID 来引用其他表中的行； ○ 但是文档数据库（比如 JSON），对连接支持很弱。 如果数据库不支持链接，那么就需要在应用代码中，对数据库执行多个查询进行模拟。执行连接的工作从数据库被转移到应用程序代码上。 哪怕最开始的应用适合无连接的文档模型，但是随着功能添加，数据会变得更加互联，比如对简历修改：\n组织和学校作为实体：假如组织和学校有主页 推荐：给别人做推荐，当别人的信息更改的时候，所有地方要同步更新。 文档数据库是否在重蹈覆辙？ 20 世纪 70 年代，最受欢迎的是层次模型（hierarchical model），它与文档数据库使用的JSON模型有一些惊人的相似之处。它将所有数据表示为嵌套在记录中的记录树。虽然能处理一对多的关系，但是很难应对多对多的关系，并且不支持链接。\n提出的解决方案：\n关系模型（relational model）（它变成了SQL，统治了世界） 网络模型（network model）（最初很受关注，但最终变得冷门） 网络模型 支持多对多，每条记录可能有多个父节点。 网络模型中记录之间的链接不是外键，而更像编程语言中的指针（同时仍然存储在磁盘上）。访问记录的唯一方法是跟随从根记录起沿这些链路所形成的路径。这被称为访问路径（access path）。 最简单的情况下，访问路径类似遍历链表：从列表头开始，每次查看一条记录，直到找到所需的记录。但在多对多关系的情况中，数条不同的路径可以到达相同的记录，网络模型的程序员必须跟踪这些不同的访问路径。 缺点：查询和更新数据库很麻烦。 关系模型 数据：一个 关系（表） 只是一个 元组（行） 的集合，很简单。 在关系数据库中，查询优化器自动决定查询的哪些部分以哪个顺序执行，以及使用哪些索引。这些选择实际上是“访问路径”，但最大的区别在于它们是由查询优化器自动生成的，不需要程序猿考虑。 与文档数据库相比 但是，在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为外键，在文档模型中称为文档引用。\n关系型数据库与文档数据库在今日的对比 ● 支持文档数据模型的主要论据是架构灵活性，因局部性而拥有更好的性能，以及对于某些应用程序而言更接近于应用程序使用的数据结构。 ● 关系模型通过为连接提供更好的支持以及支持多对一和多对多的关系来反击。\n哪个数据模型更方便写代码？ 文档模型： ● 优点： ○ 如果应用程序中的数据具有类似文档的结构（即，一对多关系树，通常一次性加载整个树），那么使用文档模型可能是一个好主意。 ● 缺点： ○ 不能直接引用文档中的嵌套的项目，而是需要说“用户251的位置列表中的第二项”（很像分层模型中的访问路径）。但是，只要文件嵌套不太深，这通常不是问题。 ○ 文档数据库对连接的糟糕支持也许或也许不是一个问题，这取决于应用程序。 ○ 如果应用程序使用多对多关系，那么文档模型就没有那么吸引人了。 ○ 对于高度相联的数据，选用文档模型是糟糕的，选用关系模型是可接受的，而选用图形模型是最自然的。\n文档模型中的架构灵活性 文档模型是「读时模式」 ○ 文档数据库有时称为无模式（schemaless），但这具有误导性，因为读取数据的代码通常假定某种结构——即存在隐式模式，但不由数据库强制执行 ○ 一个更精确的术语是读时模式（schema-on-read）（数据的结构是隐含的，只有在数据被读取时才被解释），相应的是写时模式（schema-on-write）（传统的关系数据库方法中，模式明确，且数据库确保所有的数据都符合其模式） ○ 读时模式类似于编程语言中的动态（运行时）类型检查，而写时模式类似于静态（编译时）类型检查。 模式变更 ○ 读时模式变更字段很容易，只用改应用代码 ○ 写时模式变更字段速度很慢，而且要求停运。它的这种坏名誉并不是完全应得的：大多数关系数据库系统可在几毫秒内执行ALTER TABLE语句。MySQL是一个值得注意的例外，它执行ALTER TABLE时会复制整个表，这可能意味着在更改一个大型表时会花费几分钟甚至几个小时的停机时间，尽管存在各种工具来解决这个限制。 查询的数据局部性 ● 文档通常以单个连续字符串形式进行存储，编码为JSON，XML或其二进制变体 ● 读文档： ○ 如果应用程序经常需要访问整个文档（例如，将其渲染至网页），那么存储局部性会带来性能优势。 ○ 局部性仅仅适用于同时需要文档绝大部分内容的情况。 ● 写文档： ○ 更新文档时，通常需要整个重写。只有不改变文档大小的修改才可以容易地原地执行。 ○ 通常建议保持相对小的文档，并避免增加文档大小的写入\n文档和关系数据库的融合 ● MySQL 等逐步增加了对 JSON 和 XML 的支持 ● 关系模型和文档模型的混合是未来数据库一条很好的路线。\n数据查询语言 ● 关系模型包含了一种查询数据的新方法：SQL是一种 声明式 查询语言，而IMS和CODASYL使用 命令式 代码来查询数据库。 ● 命令式语言：告诉计算机以特定顺序执行某些操作，比如常见的编程语言。 ● 声明式查询语言（如SQL或关系代数）：你只需指定所需数据的模式 - 结果必须符合哪些条件，以及如何将数据转换（例如，排序，分组和集合） - 但不是如何实现这一目标。数据库系统的查询优化器决定使用哪些索引和哪些连接方法，以及以何种顺序执行查询的各个部分。 ○ SQL相当有限的功能性为数据库提供了更多自动优化的空间。 ○ 声明式语言往往适合并行执行。\nWeb上的声明式查询 ● 声明式语言更加泛化，不用关心底层的数据存储变化 ● 在Web浏览器中，使用声明式CSS样式比使用JavaScript命令式地操作样式要好得多。 ● 类似地，在数据库中，使用像SQL这样的声明式查询语言比使用命令式查询API要好得多。\nMapReduce查询 ● 一些NoSQL数据存储（包括MongoDB和CouchDB）支持有限形式的MapReduce，作为在多个文档中执行只读查询的机制。 ● MapReduce既不是一个声明式的查询语言，也不是一个完全命令式的查询API，而是处于两者之间 ○ 查询的逻辑用代码片断来表示，这些代码片段会被处理框架重复性调用。 ○ 它基于map（也称为collect）和reduce（也称为fold或inject）函数，两个函数存在于许多函数式编程语言中。 ● map和reduce函数在功能上有所限制： ○ 它们必须是纯函数，这意味着它们只使用传递给它们的数据作为输入，它们不能执行额外的数据库查询，也不能有任何副作用。 ○ 这些限制允许数据库以任何顺序运行任何功能，并在失败时重新运行它们。 ○ MapReduce是一个相当底层的编程模型，用于计算机集群上的分布式执行。像SQL这样的更高级的查询语言可以用一系列的MapReduce操作来实现，但是也有很多不使用MapReduce的分布式SQL实现。 ○ MapReduce的一个可用性问题：必须编写两个密切合作的JavaScript函数，这通常比编写单个查询更困难。此外，声明式查询语言为查询优化器提供了更多机会来提高查询的性能。基于这些原因，MongoDB 2.2添加了一种叫做聚合管道的声明式查询语言的支持\n图数据模型 多对多关系是不同数据模型之间具有区别性的重要特征。\n文档模型：适合数据有一对多关系、不存在关系\n图数据模型：适合多对多关系\n一个图由两种对象组成： a. 顶点（vertices）（也称为节点（nodes） 或实体（entities）） b. 边（edges）（ 也称为关系（relationships）或弧 （arcs） ）。\n举例：社交图谱，网络图谱，公路或铁路网络\n图数据结构示例（以社交网络为例）\n存储方式：属性图，三元组\n属性图 在属性图模型中，每个顶点（vertex）包括： ● 唯一的标识符 ● 一组 出边（outgoing edges） ● 一组 入边（ingoing edges） ● 一组属性（键值对） 每条 边（edge） 包括： ● 唯一标识符 ● 边的起点/尾部顶点（tail vertex） ● 边的终点/头部顶点（head vertex） ● 描述两个顶点之间关系类型的标签 ● 一组属性（键值对） 使用关系模式来表示属性图\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 CREATE TABLE vertices ( vertex_id INTEGER PRIMARY KEY, properties JSON ); CREATE TABLE edges ( edge_id INTEGER PRIMARY KEY, tail_vertex INTEGER REFERENCES vertices (vertex_id), head_vertex INTEGER REFERENCES vertices (vertex_id), label TEXT, properties JSON ); CREATE INDEX edges_tails ON edges (tail_vertex); CREATE INDEX edges_heads ON edges (head_vertex); 关于这个模型的一些重要方面是：\n任何顶点都可以有一条边连接到任何其他顶点。没有模式限制哪种事物可不可以关联。 给定任何顶点，可以高效地找到它的入边和出边，从而遍历图，即沿着一系列顶点的路径前后移动。（这就是为什么例2-2在tail_vertex和head_vertex列上都有索引的原因。） 通过对不同类型的关系使用不同的标签，可以在一个图中存储几种不同的信息，同时仍然保持一个清晰的数据模型。 Cypher查询语言 Cypher是属性图的声明式查询语言，为Neo4j图形数据库而发明 通常对于声明式查询语言来说，在编写查询语句时，不需要指定执行细节：查询优化程序会自动选择预测效率最高的策略，因此你可以继续编写应用程序的其他部分。 查找所有从美国移民到欧洲的人的Cypher查询 1 2 3 4 MATCH (person) -[:BORN_IN]-\u0026gt; () -[:WITHIN*0..]-\u0026gt; (us:Location {name:\u0026#39;United States\u0026#39;}), (person) -[:LIVES_IN]-\u0026gt; () -[:WITHIN*0..]-\u0026gt; (eu:Location {name:\u0026#39;Europe\u0026#39;}) RETURN person.name SQL中的图查询 用关系数据库表示图数据，那么也可以用SQL，但有些困难。 在关系数据库中，你通常会事先知道在查询中需要哪些连接。在图查询中，你可能需要在找到待查找的顶点之前，遍历可变数量的边。也就是说，连接的数量事先并不确定。 语法很复杂， 三元组存储和SPARQL 在三元组存储中，所有信息都以非常简单的三部分表示形式存储（主语，谓语，宾语）。例如，三元组 (吉姆, 喜欢 ,香蕉) 中，吉姆 是主语，喜欢 是谓语（动词），香蕉 是对象。 三元组的主语相当于图中的一个顶点。而宾语是下面两者之一： a. 原始数据类型中的值，例如字符串或数字。在这种情况下，三元组的谓语和宾语相当于主语顶点上的属性的键和值。例如，(lucy, age, 33)就像属性{“age”：33}的顶点lucy。 b. 图中的另一个顶点。在这种情况下，谓语是图中的一条边，主语是其尾部顶点，而宾语是其头部顶点。例如，在(lucy, marriedTo, alain)中主语和宾语lucy和alain都是顶点，并且谓语marriedTo是连接他们的边的标签。 当主语一样的时候，可以进行省略写法 1 2 3 4 5 @prefix : \u0026lt;urn:example:\u0026gt;. _:lucy a :Person; :name \u0026#34;Lucy\u0026#34;; :bornIn _:idaho. _:idaho a :Location; :name \u0026#34;Idaho\u0026#34;; :type \u0026#34;state\u0026#34;; :within _:usa _:usa a :Loaction; :name \u0026#34;United States\u0026#34;; :type \u0026#34;country\u0026#34;; :within _:namerica. _:namerica a :Location; :name \u0026#34;North America\u0026#34;; :type \u0026#34;continent\u0026#34;. 语义网络 语义网是一个简单且合理的想法：网站已经将信息发布为文字和图片供人类阅读，为什么不将信息作为机器可读的数据也发布给计算机呢？ 资源描述框架（RDF）的目的是作为不同网站以一致的格式发布数据的一种机制，允许来自不同网站的数据自动合并成一个数据网络 - 一种互联网范围内的“关于一切的数据库“。 现在已经凉了。 SPARQL查询语言 SPARQL是一种用于三元组存储的面向RDF数据模型的查询语言 查找从美国转移到欧洲的人 1 2 3 4 5 6 PREFIX : \u0026lt;urn:example:\u0026gt; SELECT ?personName WHERE { ?person :name ?personName. ?person :bornIn / :within* / :name \u0026#34;United States\u0026#34;. ?person :livesIn / :within* / :name \u0026#34;Europe\u0026#34;. } 基础：Datalog Datalog是比SPARQL或Cypher更古老的语言，在20世纪80年代被学者广泛研究 本章小结 在历史上，数据最开始被表示为一棵大树（层次数据模型），但是这不利于表示多对多的关系，所以发明了关系模型来解决这个问题。 最近，开发人员发现一些应用程序也不适合采用关系模型。新的非关系型“NoSQL”数据存储在两个主要方向上存在分歧：\n文档数据库的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。 图形数据库用于相反的场景：任意事物都可能与任何事物相关联。 文档数据库和图数据库有一个共同点，那就是它们通常不会为存储的数据强制一个模式，这可以使应用程序更容易适应不断变化的需求。但是应用程序很可能仍会假定数据具有一定的结构；这只是模式是明确的（写入时强制）还是隐含的（读取时处理）的问题。 每个数据模型都具有各自的查询语言或框架，我们讨论了几个例子：SQL，MapReduce，MongoDB的聚合管道，Cypher，SPARQL和Datalog。我们也谈到了CSS和XSL/XPath，它们不是数据库查询语言，而包含有趣的相似之处。 ","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E4%BA%8C%E7%AB%A0/","summary":"第二章：数据模型与查询语言 数据模型可能是软件开发中最重要的部分了，因为它们的影响如此深远：不仅仅影响着软件的编写方式，而且影响着我们的解题思","title":"DDIA第二章"},{"content":"第一章：可靠性，可扩展性，可维护性 关于数据系统的思考 单个工具已经不能满足应用系统的需求，总体工作被拆分成一系列能被单个工具高效完成的任务，并通过应用代码将它们缝合起来。比如一个缓存、索引、数据库协作的例子：\n一个应用被称为数据密集型的，如果数据是其主要挑战（数据量，数据复杂度、数据变化速度）——与之相对的是计算密集型，即处理器速度是其瓶颈。 软件系统中很重要的三个问题：\n可靠性（Reliability）：系统在困境（硬件故障、软件故障、人为错误）中仍可正常工作 可扩展性（Scalability）：有合理的办法应对系统的增长（数据量、流量、复杂性） 可维护性（Maintainability）：许多不同的人在不同的生命周期，都能高效地在系统上工作。 可靠性 定义 造成错误的原因叫做故障（fault），能预料并应对故障的系统特性可称为容错（fault-tolerant）或者韧性（resilient）。讨论容错时，只有讨论特定类型的错误 故障（fault）不同于失效（failure）：故障指的是一部分状态偏离标准，而失效则是系统作为一个整体停止向用户提供服务。 通常倾向于容忍错误（而不是阻止错误），但也有预防胜于治疗的情况（比如安全问题） 硬件故障 一般都是增加单个硬件的冗余度 云平台的设计是优先考虑灵活性和弹性，而不是单机可靠性。 软件错误 这类软件故障的bug 通常潜伏很长时间，直到被异常情况触发为止。往往是某个假设出于某种原因最后不在成立了。 解决办法：仔细考虑假设和交互；彻底的测试；重启；监控。 人为错误 人是不可靠的，运维配置错误是导致服务中断的首要原因。 解决办法：最小化犯错机会的方式设计系统；容易犯错的地方解耦；测试；监控；培训。 可扩展性 定义 可扩展性（Scalability）是用来描述系统应对负载增长能力的术语。 描述负载 负载可以用负载参数的数字来描述，取决于系统架构\n推特的发推设计：\na. 推文放在全局推文集合中，查询的时候做 join\nb.推文插入到每个关注者的时间线中，「扇出」比较大，当有千万粉丝的大 V 发推压力大\nc.推特从方案一变成了方案二，然后变成了两者结合的方式\n描述性能 当描述好负载以后，问题变成了：\na. 增加负载参数并保持系统资源不变时，系统性能将受到什么影响？\nb. 增加负载参数并希望性能不变时，需要增加多少系统资源？ 批处理系统，通常关心吞吐量（throughput）；在线系统，通常更关心响应时间（response time） 对于系统响应时间而言，最好用百分位点，比如中位数、p99 等标识。 测量客户端的响应时间非常重要（而不是服务端），比如会出现头部阻塞、网络延迟等。 实践中的百分位点，可以用一个滑动的时间窗口（比如 10 分钟）进行统计。可以对列表进行排序，效率低的话，考虑一下前向衰减，t-digest 等方法近似计算。 应对负载的方法 纵向扩展：转向更强大的机器 横向扩展：将负载分布到多台小机器上 弹性系统：检测到负载增加时自动增加计算资源 跨多台机器部署无状态服务比较简单，但是把带状态的数据系统从单节点变成分布式配置则可能引入许多额外复杂度。因此，应该尽量将数据库放在单个节点上。 可维护性 在设计之初就尽量考虑尽可能减少维护期间的痛苦，从而避免自己的软件系统变成遗留系统。 三个设计原则：可操作性（Operability）便于运维团队保持系统平稳运行。简单性（Simplicity）从系统中消除尽可能多的复杂度（complexity），使新工程师也能轻松理解系统。（注意这和用户接口的简单性不一样。）可演化性（evolability）使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为可扩展性（extensibility），可修改性（modifiability）或可塑性（plasticity）。 可操作性：人生苦短，关爱运维 ● 尽量自动化\n简单性：管理复杂度 ● 消除额外的（accidental）的复杂度 ● 消除额外复杂度的最好工具之一是抽象（abstraction）\n可演化性：拥抱变化 ● 敏捷（agile） 工作模式为适应变化提供了一个框架\n● 简单易懂的系统通常比复杂系统更容易修改，即可演化性（evolvability）\n参考文章: https://www.yuque.com/fuxuemingzhu/ddia/hqu56x\n","permalink":"https://csqread.top/posts/tech/ddia%E7%AC%AC%E4%B8%80%E7%AB%A0/","summary":"第一章：可靠性，可扩展性，可维护性 关于数据系统的思考 单个工具已经不能满足应用系统的需求，总体工作被拆分成一系列能被单个工具高效完成的任务，并","title":"DDIA第一章"},{"content":"推荐序 这本书的适合所有后台开发工程师、大数据工程师，也很适合面试前复习系统设计的同学。\n什么是「数据密集型应用系统」？\n当数据（数据量、数据复杂度、数据变化速度）是一个应用的主要挑战，那么可以把这个应用称为数据密集型的。与之相对的是计算密集型——处理器速度是主要瓶颈。\n其实我们平时遇到的大部分系统都是数据密集型的——应用代码访问内存、硬盘、数据库、消息队列中的数据，经过业务逻辑处理，再返回给用户。\n很多应用都是在解决不同场景下的数据存储和检索问题——MySQL，Redis，HBase，Kafka，ElasticSearch…… 还有很多技术是围绕着数据展开——索引，编码（JSON, XML, Thrift, ProtoBuffer），行列存储…… 当数据在分布式处理时，要考虑——数据复制，分区，事务…… 大数据场景下，我们会使用——MapReduce，Spark，Flink 等批处理、流处理框架。 《数据密集型应用系统设计》这本书，把所有跟「数据」有关的知识点做了剖析、整理、总结，从一个很高的层次把各项技术的共性和区别讲得透彻。 当我们懂了底层原理之后，就明白了每项技术产生的背景是什么，解决了什么问题，有什么适用场景。\n这本书既有理论也有实践，基本没有公式，图很多，阅读起来很流畅，比较容易理解。\n这本书分为了三部分： ● 第一部分：数据系统的基石，包括数据模型与查询语言、存储与检索、数据编码与演化； ● 第二部分：分布式数据，包括复制、分片、事务、一致性与共识； ● 第三部分：衍生数据，包括批处理、流处理、数据系统的未来。\n阅读资源 这是一些阅读资源：\n《数据密集型应用系统设计》开源翻译仓库（9.3K star）： https://github.com/Vonng/ddia 开源版本在线阅读： https://vonng.gitbooks.io/ddia-cn/content/ 负雪明烛的读书笔记：数据密集型应用系统设计 《数据密集型应用系统设计》纸质书（翻译水平比开源在线阅读版好很多，强烈建议买书）：京东购买链接 辅助资料 ddia-references 这个仓库包含了《数据密集型应用系统设计》每章后面的所有参考文献对应的 pdf。 地址是：https://github.com/ept/ddia-references\nBook Review 这里有个很不错的 Book Review，是一个小哥讲了《DDIA》每一章的概述，作者很用心。 全英文的，在油管可以看到。地址是： https://www.youtube.com/watch?v=PdtlXdse7pw\u0026amp;list=PL4KdJM8LzAMecwInbBK5GJ3Anz-ts75RQ\n连载 后续我会把我读书笔记以及读书感想连载更新，这里是抄的一位大佬的序 https://www.yuque.com/fuxuemingzhu/ddia/kpqcs3\n","permalink":"https://csqread.top/posts/tech/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","summary":"推荐序 这本书的适合所有后台开发工程师、大数据工程师，也很适合面试前复习系统设计的同学。 什么是「数据密集型应用系统」？ 当数据（数据量、数据复杂","title":"数据密集型应用系统设计"},{"content":"分布式系统秒杀交易性能优化 1、背景 首先介绍一下这个交易的功能： 该交易是一个定期存款交易，利率非常高，存期有三个月，六个月、一年、两年、三年、五年，年化利率基本上每天发布的产品中都有4%以上的。其中六个月和一年的年化利率最受欢迎。这个定期产品只能每天9点开始购买，并且支持的渠道只有手机银行，因此在每天8点59-9点这个区间会收到非常的请求。根据指标控制中心查询的数据大概在9点到9点01秒这一秒中大概需要处理1000个请求。不过老核心那边怕给系统搞宕机做了一个并发控制，也就是达到性能瓶颈时会限制购买，打印“系统繁忙”反馈给前端.大概在不久前，老核心反馈给我们分布式核心说该交易也还需要持续进行优化，因为目前该产品实在是太火爆了，导致老核心也一直无法处理短时间内的大量请求，只能反馈系统繁忙。\n2、分析 我对老核心的这个交易逻辑进行了分析，其实他们已经做了不少优化了，不过目前看起来也还是很慢，从9点到9点1分我统计了这一分钟成功交易的平均耗时，大概是370ms左右。这个标准在老核心的交易中其实已经是比较慢的了。而分布式这边目前观察并行生产跑的性能更是非常慢，成功交易的平均耗时大概900ms左右。。。而这个交易又是我负责的产品，因此对它进行性能优化是当务之急。该交易的大致逻辑如下：\n前端请求进来，先做一些必输项校验，包括客户信息，密码校验等。接着是查询该产品的产品信息表，获取该产品信息，与客户信息做一些校验。后面会做一些额度的扣减。因为该款产品每次发布是有限额的。比如1000万美元的额度，抢完就没了，因此每次购买完了需要做一个额度的扣减。完了之后就需要记一笔账务。即从该客户的备用金账户扣除一笔钱到该客户的定期账户。最后再落一张表存储该客户购买的信息。\n其实老核心之前做的优化是把额度扣减从交易的前面移到了交易的最后。这样做的目的是，在并发请求打进来时，在做额度扣减的时候，会锁表，把这块逻辑放在最后做，能把锁表的时间减少的最短，如果放在前面做额度扣减，那么锁表的时间就是整个交易做完的时间，但是放在最后，就是最后几十ms。其他他们也没有做什么优化，\n但是分布式这边就很麻烦了。我这边也是把额度扣减放在最后的，按照他们的想法是把锁表的时间降低到最少。但是这样的话，因为我们是分布式，我得调两次额度服务，两次RPC所耗费得的时间也是很长的。而且分布式按照之前卡服务提供的接口，需要查询三次卡服务的表才能满足业务逻辑。所以我这边所做的优化大概如下：\n3、优化 首先，向卡组提需求，将三次RPC卡服务减少为RPC一次，一次查询，把所有需要的字段全部返回，减少两次RPC的时间 关于额度这块，我的想法是得把两次RPC减少为1次，而且也要减少锁表时间。。。一种是加缓存，把查询产品信息这块加缓存，这样就不用RPC额度了，但是这块有隐患，产品信息这张表是不断更新的，每天都有新的产品发布，按照redis缓存，是一些参数数据不太变化的数据加缓存，如果加缓存，生产上也得不断地去更新缓存。到时候查不到产品信息还是得去RPC额度服务。因此考虑了第二种方法。就是把更新额度和查询额度还是放到一次RPC中去做，并且放到交易得最前面。然后这块和整个交易不放在一个全局事务里面去做，分为两个事务去做。即更新额度与记账不在一起。这样的话。我们只需要try catch整个记账得逻辑，如果记账失败了，那我们就触发一个事件，去回滚前面那个事务做的额度扣减，把这个额度给加上。这样就不会造成长时间的锁表，也不会两次RPC。 最后，其实我对分布式每秒的高并发量是保持乐观态度的，因此在单元化之后已经将客户哈希到十个不同的服务上。因此就算1s钟500个并发进来那么也是随机平均的打到10个服务上面，而且进行容器化后，每个服务也是有很多机器来处理这些请求的，大家分担之后是完全可以处理这种秒杀交易的，虽然分布式这边的交易耗时没办法降到单核心交易耗时以下，但是系统处理能力也不是单核系统能比拟的。 4、总结 该交易涉及账务和额度增减，也就是说，如果交易失败，还需要进行事务回滚。在老核心单核系统处理起来是非常简单粗暴的。但是分布式由于各种RPC的原因，处理的手法就得麻烦点，不过也非常考验对分布式事务和消息队列的理解。其实整个系统达到1000tps在之前的性能测试中已经压到这个指标了，不过还没有涉及到这个秒杀的情况。虽然做了上面的这几个优化，但是肯定还是无法从900ms的平均耗时降下来很多。根据投产后的观察，大概能到500ms，和单核系统相比仍然差距很大。后续要需要持续的进行优化。\n这里涉及到的分布式事务知识点还是很重要的。而且我们在框架设计中使用的是乐观锁，也就是已经使得系统性能不会受到很大限制了。但是我觉得在这个秒杀交易这不太适合使用乐观锁。。。。。因为可能会导致很多请求冲突无功而返浪费时间\n大致的一个工作总结吧，其实这个产品我也买了。。，但是在查询的时候，明显的在9点的时候刷不到产品信息，提示系统繁忙，其实这个产品的查询也是需要优化的，因为大家在购买产品的时候刷新这个页面看产品信息的时候可能那一秒中的并发量就破万了，这可能就是单核的局限性吧，后面还分布式了应该不会出现这种尴尬的情况。不过仅仅是查询的化从后端的角度来说，优化其实也只是在缓存和SQL上面进行优化。我也是第一次在工作中实际遇到秒杀交易的优化，也让我更加深入的理解了一下这块所涉及的分布式系统设计和后端优化上的知识点。\n","permalink":"https://csqread.top/posts/tech/%E5%88%86%E5%B8%83%E5%BC%8F%E7%A7%92%E6%9D%80%E4%BA%A4%E6%98%93%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E8%AE%B0%E5%BD%95/","summary":"分布式系统秒杀交易性能优化 1、背景 首先介绍一下这个交易的功能： 该交易是一个定期存款交易，利率非常高，存期有三个月，六个月、一年、两年、三年、","title":"分布式秒杀交易性能优化记录"},{"content":"最近在看《重构》第二版，看到替换循环这里，想到我在工作中也是无脑的使用循环和if-else，最近也有空没事就重构之前自己写的代码以及别人留下来的代码。因此就自己尝试了一下管道。发现确实非常的简单明了。大致我举个例子说明下：\n大致需求是这样，从汽车List中找到2000年以后生产的汽车:\nCar类： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package test; public class Car { private String make; private String model; private String year; public Car(String make, String model, String year) { this.make = make; this.model = model; this.year = year; } public String getMake() { return make; } public void setMake(String make) { this.make = make; } public String getModel() { return model; } public void setModel(String model) { this.model = model; } public String getYear() { return year; } public void setYear(String year) { this.year = year; } } new 对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package test; import java.util.Arrays; import java.util.List; public class Iterating { public static List\u0026lt;Car\u0026gt; createCars(){ return Arrays.asList( new Car(\u0026#34;Jeep\u0026#34;, \u0026#34;Wrangler\u0026#34;, \u0026#34;2011\u0026#34;), new Car(\u0026#34;Jeep\u0026#34;, \u0026#34;Comanche\u0026#34;, \u0026#34;1990\u0026#34;), new Car(\u0026#34;Dodge\u0026#34;, \u0026#34;Avenget\u0026#34;, \u0026#34;2010\u0026#34;), new Car(\u0026#34;Buick\u0026#34;, \u0026#34;Cascada\u0026#34;, \u0026#34;2016\u0026#34;), new Car(\u0026#34;Ford\u0026#34;, \u0026#34;Focus\u0026#34;, \u0026#34;2012\u0026#34;), new Car(\u0026#34;Chevrolet\u0026#34;, \u0026#34;Geo Metro\u0026#34;, \u0026#34;1992\u0026#34;) ); } } 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 package test; import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; import java.util.stream.Collectors; public class GetCarsModel { public static void main(String[] args) { List\u0026lt;Car\u0026gt; cars = Iterating.createCars(); System.out.println(getAfter2000years(cars)); System.out.println(getModelsAfter2000UsingPipeline(cars)); } /** * 使用for循环 * @param cars * @return */ private static List\u0026lt;String\u0026gt; getAfter2000years (List\u0026lt;Car\u0026gt; cars) { List\u0026lt;Car\u0026gt; carsDortedByYear = new ArrayList\u0026lt;\u0026gt;(); for (Car car : cars) { if (car.getYear().compareTo(\u0026#34;2000\u0026#34;) \u0026gt; 0) { carsDortedByYear.add(car); } } Collections.sort(carsDortedByYear, new Comparator\u0026lt;Car\u0026gt;() { @Override public int compare(Car o1, Car o2) { return (o1.getYear().compareTo(o2.getYear())); } }); List\u0026lt;String\u0026gt; models = new ArrayList\u0026lt;\u0026gt;(); for (Car car : carsDortedByYear) { models.add(car.getModel()); } return models; } /** * @deacription 使用管道 * @param cars * @return */ private static List\u0026lt;String\u0026gt; getModelsAfter2000UsingPipeline(List\u0026lt;Car\u0026gt; cars) { return cars.stream().filter(car -\u0026gt; car.getYear().compareTo(\u0026#34;2000\u0026#34;) \u0026gt; 0).sorted(Comparator.comparing(Car::getYear)).map(Car::getModel).collect(Collectors.toList()); } } 最后这俩结果是一样的，但是哪个更加简单明了一眼可知。\n只用了短短几行代码，代码的意图就很明显 — 给定一个汽车集合，过滤或提取仅在 2000 年或以后制造的汽车；然后按年份进行排序，将这些对象映射或转换为它们的型号，最后将结果收集到一个列表中。\n","permalink":"https://csqread.top/posts/tech/%E9%87%8D%E6%9E%84%E4%B9%8B%E7%AE%A1%E9%81%93%E6%9B%BF%E6%8D%A2%E5%BE%AA%E7%8E%AF/","summary":"最近在看《重构》第二版，看到替换循环这里，想到我在工作中也是无脑的使用循环和if-else，最近也有空没事就重构之前自己写的代码以及别人留下","title":"重构之管道替换循环"},{"content":"这几天一直在修并行环境的bug，也踩了不少坑， 记录一下\n1、关于对集合的排序循环问题。集合被修改之后不能再用于循环 原本的逻辑是这样的，在对C代码使用Java进行翻写的时候，因为C使用的是临时表，我这边用的是List集合，然后那边直接order By，而我用的是封装的一个对集合进行排序的方法。因此该集合在某种程度上是被修改了的，但是我仍然对让它进入了下一次循环，而没有break掉，或者使用一个新的集合来进行修改，导致并行生产环境报错。在不确定集合是否被修改的情况下，一定要New一个新的List来进行修改，保持原来的List进行循环。。。。\n2、spring boot redis 序列化报错 as a subtype of [simple type, class java.lang.Object]: no such class found 问题 大致场景是这样的， 有两个服务 A B, A服务用于授权， 授权成功会存储对象到redis中, B服务通过token去redis中拿到Object对象转换成业务对象。\n大致原因是： A服务存储对象到redis中时候会有一个全路径类名限定，在通过token进行取对象值并强制转换的时候，如果接受对象的全路径名与redis中保存的不一致的话就会转换失败报错。\n可能是因为之前项目类路径改造的时候，把这张表对应的类路径漏掉了，而redis那边不是实时从现有的数据库中获取的，而是根据我们各个业务组之前手动登记的路径进行修改的，因此并行生产出现这种问题。。。\n解决办法：\n1、把路径名称改成一致（使用了这个办法） 2、将保存对象的方式改成其他方式（这个存疑， 在网上看的）\n","permalink":"https://csqread.top/posts/tech/%E5%B7%A5%E4%BD%9C%E4%B8%8A%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%E8%AE%B0%E5%BD%95/","summary":"这几天一直在修并行环境的bug，也踩了不少坑， 记录一下 1、关于对集合的排序循环问题。集合被修改之后不能再用于循环 原本的逻辑是这样的，在对C代","title":"工作上遇到的坑记录"},{"content":"进程的概念 在多道程序环境下，允许多个程序并发执行，此时他们将失去封闭性，并具有间断性和不可再现性的特征。为此引入了进程的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发行和共享性。为此引入了进程的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性。\n为了是参与并发执行的程序能独立的运行，必须为之配置一个专门的数据结构，称之为进程控制块（process control block），系统利用PCB来描述进程的基本情况和运行状态，进而控制和管理进程。\n相应的，有程序段、相关数据段和PCB三部分构成了进程映像（进程实体）。所谓创建进程，实质上是创建进程映像中的PCB；而撤销进程，实质上是撤销进程的PCB。指的注意的是，进程影响是静态的，晋城市动态的。\n从不同的角度，进程可以有不同的定义，比较经典的定义有：\n1） 进程是程序的一次执行过程\n2） 进程是一个程序及其数据在处理器上顺序执行时所发生的活动。\n3） 进程是具有独立功能的程序在一个数据集合上运行的过程，他是系统进行资源分配和调度的一个独立单位。\n在引入了进程实体的概念后，我们可以吧传统的操作系统中的进程定义为：“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位”。\n进程的特征 进程是由多程序的并发执行而引出的，他和程序是两个截然不同的概念。进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求。\n1） 动态性：进程是程序的一次执行，他有着创建、活动、暂停、终止等过程，具有一定的生命周奇奇，是动态的产生、变化和消亡的。动态性是进程最基本的特征。\n2） 并发性：至多个进程实体，同存于内存中，能在一段时间内同时运行，并发性是进程的重要特征，同时也是操作系统的重要特征，引入进程的目的就是为了是程序能与去其他进程的程序并发执行，以提高资源利用率。\n3） 独立性：指进程实体是一个能独立运行、独立获得资源和独立接收调度的基本单位。范围建立PCB的程序都不能作为一个独立的单位参与运行。\n4） 异步性：由于进程的相互制约，是进程具有执行的间断性。也即进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果不可再现性，为此，在操作系统中必须配置相应的进程同步机制。\n5） 结构性：每个进程都配置一个PCB对其进行描述。从结构上来看，进程实体是由程序段、数据段和进程控制端三部分组成的。\n进程的状态与转换 进程在其生命周期内，由于系统中个进程之间的相互制约关系以及系统的运行环境的变化，使的进程的状态也在不断地发生着变化。通常进程有以下五种状态。前三种是进程的基本状态。\n1） 运行状态：进程正在处理器上运行。在单处理器的环境下，每一时刻最多只有一个进程处于运行状态。\n2） 就绪状态：进程已处于准备运行的状态，即进程获得了除CPU之外的一切所需资源，一旦得到处理器即可运行。\n3） 阻塞状态：又称为等待状态：进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理器），或等待输入输出的完成。及时处理器空闲，该进程也不能运行。\n4） 创建状态：进程正在被创建，尚未转到就绪状态。创建进程通常需要多个步骤：首先申请一个空白的PCB，并向PCB中填写一些控制和管理进程的信息；然后由系统为该进程分配运行时所必须的资源；最后把该进程转入到就绪状态。\n5） 结束状态：进程正在从系统中消失，这可能是进程正常结束或其他原因中断退出运行。当进程需要结束运行时，系统首先必须置该进程为结束状态，然后再进一步处理资源释放和回收工作。\n注意区别就绪状态和等待状态：就绪状态是指进程仅缺少处理器，只要活得处理器资源就立即执行；而等待状态是指进程需要其他资源或等待某一事件，及时处理器空闲也不能运行。\n进程控制 进程控制的主要功能是对系统中所有进程实施有效地管理，她具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段成为原语，原语的特点是执行期间不允许中断，他是一个不可分割的基本单位。\n允许一个进程创建另一个进程。\n操作系统创建一个新进程的过程如下（创建原语）：\n1） 为新进程分配一个为我一个进程标示号，并申请一个空白的PCB。\n2） 为进程分配资源，为新进程的程序和数据，以及用户占分配必要的空间。\n3） 初始化PCB，主要包括初始化标识信息、初始化处理器状态信息和初始化处理器控制信息，以及设置进程的空闲及。\n4） 如果进程就绪队列能够接纳新进程，就将新进程插入到就绪队列，等待被调度运行。\n引起进程终止的时间主要有：正常结束、表示进程的任务已经完成和准备退出运行。异常结束是指进程在运行时，发生了某种异常事件，是程序无法继续运行，如：存储区越界、保护措、非法指令、特权指令错、IO故障等。外界干预是指进程外界的请求而终止，如操作员或操作系统干预、父进程请求和父进程终止。\n操作系统终止进程的过程如下：（撤消原语）\n1） 根据被终止进程的标示符，检索PCB，从中读出该进程的状态。\n2） 若被终止进程处于执行状态，立即终止该进程的执行，将处理器资源分配给其他进程。\n3） 若该进程还有子进程，则应将其所有子进程终止。\n4） 将该进程所拥有的资源、或归还给父进程或归还给操作系统。\n5） 将该PCB从所在队列（链表）中删除。\n进程的阻塞与唤醒 正在执行的进程，犹豫期待的某些时间为发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无心工作可做等，则由系统自动执行阻塞原语，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为。\n阻塞原语的执行过程为：找到将要被阻射进城的标识号对应的PCB，如果该进程为运行状态，则保护其现场，将其状态改为阻塞状态，停止运行，并把该PCB插入响应时间的等待队列中去；若为就绪状态，则将其状态改为阻塞状态，把它溢出就绪队列，插入到等待队列中去。\n当阻塞进程所期待的时间出现时，如它所启动的IO操作已完成或其所期待的数据已到达，则有关进程（比如，提供数据的进程），调用唤醒原语，将等待该事件的进程唤醒，唤醒原语的执行过程是：在该事件的等待队列中找到相应进程的PCB，然后把该PCB插入到就绪队列中，等待调度程序调度。\n需要注意的是，Block原语和Wakeup原语是一对作用刚好相反的原语，必须成对使用。Block原语是由被阻塞进程自我调用实现的，而Wakeup原语则是由一个与被唤醒进程相合作或被其他相关进程调用实现的。\n无论什么样的进程操作，都是在内核执行的。\n进程切换是指当前正在运行的进程被转换到其他状态后，再回到运行继续执行的过程，这个过程中，进程的运行环境产生了实质性的变化。进程切换的过程如下：\n1） 保存处理器上下文，包括程序计数器和其他寄存器。\n2） 更新PCB信息。\n3） 把进程的PCB移入相应的队列，如就绪、在某时间阻塞等队列。\n4） 选择另一个进程执行，并更新其PCB。更新内存管理的数据结构。\n5） 恢复处理器的上下文。\n进程控制块 进程创建时，操作系统就新建一个PCB结构，它之后就常驻内存，任意时刻可以存取。在进程结束时删除。PCB是进程实体的一部分，是进程存在的唯一标识。\nPCB主要包括：进程描述信息、进程控制和管理信息、资源分配清单和处理器相关信息等。\n在一个系统中，通常存在这许多进程，有的处于就绪状态，有的处于阻塞状态，而且阻塞的原因各不相同。为了方便进程的调度和管理，需要将各进程的PCB用适当的方法组织起来。目前，常用的组织方式有连接方式和索引方式两种。连接方式将同一状态的PCB连接成一个队列，不同状态对应不同的队列，也可以把处于阻塞状态的进程的PCB，根据其阻塞原因的不同，排成多个阻塞队列。索引方式是将同一状态的进程组织在一个索引表中，索引表的表项只想相应的PCB，不同状态对应不同的索引表，如就绪索引表和阻塞索引表等。\n程序段就是能北京城调度程度调度到CPU执行的程序代码段。注意，程序可以被多个进程共享，就是说多个进程可以运行同一个程序。\n一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。\n进程的通信 进程通信就是进程之间的数据交换。PV操作时低级通信方式2，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法可分为共享存储、消息传递和管道通信三大类。\n共享存储 在通信的进程之间存在着一款可以直接访问的共享空见，通过对这块共享空间的读写操作时间进程之间的信息交换。在共享存储方法中，需要使用同步互斥工具。\n需要注意的是：用户进程空间一般都是相互独立的，要想让两个用户进程共享空间，必须通过特殊系统调用实现，而进程内的线程是自然共享进程空间的。\n消息传递 在消息传递系统中，进程间的数据交换，是以格式化的小心Message为单位的。\n管道通信 管道通信是消息传递的一种特殊方式。。所谓管道，就是用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名为pipe文件。向管道或共享文件提供输入的发送进程，以字符流的形势将大量的数据送入写管道；而接收管道输出的接收进城，则从管道中接受数据。为了协调双方的通信，关到极致必须他提供以下撒按方面的协调能力：互斥、同步和确定对方存在。\n线程概念和多线程模型 引入进程的目的，是为了是多道程序能并发执行，以提高资源利用率和系统吞吐量；而引入线程，则是为了减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。\n线程最直接的理解就是“轻量级进程”，它是一个基本的CPU执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位。进程只作为除CPU以外的系统资源的分配单元，线程则作为处理器的分配单元。线程也有就绪、阻塞和运行三种基本状态。\n线程和进程的比较 1） 调度：在引入线程的操作系统中，线程是独立调度的基本单位，进程是资源拥有的基本单位。\n2） 拥有资源：进程是拥有资源的基本单位，而线程不拥有系统资源，单线程可以防伪其隶属进程的系统资源。\n3） 并发性：在引入线程的操作系统中，不仅进程之间可以并发执行，线程之间也可以并发执行，从而是操作系统具有更好的并发性，大大提高了系统的吞吐量。\n4） 系统开销：线程开销极小。\n5） 地址空间和其他资源：进程的地址空间之间相互独立，同一进程的各线程间共享进程的资源，进程内的线程对进程外的其他进程不可见。\n6） 通信方面：进程间通信需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以直接读写进程数据段来进行通信。\n线程的属性 在多线程操作系统中，八仙城作为独立运行的基本单位。此时的进程已不是一个基本可执行的实体。线程的主要属性如下：\n1） 线程是一个轻型实体，它不拥有系统资源，但每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场情况。\n2） 不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统为他们创建不同的线程。\n3） 统一进程中的各个线程共享该进程所拥有的系统资源。\n4） 线程是处理器的独立调度单位，多个线程是可以并发执行的。\n5） 一个线程被创建后便开始了它的生命周期，直至终止，线程在生命周期内会经历等待态、就绪态和运行态等各种状态变化。\n线程的实现方法 线程的实现可以分为两类：用户级线程和内核级线程。\n多线程模型 有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式。\n1） 多对一模型。多对一模型将多个用户级线程映射到一个内核级线程。线程管理在用户空间完成。\n2） 一对一模型。\n3） 多对多模型。\n特点：克服了多对一模型的并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。\n线程的调度 在多道程序系统中，进程的数量往往多于处理器的个数，进程争用处理器的情况在所难免。处理器调度是对处理器进行分配，就是从就绪队列中，按照一定的算法，选择一个进程并将处理器分配给他运行，以实现进程的并发执行。\n处理器调度是多道程序操作系统的基础，它是操作系统设计的核心问题。\n一个作业从提交开始知道完成，往往要经历一下三级调度：\n1）作业调度。作业调度又称高级调度：其主要任务是按一定的原则从外存上处于后备状态的作业中挑选一个或多个作业，给他们分配内存、输入输出设备等必要的资源。并建立相应的进程，以使他们获得竞争处理器的权利。\n多道批处理系统中大多配有作业调度，而其它系统中通常不需要配置作业调度。作业调度的执行频率较低，通常为几分钟一次。\n2）中级调度。中级调度又称内存调度。引入中级调度视为了提高内存利用率和系统吞吐率，为此，应使那些暂时不能运行的进程调至外存等待，把此时的进程状态称为挂起状态。当他们已具备运行条件且内存有稍有空闲时，由中级调度来决定，吧外存上那些已具备运行条件的就绪进程，在重新调入内存，并修改其状态为就绪状态，挂在就绪队列上等待。\n3）进程调度。进程调度又称为低级调度，其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理器分配给它。进程调度是操作系统中最基本的一中调度，在一般操作系统中都不需配置进程调度。进程调度的频率很高，一般几十毫秒一次。\n作业调度从外存的后备队列中选择一批作业进入内存，为他们建立进程。这些进程被送入就绪队列。进程调度从就绪队列中选出一个进程，并把其状态改为运行状态，把CPU分配给它。中级调度是位于高级调度和低级调度之间的一种调度。为了提高内存的利用率，系统将那些暂时不能运行的进程挂起来。当内存空间宽松式，通过中级调度选择具备运行条件的进程，将其唤醒。\n调度的时机、切换与过程 进程调度和切换程序是操作系统内核程序。当请求调度的事件发生后，才可能会运行进程调度程序，当调度了新的就绪进程后，才会去进行进程间的切换。\n现在操作系统中，不能进行进程的调度与切换的情况有以下几种：\n1） 在处理中断的过程中：中断处理过程复杂，在实现上很难做到，而且中断处理时系统工作的一部分，逻辑上不属于某一进城，不应被剥夺处理器资源。\n2） 进程在操作系统内核程序临界区中：进入临界区后，需要独占式的访问共享数据，理论上必须加锁，以防止其他并行程序的进入，在解锁前不应该切换到其他进程，以加快该共享数据的释放。\n3） 其他需要完全屏蔽中断的原子操作过程中：如加锁、解锁、中断现场保护、恢复等等源自操作。在原子过程中，连中断都要屏蔽，更不应该进行进程的切换。\n如果在上述过程中发生了引起调度的条件，并不能马上进行调度和切换，应置系统请求调度标志，知道上述过程结束后才能进行相应的调度和切换。\n应该进行进程的调度与切换的情况有：\n1） 当发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度与切换。如果操作系统只在这种情况下进行进程调度，就是非剥夺调度。\n2） 当中断处理结束后或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。如果操作系统支持这种情况下的运行调度程序，就实现了剥夺方式的调度。\n进程切换往往在调度完成后立刻发生，它要求保存源进程当前切换点的县城信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将远近程的现场信息推入到当前进程的内核对战来保存他们，并更新堆栈指针。内核完成从新进程的内核栈中装入新进程的县城信息、更新当前运行进程空间指针、重设PC寄存器等相关工作之后，开始运行新的进程。\n进程调度方式 所谓进程调度方式是指当某一个进程正在处理器上执行时，若有某个更为重要或紧迫的进程需要处理，既有优先权更高的进程进入就绪队列，此时应如何分配处理器。通常有一下两种进程调度方式：\n（1） 非剥夺调度方式 非剥夺调度方式又称为非抢占调度方式，是指当一个进程正在处理器上执行时，即使有某个更为重要或紧迫的进程进入就绪状态，仍然让正在执行的进程继续执行，知道该进程完成或发生某种时间而进入阻塞状态时，才把处理器分配给更为重要或紧迫的进程。\n（2） 剥夺调度方式 剥夺调度方式又称为抢占方式，是指当一个进程正在处理器上执行时，若有某个更为重要或紧迫的进程需要使用处理器，则立即暂停正在执行的进程，将处理器分配给这个更为重要或紧迫的进程。\n“剥夺”不是一种任意性行为，必须遵循一定的原则：优先权原则，短进程优先原则和时间片原则。\n调度的基本准则 不同的调度算法具有不同的特性，在选择调度算法时，必须考虑算法所具有的特性。为了比较处理器调度算法的性能，人们提出很多评价准则，下面介绍主要的几种准则：\n（1） CPU利用率 CPU是计算机系统中最重要的资源之一，所以应尽可能使CPU保持在忙状态，是这一资源利用率最高。\n（2） 系统吞吐量 系统吞吐量表示单位时间内CPU完成作业的数量。长作业需要消耗较长的处理器时间，因此会降低系统的吞吐量。而对于短作业，他们所需要消耗的处理器时间端，因此能提高系统的吞吐量。调度算法和方式的不同，也会对系统的吞吐量产生较大的影响。\n（3） 周转时间 周转时间是指从作业提交到作业完成所经历的时间，包括作业等待、在就绪队列中排队、在处理器上运行以及进行输入输出操作所花费的时间的总和。\n作业的周转时间=作业完成时间-作业提交时间\n（4） 等待时间 等待时间是指进程处于等处理器状态时间之和，等待时间越长，用户满意度越低。处理器调度算法实际上并不影响作业执行或输入输出操作时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法优劣常常只需简单地考察等待时间。\n（5） 响应时间 响应时间是指从用户提交请求到系统首次产生响应所有的时间。在交互式系统中，周转时间不可能是最好的评测准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户的角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能够接受的范围之内。\n典型的调度算法 通常系统的设计目标不同，所采用的调度算法也不同。在操作系统中存在多种调度算法，其中有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。下面介绍几种常用的调度算法：\n（1） FIFS先来先服务调度算法 特点：算法简单，但是效率低；有利于长作业，不利于短作业；有利于CPU繁忙型作业而不利于IO繁忙型作业。\n（2） SJF短作业优先调度算法 短作业（进程）优先调度算法是指对短作业祸端进程优先调度的算法。短作业优先调度算法是从后备队列中选择一个或若干个估计运算时间最短的作业，将他们呢掉入内存运行。\nSJF调度算法的缺点：\n1） 该算法对长作业不理。\n2） 该算法完全未考虑作业的紧迫程度\n3） 由于作业的长短只根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意的缩短其作业的估计运行时间，致使该算法不一定能真正做到算作业优先调度。\n4） 注意：SJF调度算法的平均等待时间、平均周转时间最少。\n（3） 优先级调度算法 （4） 高响应比优先调度算法 高响应比优先调度算法主要用于作业调度。同时考虑从每个作业的等待时间和估计需要运行的时间。\n（5） 时间片轮转调度算法 时间片轮转调度算法主要适用于分时系统。\n（6） 多级反馈队列调度算法 多级反馈队列调度算法主要是时间片轮转调度算法和优先级调度算法的综合和发展。通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。\n","permalink":"https://csqread.top/posts/tech/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/","summary":"进程的概念 在多道程序环境下，允许多个程序并发执行，此时他们将失去封闭性，并具有间断性和不可再现性的特征。为此引入了进程的概念，以便更好地描述","title":"进程与线程"},{"content":"有效数据生成以及插入数据库方案 先产生insert数据并存到备份文件中 因为有效数据生成的数量不大， 按照压测那边给我的需求大概每个交易4千笔数据左右，需要并发量比较高的交易也不过4万笔数据，涉及到转账的交易数据量比较高一点。并且需要做一个备份为了以后压测可以备用，因此我选择先生成到不同的表对应的表名文件中，然后再写一个批量执行SQL的程序执行这些文件中的insert语句\n下面的代码做了脱敏处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.FileReader; import java.io.FileWriter; import java.io.IOException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.TimeUnit; import java.util.regex.Matcher; import java.util.regex.Pattern; public class MultiThreadScript { private static final int THREAD_POOL_SIZE = 4; // 线程池大小 private static final String INPUT_FILE_PATH = \u0026#34;input.sql\u0026#34;; // 输入文件路径 private static final String OUTPUT_FILE_PATH = \u0026#34;output.sql\u0026#34;; // 输出文件路径 private static final String INSERT_REGEX = \u0026#34;(?i)^insert into .* values\\\\s*\\\\((.*)\\\\);?$\u0026#34;; // insert语句的正则表达式 private static final String PK_REGEX = \u0026#34;\u0026#39;[0-9A-Za-z]+\u0026#39;\u0026#34;; // 主键的正则表达式 private static final int PK_INDEX = 0; // 主键在值列表中的索引 public static void main(String[] args) throws Exception { // 创建线程池 ExecutorService executor = Executors.newFixedThreadPool(THREAD_POOL_SIZE); try (BufferedReader reader = new BufferedReader(new FileReader(INPUT_FILE_PATH))) { String line; while ((line = reader.readLine()) != null) { if (isInsertStatement(line)) { executor.execute(new InsertTask(line)); } } } // 关闭线程池并等待所有任务完成 executor.shutdown(); executor.awaitTermination(1, TimeUnit.HOURS); } // 判断一行文本是否为insert语句 private static boolean isInsertStatement(String line) { return line.matches(INSERT_REGEX); } // 插入任务 private static class InsertTask implements Runnable { private final String originalSql; public InsertTask(String originalSql) { this.originalSql = originalSql; } @Override public void run() { try { // 提取主键 Pattern pkPattern = Pattern.compile(PK_REGEX); Matcher pkMatcher = pkPattern.matcher(originalSql); pkMatcher.find(); String originalPk = pkMatcher.group(); // 提取值列表 String valueList = originalSql.replaceAll(INSERT_REGEX, \u0026#34;$1\u0026#34;); String[] values = valueList.split(\u0026#34;,\u0026#34;); // 递增主键并生成新的SQL语句 StringBuilder newSqlBuilder = new StringBuilder(); for (int i = 0; i \u0026lt; 40000; i++) { String newPk = getNextPk(originalPk); String newValueList = valueList.replace(originalPk, newPk); String newSql = originalSql.replaceAll(valueList, newValueList); newSqlBuilder.append(newSql).append(\u0026#34;\\n\u0026#34;); } // 写入输出文件 synchronized (MultiThreadScript.class) { try (BufferedWriter writer = new BufferedWriter(new FileWriter(OUTPUT_FILE_PATH, true))) { writer.write(newSqlBuilder.toString()); } } } catch (IOException e) { e.printStackTrace(); } } // 获取下一个主键 private String getNextPk (String originalPk) { String prefix = originalPk.substring(0, originalPk.length() - 1); String suffix = originalPk.substring(originalPk.length() - 1); String newSuffix = getNextSuffix(suffix); return prefix + newSuffix; } // 获取下一个主键后缀 private String getNextSuffix(String suffix) { StringBuilder sb = new StringBuilder(); for (int i = 0; i \u0026lt; suffix.length(); i++) { char c = suffix.charAt(i); if (Character.isDigit(c)) { int digit = Character.getNumericValue(c); if (digit == 9) { sb.append(\u0026#39;A\u0026#39;); } else if (digit == 35) { sb.append(\u0026#39;a\u0026#39;); } else { sb.append(Character.forDigit(digit + 1, 36)); } } else if (Character.isLetter(c)) { if (c == \u0026#39;Z\u0026#39;) { sb.append(\u0026#39;0\u0026#39;); } else if (c == \u0026#39;z\u0026#39;) { sb.append(\u0026#39;0\u0026#39;); } else { sb.append((char) (c + 1)); } } else { sb.append(c); } } return sb.toString(); } } 上面的代码中，MultiThreadScript类是脚本的主类，它负责读取输入文件并创建线程池来处理每条insert语句。InsertTask类是插入任务类，它实现了Runnable接口，用于递增主键并生成新的SQL语句。为了避免多个线程同时写入输出文件，InsertTask类中使用了synchronized关键字来进行同步。\n在getNextPk()方法中，我使用了类似于Excel中列名的递增方式来递增主键。首先，将原始主键分为前缀和后缀两部分，其中前缀是主键的前面部分，后缀是主键的最后一位字符。然后，对后缀进行递增，并根据递增后的后缀重新生成新的主键。\n最后，需要注意的是，由于主键可能包含字母和数字，因此使用36进制来对主键进行递增。例如，对于主键值为\u0026quot;001\u0026quot;，它的下一个值为\u0026quot;002\u0026quot;；对于主键值为\u0026quot;AZ9\u0026quot;，它的下一个值为\u0026quot;BA0\u0026quot;。\n进行插入操作（脱敏处理后的代码）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import java.io.BufferedReader; import java.io.FileReader; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.SQLException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class InsertExecutor { private static final String URL = \u0026#34;jdbc:mysql://localhost:3306/mydatabase\u0026#34;; private static final String USER = \u0026#34;myuser\u0026#34;; private static final String PASSWORD = \u0026#34;mypassword\u0026#34;; private static final int THREAD_POOL_SIZE = 10; public static void main(String[] args) { try { // 读取insert语句文件 BufferedReader reader = new BufferedReader(new FileReader(\u0026#34;inserts.sql\u0026#34;)); String line; Queue\u0026lt;String\u0026gt; inserts = new LinkedList\u0026lt;\u0026gt;(); while ((line = reader.readLine()) != null) { inserts.add(line); } reader.close(); // 创建线程池 ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE); // 执行insert语句 while (!inserts.isEmpty()) { String insert = inserts.poll(); executorService.execute(new InsertWorker(insert)); } // 关闭线程池 executorService.shutdown(); } catch (IOException e) { e.printStackTrace(); } } static class InsertWorker implements Runnable { private String insert; public InsertWorker(String insert) { this.insert = insert; } @Override public void run() { try (Connection conn = DriverManager.getConnection(URL, USER, PASSWORD); PreparedStatement statement = conn.prepareStatement(insert)) { // 执行insert语句 statement.executeUpdate(); } catch (SQLException e) { // 主键冲突，跳过该语句 if (e.getErrorCode() == 1062) { System.out.println(\u0026#34;Skip duplicate insert: \u0026#34; + insert); } else { e.printStackTrace(); } } } } } 上面代码中我们把insert.sql取代为我们想要进行批量insert的sql文件即可，线程数量可根据CPU的情况来看，在不进行其他工作任务的情况下，可尽量压榨CPU的使用率以达到最高的效率。\n亿级别的无效数据生成并插入数据库方案 这里因为涉及到的数据量特别大， 一般是模拟生产环境，因此一张表可能有千万级别以及亿级别的数据量，因此我选择一边生成一边做insert操作。也就是一个生产者一个消费者，当然，这里都是多线程来操作的。一开始我是每次达到20个事务一次提交的，后来换了OceanBase后，只能一次提交一个事务了，效率也变满了一点点. 对于多线程插入数据库，将生成的SQL语句分配给多个线程，每个线程使用单独的数据库连接插入数据库，可以使用线程池来管理多个线程\n下面是脱敏后的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 import java.io.BufferedReader; import java.io.FileReader; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.SQLException; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; public class MultiThreadedSqlInsert { // 数据库连接信息 private static final String DB_URL = \u0026#34;jdbc:mysql://localhost:3306/mydb\u0026#34;; private static final String DB_USER = \u0026#34;root\u0026#34;; private static final String DB_PASSWORD = \u0026#34;mypassword\u0026#34;; // 主键列名和初始值 private static final String PK_COLUMN_NAME = \u0026#34;id\u0026#34;; private static final String PK_INITIAL_VALUE = \u0026#34;1000\u0026#34;; // 线程数和每个线程处理的主键值个数 private static final int THREAD_COUNT = 10; private static final int KEYS_PER_THREAD = 10000000; // 文件名和队列大小 private static final String FILE_NAME = \u0026#34;data.sql\u0026#34;; private static final int QUEUE_SIZE = 10000; public static void main(String[] args) throws Exception { // 读取文件中的 SQL 语句 String sql = readSqlFromFile(FILE_NAME); // 创建线程池和队列 ExecutorService executor = Executors.newFixedThreadPool(THREAD_COUNT); BlockingQueue\u0026lt;String\u0026gt; queue = new LinkedBlockingQueue\u0026lt;\u0026gt;(QUEUE_SIZE); // 创建多个线程，为每个线程分配一段主键值的区间 for (int i = 0; i \u0026lt; THREAD_COUNT; i++) { int start = i * KEYS_PER_THREAD; int end = (i + 1) * KEYS_PER_THREAD - 1; executor.submit(new SqlGenerator(sql, start, end, queue)); } // 创建多个数据库连接，为每个连接分配一个线程 for (int i = 0; i \u0026lt; THREAD_COUNT; i++) { Connection conn = DriverManager.getConnection(DB_URL, DB_USER, DB_PASSWORD); executor.submit(new SqlExecutor(conn, queue)); } // 等待所有线程执行完毕 executor.shutdown(); executor.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS); } // 从文件中读取 SQL 语句 private static String readSqlFromFile(String fileName) throws Exception { try (BufferedReader reader = new BufferedReader(new FileReader(fileName))) { StringBuilder sb = new StringBuilder(); String line; while ((line = reader.readLine()) != null) { sb.append(line).append(\u0026#34;\\n\u0026#34;); } return sb.toString(); } } // 生成新的 SQL 语句 private static String generateSql(String sql, int key) { String pkValue = PK_INITIAL_VALUE + key; return sql.replaceFirst(PK_COLUMN_NAME, pkValue); } // 生成新的 SQL 语句的线程 private static class SqlGenerator implements Runnable { private final String sql; private final int start; private final int end; private final BlockingQueue\u0026lt;String\u0026gt; queue; public SqlGenerator(String sql, int start, int end, BlockingQueue\u0026lt;String\u0026gt; queue) { this.sql = sql; this.start = start; this.end = end; this.queue = queue; } @Override public void run() { for (int i = start; i \u0026lt;= end; i++) { String newSql = generateSql(sql, i); try { queue.put(newSql); } catch (InterruptedException e) { Thread.currentThread().interrupt(); return; } } } } // 执行 SQL 语句的线程 private static class SqlExecutor implements Runnable { private final Connection conn; private final BlockingQueue\u0026lt;String\u0026gt; queue; public SqlExecutor(Connection conn, BlockingQueue\u0026lt;String\u0026gt; queue) { this.conn = conn; this.queue = queue; } @Override public void run() { try (PreparedStatement stmt = conn.prepareStatement(\u0026#34;\u0026#34;)) { while (true) { String sql = queue.take(); if (sql == null) { break; } stmt.addBatch(sql); if (stmt.getBatchSize() \u0026gt;= 1000) { stmt.executeBatch(); } } stmt.executeBatch(); } catch (SQLException | InterruptedException e) { e.printStackTrace(); } } } 这里使用了两个线程池，一个用于生成新的 SQL 语句，一个用于执行 SQL 语句。生成 SQL 语句的线程将生成的 SQL 语句存储到一个线程安全的队列中，执行 SQL 语句的线程从队列中取出 SQL 语句并执行插入操作。程序使用了 JDBC 连接 MySQL 数据库，并使用了 PreparedStatement 批量执行 SQL 语句，以提高插入效率。\n需要注意的是，为了避免多个线程同时操作数据库导致数据不一致的问题，每个线程使用了自己的数据库连接。此外，程序还使用了线程安全的队列和加锁机制来保证线程安全。\n总结 以上就是我在工作中遇到的问题之一，做一个小结，用到了很多线程和线程池的地方，以及操作数据库相关的知识。\n","permalink":"https://csqread.top/posts/tech/%E5%8E%8B%E6%B5%8B%E6%95%B0%E6%8D%AE%E5%BF%AB%E9%80%9F%E7%94%9F%E6%88%90%E5%B9%B6%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%80%BB%E7%BB%93/","summary":"有效数据生成以及插入数据库方案 先产生insert数据并存到备份文件中 因为有效数据生成的数量不大， 按照压测那边给我的需求大概每个交易4千笔数据","title":"压测数据快速生成并插入数据库总结"},{"content":"JVM 内存结构 Java 虚拟机的内存空间分为 5 个部分：\n程序计数器 Java虚拟机栈 本地方法栈 堆 方法区 JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。\n程序计数器(PC寄存器) 程序计数器的定义 程序计数器是一块较小的内存空间，是当前线程正在执行的那条字节码指令的地址。若当前线程正在执行的是一个本地方法，那么此时程序计数器为Undefined。在Java虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制的指示器，分支，循环，跳转、异常处理、线程恢复等基础功能都需要这个计数器来完成。\n程序计数器的作用 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了 ","permalink":"https://csqread.top/posts/tech/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","summary":"JVM 内存结构 Java 虚拟机的内存空间分为 5 个部分： 程序计数器 Java虚拟机栈 本地方法栈 堆 方法区 JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元","title":"Java虚拟机知识总结"},{"content":"什么是Netty 1、Netty 是一个 基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。 2、它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。 3、支持多种协议 如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。 用官方的总结就是：Netty 成功地找到了一种在不妥协可维护性和性能的情况下实现易于开发，性能，稳定性和灵活性的方法。\n除了上面之外，很多开源项目比如我们常用的 Dubbo、RocketMQ、Elasticsearch、gRPC 等等都用到了 Netty\n相比于直接使用 JDK 自带的 NIO 相关的 API 来说更加易用。 统一的 API，支持多种传输类型，阻塞和非阻塞的。 简单而强大的线程模型。 自带编解码器解决 TCP 粘包/拆包问题。 自带各种协议栈。 真正的无连接数据包套接字支持。 比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。 社区活跃、成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。 应用场景 NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做网络通信 : 作为 RPC 框架的网络通信工具 ：我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。不同服务节点之间的通信是如何做的呢？可以使用 Netty 来做。比如我调用另外一个节点的方法的话，至少是要让对方知道我调用的是哪个类中的哪个方法以及相关参数吧！ 实现一个自己的 HTTP 服务器 ：通过 Netty 我们可以自己实现一个简单的 HTTP 服务器，这个大家应该不陌生。说到 HTTP 服务器的话，作为 Java 后端开发，我们一般使用 Tomcat 比较多。一个最基本的 HTTP 服务器可要以处理常见的 HTTP Method 的请求，比如 POST 请求、GET 请求等等。 实现一个即时通讯系统 ：使用 Netty 我们可以实现一个可以聊天类似微信的即时通讯系统， 实现消息推送系统 ：市面上有很多消息推送系统都是基于 Netty 来做的。 Netty 的高性能表现 心跳，对服务端：会定时清除闲置会话 inactive(netty5)，对客户端:用来检测会话是否断开，是否重来，检测网络延迟，其中 idleStateHandler 类 用来检测会话状态 串行无锁化设计，即消息的处理尽可能在同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。表面上看，串行化设计似乎 CPU 利用率不高，并发程度不够。但是，通过调整 NIO 线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。 可靠性，链路有效性检测：链路空闲检测机制，读/写空闲超时机制；内存保护机制：通过内存池重用 ByteBuf;ByteBuf 的解码保护；优雅停机：不再接收新消息、退出前的预处理操作、资源的释放操作。 Netty 安全性：支持的安全协议：SSL V2 和 V3，TLS，SSL 单向认证、双向认证和第三方 CA认证。 高效并发编程的体现：volatile 的大量、正确使用；CAS 和原子类的广泛使用；线程安全容器的使用；通过读写锁提升并发性能。IO 通信性能三原则：传输（AIO）、协议（Http）、线程（主从多线程） 流量整型的作用（变压器）：防止由于上下游网元性能不均衡导致下游网元被压垮，业务流中断；防止由于通信模块接受消息过快，后端业务线程处理不及时导致撑死问题 Netty核心组件 Bootstrap和ServerBootstrap 当需要连接客户端或者服务器绑定指定端口是需要使用Bootstrap，ServerBootstrap有两种类型，一种是用于客户端的Bootstrap，一种是用于服务端 的ServerBootstrap。不管程序使用哪种协议，无论是创建一个客户端还是服务器都需要使 用“引导”。\nBootstrap 是客户端的启动引导类/辅助类\n1 2 3 4 5 6 7 8 9 10 11 12 13 EventLoopGroup group = new NioEventLoopGroup(); try { //创建客户端启动引导/辅助类： Bootstrap Bootstrap b = new Bootstrap(); //指定线程模型 b.group(group). ...... // 尝试建立连接 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); } finally { // 优雅关闭相关线程组资源 group.shutdownGracefully(); } ServerBootstrap 客户端的启动引导类/辅助类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 1.bossGroup 用于接收连接，workerGroup 用于具体的处理 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //2.创建服务端启动引导/辅助类： ServerBootstrap ServerBootstrap b = new ServerBootstrap(); //3.给引导类配置两大线程组,确定了线程模型 b.group(bossGroup, workerGroup). ...... // 6.绑定端口 ChannelFuture f = b.bind(port).sync(); // 等待连接关闭 f.channel().closeFuture().sync(); } finally { //7.优雅关闭相关线程组资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } Bootstrap 通常使用 connet() 方法连接到远程的主机和端口，作为一个 Netty TCP 协议通信中的客户端。另外，Bootstrap 也可以通过 bind() 方法绑定本地的一个端口，作为 UDP 协议通信中的一端。 ServerBootstrap通常使用 bind() 方法绑定本地的端口上，然后等待客户端的连接。\nBootstrap 只需要配置一个线程组— EventLoopGroup，而 ServerBootstrap需要配置两个线程组— EventLoopGroup ，一个用于接收连接，一个用于具体的处理。\n一个 ServerBootstrap 可以认为有2个 Channel 集合，\n第一个集合包含一个单例 ServerChannel，代表持有一个绑定了本地端口的 socket;\n第二集合包含所有创建的 Channel，处理服务器所接收到的客户端进来的连接。\nEventLoop和EventLoopGroup EventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件。\nEventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。\nChannel 和 EventLoop 直接有啥联系呢？\nChannel 为 Netty 网络操作(读写等操作)抽象类，EventLoop 负责处理注册到其上的Channel 处理 I/O 操作，两者配合参与 I/O 操作。\nEventLoopGroup包含多个EventLoop，每个EventLoop通常内部包含一个线程。EventLoop在处理IO事件时在自己的Thread线程上进行，从而保证线程安全\nNioEventLoopGroup在未指定线程数时，默认时当前cpu线程数*2\nEventLoopGroup 是一组 EventLoop 的抽象，Netty 为了更好的利用多核 CPU 资源，一般会有多个 EventLoop 同时工作，每个 EventLoop 维护着一个 Selector 实例。 EventLoopGroup 提供 next 接口，可以从组里面按照一定规则获取其中一个EventLoop来处理任务。在 Netty 服务器端编程中，我们一般都需要提供两个EventLoopGroup，例如:BossEventLoopGroup 和 WorkerEventLoopGroup。 通常一个服务端口即一个ServerSocketChannel对应一个Selector和一个EventLoop 线程。BossEventLoop 负责接收客户端的连接并将 SocketChannel 交给 WorkerEventLoopGroup 来进行 IO 处理\nBossEventLoopGroup 通常是一个单线程的 EventLoop，EventLoop 维护着一个注册了ServerSocketChannel 的Selector 实例BossEventLoop 不断轮询Selector 将连接事件分离出来 通常是 OP_ACCEPT 事件，然后将接收到的 SocketChannel 交给WorkerEventLoopGroup WorkerEventLoopGroup 会由 next 选择其中一个 EventLoop来将这个SocketChannel 注册到其维护的Selector 并对其后续的 IO 事件进行处理 EventLoop继承图\nChannel通道 Channel 接口是 Netty 对网络操作抽象类，它除了包括基本的 I/O 操作，如 bind()、connect()、read()、write() 等。\n比较常用的Channel接口实现类是NioServerSocketChannel（服务端）和NioSocketChannel（客户端），这两个 Channel 可以和 BIO 编程模型中的ServerSocket以及Socket两个概念对应上。Netty 的 Channel 接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。\n1 2 3 4 5 6 7 Channel channel = ...; // 获取channel的引用 ByteBuf buf = Unpooled.copiedBuffer(\u0026#34;your data\u0026#34;, CharsetUtil.UTF_8); //1 ChannelFuture cf = channel.writeAndFlush(buf); //2 cf.addListener(new ChannelFutureListener() { //3 @Override public void operationComplete(ChannelFuture future) { if (future.isSuccess()) { //4 } }); 创建 ByteBuf 保存写的数据 写数据，并刷新 添加 ChannelFutureListener 即可写操作完成后收到通知 写操作没有错误完成 写操作完成时出现错误 channel声明周期 | 状态 | 描述 | | —- | —- | | ChannelUnregistered | Channel 已经被创建，但还未注册到EventLoop | | ChannelRegistered | Channel 已经被注册到了EventLoop | | ChannelActive | Channel 处于活动状态（已经连接到它的远程节点）。它现在可以接收和发送数据了 | | ChannelInactive | Channel 没有连接到远程节点 |\nselector 作用：\nI/O 的就绪与选择 是 NIO 网络编程的基础 SelectonKey 状态 OP_ACCEPT 操作集位用于插座接受操作。 OP_CONNECT 用于套接字连接操作的操作集位。 OP_READ 读操作的操作位。 OP_WRITE 写操作的操作位。 1 2 3 4 5 Selector selector = new Selector.open() SelectorKey selectorKey = channel.register(selector, SelectionKey.OP_READ); int selectNum = selector.select(); Set\u0026lt;Selection\u0026gt; selectionkeys = selector.selectdkeys(); ","permalink":"https://csqread.top/posts/tech/netty%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","summary":"什么是Netty 1、Netty 是一个 基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。 2、它极大","title":"Netty相关总结"},{"content":"面试题目 记录下社招面试拼多多的总结与心得，以及失败的原因吧。\n1、服务注册是如何发现的，eureka的基本原理， 容器ip是动态的还是静态的\n答：eureka, 基本原理大概说个一些：包括服务注册，服务发现，心跳机制，服务下线， 自我保护机制等等。\n2、转账，支付如何保证数据一致性的， 说一下分布式事务的实现， 消息的生产和消费机制。\n这个基本上说出个一二三来。其实就是分布式事务，保证这个数据的一致性就是要保证事务的原子性。即，事务要么全部成功，要么全部失败。我就提了下XA协议和TCC模式，具体如何实现的我也不太清楚。\n3、mysql 索引优化，子查询优化\n这里基本上都讲出来了。之前做过很多压测，包括让sql走上索引，参数表添加缓存等等。\n4、线上有排查过什么问题.\n5、MQ的实现原理\n5、图算法题\n还有些问题已经忘了。\n总结与回顾 其实关于这次面试，我还是没有做好完全的准备，而且是近三年以来的第一次面试，心里难免还是有点紧张。导致我有些东西知道的知识可能一时半会想不起来。后面把这些问到的知识点再复习一下。基本上只是浅浅的了解了一下，细说一下底层原理我就懵了。大概知道我们有这么个流程，知道哪里出了问题该找谁来看。因为现在吧，大公司基本上就是这么个情况， 包括中间件团队，数据库团队，DTF团队，DCF团队等等。基本上我们只用知道这些东西有，然后找相应团队的负责人帮忙看下问题就能解决。我们都是在脚手架上做着CURD。\n但是还是要把面试问到的东西基本原理做一个小小的总结和记录:\nEureka Eureka是Netflix开源的一款提供服务注册和发现的产品， 开源地址为 Eureka, 注册中心是分布式开发的核心组件之一\n而eureka是spring cloud推荐的注册中心实现, Eureka是一个REST (Representational State Transfer)服务 它主要用于AWS云，用于定位服务，以实现中间层服务器的负载平衡和故障转移，我们称此服务为Eureka服务器\nEureka也有一个基于java的客户端组件，Eureka客户端，这使得与服务的交互更加容易，同时客户端也有一个内置的负载平衡器，它执行基本的循环负载均衡。\n自我保护机制 自我保护机制主要在Eureka Client和Eureka Server之间存在网络分区的情况下发挥保护作用，在服务器端和客户端都有对应实现.\n假设在某种特定的情况下（如网络故障）, Eureka Client和Eureka Server无法进行通信，此时Eureka Client无法向Eureka Server发起注册和续约请求，Eureka Server中就可能因注册表中的服务实例租约出现大量过期而面临被剔除的危险，然而此时的Eureka Client可能是处于健康状态的（可接受服务访问），如果直接将注册表中大量过期的服务实例租约剔除显然是不合理的，自我保护机制提高了eureka的服务可用性。\n当自我保护机制触发时，Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务，仍能查询服务信息并且接受新服务注册请求，也就是其他功能是正常的。\n这里思考下，如果eureka节点A触发自我保护机制过程中，有新服务注册了然后网络回复后，其他peer节点能收到A节点的新服务信息，数据同步到peer过程中是有网络异常重试的，也就是说，是能保证最终一致性的。\n服务发现原理 eureka server可以集群部署，多个节点之间会进行（异步方式）数据同步，保证数据最终一致性，Eureka Server作为一个开箱即用的服务注册中心，提供的功能包括：服务注册、接收服务心跳、服务剔除、服务下线等。\n需要注意的是，Eureka Server同时也是一个Eureka Client，在不禁止Eureka Server的客户端行为时，它会向它配置文件中的其他Eureka Server进行拉取注册表、服务注册和发送心跳等操作。\neureka server端通过appName和instanceInfoId来唯一区分一个服务实例，服务实例信息是保存在哪里呢？其实就是一个Map中：\n1 2 // 第一层的key是appName，第二层的key是instanceInfoIdprivate final ConcurrentHashMap\u0026lt;String, Map\u0026lt;String, Lease\u0026lt;InstanceInfo\u0026gt;\u0026gt;\u0026gt; registry = new ConcurrentHashMap\u0026lt;String, Map\u0026lt;String, Lease\u0026lt;InstanceInfo\u0026gt;\u0026gt;\u0026gt;(); 服务注册 Service Provider启动时会将服务信息（InstanceInfo）发送给eureka server，eureka server接收到之后会写入registry中，服务注册默认过期时间DEFAULT_DURATION_IN_SECS = 90秒。InstanceInfo写入到本地registry之后，然后同步给其他peer节点，对应方法com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl#replicateToPeers。\n写入本地redistry 服务信息（InstanceInfo）保存在Lease中，写入本地registry对应方法com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl#register，Lease统一保存在内存的ConcurrentHashMap中，在服务注册过程中，首先加个读锁，然后从registry中判断该Lease是否已存在，如果已存在则比较lastDirtyTimestamp时间戳，取二者最大的服务信息，避免发生数据覆盖。使用InstanceInfo创建一个新的InstanceInfo：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 if (existingLastDirtyTimestamp \u0026gt; registrationLastDirtyTimestamp) { // 已存在Lease则比较时间戳，取二者最大值 registrant = existingLease.getHolder(); } Lease\u0026lt;InstanceInfo\u0026gt; lease = new Lease\u0026lt;InstanceInfo\u0026gt;(registrant, leaseDuration); if (existingLease != null) { // 已存在Lease则取上次up时间戳 lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); } public Lease(T r, int durationInSecs) { holder = r; registrationTimestamp = System.currentTimeMillis(); // 当前时间 lastUpdateTimestamp = registrationTimestamp; duration = (durationInSecs * 1000); } 同步给其他peer InstanceInfo写入到本地registry之后，然后同步给其他peer节点，对应方法com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl#replicateToPeers。如果当前节点接收到的InstanceInfo本身就是另一个节点同步来的，则不会继续同步给其他节点，避免形成“广播效应”；InstanceInfo同步时会排除当前节点。\nInstanceInfo的状态有依以下几种：Heartbeat, Register, Cancel, StatusUpdate, DeleteStatusOverride，默认情况下同步操作时批量异步执行的，同步请求首先缓存到Map中，key为requestType+appName+id，然后由发送线程将请求发送到peer节点。\nPeer之间的状态是采用异步的方式同步的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的。结合服务发现的场景，实际上也并不需要节点间的状态强一致。在一段时间内（比如30秒），节点A比节点B多一个服务实例或少一个服务实例，在业务上也是完全可以接受的（Service Consumer侧一般也会实现错误重试和负载均衡机制）。所以按照CAP理论，Eureka的选择就是放弃C，选择AP。 如果同步过程中，出现了异常怎么办呢，这时会根据异常信息做对应的处理，如果是读取超时或者网络连接异常，则稍后重试；如果其他异常则打印错误日志不再后续处理。\n服务续约 Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。主要是用来告诉Eureka Server Service Provider还活着，避免服务被剔除掉。renew接口实现方式和register基本一致：首先更新自身状态，再同步到其它Peer，服务续约也就是把过期时间设置为当前时间加上duration的值。\n注意：服务注册如果InstanceInfo不存在则加入，存在则更新；而服务预约只是进行更新，如果InstanceInfo不存在直接返回false。\n服务失效剔除 Eureka Server中有一个EvictionTask，用于检查服务是否失效。Eviction（失效服务剔除）用来定期（默认为每60秒）在Eureka Server检测失效的服务，检测标准就是超过一定时间没有Renew的服务。默认失效时间为90秒，也就是如果有服务超过90秒没有向Eureka Server发起Renew请求的话，就会被当做失效服务剔除掉。失效时间可以通过eureka.instance.leaseExpirationDurationInSeconds进行配置，定期扫描时间可以通过eureka.server.evictionIntervalTimerInMs进行配置。\n服务剔除#evict方法中有很多限制，都是为了保证Eureka Server的可用性：比如自我保护时期不能进行服务剔除操作、过期操作是分批进行、服务剔除是随机逐个剔除，剔除均匀分布在所有应用中，防止在同一时间内同一服务集群中的服务全部过期被剔除，以致大量剔除发生时，在未进行自我保护前促使了程序的崩溃。\n服务信息拉取 Eureka consumer服务信息的拉取分为全量式拉取和增量式拉取，eureka consumer启动时进行全量拉取，运行过程中由定时任务进行增量式拉取，如果网络出现异常，可能导致先拉取的数据被旧数据覆盖（比如上一次拉取线程获取结果较慢，数据已更新情况下使用返回结果再次更新，导致数据版本落后），产生脏数据。对此，eureka通过类型AtomicLong的fetchRegistryGeneration对数据版本进行跟踪，版本不一致则表示此次拉取到的数据已过期。\nfetchRegistryGeneration过程是在拉取数据之前，执行fetchRegistryGeneration.get获取当前版本号，获取到数据之后，通过fetchRegistryGeneration.compareAndSet来判断当前版本号是否已更新。 注意：如果增量式更新出现意外，会再次进行一次全量拉取更新。\nEureka server的伸缩容 Eureka Server是怎么知道有多少Peer的呢？Eureka Server在启动后会调用EurekaClientConfig.getEurekaServerServiceUrls来获取所有的Peer节点，并且会定期更新。定期更新频率可以通过eureka.server.peerEurekaNodesUpdateIntervalMs配置。\n这个方法的默认实现是从配置文件读取，所以如果Eureka Server节点相对固定的话，可以通过在配置文件中配置来实现。如果希望能更灵活的控制Eureka Server节点，比如动态扩容/缩容，那么可以override getEurekaServerServiceUrls方法，提供自己的实现，比如我们的项目中会通过数据库读取Eureka Server列表。\neureka server启动时把自己当做是Service Consumer从其它Peer Eureka获取所有服务的注册信息。然后对每个服务信息，在自己这里执行Register，isReplication=true，从而完成初始化。\nService Provider Service Provider启动时首先时注册到Eureka Service上，这样其他消费者才能进行服务调用，除了在启动时之外，只要实例状态信息有变化，也会注册到Eureka Service。需要注意的是，需要确保配置eureka.client.registerWithEureka=true。register逻辑在方法AbstractJerseyEurekaHttpClient.register中，Service Provider会依次注册到配置的Eureka Server Url上，如果注册出现异常，则会继续注册其他的url。\nRenew操作会在Service Provider端定期发起，用来通知Eureka Server自己还活着。 这里instance.leaseRenewalIntervalInSeconds属性表示Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。这部分逻辑在HeartbeatThread类中。在Service Provider服务shutdown的时候，需要及时通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务，逻辑本身比较简单，通过对方法标记@PreDestroy，从而在服务shutdown的时候会被触发。\nService Consumer Service Consumer这块的实现相对就简单一些，因为它只涉及到从Eureka Server获取服务列表和更新服务列表。Service Consumer在启动时会从Eureka Server获取所有服务列表，并在本地缓存。需要注意的是，需要确保配置eureka.client.shouldFetchRegistry=true。由于在本地有一份Service Registries缓存，所以需要定期更新，定期更新频率可以通过eureka.client.registryFetchIntervalSeconds配置。\n总结 我们为什么要使用Eureka呢，在分布式开发架构中， 任何单点的服务都不能保证不会中断，因此需要服务发现机制，某个节点中断后，服务消费者能及时感知到保证服务高可用。注册中心除了Eureka之外，还有Zookeeper、consul、nacos等解决方案，实现原理不同， 各自适用于不同业务场景。\n数据一致性问题 事务 严格意义上的事务实现应该是具备原子性、一致性、隔离性和持久性，简称ACID。\n原子性(Atomicity) ， 可以理解为一个事务内的所有操作要么都执行，要么都不执行。 一致性(Consistency)， 数据是满足完整性约束的，也就是不会存在中间状态的数据，比如说你账户上有400， 我账户上有100， 你给我打200块，此时你账户上的钱应该是200， 我账户上的钱应该是300， 不会存在我账户上的钱加了，你账户上的钱没扣的中间状态 隔离性(Lsolation) ，指的是多个事务并发执行的时候不会互相干扰，即事务内部的数据对于其他事务来说是隔离的 持久性(Durability), 指的是一个事务完成了之后数据就被永远保存下来，之后的其他操作或故障都不会对事务的结果产生影响 而通俗意义上事务就是为了使得一些更新操作要么都成功，要么都失败。\n分布式事务 分布式事务顾名思义就是要在分布式系统中实现事务，它其实是由多个本地事务组合而成。\n对于分布式事务而言几乎满足不了ACID，其实对于单机事务而言大部分情况下也没有满足ACID，不然怎么会有四种隔离级别呢？所以更不用说分布在不用数据库或者不同应用上的分布式事务了。\n2PC 2PC（Two-phase commit protocol），中文叫二阶段提交。 二阶段提交是一种强一致性设计，2PC 引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备（投票）和提交两个阶段。\n注意这只是协议或者说是理论指导，只阐述了大方向，具体落地还是有会有差异的。\n让我们来看下两个阶段的具体流程。\n准备阶段协调者会给各参与者发送准备命令，你可以把准备命令理解成除了提交事务之外啥事都做完了。\n同步等待所有资源的响应之后就进入第二阶段即提交阶段（注意提交阶段不一定是提交事务，也可能是回滚事务）。\n假如在第一阶段所有参与者都返回准备成功，那么协调者则向所有参与者发送提交事务命令，然后等待所有事务都提交成功之后，返回事务执行成功。\n假如在第一阶段有一个参与者返回失败，那么协调者就会向所有参与者发送回滚事务的请求，即分布式事务执行失败。\n那第二阶段提交失败的话呢？\n这里有两种情况。\n第一种是第二阶段执行的是回滚事务操作，那么答案是不断重试，直到所有参与者都回滚了，不然那些在第一阶段准备成功的参与者会一直阻塞着。\n第二种是第二阶段执行的是提交事务操作，那么答案也是不断重试，因为有可能一些参与者的事务已经提交成功了，这个时候只有一条路，就是头铁往前冲，不断的重试，直到提交成功，到最后真的不行只能人工介入处理。\n大体上二阶段提交的流程就是这样，我们再来看看细节。\n首先 2PC 是一个同步阻塞协议，像第一阶段协调者会等待所有参与者响应才会进行下一步操作，当然第一阶段的协调者有超时机制，假设因为网络原因没有收到某参与者的响应或某参与者挂了，那么超时后就会判断事务失败，向所有参与者发送回滚命令。\n在第二阶段协调者的没法超时，因为按照我们上面分析只能不断重试！\n协调者故障分析 协调者是一个单点，存在单点故障问题\n假设协调者在发送准备命令之前挂了， 还行，等于事务没开始。\n假设协调者在发送准备命令之后挂了，这就不太行了，有些参与者等于都执行了处于事务资源锁定的状态。不仅事务执行不下去，还会因为锁定了一些公共资源而阻塞系统其他操作。\n假设协调者在发送事务回滚命令之前挂了，那么事务也是执行不下去，且在第一阶段那些准备成功参与者都阻塞着。\n假设协调者在发送回滚事务命令之后挂了，这个还行，至少命令发出去了，很大概率都会回滚成功，资源都会释放。但是如果出现网络分区问题，某些参与者将因为收不到命令而阻塞着。\n假设协调者在发送提交事务命令之前挂了，这个不行，这下所有资源都阻塞着。\n假设协调者在发送提交事务命令之后挂了，很大概率都会提交成功，然后释放资源。但是如果出现网络分区问题某些参与者因为收不到命令而阻塞着。\n协调者故障，通过选举得到新的协调者 因为协调者单点问题，因此我们可以通过选举等操作选出一个新协调者来顶替。\n如果处于第一阶段，其实影响不大都回滚好了，在第一阶段事务肯定还没提交。\n如果处于第二阶段，假设参与者都没挂，此时新协调者可以向所有参与者确认它们自身情况来推断下一步的操作。\n假设有个别参与者挂了！这就有点僵硬了，比如协调者发送了回滚命令，此时第一个参与者收到了并执行，然后协调者和第一个参与者都挂了。\n此时其他参与者都没收到请求，然后新协调者来了，它询问其他参与者都说OK，但它不知道挂了的那个参与者到底O不OK，所以它傻了。\n问题其实就出在每个参与者自身的状态只有自己和协调者知道，因此新协调者无法通过在场的参与者的状态推断出挂了的参与者是什么情况。\n虽然协议上没说，不过在实现的时候我们可以灵活的让协调者将自己发过的请求在哪个地方记一下，也就是日志记录，这样新协调者来的时候不就知道此时该不该发了？\n但是就算协调者知道自己该发提交请求，那么在参与者也一起挂了的情况下没用，因为你不知道参与者在挂之前有没有提交事务。\n如果参与者在挂之前事务提交成功，新协调者确定存活着的参与者都没问题，那肯定得向其他参与者发送提交事务命令才能保证数据一致。\n如果参与者在挂之前事务还未提交成功，参与者恢复了之后数据是回滚的，此时协调者必须是向其他参与者发送回滚事务命令才能保持事务的一致。\n所以说极端情况下还是无法避免数据不一致问题。\ntalk is cheap 让我们再来看下代码，可能更加的清晰。以下代码取自 Distributed System: Principles and Paradigms。\n这个代码就是实现了 2PC，但是相比于2PC增加了写日志的动作、参与者之间还会互相通知、参与者也实现了超时。这里要注意，一般所说的2PC，不含上述功能，这都是实现的时候添加的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 协调者: write START_2PC to local log; //开始事务 multicast VOTE_REQUEST to all participants; //广播通知参与者投票 while not all votes have been collected { wait for any incoming vote; if timeout { //协调者超时 write GLOBAL_ABORT to local log; //写日志 multicast GLOBAL_ABORT to all participants; //通知事务中断 exit; } record vote; } //如果所有参与者都ok if all participants sent VOTE_COMMIT and coordinator votes COMMIT { write GLOBAL_COMMIT to local log; multicast GLOBAL_COMMIT to all participants; } else { write GLOBAL_ABORT to local log; multicast GLOBAL_ABORT to all participants; } 参与者: write INIT to local log; //写日志 wait for VOTE_REQUEST from coordinator; if timeout { //等待超时 write VOTE_ABORT to local log; exit; } if participant votes COMMIT { write VOTE_COMMIT to local log; //记录自己的决策 send VOTE_COMMIT to coordinator; wait for DECISION from coordinator; if timeout { multicast DECISION_REQUEST to other participants; //超时通知 wait until DECISION is received; /* remain blocked*/ write DECISION to local log; } if DECISION == GLOBAL_COMMIT write GLOBAL_COMMIT to local log; else if DECISION == GLOBAL_ABORT write GLOBAL_ABORT to local log; } else { write VOTE_ABORT to local log; send VOTE_ABORT to coordinator; } 每个参与者维护一个线程处理其它参与者的DECISION_REQUEST请求： while true { wait until any incoming DECISION_REQUEST is received; read most recently recorded STATE from the local log; if STATE == GLOBAL_COMMIT send GLOBAL_COMMIT to requesting participant; else if STATE == INIT or STATE == GLOBAL_ABORT; send GLOBAL_ABORT to requesting participant; else skip; /* participant remains blocked */ } 至此已经详细分析了2PC的各种细节，总结如下：\n2PC是一种尽量保证强一致性的分布式事务，因此它是同步阻塞的，而同步阻塞就导致长久的资源锁定问题，总体而言效率低，并且存在单点故障问题，在极端条件下存在数据不一致的风险。\n当然具体的实现可以变形，比如Tree 2PC、Dynamic 2PC\n2PC适用于数据库层面的分布式事务场景，而我们业务需求有时候不仅仅关乎数据库，也有可能是上传一张图片或者发送一条短信。\n而且像Java中的JTA, 它是基于XA规范实现的事务接口，这里的XA可以简单理解为基于数据库的XA规范来实现的2PC。\n解决方案 XA方案 2PC的传统方案是在数据库层面实现的，如 Oracle、MySQL 都支持 2PC 协议，为了统一标准减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织 Open Group 定义了分布式事务处理模型DTP（Distributed Transaction Processing Reference Model）。\n整个 2PC 的事务流程涉及到三个角色 AP、RM、TM。AP 指的是使用 2PC 分布式事务的应用程序；RM 指的是资源管理器，它控制着分支事务；TM 指的是事务管理器，它控制着整个全局事务。\n（1）在准备阶段 RM 执行实际的业务操作，但不提交事务，资源锁定\n（2）在提交阶段 TM 会接受 RM 在准备阶段的执行回复，只要有任一个RM执行失败，TM 会通知所有 RM 执行回滚操作，否则，TM 将会通知所有 RM 提交该事务。提交阶段结束资源锁释放。\nXA方案的问题\n需要本地数据库支持XA协议。 资源锁需要等到两个阶段结束才释放，性能较差。\nSeata方案 Seata 是由阿里中间件团队发起的开源项目 Fescar，后更名为 Seata，它是一个是开源的分布式事务框架。\n传统 2PC 的问题在 Seata 中得到了解决，它通过对本地关系数据库的分支事务的协调来驱动完成全局事务，是工作在应用层的中间件。主要优点是性能较好，且不长时间占用连接资源，它以高效并且对业务 0 侵入的方式解决微服务场景下面临的分布式事务问题，它目前提供 AT 模式（即 2PC）及 TCC 模式的分布式事务解决方案。\nSeata 的设计思想如下: Seata 的设计目标其一是对业务无侵入，因此从业务无侵入的 2PC 方案着手，在传统 2PC的基础上演进，并解决 2PC 方案面临的问题。\nSeata 把一个分布式事务理解成一个包含了若干分支事务的全局事务。全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系数据库的本地事务。\nSeata实现2PC与传统2PC的差别\n架构层次方面：传统 2PC 方案的 RM 实际上是在数据库层，RM 本质上就是数据库自身，通过 XA 协议实现，而 Seata 的 RM 是以 jar 包的形式作为中间件层部署在应用程序这一侧的。\n两阶段提交方面：传统 2PC无论第二阶段的决议是 commit 还是 rollback ，事务性资源的锁都要保持到 Phase2 完成才释放。而 Seata 的做法是在 Phase1 就将本地事务提交，这样就可以省去 Phase2 持锁的时间，整体提高效率。\n","permalink":"https://csqread.top/posts/tech/%E6%8B%BC%E5%A4%9A%E5%A4%9A%E9%9D%A2%E7%BB%8F/","summary":"面试题目 记录下社招面试拼多多的总结与心得，以及失败的原因吧。 1、服务注册是如何发现的，eureka的基本原理， 容器ip是动态的还是静态的 答：","title":"拼多多面经"},{"content":"ArrayList 1. 概览 实现了 RandomAccess 接口，因此支持随机访问。这是理所当然的，因为 ArrayList 是基于数组实现的。\n1 2 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。\n1 private static final int DEFAULT_CAPACITY = 10; 2. 扩容 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1)，也就是旧容量的 1.5 倍。\n扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length \u0026gt; 0) grow(minCapacity); } private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } 3. 删除元素 需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看出 ArrayList 删除元素的代价是非常高的。\n1 2 3 4 5 6 7 8 9 10 public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; } 4. Fail-Fast modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。\n在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i\u0026lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } 5. 序列化 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。\n保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。\n1 transient Object[] elementData; // non-private to simplify nested class access ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size \u0026gt; 0) { // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i\u0026lt;size; i++) { a[i] = s.readObject(); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i\u0026lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } 序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。\n1 2 3 ArrayList list = new ArrayList(); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file)); oos.writeObject(list); ","permalink":"https://csqread.top/posts/tech/java-arraylist%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%8E%E6%80%BB%E7%BB%93/","summary":"ArrayList 1. 概览 实现了 RandomAccess 接口，因此支持随机访问。这是理所当然的，因为 ArrayList 是基于数组实现的。 1 2 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1 private static final int DEFAULT_CAPACITY =","title":"Java ArrayList源码分析与总结"},{"content":"缓存优化 1、对应参数表数据量如果小于10M，数据要同时缓存到Redis和本地，查询遵循的缓存原则为:优先查询本地缓存，本地没有查询Redis缓存，Redis没有再查询数据库.\n2、对参数表的缓存要分类进行配置：黑名单类参数表查询，Redis缓存为空时不再查询数据库：常规类参数表查询，Redis缓存为空的时候需要再查询数据库\n3、如果参数表出现大量RPC。确定SQL都是等值的情况下，一般是缓存索引配置的不合适/\n4、如果出现大量RPC，在SQL非等值情况下，需要通过等值SQL去查询，然后在程序代码中去判断数据是否符合要求。\n5、针对查询比较多并且修改也比较多的数据，可以针对部分不变的数据配置缓存。 （比如针对内部合约相关的数据，需要频繁的调用内部账的科目存储字段，虽然内部户的一整条数据会经常变动，但是内部户的科目存储字段基本上不会改变，就可以把这些不变的数据配置缓存，提升查询效率，并且可以减少RPC的次数）。\n6、根据不同条件调用他组缓存表的接口时，可以现根据他组配置缓存索引条件进行查询，然后在程序中再根据非索引条件过滤查询结果。\n编码优化 1、当某业务构件执行缓慢时，除了要排查是否有非必要RPC时或环境影响因素外，还需要检查构件中是否有重复执行的代码和SQL，第一次执行向后传递可以提升传递效率。\n2、如果通过实现JAR包调用他组接口还RPC了的，首先检查他们是否缓存表以及缓存表索引配置是否正确，如以上没问题，则可能是JAR包中未打入实现类。\n3、因为Java接口中传递对象是通过引用方式传递的，如果接口对传入的对象进行了修改，当执行完接口在接口外部拿到的该对象中的数据是被修改的，此时在接口外部继续获取对象中被修改的原数据时容易得到意想不到的结果。\n4、调用某构件的时候，构件中又要获取一些数据进行RPC，如果调用构件之前已有相关数据，可以调用构件时传递进去，可减少RPC。\n5、根据不同条件多次使用其他组的接口进行查询时，可以提取多个条件的交集，根据交集条件查询所有数据，然后在程序中分别根据非交集的条件进行过滤。\n6、对于多次循环调用他组同一个方法时，每次输入的值不同，可将所有输入值包装成LIST一次性传入，得到一个查询列表集合作为类似本地缓存，然后对这个LSIT集合进行循环整理。\n7、RPC接口要尽量简单，输入输出接口不要继承一些不需要的东西，既能减少网络传输消耗，还能减少序列化和反序列化的时间。\n数据库及SQL优化 1、尽量避免使用SELECT * 来查询所有字段，仅查询必要数据行及字段，既能减少网络传输消耗，还能提高命中覆盖索引的概率。\n2、写SQK的时候永远记得WHERE条件要和主键或者索引匹配。\n3、对于查询量非常大修改比较少的表， 且SELECT的字段正好比索引多一个或者两个字段的时候，可以采取把多余的一个或者两个字段冗余到索引上，这种一空间换取时间的方式虽然一定程度上增加了索引空间的开销，但是对于非常高频的SQL直接命中了覆盖索引，避免了回表查询，有助于提升查询效率。\n4、对于修改量非常大的交易，要及其精简索引，能不要的索引最好不要建，在修改表的时候可以减少索引的维护，有助于提升修改效率。\n以上是工作中的性能优化总结，后续如果有新的总结再来记录\n","permalink":"https://csqread.top/posts/tech/%E5%88%86%E5%B8%83%E5%BC%8F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/","summary":"缓存优化 1、对应参数表数据量如果小于10M，数据要同时缓存到Redis和本地，查询遵循的缓存原则为:优先查询本地缓存，本地没有查询Redis","title":"分布式性能优化总结"},{"content":"字符操作 编码与解码 编码就是把字符转换为字节，而解码是把字节重新组合成字符。\n如果编码和解码过程使用不同的编码方式那么就出现了乱码。\nGBK 编码中，中文字符占 2 个字节，英文字符占 1 个字节； UTF-8 编码中，中文字符占 3 个字节，英文字符占 1 个字节； UTF-16be 编码中，中文字符和英文字符都占 2 个字节。 UTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。\nJava 的内存编码使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码是为了让一个中文或者一个英文都能使用一个 char 来存储。\nString 的编码方式 String 可以看成一个字符序列，可以指定一个编码方式将它编码为字节序列，也可以指定一个编码方式将一个字节序列解码为 String。\n1 2 3 4 String str1 = \u0026#34;中文\u0026#34;; byte[] bytes = str1.getBytes(\u0026#34;UTF-8\u0026#34;); String str2 = new String(bytes, \u0026#34;UTF-8\u0026#34;); System.out.println(str2); 在调用无参数 getBytes() 方法时，默认的编码方式不是 UTF-16be。双字节编码的好处是可以使用一个 char 存储中文和英文，而将 String 转为 bytes[] 字节数组就不再需要这个好处，因此也就不再需要双字节编码。getBytes() 的默认编码方式与平台有关，一般为 UTF-8。\n1 byte[] bytes = str1.getBytes(); Reader 与 Writer 不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符。但是在程序中操作的通常是字符形式的数据，因此需要提供对字符进行操作的方法。\nInputStreamReader 实现从字节流解码成字符流； OutputStreamWriter 实现字符流编码成为字节流。 实现逐行输出文本文件的内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void readFileContent(String filePath) throws IOException { FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) { System.out.println(line); } // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close(); } ","permalink":"https://csqread.top/posts/tech/java%E4%B8%AD%E7%9A%84%E5%AD%97%E7%AC%A6%E6%93%8D%E4%BD%9C/","summary":"字符操作 编码与解码 编码就是把字符转换为字节，而解码是把字节重新组合成字符。 如果编码和解码过程使用不同的编码方式那么就出现了乱码。 GBK 编码中，中","title":"Java中的字符操作"},{"content":"自旋锁 互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n锁消除 锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁：\n1 2 3 public static String concatString(String s1, String s2, String s3) { return s1 + s2 + s3; } String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作：\n1 2 3 4 5 6 7 public static String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString(); } 每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。\n锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。\n轻量级锁 JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。\n下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。\n如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。\n偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。\n当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。\n","permalink":"https://csqread.top/posts/tech/java%E9%94%81%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/","summary":"自旋锁 互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求","title":"Java锁优化相关笔记"},{"content":"C. x的最低有效字节中的位都等于1 D. x的最高有效字节中的位都等于0 代码应该遵循位级整数编码规则，另外还有一个限制，不能使用(==)和(!=)测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 /* * 2.61.c */ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;assert.h\u0026gt; int A(int x) { return !~x; } int B(int x) { return !x; } int C(int x) { return A(x | ~0xff); } int D(int x) { return B((x \u0026gt;\u0026gt; ((sizeof(int)-1) \u0026lt;\u0026lt; 3)) \u0026amp; 0xff); } int main(int argc, char* argv[]) { int all_bit_one = ~0; int all_bit_zero = 0; assert(A(all_bit_one)); assert(!B(all_bit_one)); assert(C(all_bit_one)); assert(!D(all_bit_one)); assert(!A(all_bit_zero)); assert(B(all_bit_zero)); assert(!C(all_bit_zero)); assert(D(all_bit_zero)); // test magic number 0x1234ff assert(!A(0x1234ff)); assert(!B(0x1234ff)); assert(C(0x1234ff)); assert(D(0x1234ff)); // test magic number 0x1234 assert(!A(0x1234)); assert(!B(0x1234)); assert(!C(0x1234)); assert(D(0x1234)); return 0; } 2.62编写一个函数int_shifts_are_arithemtic()，在对int类型的数使用算数右移的机器上运行时这个函数生成1，而其他情况下生成0.你的代码应该可以运行在任何字长的机器上。在几种机器上测试你的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /* * int-shifts-are-arithemetic.c */ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;assert.h\u0026gt; int int_shifts_are_arithemetic() { int num = -1; return !(num ^ (num \u0026gt;\u0026gt; 1)); } int main(int argc, char* argv[]) { assert(int_shifts_are_arithemetic()); return 0; } 2.63 将下面的c代码补充完整。函数srl用算术右移(由值xsra给出)来完成逻辑右移，后面的其他操作不包括右移或者除法。函数sra用逻辑右移(由值xsrl给出)来完成算术右移，后面的其他操作不包括右移或者除法。可以通过计算8*sizeof(int)来确定数据类型int中的位数w。位移量k的取值范围为0~w-1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 /* * srl-sra.c */ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;assert.h\u0026gt; unsigned srl(unsigned x, int k) { unsigned xsra = (int) x \u0026gt;\u0026gt; k; int w = sizeof(int) \u0026lt;\u0026lt; 3; int mask = (int) -1 \u0026lt;\u0026lt; (w - k); return xsra \u0026amp; ~mask; } int sra(int x, int k) { int xsrl = (unsigned) x \u0026gt;\u0026gt; k; int w = sizeof(int) \u0026lt;\u0026lt; 3; int mask = (int) -1 \u0026lt;\u0026lt; (w - k); //let mask remain unchanged when the first bit of x is 1, otherwise 0. int m = 1 \u0026lt;\u0026lt; (w - 1); mask \u0026amp;= ! (x \u0026amp; m) - 1; return xsrl | mask; } int main(int argc, char* argv[]) { unsigned test_unsigned = 0x12345678; int test_int = 0x12345678; assert(srl(test_unsigned, 4) == test_unsigned \u0026gt;\u0026gt; 4); assert(sra(test_int, 4) == test_int \u0026gt;\u0026gt; 4); test_unsigned = 0x87654321; test_int = 0x87654321; assert (srl (test_unsigned, 4) == test_unsigned \u0026gt;\u0026gt; 4); assert (sra (test_int, 4) == test_int \u0026gt;\u0026gt; 4); return 0; } 2.64 写出代码实现如下函数：\n1 2 /*Return 1 when any odd bit of x equals 1; 0 otherwise. Assume w=32 */ int any_odd_one(unsigned x) 函数应该遵循位级整数编码规则，不过你可以假设数据类型int有w=32位。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* * any-odd-one.c */ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;assert.h\u0026gt; int any_odd_one(unsigned x) { return !!(0xAAAAAAAA \u0026amp; x); } int main(int argc, char* argv[]) { assert(any_odd_one(0x2)); assert(!any_odd_one(0x4)); return 0; } 2.65 写出代码实现如下函数：\n1 2 /* return 1 when x contains an odd number of 1s; 0 otherwise. Assume w =32 */ int odd_ones(unsigned x); 函数应该遵循位级整数编码规则，不过你可以假设数据类型int有w=32位。你的代码最多只能包含12个算数运算，位运算和逻辑运算。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* * odd-ones.c */ #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;assert.h\u0026gt; int odd_ones(unsigned x) { x ^= x \u0026gt;\u0026gt; 16; x ^= x \u0026gt;\u0026gt; 8; x ^= x \u0026gt;\u0026gt; 4; x ^= x \u0026gt;\u0026gt; 2; x ^= x \u0026gt;\u0026gt; 1; x \u0026amp;= 0x1; return x; } int main(int argc, char* argv[]) { assert(odd_ones(0x10101011)); assert(!odd_ones(0x01010101)); return 0; } 代码参考自GitHub\n","permalink":"https://csqread.top/posts/tech/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-chapter-2-practice/","summary":"C. x的最低有效字节中的位都等于1 D. x的最高有效字节中的位都等于0 代码应该遵循位级整数编码规则，另外还有一个限制，不能使用(==)和(!=)测","title":"深入理解计算机系统 Chapter 2 Practice"},{"content":" 我大概是从3月中旬发现这部剧集的，那个时候还是因为在tg的某句台词引起了我的兴趣，在这里就不说了，说了这篇公众号就发不出去了，说不定我的号也就没了。然后我就开始在各种电影网站搜罗资源，结果发现低端影视已经出了好几集了，ddys站长真的是良心大大滴好，以后有钱了我一定要donate，现在就白嫖吧。\n说到Alex Garland，我不得不想起来以前看过的他的两部科幻电影。一部是《机械姬》，另一部是《湮灭》。两部电影分别从人工智能和生物科学的主题进行探讨，从这两部以及现在的《devs》来看，他的电影的画面都有那种给虚无缥缈的一种奇幻的氛围，\n不过，这部Devs从量子力学的角度来探讨在今天还是很热门，一开始看得时候我有点懵，不懂什么叫做量子力学，看完第一集我去维基百科查看了一下量子力学的定义：\n量子力学（英语：quantum mechanics）是物理学的分支学科。它主要描写微观的事物，与相对论一起被认为是现代物理学的两大基本支柱，许多物理学理论和科学，如原子物理学、固体物理学、核物理学和粒子物理学以及其它相关的学科，都是以其为基础。\n19世纪末，人们发现旧有的经典理论无法解释微观系统，于是经由物理学家的努力，在20世纪初创立量子力学，解释了这些现象。量子力学从根本上改变人类对物质结构及其相互作用的理解。除了透过广义相对论描写的引力外，迄今所有基本相互作用均可以在量子力学的框架内描述（量子场论）。\n量子理论的重要应用包括量子化学、量子光学、量子计算、超导磁体、发光二极管、激光器、晶体管和半导体如微处理器等。\n这里面涉及到的东西太多，我看了半天也就了解了几个概念的定义，比如量子纠缠，量子退相干等等，总之一句话：不知道是什么玩意\n所以人们经常有一个说法：人类如果能够突破量子力学，也就能够确认灵魂是否存在。在众多的科幻小说里面，量子力学主要是突破意识的决定存在。我们经常所说的“薛定谔的猫”，“电子双缝实验”以及“上帝掷骰子”也有些相关性。不过在影视作品中这个概念特别吃香：自我最早看到的变形金刚系列开始的美帝影视作品中就开始：遇事不决，量子力学\n而《Devs》是一部与量子力学强相关的作品。\n何为强相关？强相关又称高度相关，即当一列变量变化时，与之相应的另一列变量增大（或减少）的可能性非常大。在坐标图上则表现为散点图较为集中在某条直线的周围。-摘自百度百科；\n剧中有专门研究量子力学的公司，并且取得了突破性的成果。不过不仅仅如此，这部剧中还涉及到了多重宇宙，自由意志以及万事万物之间都有因果关系这些概念，看起来还是挺有意思的，能够感受到美帝的电影人在这方面确实有些功底，或者说下了不少功夫。\n并且，我认为，这还是一部不可多得的悬疑剧，和之前的《误杀》一样足以调动观众的胃口，感觉不巧的是同时和《西部世界》第三季上映，让很多人没有能够了解到这部剧集。\n第一集主要介绍了一下这个量子力学的公司以及男主女主的出现：\n阿玛雅\u0026ndash;量子未来 故事开始，阿玛雅的工程师谢尔盖和团队争取到了15分钟，在CEO面前演示自己团队的成果\u0026ndash;线虫仿真映射实验。\n什么是线虫？：\n线虫动物门是动物界中最大的门之一，为假体腔动物，有超过28,000个已被记录的物种，尚有大量种尚未命名。绝大多数体小呈圆柱形，又称圆虫（roundworms）。它们在淡水、海水、陆地上随处可见，不论是个体数或物种数都往往超越其他动物，并在极端的环境如南极和海沟都可发现。此外，有许多种的线虫是寄生性的(超过16,000种)，包括许多植物及人类在内的动物的病原体。只有节肢动物比线虫更多样化-线虫也是目前世界上唯一被完整绘制出神经网络的生物，因此可以很好的进行观测，并用计算机来模拟实验\n通过这次实验，他们团队展示了他们可以通过计算机追踪线虫的神经系统培养数据，并在电脑中模拟出一条仿真线虫。不仅仅如此，它可以预测该线虫在接下来10秒中的行为。这种科技成果意味着什么，可想而知。\n接下来，谢尔盖被CEO邀请加入Devs Devs，阿玛雅公司迄今为止最机密，最隐秘的实验项目，没有人知道它是做什么的。在加入Devs之前还做了严格的审查，在这里又爆出了美剧中常黑的中俄 不过，谢尔盖还是顺利通过了审查，CEO亲自带领谢尔盖进入Devs内部。\n在这里，就可以发现Alex Garland电影的某一共同之处，就是营造神秘气氛的手法，通过灯光变化，明暗交替以及一些硬科学的概念。\n带着谢尔盖简单的观光之后，CEO神秘的对他说，坐下来，read code，你就会明白这里的一切。谢尔盖读完代码后盯着屏幕良久，一脸懵逼，跑到厕所又哭又吐。看到这里我也是一脸懵逼加好奇。这代码有什么？还能让一个人感到这么恶心？\n谢尔盖从厕所出来后问到项目负责人Katie:这只是理论上的还是真的？代码你们已经运行过了吗？Katie淡定的回答：代码我们已经运行过了，并且已经有了结果。“但并不会改变什么，这就是意义所在”。\n晚上谢尔盖神色匆匆的离开Devs实验室，被CEO Forest撞个正着。Forest直接说出了谢尔盖的真实身份：俄罗斯特工（看到这里我有点想diss，多少年了，美帝还是在疯狂在电影里搞阴谋论）。但是这个时候Forest并没有责怪谢尔盖，而是试图让他理解，你所做的并非出于自己的自由意志，你的选择只是一系列的因果，这句话在后面也好像经常被提起过，前面的剧集好久之前看的了，有些忘记了。“如果我们生活在确定的宇宙中，这些决定，只能是之前一些事情的结果：你出生在哪，你如何长大，你大脑的物理构造，这就是先天后天矩阵，，就像你仿真演示的线虫，不过更复杂，但仍然是遵循因果。”感觉有点像我们佛家的因果循环。善有善报，恶有恶报，一切因皆有果的样子。感觉有点玄学的味道了。然后，谢尔盖被Forest的贴身保镖用塑料袋窒息，谢尔盖卒，谢尔盖女友开始着急，并开始探寻事情的真相。第一集结束\n第一集做了一个很好的铺垫，让我想知道这个Devs到底是干嘛的。后面的剧情慢慢的给出了解释：\n通过无数次的量子计算，Devs投射出了2000多年前耶稣受难的影像 “这不是想象，也不是重绘，这是对过去的量子直播\u0026quot;\n\u0026ldquo;Devs\u0026quot;在追寻神的起源\n不过看到最后就会发现Devs不仅仅可以追溯神的起源，它还可以让你变成Deus，这也就是这两张图片的寓意： 最后这两个人都变成了另一个世界的神。具体怎么变成的，最后一集中是这样描述的：他们两因为某种”宿命“或者什么原因，在Devs实验室死去，这也是他们都知道会发生的结果，CEO Forest让Katie捕获了他们死亡那个时刻的数据，通过Devs项目在计算机中进行模拟，也就是说，他们在系统中又重新复活了，并且有死亡之前的记忆，可以在另一个世界，一个真实的世界仿真的存在，并且，只要他们愿意，他们就可以重新来过。\n在理论物理中，时间并不是一个切实的存在\n只是因为意识的存在或者说生命的有限才造成了这种概念\n回想之前的线虫实验，生命体的神经活动可以被预测，而大脑的构造是写进\u0026quot;DNA\u0026quot;的，这意味着从一颗胚胎开始，未来就可以被决定。这里又让我想起来《Brave New World》，哈哈哈。\n不过这部剧不适合有巨恐的人观看，因为那个巨娃娃看着挺瘆人的 诺贝尔奖得主尤金维·格纳认为，因为存在观察者的意识，宇宙的存在才有意义\n线虫的观察者是人类，那么人类的观察者的是什么？宇宙的观察者是什么？\n是否存在一个最高的宇宙意识在观察整个宇宙？\n这里我想到了三体中的宇宙观察者的概念，一维二维三维到十维的概念。更高维度的观察者是否此刻正在观察着我们的一举一动？\n今天总算是追完了这部剧，接下来可以安安心心的看《西部世界》了。Anyway，又是胡思乱想的时刻，在这里胡思乱想。 Big Cat Is Watching You ! ","permalink":"https://csqread.top/posts/read/%E5%BC%80%E5%8F%91%E8%80%85%E5%BD%B1%E8%AF%84/","summary":"我大概是从3月中旬发现这部剧集的，那个时候还是因为在tg的某句台词引起了我的兴趣，在这里就不说了，说了这篇公众号就发不出去了，说不定我的号也","title":"《开发者》影评"},{"content":"刚开始我没想到用爬虫，就直接手创了一个字典\u0026hellip; 需要安装模块pyechart and pyechart-china-provinces-pypkg\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 from pyecharts.charts import Map from pyecharts import options as opts #省和直辖市 province_distribution = { \u0026#39;湖北\u0026#39;: 4586, \u0026#39;浙江\u0026#39;: 428, \u0026#39;广东\u0026#39;: 311, \u0026#39;湖南\u0026#39;: 277, \u0026#39;河南\u0026#39;: 278, \u0026#39;安徽\u0026#39;: 200, \u0026#39;重庆\u0026#39;: 165, \u0026#39;山东\u0026#39;: 145, \u0026#39;江西\u0026#39;: 162, \u0026#39;四川\u0026#39;: 142, \u0026#39;江苏\u0026#39;: 129, \u0026#39;北京\u0026#39;: 111, \u0026#39;福建\u0026#39;: 101, \u0026#39;上海\u0026#39;: 101, \u0026#39;广西\u0026#39;: 78, \u0026#39;陕西\u0026#39;: 56, \u0026#39;河北\u0026#39;: 48, \u0026#39;云南\u0026#39;: 44, \u0026#39;海南\u0026#39;: 43, \u0026#39;黑龙江\u0026#39;: 43, \u0026#39;辽宁\u0026#39;: 39, \u0026#39;山西\u0026#39;: 35, \u0026#39;天津\u0026#39;: 28, \u0026#39;甘肃\u0026#39;: 26, \u0026#39;内蒙古\u0026#39;: 16, \u0026#39;新疆\u0026#39;: 14, \u0026#39;宁夏\u0026#39;: 12, \u0026#39;贵州\u0026#39;: 12, \u0026#39;吉林\u0026#39;: 14, \u0026#39;台湾\u0026#39;: 8, \u0026#39;香港\u0026#39;: 10, \u0026#39;澳门\u0026#39;: 7, \u0026#39;青海\u0026#39;: 6, \u0026#39;西藏\u0026#39;: 1 } # maptype = \u0026#39;china\u0026#39; 只显示全国直辖市和省级 map = Map() map.set_global_opts( title_opts=opts.TitleOpts(title=\u0026#34;2020中国疫情地图\u0026#34;), visualmap_opts=opts.VisualMapOpts(max_=3600, is_piecewise=True, pieces=[ {\u0026#34;max\u0026#34;: 5000, \u0026#34;min\u0026#34;: 1001, \u0026#34;label\u0026#34;: \u0026#34;\u0026gt;1000\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#8A0808\u0026#34;}, {\u0026#34;max\u0026#34;: 1000, \u0026#34;min\u0026#34;: 500, \u0026#34;label\u0026#34;: \u0026#34;500-1000\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#B40404\u0026#34;}, {\u0026#34;max\u0026#34;: 499, \u0026#34;min\u0026#34;: 100, \u0026#34;label\u0026#34;: \u0026#34;10-99\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#78181\u0026#34;}, {\u0026#34;max\u0026#34;: 99, \u0026#34;min\u0026#34;: 1, \u0026#34;label\u0026#34;: \u0026#34;1-9\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#F5A9A9\u0026#34;}, {\u0026#34;max\u0026#34;: 0, \u0026#34;min\u0026#34;: 0, \u0026#34;label\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#FFFFFF\u0026#34;}, ] ) ) map.add(\u0026#34;20200130中国疫情地图\u0026#34;, data_pair=province_distribution.items(), maptype=\u0026#34;china\u0026#34;, is_roam=True) map.render(\u0026#39;20200130中国1疫情地图.html\u0026#39;) 然后生成了一张图，看起来还行 但是昨天学习了API调用，以及进行可视化，今天怎么能用这么粗糙的方法来做统计，直接爬下来放到字典里然后用pyechart进行可视化岂不美哉\nmain.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 import matplotlib.pyplot as plt import numpy as np import json import requests from matplotlib.font_manager import FontProperties import re import os from pyecharts.charts import Line, Pie, Map from pyecharts import options as opts import pygal from pygal.style import LightColorizedStyle as LCS, LightenStyle as LS # 获取各省市今日的数据，存入josn文件 def get_province_data(month, day, province_name=None): file = open(\u0026#39;results/%d%d.json\u0026#39; % (month, day), \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) json_array = json.loads(file.read()) file.close() if not province_name: return json_array for json_object in json_array: if json_object[\u0026#39;provinceName\u0026#39;] == province_name: return json_object if json_object[\u0026#39;provinceShortName\u0026#39;] == province_name: return json_object return None def get_province_status(month, day, province_name=None): if province_name: print(province_name) json_object = get_province_data(month, day, province_name) data = [] for city in json_object[\u0026#39;cities\u0026#39;]: data.append((city[\u0026#39;cityName\u0026#39;], city[\u0026#39;confirmedCount\u0026#39;])) data.sort(key=lambda x: -x[1]) title = \u0026#39;%s2020年%d月%d日确诊病例\u0026#39; % (province_name, month, day) else: json_array = get_province_data(month, day, province_name) data = [] for province in json_array: data.append((province[\u0026#39;provinceShortName\u0026#39;], province[\u0026#39;confirmedCount\u0026#39;])) data.sort(key=lambda x: -x[1]) title = \u0026#39;全国2020年%d月%d日确诊病例\u0026#39; % (month, day) labels = [d[0] for d in data] counts = [d[1] for d in data] return labels, counts, title def show_province_status(month, day, province_name=None): labels, counts, title = get_province_status(month, day, province_name) # draw_pie(month, day, labels, counts, title) get_pyecharts_pie(month, day, labels, counts, title) #饼状图 def draw_pie(month, day, labels, counts, title): if len(labels) == 0: return labels = np.array(labels) counts = np.array(counts) title += \u0026#39;-%d例\u0026#39; % sum(counts) fig, ax = plt.subplots(figsize=(6, 3), subplot_kw=dict(aspect=\u0026#34;equal\u0026#34;)) explode = np.zeros(len(labels)) explode[np.argmax(counts)] = 0.1 wedges, texts = ax.pie(counts, wedgeprops=dict(width=0.5), startangle=-40, explode=explode) font = FontProperties(fname=\u0026#39;font/ZiXinFangYunYuanTi-2.ttf\u0026#39;) bbox_props = dict(boxstyle=\u0026#34;square,pad=0.3\u0026#34;, fc=\u0026#34;w\u0026#34;, ec=\u0026#34;k\u0026#34;, lw=0.72) kw = dict(arrowprops=dict(arrowstyle=\u0026#34;-\u0026#34;), bbox=bbox_props, zorder=0, va=\u0026#34;center\u0026#34;, fontproperties=font) for i, p in enumerate(wedges[:6]): ang = (p.theta2 - p.theta1) / 2. + p.theta1 y = np.sin(np.deg2rad(ang)) x = np.cos(np.deg2rad(ang)) horizontalalignment = {-1: \u0026#34;right\u0026#34;, 1: \u0026#34;left\u0026#34;}[int(np.sign(x))] connectionstyle = \u0026#34;angle,angleA=0,angleB={}\u0026#34;.format(ang) kw[\u0026#34;arrowprops\u0026#34;].update({\u0026#34;connectionstyle\u0026#34;: connectionstyle}) ax.annotate(\u0026#39;%s-%d例\u0026#39; % (labels[i], counts[i]), xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y), horizontalalignment=horizontalalignment, **kw) ax.set_title(title, fontproperties=font) root = \u0026#39;charts/%d%d\u0026#39; % (month, day) create_dir(root) plt.savefig(\u0026#39;%s/%s.jpg\u0026#39; % (root, title)) plt.show() def create_dir(root): if not os.path.exists(root): os.makedirs(root) def draw(month, day): provinces = get_province_data(month, day) for p in provinces: show_province_status(month, day, p[\u0026#39;provinceShortName\u0026#39;]) show_province_status(month, day) def get_html(month, day): import requests url = \u0026#39;http://3g.dxy.cn/newh5/view/pneumonia\u0026#39; response = requests.get(url) html = str(response.content, \u0026#39;UTF-8\u0026#39;) html_file = open(\u0026#39;results/%d%d.html\u0026#39; % (month, day), \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) html_file.write(html) html_file.close() json_file = open(\u0026#39;results/%d%d.json\u0026#39; % (month, day), \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) matches = re.findall(\u0026#39;\\[[^\u0026gt;]+\\]\u0026#39;, html) for match in matches: if \u0026#39;provinceName\u0026#39; in json.loads(match)[0]: json_file.write(match) break json_file.close() def compare(m1, d1, m2, d2): ps1 = get_province_data(m1, d1) ps2 = get_province_data(m2, d2) ps_dict1 = {} ps_dict2 = {} for p in ps1: ps_dict1[p[\u0026#39;provinceShortName\u0026#39;]] = p[\u0026#39;confirmedCount\u0026#39;] for p in ps2: ps_dict2[p[\u0026#39;provinceShortName\u0026#39;]] = p[\u0026#39;confirmedCount\u0026#39;] data = [] for key in ps_dict2: increased_count = ps_dict2[key] if key in ps_dict1: increased_count -= ps_dict1[key] data.append((key, increased_count)) data.sort(key=lambda x: -x[1]) labels = [d[0] for d in data] counts = [d[1] for d in data] title = \u0026#39;2020年%d月%d日全国新增确诊病例\u0026#39; % (m2, d2) draw_pie(m2, d2, labels, counts, title) get_pyecharts_pie(m2, d2, labels, counts, title) def get_pyecharts_pie(month, day, labels, counts, title): title += \u0026#39;-%d例\u0026#39; % (sum(counts)) c = ( Pie(init_opts=opts.InitOpts(width=\u0026#39;1200px\u0026#39;, height=\u0026#39;700px\u0026#39;)) .add( \u0026#34;\u0026#34;, [list(z) for z in zip(labels, counts)], radius=[\u0026#34;40%\u0026#34;, \u0026#34;80%\u0026#34;], center=[\u0026#39;50%\u0026#39;, \u0026#39;60%\u0026#39;], ) .set_global_opts( title_opts=opts.TitleOpts(title=title), legend_opts=opts.LegendOpts( orient=\u0026#34;vertical\u0026#34;, pos_top=\u0026#34;15%\u0026#34;, pos_left=\u0026#34;2%\u0026#34; ), ) .set_series_opts(label_opts=opts.LabelOpts(formatter=\u0026#34;{b}: {c}\u0026#34;)) ) root = \u0026#39;html-charts/%d%d\u0026#39; % (month, day) create_dir(root) c.render() c.render(\u0026#39;%s/%s.html\u0026#39; % (root, title)) return c def draw_tendency(month, day): dates = [\u0026#39;1-%d\u0026#39; % i for i in range(16, 30)] v0 = [4, 17, 59, 78, 92, 149, 131, 259, 444, 688, 769, 1771, 1459, 1576 ] v1 = [4, 17, 59, 77, 72, 105, 69, 105, 180, 323, 371, 1291, 840, 1032] c = ( Line() .add_xaxis(dates) .add_yaxis(\u0026#34;全国新增确诊病例\u0026#34;, v0, is_smooth=True, linestyle_opts=opts.LineStyleOpts(width=4, color=\u0026#39;#B44038\u0026#39;), itemstyle_opts=opts.ItemStyleOpts( color=\u0026#39;#B44038\u0026#39;, border_color=\u0026#34;#B44038\u0026#34;, border_width=5 )) .add_yaxis(\u0026#34;湖北新增确诊病例\u0026#34;, v1, is_smooth=True, linestyle_opts=opts.LineStyleOpts(width=2, color=\u0026#39;6FA0A7\u0026#39;), label_opts=opts.LabelOpts(position=\u0026#39;bottom\u0026#39;), itemstyle_opts=opts.ItemStyleOpts( color=\u0026#39;#6FA0A7\u0026#39;, border_color=\u0026#34;#6FA0A7\u0026#34;, border_width=3 )) .set_global_opts(title_opts=opts.TitleOpts(title=\u0026#34;\u0026#34;), yaxis_opts=opts.AxisOpts( type_=\u0026#34;log\u0026#34;, name=\u0026#34;y\u0026#34;, splitline_opts=opts.SplitLineOpts(is_show=True), is_scale=True, axisline_opts=opts.AxisLineOpts(is_show=False) ) ) ) c.render(\u0026#39;results/%d%d-新增病例趋势图.html\u0026#39; % (month, day)) return c def draw_map(month, day): labels, counts, title = get_province_status(month, day, None) c = ( Map() .add(\u0026#34;\u0026#34;, [list(z) for z in zip(labels, counts)], \u0026#34;china\u0026#34;) .set_global_opts( title_opts=opts.TitleOpts(title=\u0026#34;新型肺炎全国确诊病例\u0026#34;), visualmap_opts=opts.VisualMapOpts( pieces=[ {\u0026#39;min\u0026#39;: 1000, \u0026#39;color\u0026#39;: \u0026#39;#450704\u0026#39;}, {\u0026#39;max\u0026#39;: 999, \u0026#39;min\u0026#39;: 100, \u0026#39;color\u0026#39;: \u0026#39;#75140B\u0026#39;}, {\u0026#39;max\u0026#39;: 99, \u0026#39;min\u0026#39;: 10, \u0026#39;color\u0026#39;: \u0026#39;#AD2217\u0026#39;}, {\u0026#39;max\u0026#39;: 9, \u0026#39;min\u0026#39;: 1, \u0026#39;color\u0026#39;: \u0026#39;#DE605B\u0026#39;}, {\u0026#39;max\u0026#39;: 0, \u0026#39;color\u0026#39;: \u0026#39;#FFFEE7\u0026#39;}, ], is_piecewise=True ), ) ) c.render(\u0026#39;results/%d%d-疫情地图.html\u0026#39; % (month, day)) if __name__ == \u0026#39;__main__\u0026#39;: m, d = 1, 30 #get_html(m, d) #draw(m, d) #compare(1, 28, 1, 29) #show_province_status(m, d, \u0026#39;云南\u0026#39;) #show_province_status(m, d, None) draw_tendency(m, d) draw_map(m, d) 函数直接都放一个文件里面了，其实进行重构一下代码会更简洁一些\n","permalink":"https://csqread.top/posts/tech/2020-ncov%E7%88%AC%E8%99%AB%E7%BB%9F%E8%AE%A1/","summary":"刚开始我没想到用爬虫，就直接手创了一个字典\u0026hellip; 需要安装模块pyechart and pyechart-china-provinces-pypkg 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25","title":"2020 NCov爬虫统计"},{"content":"《拍电影时我在想的事》是戛纳电影节金棕榈奖得主是枝裕和历史8年，写下的首部自传性随笔集。是枝裕和在书中回顾三十余年的创作生涯，讲述每一部经典作品背后的传奇故事、缘起和理念，记录各个创作时期对电影的创作和思考，以及对世界和人生的看法。 其中不仅汇集了电影大师的哲思与灵光，更讲述了一位导演脚踏实地，从赊账拍片到斩获世界各大电影节奖项的励志旅程。《拍电影时我在想的事》在日本出版后，连续六次紧急加印，得到《朝日新闻》等各大媒体的高度评价，被盛赞到：哪怕再过100年，这本书也一定是作者的圣经，世界如此精彩，日常就很美丽，生命本身就是奇迹。是枝裕和打动世界的理由，都在这本书里。\n关于是枝裕和，大概是我在两年之前接触到的一位导演，那是因为室友推荐的一部电影《无人知晓》，看完之后感觉特别棒，就继续搜罗这他的电影资源，把他的电影大都看了一遍。其中不仅仅是无人知晓让我印象深刻，《如父如子》，《海街日记》，《比海更深》，《奇迹》都挺好看的。我就不一一剧透了，想看的话资源在页面最下面，是枝裕和蓝光合集。 关于他的这本书，看了之后发现其实是枝裕和开始的时候是拍纪录片起家的。那个时候和侯孝贤和杨德昌是同一个时代的导演。甚至是他俩的后来者。记得书中他说过，侯孝贤导演对他在电影上面也有过帮助呢。在开始的时候，是枝裕和使用分镜完成了他的处女作，幻之光，看了他画的分镜，挺有意思的，发现原来电影就是这样开始先是被简单的画出来的啊\n他的第一部电视纪录片的拍摄过程就他别传奇。采访自杀官员的遗孀，对方在一堆采访者中唯独接受是枝裕和的访问，其实是枝裕和也不知道为什么，事后她才道出原委：“你第一天来这里的时候，拘谨地坐在榻榻米上。当时的你，跟我丈夫和我相亲的样子特别像” 我讲述的电影语言，与以电影为母语的创作者所讲述的不同是带着电视口音的方言，也就是说，在语法上是不规范的。对电视的养育之情，我心怀感激，也坦率地承认自己“电视人”的身份。与此同时，我对目前所处的环境感到了某种责任。\n一些笔记： 关于分镜，他还曾被侯孝贤导演指出过： ‘知道被侯孝贤导演指出来，我才意识到自己“被分镜图绑住了手脚”’。 侯导来到日本参加东京电影节，见面时，他对我说：“技术很厉害，但是在拍摄之前，你早就画好了所有的分镜图吧？” “是的，画了，当时的我特别没有自信”我回答。 “不是应该看了演员的表演之后，才确定摄影机的位置吗？你以前是拍记录片的应该知道啊。”\n他对于虚构作品和纪录片的理解： “我一直认为，虚构作品要令观众‘沉醉’，而纪录片”则要让观众清醒。\n“比起有意义的死，不如去发现有意义却丰富的生”作为想法，这是正确的。但是从拍摄的电影来看，与带着这种意识拍摄面成的《花之舞者》相比，将生的实感通过细节表现出来的下一部电影《步履不停》，更明显地体现了这种价值观。\n电影并非空喊口号的东西，它是为了表达生命真实丰富的感受而1存在的。现在我正义这一点为目标而努力\n“在《无人知晓》中，我不想探讨谁对谁错的问题，也不想追究大人应该如何对待孩子，以及围绕孩子的法律应该如何修改等等。所谓的批判，教训和建议都不是我想讲的。我真正想做的是讲述孩子们的日常生活，以及在一旁观察他们，倾听他们的声音。这样一来，孩子们的话语就不再是独白，而是变成了对话。同样孩子们也通过双眼观察着我们”-（这应该是是枝裕和拍纪录片时养成的习惯）\n“我仍然要坚持这样来拍摄《无人知晓》，并非从单纯的黑与白的对立出发，而是从灰色的视角记录世界。没有纯粹的英雄或坏人只是如实的描述我们生活的这个由相对主义价值观构筑的世界”\n“明显的不同在于，在西方人看来，死亡始于生命的终结，也就是说生与死是两个对立的概念。但是在东方人（特别是日本人）看来，生与死是表里一本的，两者的关系甚至有点亲近。死亡未必始于生命的终结，死常常存在于圣的内部。这个观念一直以来都存在于我的思想中”\n“在欧洲，我反复被问到‘为什么您的作品中经常并不出现的死者，为什么不讲述死亡，而是常常讲述死后的世界’，我一直苦于如何回答，当时却不知不觉地说出了这样的答案：日本到某个时期为止，一直都有‘无颜面对祖先’地观念。日本没有绝对权威的神明，但是在日常生活中存在这一种伦理观：应该活得对得起死去的人。我也怀着这样的伦理观。因此在日本文化中的‘死者’代替了西方文化中的‘神’。死去的人并不是就这样离开了世间，而是从外部批判我们的生活，承担着伦理规范的作用1.也就是说，从故事外部批判我们的是死者，而站在故事内部承担这一角色的是孩子” -原来如父如子也是这样的观念啊\n对于死亡，是枝裕和所认为的与村上春树在《挪威的森林》中所写的几乎一模一样：“生常常存在与死的内部”。他们都认为，日本传统文化中一味看重“有意义的死”并非病态文化，没有实实在在生活过的实感，是无法去探讨死亡的意义的。这点和黑泽明在《梦》中所表现的也一样。死去的桃树化为桃树神，从外部批判着我们的生活。日本是一个泛灵的国家，万物皆有灵气，这一点在《千与千寻》，《幽灵公主》等宫崎骏的动漫中也可得以一窥。在《菊与刀》中更是系统的阐述了这一点。\n“游走在网络上的人为u什么普遍是右翼，或者是国家主义者？思考这个问题，会发现与他人缺乏紧密联系的人容易沉迷于网络世界，‘国家’这种概念轻轻松松就会将他们收编，成为他们内心唯一的价值观。在现代日本，所谓的地区共同体已经趋向崩溃，企业共同体随着终身雇佣制度一起消亡，家庭内的关系也越发越远。因此，如果没有可以代替共同体和家庭的事务、场所和价值观，将会有越来越多的人陷入虚幻的国家主义之中” 这么说来来我们人均陷入了虚幻的国家主义，难道因为天朝是家国情怀？\n一些想法： 看完这本书我知道了《无人知晓》是如何拍出来的，《小偷家族》是在表达什么。是枝裕和的电影观念可以这样表达：比起有意义的死，不如去发现无意义却丰富的生。\n电影并非高喊口号的东西，它就是为了表达生命真实丰富的感受而存在的。 有人问是枝裕和，在《无人知晓》中，作为导演你没有对电影中的人物进行道德上的审判，甚至没有指责抛弃孩子的母亲。是枝裕和是这样回答：\n电影不是用来审判人的，电影导演也不是法官。设计一个坏蛋可能会让故事（世界）更易于理解，但是不这样做，反而能让观众将电影中的问题带入日常生活中去思考。 因为观众是要回归日常生活的，每一个观众都要在电影结束后离开电影院。如果一个观众能够看完电影之后，对生活的看法会有所改变，这或许会成为他们带着批判性的视角观察日常生活的契机。\n是的，我喜欢这样的电影哲学，所谓的批判留给其他人，电影只带给观众真实生活的感受。杨德昌说：电影发明之后，人类的生命，比以前延长了三倍。而在观看好莱坞大片时，我们的生活近乎暂停了两个小时。但在观看这种电影时，我们并没有离开生活。所有的电影观众，无一例外的都要在电影散场之后，必须回到他们的日常生活。是枝裕和就这样影响了我们的生活，像他所说 “如果说我的电影中更有共通的东西，那就是无法取代的珍贵之物不在日常生活之外，而是蕴藏在日常生活的细枝末节里”\n是枝裕和合集： 链接：https://pan.baidu.com/s/1dUz8weNnzyc9s3zpKUCO_Q 提取码：janz\n","permalink":"https://csqread.top/posts/read/%E6%88%91%E5%9C%A8%E6%8B%8D%E7%94%B5%E5%BD%B1%E6%97%B6%E6%83%B3%E7%9A%84%E4%BA%8B-%E6%98%AF%E6%9E%9D%E8%A3%95%E5%92%8C/","summary":"《拍电影时我在想的事》是戛纳电影节金棕榈奖得主是枝裕和历史8年，写下的首部自传性随笔集。是枝裕和在书中回顾三十余年的创作生涯，讲述每一部经典","title":"‘我在拍电影时想的事‘ 是枝裕和"},{"content":"上午两节课睡过了，就没去了，吃了个早饭，还有一堆事情没有做，就开始先把昨晚没弄完的python词频分析的代码给写完了。做一个记录吧，防止以后用得着\n工具 工具：python3.7 Vscode wordcloud jieba 等 获取数据源 点击Tim左上角头像 要用txt导出到任意盘，接下来就是要对导出的文件进行数据分析\n下载对应库 到官方网站下载对应包 传送门 重要提醒：通过cmd中输入 Python -V 来查看python版本并下载相应的安装包，同时注意python是32位的还是64位的，我这里是32位的 下载完成后，进入刚刚下载该文件的路径，使用pip3 install wordcloud-1.3.3-cp-37-cp-37-win_amd32-whl命令开始安装， 这样 wordcloud就安装完成了。 接下来还要安装jieba matplotlib scipy 均使用 pip3 install xxx 即可 代码 首先过滤掉txt文件中无用的信息，比如时间，以及聊天的名片，避免词云中都是无效信息，并用jieba进行分词 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import jieba newtext = [] # 打开E盘下的聊天记录文件qq.txt for word in open(\u0026#39;E:\\\\qq.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;): tmp = word[0:4] if (tmp == \u0026#34;2017\u0026#34; or tmp == \u0026#34;====\u0026#34;or tmp == \u0026#34;2018\u0026#34;): # 过滤掉聊天记录的时间和qq名称 continue tmp = word[0:2] if (tmp[0] == \u0026#39;[\u0026#39; or tmp[0] == \u0026#39;/\u0026#39;or tmp[0] == \u0026#39;@\u0026#39;): # 过滤掉图片和表情，例如[图片]，/滑稽 continue newtext.append(word) # 将过滤掉图片和表情和时间信息和qq名称剩下的文字重新写入E盘下的q1.txt文件中去 with open(\u0026#39;E:\\\\q1.txt\u0026#39;, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: for i in newtext: f.write(i) # 打开新生成的聊天记录文件 text = open(\u0026#39;E:\\\\q1.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;).read() word_jieba = jieba.cut(text, cut_all=True) word_split = \u0026#34; \u0026#34;.join(word_jieba) 通过这步在E盘中得到了一个q1.txt文件，打开会发现变的整洁干净了许多.\n2.再新建一个.py文件，用到wordcloud库来绘制词云图\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator import matplotlib.pyplot as plt from scipy.misc import imread text = open(\u0026#39;E:\\\\q1.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;).read() # 打开过滤好的txt文件 print(text) bg_pic = imread(\u0026#39;E:\\\\sjt.jpg\u0026#39;) # 导入词云背景 wordcloud = WordCloud(mask=bg_pic, background_color=\u0026#39;white\u0026#39;, scale=1.5, font_path=\u0026#39;C:/Windows/Fonts/simhei.ttf\u0026#39;, width=1000,height=600,stopwords={\u0026#39;表情\u0026#39;,\u0026#39;糊脸\u0026#39;,\u0026#39;拍桌\u0026#39;,\u0026#39;拍头\u0026#39;},min_font_size=10,max_font_size=36,font_step=4, ).generate(text) # 定义词云的各种变量，可以控制词云的形式，这里的控制变量可以去网上查找，stopwords={\u0026#39;表情\u0026#39;,\u0026#39;糊脸\u0026#39;,\u0026#39;拍桌\u0026#39;,\u0026#39;拍头\u0026#39;\u0026#39;是为了过滤掉里面的部分表情信息 image_colors = ImageColorGenerator(bg_pic) plt.imshow(wordcloud) plt.axis(\u0026#39;off\u0026#39;) plt.show() wordcloud.to_file(\u0026#39;E:\\\\text.jpg\u0026#39;) # 输出词云 做出的结果图\n挺好玩的，就多测试了几个群，就这样\n对词频出现次数进行统计，并生成统计表 直接上代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import jieba fr=open(\u0026#39;q1.txt\u0026#39;,\u0026#39;r\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;) //打开上面经过分词后的txt文件 s=\u0026#34;\u0026#34; data={} for line in fr: line=line.strip() if len(line)==0: continue if line[0]==\u0026#39;2\u0026#39;: continue for x in range(0,len(line)): if line[x] in [\u0026#39; \u0026#39;,\u0026#39;\\t\u0026#39;,\u0026#39;\\n\u0026#39;,\u0026#39;。\u0026#39;,\u0026#39;，\u0026#39;,\u0026#39;[\u0026#39;, \u0026#39;]\u0026#39;, \u0026#39;（\u0026#39;, \u0026#39;）\u0026#39;, \u0026#39;:\u0026#39;, \u0026#39;-\u0026#39;, \u0026#39;？\u0026#39;, \u0026#39;！\u0026#39;, \u0026#39;《\u0026#39;, \u0026#39;》\u0026#39;, \u0026#39;、\u0026#39;, \u0026#39;；\u0026#39;, \u0026#39;“\u0026#39;, \u0026#39;”\u0026#39;, \u0026#39;……\u0026#39;,\u0026#39;0\u0026#39;,\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;,\u0026#39;6\u0026#39;,\u0026#39;7\u0026#39;,\u0026#39;8\u0026#39;,\u0026#39;9\u0026#39;,\u0026#39;=\u0026#39;,\u0026#39;~\u0026#39;,\u0026#39;…\u0026#39;]: //去除一些不希望被统计的东西 continue s+=str(line[x]) print(s) seg_list = jieba.cut(s, cut_all=False, HMM=True) for word in seg_list: if len(word)\u0026gt;=2: if not data.__contains__(word): data[word]=0 data[word]+=1 data=sorted(data.items(),key=lambda d:d[1],reverse=True) fw=open(\u0026#39;安工程失物招领群1词频统计.csv\u0026#39;,\u0026#39;w\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;) //生成词频统计表 fw.write(str(len(data))+\u0026#39;\\n\u0026#39;) for item in data: fw.write(item[0]+\u0026#39;,\u0026#39;+str(item[1])+\u0026#39;\\n\u0026#39;) fr.close() fw.close() 这段代码结合上面分词的代码，即可生成统计表，近期来群里关键字出现的字眼一目了然 失物招领群1词频统计 谢谢的次数即代表我们一个月发过的消息总数，因为我们要求每条消息后面必须加个谢谢 由图可见，我们一个月发了1910条消息 其中校园卡类876条 寻物消息585条 失物消息526条 身份证消息41条 等等\n","permalink":"https://csqread.top/posts/tech/python%E5%AF%B9%E5%A4%B1%E7%89%A9%E6%8B%9B%E9%A2%86%E7%BE%A4%E8%BF%9B%E8%A1%8C%E8%AF%8D%E9%A2%91%E5%88%86%E6%9E%90/","summary":"上午两节课睡过了，就没去了，吃了个早饭，还有一堆事情没有做，就开始先把昨晚没弄完的python词频分析的代码给写完了。做一个记录吧，防止以后","title":"Python对失物招领群进行词频分析"},{"content":"“可是为什么要禁掉呢？”野人问道。遇见一位读过莎士比亚的人，使他一时忘了形。 元首耸耸肩膀：“”因为这本书太旧了，这是主要原因。旧东西在我们这儿是毫无用处的。 “即使他们是美好的？” “特别因为他们是美好的。美好便有吸引力了，而我们不要人们被旧的东西吸引。我们要他们喜欢新的。” “可是新的东西确是那么的愚昧和可怕。那些戏剧，空洞无物，只有直升机飞来飞去，而你感受到人家再接吻”他蹙眉颦额，“一群山羊和猴子！”只有《奥赛罗》里的字句才能适切地表达他的轻蔑和憎恨。 “然而是驯养好的好兽呢。”元首低声插嘴。 “你为什么不换成《奥赛罗》给他们看呢？” “我告诉过你了，那个旧了。此外，它们不可能懂得。” 对，这是真话。他记起汉姆赫兹怎样地嘲笑《罗密欧与朱丽叶》。“好吧，那么，”他停顿了一下，“一些像《奥赛罗》地新东西，他们能懂得东西” “那正是我们一直在写的”，汉姆赫兹打破了长时间的沉默说道。 “而那也正是你永远写不出来的。”元首说，“因为，如果那真的像《奥赛罗》，无论怎么新也不会有人懂得。而如果是新的就不可能像《奥赛罗》。” “为什么不可能？” “因为我们的世界不像奥赛罗的世界。没有钢铁你就造不出汽车，同理，没有不安定的社会你就造不出悲剧。今天的世界是安定的。人们很快乐，他们要什么就会得到什么，而他们永远不会要他们得不到的。”\n后面的这些对话确实发人深省\n2503年，一个婴儿养育室里。护士们在地板上摆了一堆图书和鲜花，然后把一群长得一摸一样的、8个月大的婴儿放到了地板上。婴儿们看到图书和鲜花，飞快地爬过去，拿起来玩耍。这时候，长官一声令下，护士长启动电路装置，一时间，刺耳的警报响起，地板被通上了电，触电的婴儿们在痛苦中痉挛并尖叫不已。过了一会儿，护士长关上了电闸。 “这样的试验大约重复200次左右，”长官微笑着对参观者说：“这些孩子们就会对图书和花朵形成本能的憎恨，他们的条件反射就这样被限定了。” “限定”，大约是《Brave New World》一书中的最关键词汇。在Aldous Huxley笔下的那个美好盛世里，人从受精开始就被“限定”了。精子和卵子在试管里被调制好，不健康的胚胎被“限定”出局，健康胎儿在孵化器里大。然后从婴儿养育室开始，孩子们一路被“限定”得厌恶书籍和自然、厌恶独处、厌恶家庭、厌恶宗教和艺术，同时被“限定”得热爱集体、热爱消费、热爱滥交。 当然，并不是所有的人被限定的方式都一样。美好新世界里，人类被分成了五级，Alpha、Beta、Gamma、Delta以及Epsilon——Alpha被限定得聪明漂亮，而Gamma以下的人不但被限定得矮小愚钝，还批量生产。不过 没关系，虽然在那个世界里人有等级贵贱，但是他们都一样幸福——因为无论哪个等级，其接受的“睡梦教育”都会告诉他，他所在的等级最美好最幸运。 这样的世界，有什么问题吗？ 美好新世界的首长Mustapha，问质疑者“野人”John。 有什么人类跋山涉水追求了几千年的东西，新世界里没有呢？经济发展？新世界里如此富足，上至Alphas下至Epsilons，人们不愁吃穿。健康？生物学家们早就把人类限定得不再有疾病。青春？这里人们青春永驻，直到突然死亡。美女帅哥的青睐？这个更不用担心，因为新世界里“每个人都属于他人”，滥交是最大的美德，你要是长期只跟一个美女上床，会成为该世界里骇人的丑闻。 不错，这个世界里没有艺术、诗歌、撕心裂肺的爱情、没有毕加索或者莎士比亚，但是，当你每天都幸福得晕眩时，为什么还会需要毕加索或者莎士比亚？文学艺术往往是为了表达冲突超越痛苦，那么，在一个冲突和痛苦根本不存在的世界里，文学艺术也就变成了社会的阑尾。更不要说“爱情”，那简直是高速公路上突然蹦出来的一头羚羊，如此危险，通通地，限定了之。 所以，这样的世界，有什么问题吗？ 柏拉图估计不会觉得有什么问题，因为新世界里政治家和科学家就是智慧非凡的哲学王。老子估计也不会觉得有什么问题，“劳心者治人，劳力者治于人”在这个桃花源里被充分实施。希特勒更是会欣喜若狂，因为将人类的未来当作一个巨大的生物工程来建设，简直是他的毕生追求。还有斯大林，荡漾在新世界人们脸上的微笑，与沉浸在丰收喜悦里的社会主义农民如出一辙，而新世界的“睡梦教育”，简直可以说是对苏式灌输教育赤裸裸的抄袭。所有那些信奉“精英治国”、信奉“稳定高于一切”、信奉“老百姓无非就是关心吃饱穿暖”的人，都会是“美好新世界”的热情粉丝。 这个新世界如此美好，它只有一个小小的缺陷——在那里，幸福的人们全都是“被幸福”的。 就是说，在那里，人们的幸福是政治家和科学家呕心沥血的科研成果，与每个个体自己的创造力、情感体验能力、审美能力都毫无关系。 民众只需像儿童那样，系上围兜，张口吞下哲学王或者先锋队一勺一勺送过来的食物，就乘坐直升电梯抵达了极乐世界。而精英们为了民众，制作食物既考虑营养，又考虑消化，可以说是殚精竭虑。有如此鞠躬尽瘁的统治者，民众的个体自由意志完全是多此一举。 如果说奥威尔的《1984》里，人们为失去自由而痛苦，那么Huxley的《勇敢新世界》里，人们则为摆脱了自由的重负而狂喜。真的，如果政治家科学家给民众带来如此丰盛的快乐，民众何必要自己去斗争？就像如果你可以从父亲那里继承一大笔遗产，何必要自己去辛苦挣钱？除非—— 你认为得到的过程比得到本身更有意义。除非你不识抬举地认为，通过个体努力去争取幸福比“被幸福”更体现生命的价值。 也正是在这个意义上，我在一切精英治国观里读到的是对生命的藐视。当统治者的恩赐被视为民众幸福的源泉时，统治者越高大，民众就越渺小。对有些人来说，幸福如此简单，无非是对着送过来的汤勺不断张嘴，而对另一些人来说，它如此复杂，需要汗滴禾下土粒粒皆辛苦。由于运气和能力，也许耕耘未必能带来收获，但是恩赐来的幸福和捕猎来的痛苦之间，你选什么呢？在幸福药丸soma和跌宕起伏的莎士比亚之间，野人John选择了莎士比亚。但是当然，对于美好新世界里的绝大多数人，这根本不是一个问题。他们从来没有选择的权利，无处不在的幸福不由分说，一把把他们给罩住，他们只能躺在幸福的牙缝里，被咀嚼，然后变成一堆残渣，被气势磅礴地给吐出来。\n","permalink":"https://csqread.top/posts/read/%E7%BE%8E%E4%B8%BD%E6%96%B0%E4%B8%96%E7%95%8C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","summary":"“可是为什么要禁掉呢？”野人问道。遇见一位读过莎士比亚的人，使他一时忘了形。 元首耸耸肩膀：“”因为这本书太旧了，这是主要原因。旧东西在我们这","title":"《美丽新世界》读书笔记"},{"content":"一直以来，我在想做一个qq机器人，能够实现qq消息的转发，因为对于失物招领工作，其他的都挺满意的，但每天发那么多消息确实很浪费时间，所以就想做一个能够实现自动转发消息的机器人。对于这个需求如何实现，我也构思了很久。这个想法是大二下学期就有的，但一直没有去实现。暑假的时候在家中自学了前端，准备做好一个失物招领网站，但那又是一个半吊子项目，网站并没有完全达到我想要的那种结果。现在来做一个博客，来详细说明我的机器人是如何实现的：\n在gooogle的时候，发现了一个很好的框架，一位github大佬写的qqbot框架。于是乎我们只需要调用他的api，以及他的框架来实现我们所想要的需求就可以了。当然，这是需要用python来实现的，所以需要会一些python的基础语法。\n下面介绍github这位大佬的qqbot框架：\n一、介绍 qqbot 是一个用 python 实现的、基于腾讯 SmartQQ 协议的 QQ 机器人，可运行在 Linux, Windows 和 Mac OSX 平台下。 本项目 github 地址： https://github.com/pandolia/qqbot\n你可以通过扩展 qqbot 来实现：\n监控、收集 QQ 消息 自动消息推送 聊天机器人 通过 QQ 远程控制你的设备\n二、安装方法 在 Python 2.7/3.4+ 下使用，用 pip 安装： pip install qqbot 或者下载 源码 解压后 cd 到该目录并运行： pip install.\n三、使用方法 1. 启动 QQBot 在命令行输入： qqbot ，即可启动一个 QQBot 。 启动过程中会自动弹出二维码图片，需要用手机 QQ 客户端扫码并授权登录。启动成功后，会将本次登录信息保存到本地文件中，下次启动时，可以输入： qqbot -q qq号码 ，先尝试从本地文件中恢复登录信息（不需要手动扫码），只有恢复不成功或登录信息已过期时才会需要手动扫码登录。一般来说，保存的登录信息将在 2 天之后过期。\n注意： Linux 下，需要系统中有 gvfs-open 或者 shotwell 命令才能自动弹出二维码图片（一般安装有 GNOME 虚拟文件系统 gvfs 的系统中都会含这两个命令之一）。 Windows10 下，需要系统中已设置了 png 图片文件的默认打开程序才能自动弹出二维码图片。\n若系统无法自动弹出二维码图片，可以手动打开图片文件进行扫码，也可以将二维码显示模式设置为 邮箱模式 、 服务器模式 或 文本模式 进行扫码，详见本文档的第七节。\n操作 QQBot QQBot 启动后，在另一个控制台窗口使用 qq 命令操作 QQBot ，目前提供以下命令： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 1） 帮助、停机和重启命令 qq help|stop|restart|fresh-restart 2） 联系人查询、搜索命令 qq list buddy|group|discuss [$cinfo|$clike] ( $cinfo --\u0026gt; $qq|$name|$key=$val ) ( $clike --\u0026gt; :like:$qq|:like:$name|$key:like:$name ) qq list group-member|discuss-member $oinfo|$olike [$cinfo|$clike] ( $oinfo --\u0026gt; $oqq|$oname|$okey=$oval ) ( $cinfo --\u0026gt; $qq|$name|$key=$val ) ( $olike --\u0026gt; :like:$oqq|:like:$oname|$okey:like:$oname ) ( $clike --\u0026gt; :like:$qq|:like:$name|$key:like:$name ) 3） 联系人更新命令 qq update buddy|group|discuss qq update group-member|discuss-member $ginfo 4） 消息发送命令 qq send buddy|group|discuss $rinfo $message 5） 加载/卸载/显示插件 qq plug/unplug myplugin qq plugins list 命令提供强大的联系人查询和搜索功能，用法示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 列出所有好友 qq list buddy # 列出 名称 为 xxx 的群 qq list group xxx # 列出备注名为 jack 的好友 qq list buddy mark=jack # 列出 群“456班” 的所有成员 qq list group-member 456班 # 列出 群“456班” 中名片为 “mike” 的成员 qq list group-member 456班 card=mike # 列出 讨论组“XX小组” 中名为 jack 的好友 qq list discuss-member XX小组 jack 其中第三、四个参数如果是 key=val 的格式，则应为 name=xx|nick=xx|mark=xx|card=xx|qq=xx 的格式，如果不是 key=val 的格式，则按以下原则进行处理：若是一串数字，则按 QQ 号进行查询，否则，按名称进行查询。\n如果存在重名现象，会列出所有重名的联系人。如：\n1 qq list group 机器人测试 将列出所有名为 “机器人测试” 的群。\n如果在 list 命令的第三、四个参数中加入 “:like:” ，则会按部分匹配的模式进行搜索，用法示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 列出名称中含有 “李” 的好友 qq list buddy :like:李 # 列出 QQ 中含有 “234” 的群 qq list group :like:234 # 列出备注名中含有 jack 的好友 qq list buddy mark:like:jack # 列出 群“456班” 的中名称中含有 “李” 的成员 qq list group-member 456班 :like:李 # 列出 群“456班” 中名片中含有 “mike” 的成员 qq list group-member 456班 card:like:mike # 列出的 讨论组“xx小组” 中名为 jack 的好友 qq list discuss-member :like:小组 jack 从 v2.2.5 版开始， list 命令采用表格的形式输出联系人列表，其输出样式示例如下：\n为保证表格在终端中的显示效果，建议将终端的输出字体设置为 consolas 、且每行可打印的最大字符数大于 120 。另外需要注意：为保证表格的显示效果，当联系人的名称、名片等属性的长度太长或含有特殊字符时，将对这些属性进行截断或过滤后再输出至终端。\nupdate 命令更新指定的联系人列表，其参数含义和 list 命令相同，如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 更新好友列表 qq update buddy # 更新群列表 qq update group # 更新 群“456班” 的成员列表 qq update group-member 456班 send 命令中第三个参数和 list 命令中的第三个参数格式一致。要注意，如果有重名现象，会给所有重名的联系人发信息。 另外要注意，第二个参数只能是 buddy/group/discuss ，不能是 group-member/discuss-member 。示例： # 给 好友“jack” 发消息 “你好” qq send buddy jack 你好 # 给 群“198班” 发消息 “大家好” qq send group 198班 大家好 # 给 QQ 为 12345 的好友发消息 qq send buddy 12345 xxx # 给讨论组发消息 qq send discuss MyDiscuss hello 可以在消息内容中嵌入“/可爱”等表情关键词来向对方发送表情，详见 facemap.py。还可以在消息内容中使用 \\n,\\t 这两个转义字符（如： send buddy jack 第一行\\n第二行）。\n以上所有命令都提供对应的 HTTP API 接口，供 web 前端开发者调用，接口的 url 地址为 http://127.0.0.1:8188/{command} ，只需要将 qq 后面的命令各参数用 \u0026ldquo;/\u0026rdquo; 分隔开替换 url 中的 command 就可以了，如: http://127.0.0.1:8188/send/buddy/jack/hello ，其他示例详见 urltestbot.md 。注意：如果命令中含有中文或特殊字符，需要先进行 url 编码（ utf8 ），例如，调用 http://127.0.0.1:8188/send/buddy/jack/nihao%20%E4%BD%A0%E5%A5%BD%20wohao 将发送消息 ”nihao 你好 wohao“ 。（提示：在 JavaScript 中，可以使用 encodeURIComponent 函数进行编码）。\n另外， QQBot 启动后，用本 QQ 号在其他客户端（如：手机 QQ ）上向某个 群/讨论组 发消息 “\u0026ndash;version” ，则 QQBot 会自动在该 群/讨论组 回复： “QQBot-v2.x.x” 。\n四、实现你自己的 QQ 机器人 实现自己的 QQ 机器人非常简单，只需要定义一个自己的消息响应函数并按插件加载。示例代码： ``` # -*- coding: utf-8 -*- def onQQMessage(bot, contact, member, content): if content == \u0026lsquo;-hello\u0026rsquo;: bot.SendTo(contact, \u0026lsquo;你好，我是QQ机器人\u0026rsquo;) elif content == \u0026lsquo;-stop\u0026rsquo;: bot.SendTo(contact, \u0026lsquo;QQ机器人已关闭\u0026rsquo;) bot.Stop()\n1 2 3 4 5 6 7 8 9 注意，上面注册的响应函数的函数名必须为 “onQQMessage” ，函数参数也必须和上面的一致。 将以上代码另存为 sample.py （注意保存为 utf8 编码的文件）。放到 ~/.qqbot-tmp/plugins/ 目录下（ ~ 代表用户主目录， win7 下为 C:\\Users\\xxx ），或系统中可以 import 到的目录下（如 python 的安装目录下的 Lib/site-packages 目录）。 之后，保持前面的 qqbot 进程运行，在另一个控制台输入 qq plug sample ，则可将此文件中的 onQQMessage 函数注册到 QQBot 的相应事件上去。此时，用另外一个 QQ 向本 QQ 发送消息 “-hello”，则会自动回复 “你好，我是 QQ 机器人”，发送消息 “-stop” 则会关闭 QQ 机器人。 在控制台输入 qq unplug sample 可以卸载此插件及相应的回调函数。可以同时加载多个插件，此时各插件中的相应函数会依次被调用（但调用顺序和加载次序无关）。 QQBot 开始运行后，每收到一条 QQ 消息，会将消息来源、消息内容以及一个 QQBot 对象传递给已注册的消息响应函数。其中： bot : QQBot 对象，提供 List/SendTo/Stop/Restart 等接口，详见本文档第五节 contact : QContact 对象，消息的发送者，具有 ctype/qq/uin/nick/mark/card/name 等属性 member : QContact 对象，仅当本消息为 群消息或讨论组消息 时有效，代表实际发消息的成员 content : str 对象，消息内容 contact 代表消息发送者，其 ctype 属性可以为 buddy/group/discuss ，代表 好友/群/讨论组 对象，表示本消息是 好友消息/群消息/讨论组消息 。\n1 2 3 4 5 6 7 8 9 10 11 12 member 仅当本消息为 群消息或讨论组消息 时有效，代表实际发消息的成员，它的 ctype 属性可以为 group-member/discuss-member ，代表 群成员/讨论组成员 对象。当本消息为 好友消息 时， member 等于 None 。 contact 和 member 都是 QContact 对象，不同类型的 QContact 对象所具有的属性含义见： qcontact-attr 。注意所有 QContact 对象都是 只读对象 ，只能读取它的属性，不能设置它的属性，也不能向它添加额外的属性。 可以调用 QQBot 对象的 SendTo 接口向 QContact 对象发送消息，但要注意：只可以向 好友/群/讨论组 发消息， 不可以向 群成员/讨论组成员 发送消息 。也就是说，只可以调用 bot.SendTo(contact, \u0026#39;xxx\u0026#39;) ， 不可以调用 bot.SendTo(member, \u0026#39;xxx\u0026#39;) 。 \u0026lt;h1\u0026gt;五、 QQBot 对象的公开接口和属性\u0026lt;/h1\u0026gt; QQBot 对象提供 List/Update/SendTo/Plug/Unplug/Login/Stop/Restart/FreshRestart 共计 9 个公开接口，这些接口的第一个字母都是大写的。另外，提供一个公开属性 conf 保存全局的配置信息。 一般情况下，请勿 调用/存取 此对象的其他 方法/属性 。特别的， 请勿在子线程中调用这些接口 。 以下介绍前 7 个接口和 conf 属性。 如果需要在 IDE 或 python-shell 中运行或测试以上接口，需要先关闭 qqbot 进程，并在 IDE 或 python-shell 中运行以下代码进行登录： from qqbot import _bot as bot bot.Login([\u0026rsquo;-q\u0026rsquo;, \u0026lsquo;1234\u0026rsquo;])\n1 2 3 4 5 6 （1） bot.List(tinfo, [cinfo]) --\u0026gt; [contact0, contact1, ..., ]/[]/None 对应本文档第三节的 list 命令。返回联系人对象（ QContact 对象）列表或者 None 。第一个参数 tinfo 是联系人列表的代号，第二个参数是可选的（和 list 命令的第三个参数格式一致）。 参数 tinfo 用来代表某个联系人列表，该参数在联系人的查询中非常重要，请务必理解以下两种情况 ： tinfo 的含义（情况1）： tinfo 可以为 buddy/group/discuss ，分别代表 好友列表/群列表/讨论组列表 。示例： 返回 好友列表： bot.List(\u0026lsquo;buddy\u0026rsquo;)\n返回名为 \u0026lsquo;jack\u0026rsquo; 的好友的列表： bot.List(\u0026lsquo;buddy\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;)\n返回 群列表： bot.List(\u0026lsquo;group\u0026rsquo;)\n返回名为 “机器人测试” 的群的列表： bot.List(\u0026lsquo;group\u0026rsquo;, \u0026lsquo;机器人测试\u0026rsquo;)\n1 tinfo 的含义（情况2）： tinfo 也可以是一个 ctype 等于 group/discuss 的 QContact 对象，代表该 群/讨论组 的成员列表。如以下第二句和第三句分别返回 群“456班” 的成员列表和该群中名片为 “jack” 的成员列表： g = bot.List(\u0026lsquo;group\u0026rsquo;, \u0026ldquo;456班\u0026rdquo;)[0] # g 是一个 Group 对象（群“456班”） bot.List(g) # 返回 群“456班” 的成员列表 bot.List(g, \u0026lsquo;card=jack\u0026rsquo;) # 返回 群“456班” 中名片为 “jack” 的成员列表 注意上面第三句不允许是 bot.List(g, card=\u0026lsquo;jack\u0026rsquo;) 的格式。\n1 2 3 4 5 6 7 List 接口的内部执行顺序： 首先在 QQBot 的联系人数据库内查找 tinfo 所代表的联系人列表；若数据库内已有此列表，则在此列表内进行搜索，并返回一个包含 “此列表中所有和 cinfo 匹配的联系人” 的列表；若数据库内没有此列表，则向 QQ 服务器请求数据获取联系人列表，获取成功后将联系人列表保存到数据库内，然后再进行搜索并返回一个包含 “此列表中所有和 cinfo 匹配的联系人” 的列表；如果在向 QQ 服务器请求数据的过程中出错了，则打印相关的失败信息，并返回 None 。 List 接口返回值的含义： 返回一个非空列表表示 tinfo 所指定的联系人列表内所有和 cinfo 匹配的联系人；返回一个空列表表示该联系人列表内没有和 cinfo 匹配的联系人；返回 None 表示向 QQ 服务器请求联系人列表和资料失败，不知道是否有相匹配的联系人。 调用 List 接口后， 务必 先根据以上三种情况对返回值进行判断，然后再执行后续代码。 注意： 当 List 接口返回非空列表时，列表内的元素是 QContact 对象，而不是 str 对象： g = bot.List(\u0026lsquo;group\u0026rsquo;)[0] # g 是一个 Group 对象 print([g, type(g), g.qq, g.name, g.uin, g.mark])\t# 打印 g 的各项属性\n1 2 3 4 5 6 7 8 不同类型的 QContact 对象所具有的属性含义见： qcontact-attr 。 （2） bot.Update(tinfo) --\u0026gt; True/False Update 接口的参数 tinfo 和 List 接口中的参数含义相同，调用此接口会立即向 QQ 服务器请求相应的联系人列表并更新联系人数据库，并一直阻塞至更新成功。更新最慢的是好友列表，若好友较多可能会阻塞 5 ~ 10 秒。成员列表更新的较快，即便是 2000 人的大群，更新时间仅 1 ~ 2 秒。 若更新成功，返回 True ，否则，返回 False 。 示例： 更新 好友列表 ： bot.Update(\u0026lsquo;buddy\u0026rsquo;)\n更新 群列表 ： bot.Update(\u0026lsquo;group\u0026rsquo;)\n更新 某个群的成员列表 ： gl = bot.List(\u0026lsquo;group\u0026rsquo;, \u0026ldquo;456班\u0026rdquo;) if gl: g = gl[0] bot.Update(g)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 （3） bot.SendTo(contact, content, resendOn1202=True) --\u0026gt; \u0026#39;向 xx 发消息成功\u0026#39;/\u0026#39;错误：...\u0026#39; 向联系人发送消息。第一个参数为 QContact 对象，第二个参数为消息内容。再次提醒： 只可以向 好友/群/讨论组 发消息， 不允许向 群成员/讨论组成员 发消息 。 可以在消息内容中嵌入“/微笑”等表情关键词来向对方发送表情，详见 facemap.py 。 若发送成功，返回字符串（向 xx 发消息成功）。否则，返回含错误原因的字符串（错误：...）。 发消息时可能会重复发消息，这是因为 QQ 服务器返回代码 1202 的原因。v2.1.17版已针对此问题在 bot.SendTo 接口中增加了一个参数： resendOn1202 ，若此参数为 True （默认值），则发消息时如果 QQ 服务器返回代码 1202 （表明发消息可能失败），还会继续发送 3 次，直至返回代码 0 ， 若此参数为 False ，则不会尝试重发。 设为 True 在绝大部分情况下能保证消息一定能发出去，但缺点是有时一条消息会重复发送。设为 False 则相反，消息不会重复发送，但有时消息发送不出去。 总之因为这个 1202 代码的不确定性，没有完美的解决办法。请根据各自的实际情况选择 resendOn1202 的值。 第一个参数 contact 必须是通过 bot.List 返回的 QContact 对象、或回调函数 onQQMessage 传递进来的第一个参数。示例： 向 昵称 为 jack 的好友发消息 bl = bot.List(\u0026lsquo;buddy\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;) if bl: b = bl[0] bot.SendTo(b, \u0026lsquo;hello\u0026rsquo;)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 （4） bot.conf bot.conf 中保存全局的配置信息，各项配置详见本文档第七节。如 bot.conf.termServerPort 保存 QQBot 命令行服务器的端口号， bot.conf.qq 保存本次登录的 QQ 号码。 注意： bot.conf 中保存的配置信息是只读的，请勿修改这些配置信息。 \u0026lt;h1\u0026gt;六、 注册回调函数、被他人 @ 的通知、判断是否是自己发的消息、定制定时任务\u0026lt;/h1\u0026gt; 注册回调函数 除了上面提到的 onQQMessage 响应函数，还可以注册 onInit/onQrcode/onStartupComplete/onInterval/onUpdate/onPlug/onUnplug/onExit 共计九种事件的回调函数，所有事件的回调函数参数格式、含义及示例详见 sampleslots.py 。 程序的运行流程以及各回调函数的调用时机如下： \u0026lt;img src=\u0026#34;define-my-qqbot/main.png\u0026#34;\u0026gt; 再次提醒：注册的回调函数的函数名以及函数参数（数量和名称）都不得更改 。 被群内其他成员 @ 的通知 QQBot 收到群消息时，会先根据消息内容判断是否有人 @ 自己。如果是，则在消息内容的开头加一个 [@ME] 的标记，再传递给 onQQMessage 函数；否则，将消息内容中的所有 @ME 替换成 @Me 再传给 onQQMessage 。因此，在 onQQMessage 函数内，只需要判断 content 内是否含有 @ME 就知道自己是否被消息发送者 @ 了。例如： def onQQMessage(bot, contact, member, content): if \u0026lsquo;@ME\u0026rsquo; in content: bot.SendTo(contact, member.name+\u0026rsquo;，艾特我干嘛呢？\u0026rsquo;)\n1 2 3 4 请注意，若群内有另一个成员的名字和自己的名字的开头部分相同（如：自己的名字是 ab ，另一个成员的名字是 abc ），那么当有人 @abc 时，也会误报成 @ME ，在这种情况下，需要修改自己的群名片，以免误报。 判断是否是自己发的消息 当本 QQ 发消息时， QQBot 也会收到一条同样的消息， bot 对象提供一个 isMe 方法来判断是否是自己发的消息： def onQQMessage(bot, contact, member, content): if bot.isMe(contact, member): print(\u0026lsquo;This is me\u0026rsquo;)\n1 2 定制定时任务 从 2.1.13 起， qqbot 提供一个功能强大的函数装饰器 -- qqbotsched 来定制定时任务，示例代码： from qqbot import qqbotsched\n@qqbotsched(hour=\u0026lsquo;11,17\u0026rsquo;, minute=\u0026lsquo;55\u0026rsquo;) def mytask(bot): gl = bot.List(\u0026lsquo;group\u0026rsquo;, \u0026lsquo;456班\u0026rsquo;) if gl is not None: for group in gl: bot.SendTo(group, \u0026lsquo;同志们：开饭啦啦啦啦啦啦！！！\u0026rsquo;)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 以上代码以插件形式加载后，每到 11:55 和 17:55 ，都会自动向 群“456班” 发送消息：“同志们：开饭啦啦啦啦啦啦！！！” 。 qqbotsched 装饰器接受 year, month, day, week, day_of_week, hour, minute, second, start_date, end_date, timezone 共计 11 个关键字参数，每个参数表示任务的定制时间的分量所应匹配的值。例如： hour=\u0026#39;11,17\u0026#39; 表示应在 11:xx 或 17:xx 执行任务， minute=\u0026#39;55\u0026#39; 表示应在 xx:55 执行任务， minute=\u0026#39;0-55/5\u0026#39; 表示应在 xx:00, xx:05, xx:10, ..., xx:55 执行任务， day_of_week=\u0026#39;mon-fri\u0026#39; （或 \u0026#39;0-4\u0026#39; ） 表示应在 星期一 ~ 星期五 执行任务。 qqbotsched 是对 Python 的定时任务框架 apscheduler 的简单封装，其各项参数应采用 Unix 系统中的 crontab 格式输入。有关 crontab 以及 Python 的定时任务框架 apscheduler 的内容可参见以下参考资料： https://code.tutsplus.com/tutorials/scheduling-tasks-with-cron-jobs--net-8800/ http://apscheduler.readthedocs.io/en/latest/userguide.html https://lz5z.com/Python定时任务的实现方式/ http://debugo.com/apscheduler/ crontab 各项参数格式说明详见： http://apscheduler.readthedocs.io/en/latest/modules/triggers/cron.html 注册回调函数和定制定时任务的注意事项 注册回调函数和定制定时任务是对 QQBot 进行扩展的唯一方式，在编写这些函数时，请注意以下事项： 回调函数的函数名、参数名、参数数量、参数顺序都不得更改 定时任务的函数名可以自己定义，但参数有且只有一个，参数名必须为 bot ，为一个 QQBot 对象。 所有回调函数和定时任务都将在主线程中被依次调用，因此不必担心全局变量的线程安全问题。 回调函数和定时任务的运行时间应尽量短，尽量不要再这些函数中进行阻塞式的操作，否则会阻塞整个程序的运行。一般来说，每个函数的运行时间在 5 秒以内是可以接受的。 绝对不要 在回调函数、定时任务或 qqbot 主线程的内部调用 os.system 执行 本 QQ 号对应的 qq 命令 （ 如 os.system(\u0026#39;qq send buddy jack hello\u0026#39;) ）或请求 本 QQ 号对应的 HTTP-API 接口 ，否则整个程序会形成死锁（因为 os.system 要等 qq 命令执行完成后才返回、而 qq 命令要等 os.system 返回后才会被执行）。请直接使用 bot 的 SendTo/List 等接口。 \u0026lt;h1\u0026gt;七、二维码管理器、QQBot 配置、命令行参数以及工作目录\u0026lt;/h1\u0026gt; 二维码的显示模式 WebQQ 登录时需要用手机 QQ 扫描二维码图片，在 QQBot 中，二维码图片可以通过以下四种模式显示： GUI模式： 在 GUI 界面中自动弹出二维码图片 邮箱模式： 将二维码图片发送到指定的邮箱 服务器模式： 在一个 HTTP 服务器中显示二维码图片 文本模式： 在 Term 中以文本形式展示二维码(需要自行安装 pillow 和 wcwidth 库) GUI 模式是默认的模式，只适用于个人电脑。邮箱模式可以适用于个人电脑和远程服务器。服务器模式一般只在有公网 ip 的系统中使用。如果使用 QQ 邮箱来接收二维码，则发送二维码图片之后，手机 QQ 客户端会立即收到通知，在手机 QQ 客户端上打开邮件，再长按二维码就可以扫描了。文本模式方便在开发过程或者服务器部署时使用，为开发者提供快捷方式登陆 QQ 。 注意：当开启了 邮箱模式/服务器模式/文本模式 时， GUI 模式是关闭的，登陆时不会自动弹出二维码图片。 每次登录时会创建一个二维码管理器 （ QrcodeManager 对象） ，二维码管理器会根据配置文件及命令行参数来选择二维码图片的显示方式。 配置文件的使用方法 配置文件为 ~/.qqbot-tmp/v2.x.conf （ ~ 代表用户主目录， win7 下为 C:\\Users\\xxx ， linux 下为 /home/xxx ），第一次运行 QQBot 后就会自动创建这个配置文件，其中内容如下： {\n# QQBot 的配置文件 # 使用 qqbot -u somebody 启动程序时，依次加载： # 根配置 -\u0026gt; 默认配置 -\u0026gt; 用户 somebody 的配置 -\u0026gt; 命令行参数配置 # 使用 qqbot 启动程序时，依次加载： # 根配置 -\u0026gt; 默认配置 -\u0026gt; 命令行参数配置 # 用户 somebody 的配置 \u0026quot;somebody\u0026quot; : { # QQBot-term （HTTP-API） 服务器端口号（该服务器监听 IP 为 127.0.0.1 ） # 设置为 0 则不会开启本服务器（此时 qq 命令和 HTTP-API 接口都无法使用）。 \u0026quot;termServerPort\u0026quot; : 8188, # 二维码 http 服务器 ip，请设置为公网 ip 或空字符串 \u0026quot;httpServerIP\u0026quot; : \u0026quot;\u0026quot;, # 二维码 http 服务器端口号 \u0026quot;httpServerPort\u0026quot; : 8189, # 自动登录的 QQ 号 \u0026quot;qq\u0026quot; : \u0026quot;3497303033\u0026quot;, # 接收二维码图片的邮箱账号 \u0026quot;mailAccount\u0026quot; : \u0026quot;3497303033@qq.com\u0026quot;, # 该邮箱的 IMAP/SMTP 服务授权码 \u0026quot;mailAuthCode\u0026quot; : \u0026quot;feregfgftrasdsew\u0026quot;, # 是否以文本模式显示二维码 \u0026quot;cmdQrcode\u0026quot; : False, # 显示/关闭调试信息 \u0026quot;debug\u0026quot; : False, # QQBot 掉线后自动重启 \u0026quot;restartOnOffline\u0026quot; : False, # 在后台运行 qqbot ( daemon 模式) \u0026quot;daemon\u0026quot;: False, # 完成全部联系人列表获取之后才启动 QQBot \u0026quot;startAfterFetch\u0026quot; : False, # 插件目录 \u0026quot;pluginPath\u0026quot; : \u0026quot;.\u0026quot;, # 启动时需加载的插件 \u0026quot;plugins\u0026quot; : [], # 插件的配置（由用户自定义） \u0026quot;pluginsConf\u0026quot; : {}, }, # 可以在 默认配置 中配置所有用户都通用的设置 \u0026quot;默认配置\u0026quot; : { \u0026quot;qq\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;pluginPath\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;plugins\u0026quot; : [ 'qqbot.plugins.sampleslots', 'qqbot.plugins.schedrestart', ], \u0026quot;pluginsConf\u0026quot; : { 'qqbot.plugins.schedrestart': '8:00', } }, # # 注意：根配置是固定的，用户无法修改（在本文件中修改根配置不会生效） # \u0026quot;根配置\u0026quot; : { # \u0026quot;termServerPort\u0026quot; : 8188, # \u0026quot;httpServerIP\u0026quot; : \u0026quot;\u0026quot;, # \u0026quot;httpServerPort\u0026quot; : 8189, # \u0026quot;qq\u0026quot; : \u0026quot;\u0026quot;, # \u0026quot;mailAccount\u0026quot; : \u0026quot;\u0026quot;, # \u0026quot;mailAuthCode\u0026quot; : \u0026quot;\u0026quot;, # \u0026quot;cmdQrcode\u0026quot; : False, # \u0026quot;debug\u0026quot; : False, # \u0026quot;restartOnOffline\u0026quot; : False, # \u0026quot;daemon\u0026quot; : False, # \u0026quot;startAfterFetch\u0026quot; : False, # \u0026quot;pluginPath\u0026quot; : \u0026quot;\u0026quot;, # \u0026quot;plugins\u0026quot; : [], # \u0026quot;pluginsConf\u0026quot; : {} # }, }\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 可以在配置文件中添加自己的用户配置（即在该文件的字典中新增一个 item ，此 item 的 key 就代表一个用户），例如，该文件中已有的 somebody 项目就代表名为 somebody 的用户，运行 QQBot 时，输入 qqbot -u somebody ，则会加载 somebody 项目下的各项配置。 下面介绍配置文件中各项配置的功能，以下内容均假定已修改了 somebody 下的配置，且以 qqbot -u somebody 的方式运行。 邮箱模式的配置（ mailAccount 和 mailAuthCode ） 如果需要使用邮箱模式显示二维码，可以将 mailAccount 和 mailAuthCode 项中分别设置为邮箱帐号和授权码，运行后，二维码管理器会将二维码图片发送至该邮箱。 注意：授权码不是邮箱的登录密码，而是邮箱服务商提供的开通 IMAP/SMTP 服务的授权码（提醒：不是 POP3/SMTP 服务）， QQ/网易 邮箱可以在网页版的邮箱设置里面开通此项服务，并得到授权码。如果只定义了 mailAccount 而没定义 mailAuthCode ，则程序运行的开始时会要求手工输入此授权码。 邮箱模式已在 QQ 、 网易 和 Google 邮箱中测试过。 服务器模式的配置（ httpServerIP 和 httpServerPort ） 如果需要使用服务器模式，可以配置 httpServerIP 和 httpServerPort 项，一般来说应该设置为公网 ip 。服务器模式开启后，可以通过 http://{httpServerIP}:{httpServerPort}/{any} 来访问二维码图片。其中 {any} 可以是任何非空的数字或字母串。 当邮箱模式和服务器模式同时开启时，发邮件时不会发送真正的图片，只会将图片地址发到邮箱中去，而且只发送一次，二维码过期时刷新一下邮件就可以了。如果只开启邮箱模式，则发邮件时会发送真正的图片，当二维码过期时，需要将邮件设置为已读（用手机 QQ 点开邮件后该邮件就是已读了），之后才会发送最新的二维码图片。 文本模式显示二维码（cmdQrcode） 若 cmdQrcode 项设置为 True ，则会在 term 中以文本模式显示二维码。注意：要使用文本模式，需要自行安装 pillow 和 wcwidth 库，可使用 pip 安装。 自动登录的 QQ 号码（ qq ） 配置文件中每个用户都有 qq 这一项，若此项已设置为某 QQ 号码，则 QQBot 在启动时会先使用此 QQ 号上次登录保存的登录信息来自动登录。 掉线后自动重启（ restartOnOffline ） 如果配置文件中将 restartOnOffline 项设置为 True ，则当 QQBot 掉线或出错终止时，会自动重新启动 QQBot 。 在后台运行 qqbot （ daemon ） 此选项仅在 UNIX 类系统中有效，将配置中的 daemon 选项设置为 True 则会以 daemon 模式运行程序。此时，标准输出和标准错误会重定向到 daemon-$qq.log 文件（其中 $qq 是配置中 qq 选项的值）。 联系人列表获取完成后再启动（ startAfterFetch ） 一般情况下，扫码登录完成就立即启动 QQBot，只有在需要的时候才会去获取联系人列表并更新联系人数据库。如果将配置文件中的 startAfterFetch 设置为 True ，则 QQBot 会等待所有联系人列表获取完成后才启动 ，注意，如果联系人较多，会耗费较长的时间。 QQBot-term 服务器端口号（ termServerPort ） QQBot 启动后，会开启一个 QQBot-term 服务器监听用户通过 qq 命令行工具发过来的操作命令以及通过 HTTP API 接口发过来的操作命令，此服务器的监听 IP 永远为 127.0.0.1 ，监听端口号默认为 8188 ，可以通过修改 termServerPort 的值来修改此端口号。 如果配置的 QQBot-term 服务器端口号不是默认的 8188 ，那么在运行 qq 命令时，需要在第一个参数中指定端口号，如： $ qq 8100 send buddy jack hello $ qq 8100 list group-member chatbot 同样，HTTP API 接口的端口号也需要改变，如： http://127.0.0.1:8100/send/buddy/jack/hello 。 如果不需要使用 qq 命令和 HTTP-API 接口，可以将此端口号设置为 0 ，此时 QQBot-term 服务器不会开启。 如果需要在同一台机器上登录多个 QQ 号码，可以直接在不同的终端中开启多个 qqbot 进程进行登录，但是，每个 qqbot 进程必须设置专有的 termServerPort 和 httpServerPort （或者全部设置为 0 或 空值 ），否则会造成端口号冲突。 调试模式（ debug ） 若 debug 项设置为 True ，则运行过程中会打印调试信息。 插件的配置（ pluginPath 和 plugins ） 一般情况下，插件需要存放在系统的 import 目录下或 ~/.qqbot-tmp/plugins 目录下，可以在 pluginPath 选项中配置其他的存放目录。另外，在 plugins 选项中可以指定 QQBot 启动时需要加载的插件。 命令行参数及配置的优先级 配置文件中的所有选项都有对应的命令行参数，在命令行参数中输入的选项优先级比配置文件高。输入 qqbot -h 可查看所有命令行参数格式。 程序一共有四个级别的配置，其优先级如下： 使用 qqbot -u somebody 启动程序时，依次加载： 根配置 -\u0026gt; 默认配置 -\u0026gt; 用户 somebody 的配置 -\u0026gt; 命令行参数配置 使用 qqbot 启动程序时，依次加载： 根配置 -\u0026gt; 默认配置 -\u0026gt; 命令行参数配置 其中：根配置 是固定的，用户无法修改； 默认配置 和 用户配置 可由用户在 v2.x.conf 文件中进行修改；最后，还可以在 命令行参数 中输入配置。 工作目录 qqbot 运行时，会在 工作目录 下 搜索/创建 以下 文件/目录 ： 配置文件： v2.x.conf 插件目录： plugins/ 登录文件： v2.x-pyx-xxxx.pickle 联系人数据库文件： 2017-05-06-20-03-12-xxxx-contact.db 临时二维码图片： xxxx.png 保存QQ的文件： qq(pid9816) 以 daemon 模式运行时的 log 文件： daemon-xxx.log 默认的工作目录为 ~/.qqbot-tmp/ ，可以在启动 qqbot 时通过命令行参数 -b|--bench 指定其他工作目录，例如： qqbot -b bench 。 \u0026lt;h1\u0026gt;八、 插件\u0026lt;/h1\u0026gt; 插件的存放位置 插件实际上是一个 python 模块，因此可以是一个 python 文件，也可以是一个 python package。 qqbot 会根据插件名在以下目录中搜索插件： 配置中的 pluginPath 选项（命令行参数 -pp|--pluginPath ）指定的目录 工作目录下的 plugins 目录 python 的导入目录 插件的加载/卸载 hot-plug 方式 可以在 qqbot 的运行过程中动态的加载/卸载插件，有以下三种方法： 利用 qq 命令行工具： qq plug pluginname 或 qq unplug pluginname 利用 http-api 接口： http://127.0.0.1:8188/plug/pluginname 或 http://127.0.0.1:8188/unplug/pluginname 利用 bot 对象的接口： bot.Plug(\u0026#39;pluginname\u0026#39;) 或 bot.Unplug(\u0026#39;pluginname\u0026#39;) 前面两种方法是供 qqbot 进程的外部进程调用的，第三种方法是在 qqbot 进程内部使用的。请勿在 qqbot 进程的内部使用前面两种方法。 注意：采用 hot-plug 方式加载的插件在 qqbot 重启后会丢失。 auto-plug-at-start 方式 也可以在 qqbot 的启动时自动加载插件，在配置中的 plugins 选项（命令行参数 -pl|--plugins ）中指定需要加载的插件名就可以了。这些插件将在启动时、登录之前被加载。 另外，如果系统中（或插件目录中）存在名为 qqbotdefault 的 package ，那么该 package 下面的所有子模块都会被当成插件在启动时自动加载（注意：qqbotdefault 本身不会作为插件加载）。 插件内的 onPlug 和 onUnplug 回调函数 插件被加载时，会执行 reload(pluginName) ，因此插件内的所有代码都会被执行一次 当采用 hot-plug 的方式加载时，插件内的 onPlug 函数会紧接在 reload 成功后被执行 当采用 auto-plug-at-start 方式加载时，插件在启动时、登录之前被加载，但插件内的 onPlug 函数会延迟到登录成功后才被执行 插件被卸载时，插件内的 onUnplug 被执行 插件的编写 编写插件主要就是编写回调函数或定时任务函数，详见 第四~六节 。 插件列表 名称\tgithub作者\t功能说明\t是否默认加载 qqbot.plugins.sampleslots\tpandolia\t回调函数示例\t是 qqbot.plugins.schedrestart\tpandolia\t定时重启\t是 qqbot.plugins.miniirc\tpandolia\tIRC服务器\t否 passwordlogin\tpandolia\t使用用户名-密码登录\t否 adblock\tfeisuweb\t群广告拦截\t否 chatlog\tfeisuweb\t聊天内容记录\t否 如果您有好用的插件分享，欢迎发邮件给我。 \u0026lt;h1\u0026gt;九、 命令行模式下使用 IRC 聊天\u0026lt;/h1\u0026gt; linux 系统下，由于无法使用 QQ 客户端，可以使用插件 qqbot.plugins.miniirc 来实现用 IRC 聊天的功能。加载方式： qq plug qqbot.plugins.miniirc ，或启动时加载： qqbot -pl qqbot.plugins.miniirc ，或者在配置文件中的 plugins 选项中加入 qqbot.plugins.miniirc 。 插件加载后将在 6667 端口开启一个微型的 IRC 服务器，用户可以使用 IRC 客户端（如 weechat, irssi 等）连接此服务器来实现命令行模式下的聊天。以下以 weechat 为例介绍使用方法： 启动 weechat ： weechat\n连接本服务器： /connect localhost\n进入 群聊天 会话： /join group-name\n进入 讨论组聊天 会话： /join !discuss-name\n进入 好友聊天 会话： /query buddy-name\n进入 聊天会话 后，直接敲入文本并回车就可以向对方发送消息了。所有接收到的 QQ 消息也会被转发给相应的 聊天会话 。\n在聊天会话之间切换： ctrl+P 或 ctrl+N\n显示所有 群和讨论组 的名称： /list\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 以上几乎就是此微型 IRC 服务器所提供的所有功能了，但已经足够用来和 QQ 好友/群/讨论组 聊天了。 \u0026lt;h1\u0026gt;十、 smartqq 协议支持及限制\u0026lt;/h1\u0026gt; 本项目已实现绝大部分 smartqq 协议支持的功能，如下： 消息收/发 联系人（包括 好友/群/讨论组/群成员/讨论组成员）资料获取和查询（包括 昵称/名称/备注名） 联系人资料根据需要动态更新 被群内其他成员 @ 的通知 发送、接收表情（详见 facemap.py） 可以获取到自身发送的 好友/群/讨论组 消息。但若是自身发送的 好友 消息，只能获取消息文本，无法知道该消息发送给谁。 其他功能： 调用系统默认图片浏览器显示登录二维码、将登录二维码发送至邮箱、开启一个 http 服务器用来显示登录二维码、在命令行窗口使用文本模式显示二维码 用 qq 命令行工具发消息、查询|更新联系人 提供 HTTP-API 接口发消息、查询|更新联系人 提供 miniirc 插件，可以在命令行模式下使用 IRC 客户端聊天 掉线后自动重启功能（有时需要手工扫码） 定时执行任务（通过 qqbotsched 实现） 因 smartqq 协议的限制，以下问题尚无完美的解决方法： 无法长时间保持在线状态，每次登录成功后的 cookie 会每在 1 ~ 2 天后失效，将被腾讯服务器强制下线，此时 必须 重新登录。可以打开邮箱模式和自动重启模式，并配合 qqbot.plugins.schedrestart 插件使用，每天在固定的时间 手工扫码 登录一次，基本上可以稳定的保持在线状态。 无法发送图片、文件、音频、 xml 卡片消息 无法获取到联系人的实际 QQ 无法在群内 @ 其他成员，即便用本程序在群里发送了 “@jack xxx” 这样的消息， jack 也只能收到这个纯文本，收不到“有人@我”的提醒。 无法向 群/讨论组 内的其他非好友成员发消息，也无法收到非好友成员发过来的临时会话消息 在非常少的情况下，发消息时会重复发送多次，也可能对方已收到消息但返回发送失败的结果 \u0026lt;h1\u0026gt;十一、其他\u0026lt;/h1\u0026gt; 常见问题 更新日志 \u0026lt;h1\u0026gt;十二、参考资料\u0026lt;/h1\u0026gt; QQBot 参考了以下开源项目： ScienJus/qqbot (ruby) floatinghotpot/qqbot (node.js) sjdy521/Mojo-Webqq (perl) 在此感谢以上三位作者的无私分享，特别是感谢 ScienJus 对 SmartQQ 协议所做出的深入细致的分析。 \u0026lt;h1\u0026gt;十三、反馈\u0026lt;/h1\u0026gt; 有任何问题或建议可以发邮件给我 pandolia@yeah.net ，或者直接提 issue ，也可以加 QQ 群： 577126408 。但还是希望您在提问之前通读一下本文档，很有可能您想要的答案已经在文档中了。 \u0026lt;h1\u0026gt;定制我想要的机器人\u0026lt;/h1\u0026gt; 根据这位大佬的框架，如何写一个自己的机器人呢？ 我开始是这样构思的，如何将机器人实现，如果他接收到一条失物消息，那么就将这条消息转发到我们失物招领三个群当中去，这是我们的用户需求。 我们现在来把它转换成系统需求： （1）机器人需要监控它所接收到的消息，判断是否是失物招领消息。 （2）如果是失物招领消息，那么把消息提取出来作为一个字符串发送到我所指定的三个群当中去。 嗯，大体上就是这个样子的，应该定义一个函数就能解决了。 一开始我写了这样的一个函数： from qqbot import qqbotsched def onQQMessage(bot,cntact,member,content): qian=bot.list(\u0026lsquo;buddy\u0026rsquo;,\u0026lsquo;不一\u0026rsquo;)[0] //将我qq号昵称检测到qian中 linux=bot.list(\u0026lsquo;group\u0026rsquo;,\u0026lsquo;驾校\u0026rsquo;)[0] //将我们寝室群放到linux中 windows=bot.list(\u0026lsquo;group\u0026rsquo;,\u0026lsquo;Ingress\u0026rsquo;)[0] //将另一个群放到windows中 if content from qian.name: //如果监测到消息中有我qq号的消息 bot.SendTo(linux,content) //那么将这条消息转发到指定的群\n1 2 但经过测试，这几行代码并没有什么用，然后我有做了一些修改： form qqbot import qqbotsched def onQQMessage(bot,cntact,member,content): linux=bot.List(\u0026lsquo;group\u0026rsquo;,\u0026lsquo;安工程失物招领群1\u0026rsquo;) windows=bot.List(\u0026lsquo;group\u0026rsquo;,\u0026lsquo;安工程失物招领群2\u0026rsquo;) deepin=bot.List(\u0026lsquo;group\u0026rsquo;,\u0026lsquo;安工程失物招领群3\u0026rsquo;) if \u0026lsquo;@ME\u0026rsquo; in content: bot.SendTo()\n1 2 3 就酱紫，就这么简单的几行代码。但是我却想了很久，看了很长时间的文档。 现在是深刻的理解到了。编程并不是写代码，思考和选择算法的过程才是最重要的！ ","permalink":"https://csqread.top/posts/tech/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%88%91%E7%9A%84qq%E6%9C%BA%E5%99%A8%E4%BA%BA/","summary":"一直以来，我在想做一个qq机器人，能够实现qq消息的转发，因为对于失物招领工作，其他的都挺满意的，但每天发那么多消息确实很浪费时间，所以就想","title":"自定义我的QQ机器人"}]